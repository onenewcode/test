{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 2, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 设置随机种子以便结果可复现\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 定义矩阵尺寸\n",
    "bsz = 16\n",
    "nt = 1\n",
    "kv_lora = 512\n",
    "\n",
    "# 随机生成两个矩阵\n",
    "matrix_a = torch.randn(bsz, nt,kv_lora)\n",
    "matrix_a =matrix_a.unsqueeze(-3)\n",
    "\n",
    "\n",
    "\n",
    "# 输出结果形状\n",
    "print(matrix_a.shape)\n",
    "\n",
    "# # 如果需要，可以将输出reshape回原始形状\n",
    "# output_reshaped = output.view(bsz, q_len, num_heads * nope_plus_rope)\n",
    "# print(output_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 定义矩阵尺寸\n",
    "nh = 16\n",
    "nt = 1\n",
    "nope=64\n",
    "kv_lora = 512\n",
    "\n",
    "# 随机生成两个矩阵\n",
    "matrix_a = torch.randn(nh, nt,nope)\n",
    "matrix_b =torch.randn(nh, nope,kv_lora)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 输出结果形状\n",
    "print(torch.matmul(matrix_a,matrix_b).shape)\n",
    "\n",
    "# # 如果需要，可以将输出reshape回原始形状\n",
    "# output_reshaped = output.view(bsz, q_len, num_heads * nope_plus_rope)\n",
    "# print(output_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 定义矩阵尺寸\n",
    "bsz=2\n",
    "nh = 16\n",
    "nt = 1\n",
    "nope=64\n",
    "kv_lora = 512\n",
    "\n",
    "# 随机生成两个矩阵\n",
    "matrix_a = torch.randn(bsz,nh, nt,nope)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 输出结果形状\n",
    "print(matrix_a.transpose(1,2).shape)\n",
    "\n",
    "# # 如果需要，可以将输出reshape回原始形状\n",
    "# output_reshaped = output.view(bsz, q_len, num_heads * nope_plus_rope)\n",
    "# print(output_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16])\n",
      "torch.Size([16])\n",
      "tensor([1.0000, 0.6494, 0.4217, 0.2738, 0.1778, 0.1155, 0.0750, 0.0487, 0.0316,\n",
      "        0.0205, 0.0133, 0.0087, 0.0056, 0.0037, 0.0024, 0.0015])\n",
      "tensor([[ 0.6389,  0.6242,  2.8704,  1.6577, -0.8475, -1.0394,  2.2760,  0.3400,\n",
      "         -2.2318,  0.5693, -2.0551, -2.3342, -6.0017, -0.5811, -0.6440,  2.9087],\n",
      "        [ 0.3583,  0.3500,  1.6096,  0.9296, -0.4752, -0.5829,  1.2764,  0.1907,\n",
      "         -1.2516,  0.3193, -1.1525, -1.3090, -3.3656, -0.3259, -0.3612,  1.6311],\n",
      "        [ 0.5299,  0.5178,  2.3810,  1.3751, -0.7030, -0.8622,  1.8880,  0.2821,\n",
      "         -1.8513,  0.4723, -1.7048, -1.9363, -4.9785, -0.4821, -0.5342,  2.4128],\n",
      "        [-0.1617, -0.1580, -0.7265, -0.4196,  0.2145,  0.2631, -0.5760, -0.0861,\n",
      "          0.5648, -0.1441,  0.5201,  0.5908,  1.5190,  0.1471,  0.1630, -0.7362],\n",
      "        [ 0.7609,  0.7434,  3.4188,  1.9745, -1.0094, -1.2380,  2.7109,  0.4050,\n",
      "         -2.6582,  0.6781, -2.4478, -2.7802, -7.1484, -0.6922, -0.7671,  3.4644]])\n",
      "tensor([[ 6.3886e-01,  4.0532e-01,  1.2104e+00,  4.5396e-01, -1.5070e-01,\n",
      "         -1.2003e-01,  1.7068e-01,  1.6559e-02, -7.0576e-02,  1.1691e-02,\n",
      "         -2.7405e-02, -2.0214e-02, -3.3750e-02, -2.1222e-03, -1.5273e-03,\n",
      "          4.4792e-03],\n",
      "        [ 3.5826e-01,  2.2729e-01,  6.7878e-01,  2.5457e-01, -8.4511e-02,\n",
      "         -6.7307e-02,  9.5713e-02,  9.2858e-03, -3.9578e-02,  6.5563e-03,\n",
      "         -1.5368e-02, -1.1335e-02, -1.8926e-02, -1.1901e-03, -8.5646e-04,\n",
      "          2.5118e-03],\n",
      "        [ 5.2995e-01,  3.3622e-01,  1.0041e+00,  3.7657e-01, -1.2501e-01,\n",
      "         -9.9563e-02,  1.4158e-01,  1.3736e-02, -5.8544e-02,  9.6982e-03,\n",
      "         -2.2733e-02, -1.6768e-02, -2.7996e-02, -1.7604e-03, -1.2669e-03,\n",
      "          3.7156e-03],\n",
      "        [-1.6169e-01, -1.0258e-01, -3.0635e-01, -1.1489e-01,  3.8142e-02,\n",
      "          3.0377e-02, -4.3197e-02, -4.1909e-03,  1.7862e-02, -2.9590e-03,\n",
      "          6.9360e-03,  5.1159e-03,  8.5418e-03,  5.3710e-04,  3.8654e-04,\n",
      "         -1.1336e-03],\n",
      "        [ 7.6092e-01,  4.8276e-01,  1.4417e+00,  5.4069e-01, -1.7950e-01,\n",
      "         -1.4296e-01,  2.0329e-01,  1.9722e-02, -8.4060e-02,  1.3925e-02,\n",
      "         -3.2641e-02, -2.4076e-02, -4.0198e-02, -2.5276e-03, -1.8191e-03,\n",
      "          5.3349e-03]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 定义矩阵尺寸\n",
    "ext_l=16\n",
    "t_l=5\n",
    "nh = 16\n",
    "nt = 1\n",
    "nope=64\n",
    "kv_lora = 512\n",
    "base=1000\n",
    "dim=32\n",
    "inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() /dim))\n",
    "# 随机生成两个矩阵\n",
    "ext_factors = torch.randn(ext_l)\n",
    "t= torch.randn(t_l)\n",
    "tmp= torch.outer(t, 1.0 / ext_factors)\n",
    "print(tmp.shape)\n",
    "print(inv_freq.shape)\n",
    "r=torch.mul(\n",
    "    tmp,\n",
    "    inv_freq\n",
    ")\n",
    "print(inv_freq)\n",
    "print(tmp)\n",
    "print(r)\n",
    "    # freqs = torch.mul(\n",
    "    #         # s*16\n",
    "           \n",
    "    #         self.inv_freq.to(device=device).to(dtype)\n",
    "    #     )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [8, 7, 6, 5, 4, 3, 2, 1]])\n",
      "\n",
      "After applying rotate_half:\n",
      "tensor([[-5, -6, -7, -8,  1,  2,  3,  4],\n",
      "        [-4, -3, -2, -1,  8,  7,  6,  5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个示例张量 x，形状为 (2, 8)\n",
    "x = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                  [8, 7, 6, 5, 4, 3, 2, 1]])\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "# 应用 rotate_half 函数到 x 上\n",
    "result = rotate_half(x)\n",
    "\n",
    "print(\"Original tensor:\")\n",
    "print(x)\n",
    "print(\"\\nAfter applying rotate_half:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6740787420000003\n"
     ]
    }
   ],
   "source": [
    "p=2.7943e-01*0.5864+3.0990e+00*8.1001e-01\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爱因斯坦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(2,3)\n",
    "b = torch.rand(3,4)\n",
    "c = torch.einsum(\"ik,kj->ij\", [a, b])\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设 b=2, h=3, q=4, l=5, c=6 作为例子\n",
    "b, h, q, l, c = 2, 3, 4, 5, 6\n",
    "\n",
    "# 创建示例张量\n",
    "attn_weights = torch.randn(b, h, q, l)\n",
    "compressed_kv = torch.randn(b, l, c)\n",
    "\n",
    "result=torch.einsum('bhql,blc->bhqc', attn_weights, compressed_kv)\n",
    "\n",
    "compressed_kv_expanded = compressed_kv.unsqueeze(1)  # 形状变为 [bsz, 1, nt, dkv_lora]\n",
    "\n",
    "# 执行批量矩阵乘法\n",
    "attn_output = torch.matmul(attn_weights, compressed_kv_expanded)  # 输出形状 [bsz, nh, nt,\n",
    "\n",
    "print(torch.equal(result,attn_output))  # 应该打印出 torch.Size([2, 3, 4, 6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

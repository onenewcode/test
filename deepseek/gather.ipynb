{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出显卡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "PyTorch version: 2.5.1\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Available GPUs: 1\n",
      "Current GPU: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU.\")\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Current GPU: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniCPM3ForCausalLM(\n",
      "  (model): MiniCPM3Model(\n",
      "    (embed_tokens): Embedding(73448, 2560)\n",
      "    (layers): ModuleList(\n",
      "      (0-61): 62 x MiniCPMDecoderLayer(\n",
      "        (self_attn): MiniCPMSdpaAttention(\n",
      "          (q_a_proj): Linear(in_features=2560, out_features=768, bias=False)\n",
      "          (q_a_layernorm): MiniCPMRMSNorm()\n",
      "          (q_b_proj): Linear(in_features=768, out_features=3840, bias=False)\n",
      "          (kv_a_proj_with_mqa): Linear(in_features=2560, out_features=288, bias=False)\n",
      "          (kv_a_layernorm): MiniCPMRMSNorm()\n",
      "          (kv_b_proj): Linear(in_features=256, out_features=5120, bias=False)\n",
      "          (o_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
      "          (rotary_emb): MiniCPMLongRoPE()\n",
      "        )\n",
      "        (mlp): MiniCPMMLP(\n",
      "          (gate_proj): Linear(in_features=2560, out_features=6400, bias=False)\n",
      "          (up_proj): Linear(in_features=2560, out_features=6400, bias=False)\n",
      "          (down_proj): Linear(in_features=6400, out_features=2560, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MiniCPMRMSNorm()\n",
      "        (post_attention_layernorm): MiniCPMRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MiniCPMRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=73448, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "device_id = 0  # ← 修改这里选择GPU编号\n",
    "device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = r\"F:\\edged\\cpm\"\n",
    "\n",
    "# 加载模型时指定设备\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, trust_remote_code=True\n",
    ")  # 将模型直接加载到指定设备\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出模型元信息和张量信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniCPM3Config {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"/home/ztf/cpm\",\n",
      "  \"architectures\": [\n",
      "    \"MiniCPM3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_minicpm.MiniCPM3Config\",\n",
      "    \"AutoModel\": \"modeling_minicpm.MiniCPM3Model\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_minicpm.MiniCPM3ForCausalLM\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_minicpm.MiniCPM3ForCausalLM\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_minicpm.MiniCPM3ForSequenceClassification\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dim_model_base\": 256,\n",
      "  \"eos_token_id\": [\n",
      "    2,\n",
      "    73440\n",
      "  ],\n",
      "  \"head_dim\": 96,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.1,\n",
      "  \"intermediate_size\": 6400,\n",
      "  \"kv_lora_rank\": 256,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"minicpm3\",\n",
      "  \"num_attention_heads\": 40,\n",
      "  \"num_hidden_layers\": 62,\n",
      "  \"num_key_value_heads\": 40,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"q_lora_rank\": 768,\n",
      "  \"qk_nope_head_dim\": 64,\n",
      "  \"qk_rope_head_dim\": 32,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"long_factor\": [\n",
      "      1.0591234137867171,\n",
      "      1.1241891283591912,\n",
      "      1.2596935748670968,\n",
      "      1.5380380402321725,\n",
      "      2.093982484148734,\n",
      "      3.1446935121267696,\n",
      "      4.937952647693647,\n",
      "      7.524541999994549,\n",
      "      10.475458000005451,\n",
      "      13.062047352306353,\n",
      "      14.85530648787323,\n",
      "      15.906017515851266,\n",
      "      16.461961959767827,\n",
      "      16.740306425132907,\n",
      "      16.87581087164081,\n",
      "      16.940876586213285\n",
      "    ],\n",
      "    \"original_max_position_embeddings\": 32768,\n",
      "    \"short_factor\": [\n",
      "      1.0591234137867171,\n",
      "      1.1241891283591912,\n",
      "      1.2596935748670968,\n",
      "      1.5380380402321725,\n",
      "      2.093982484148734,\n",
      "      3.1446935121267696,\n",
      "      4.937952647693647,\n",
      "      7.524541999994549,\n",
      "      10.475458000005451,\n",
      "      13.062047352306353,\n",
      "      14.85530648787323,\n",
      "      15.906017515851266,\n",
      "      16.461961959767827,\n",
      "      16.740306425132907,\n",
      "      16.87581087164081,\n",
      "      16.940876586213285\n",
      "    ],\n",
      "    \"type\": \"longrope\"\n",
      "  },\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_depth\": 1.4,\n",
      "  \"scale_emb\": 12,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.48.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"v_head_dim\": 64,\n",
      "  \"vocab_size\": 73448\n",
      "}\n",
      "\n",
      "Layer: model.embed_tokens.weight | Shape Type: torch.Size([73448, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 3.0518e-02,  2.5269e-02,  8.2031e-02,  ...,  9.4604e-03,\n",
      "         -5.4932e-02,  2.0630e-02],\n",
      "        [ 1.8539e-03,  4.6875e-02, -3.0518e-03,  ...,  3.0273e-02,\n",
      "         -1.6846e-02, -4.8828e-02],\n",
      "        [ 6.4941e-02,  4.5654e-02, -1.5503e-02,  ..., -2.8442e-02,\n",
      "          7.0801e-02,  4.6875e-02],\n",
      "        ...,\n",
      "        [ 1.8677e-02,  1.8463e-03, -4.6082e-03,  ...,  1.4186e-05,\n",
      "         -1.0300e-03,  5.3101e-03],\n",
      "        [ 1.8677e-02,  1.8463e-03, -4.6082e-03,  ...,  1.4186e-05,\n",
      "         -1.0300e-03,  5.3101e-03],\n",
      "        [ 1.8677e-02,  1.8463e-03, -4.6082e-03,  ...,  1.4186e-05,\n",
      "         -1.0300e-03,  5.3101e-03]], requires_grad=True)\n",
      "Layer: model.layers.0.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0327,  0.0249,  0.0008,  ..., -0.0051,  0.0078,  0.0041],\n",
      "        [-0.0096, -0.0054,  0.0483,  ...,  0.0067,  0.0042, -0.0066],\n",
      "        [ 0.0107, -0.0172, -0.0205,  ...,  0.0078, -0.0129, -0.0327],\n",
      "        ...,\n",
      "        [ 0.0137,  0.0073,  0.0116,  ..., -0.0109, -0.0093, -0.0037],\n",
      "        [ 0.0211,  0.0009, -0.0293,  ...,  0.0056, -0.0317,  0.0135],\n",
      "        [ 0.0146,  0.0074,  0.0232,  ...,  0.0060,  0.0040,  0.0226]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.0.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.0.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0251, -0.0022,  0.0204,  ..., -0.0026,  0.0100, -0.0099],\n",
      "        [ 0.0256,  0.0024, -0.0204,  ...,  0.0025, -0.0098,  0.0103],\n",
      "        [-0.0251, -0.0022,  0.0204,  ..., -0.0027,  0.0103, -0.0099],\n",
      "        ...,\n",
      "        [-0.0491,  0.0033,  0.0518,  ..., -0.0112,  0.0605,  0.0082],\n",
      "        [-0.0332,  0.0041,  0.0791,  ..., -0.0608,  0.1069,  0.0295],\n",
      "        [ 0.0084, -0.0243, -0.0376,  ...,  0.0369, -0.0928, -0.0476]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.0.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0272,  0.0085, -0.0157,  ..., -0.0016,  0.0299,  0.0164],\n",
      "        [-0.0295, -0.0146,  0.0226,  ..., -0.0239, -0.0281,  0.0168],\n",
      "        [-0.0110, -0.0273, -0.0211,  ...,  0.0044, -0.0236, -0.0133],\n",
      "        ...,\n",
      "        [ 0.0003, -0.0063,  0.0106,  ...,  0.0027, -0.0104,  0.0239],\n",
      "        [ 0.0243, -0.0535,  0.0253,  ...,  0.0442, -0.0371,  0.0474],\n",
      "        [-0.0273,  0.0227, -0.0084,  ...,  0.0101,  0.0261, -0.0398]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.0.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.0.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-1.0803e-02, -7.2266e-02,  5.9814e-03,  ...,  4.0527e-02,\n",
      "          1.0925e-02,  8.9722e-03],\n",
      "        [ 1.1047e-02,  7.3242e-02, -5.8899e-03,  ..., -4.0527e-02,\n",
      "         -1.1108e-02, -8.4229e-03],\n",
      "        [-1.0742e-02, -7.2754e-02,  5.8899e-03,  ...,  4.0527e-02,\n",
      "          1.1108e-02,  9.0942e-03],\n",
      "        ...,\n",
      "        [ 9.1553e-03, -1.8921e-02,  3.2043e-03,  ..., -2.0142e-03,\n",
      "         -1.9043e-02,  1.5640e-03],\n",
      "        [ 2.1515e-03,  1.4893e-02,  5.8289e-03,  ..., -1.1658e-02,\n",
      "          1.6403e-03,  3.6926e-03],\n",
      "        [-8.1062e-06,  9.0942e-03,  9.6436e-03,  ..., -1.3428e-02,\n",
      "          2.5940e-03,  3.7231e-03]], requires_grad=True)\n",
      "Layer: model.layers.0.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0111, -0.0022, -0.0013,  ..., -0.0056, -0.0029, -0.0021],\n",
      "        [ 0.0011, -0.0064,  0.0023,  ...,  0.0190,  0.0027,  0.0025],\n",
      "        [ 0.0150,  0.0092, -0.0028,  ...,  0.0269, -0.0069, -0.0035],\n",
      "        ...,\n",
      "        [-0.0003, -0.0008, -0.0066,  ...,  0.0096, -0.0045, -0.0033],\n",
      "        [-0.0118,  0.0130,  0.0019,  ..., -0.0242, -0.0022, -0.0047],\n",
      "        [-0.0079,  0.0107,  0.0032,  ...,  0.0122,  0.0024,  0.0017]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.0.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0054,  0.0003, -0.0177,  ...,  0.0151, -0.0139, -0.0034],\n",
      "        [-0.0060, -0.0154, -0.0053,  ...,  0.0064, -0.0024, -0.0133],\n",
      "        [-0.0220, -0.0361,  0.0044,  ...,  0.0270,  0.0188, -0.0295],\n",
      "        ...,\n",
      "        [ 0.0183, -0.0152, -0.0078,  ..., -0.0466, -0.0175,  0.0189],\n",
      "        [ 0.0088, -0.0059, -0.0275,  ...,  0.0092,  0.0168, -0.0116],\n",
      "        [-0.0452, -0.0063,  0.0262,  ...,  0.0243, -0.0208,  0.0148]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.0.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0260, -0.0078,  0.0030,  ...,  0.0391, -0.0013,  0.0135],\n",
      "        [ 0.0623,  0.0231, -0.0334,  ..., -0.0258,  0.0703, -0.0625],\n",
      "        [ 0.0386, -0.0347,  0.0225,  ..., -0.0349, -0.0054,  0.0166],\n",
      "        ...,\n",
      "        [ 0.0009, -0.0111,  0.0043,  ...,  0.0107, -0.0820, -0.0640],\n",
      "        [ 0.0247, -0.0192,  0.0211,  ...,  0.0291, -0.0266, -0.0464],\n",
      "        [ 0.0167, -0.0280, -0.0034,  ...,  0.0181, -0.0403, -0.1191]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.0.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0265,  0.0391,  0.0286,  ..., -0.0100,  0.0376, -0.0014],\n",
      "        [-0.0223,  0.0182,  0.0020,  ..., -0.0103, -0.0308, -0.0337],\n",
      "        [-0.0192, -0.0177,  0.0182,  ...,  0.0210,  0.0437,  0.0077],\n",
      "        ...,\n",
      "        [ 0.0835, -0.0405, -0.0198,  ...,  0.0195,  0.0205, -0.0247],\n",
      "        [ 0.0020,  0.0354, -0.0148,  ..., -0.0603, -0.0347, -0.0615],\n",
      "        [ 0.0244, -0.0297,  0.0109,  ..., -0.0510, -0.0264, -0.0820]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.0.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.0.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.1.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0093,  0.0067, -0.0562,  ...,  0.0223, -0.0366, -0.0016],\n",
      "        [-0.0022, -0.0129, -0.0014,  ...,  0.0089, -0.0024,  0.0281],\n",
      "        [ 0.0156,  0.0403,  0.0166,  ...,  0.0089,  0.0013,  0.0464],\n",
      "        ...,\n",
      "        [-0.0029,  0.0239, -0.0305,  ...,  0.0105, -0.0168,  0.0042],\n",
      "        [-0.0106, -0.0006, -0.0042,  ...,  0.0084,  0.0073, -0.0099],\n",
      "        [ 0.0199, -0.0066, -0.0186,  ...,  0.0408,  0.0378, -0.0036]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.1.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.1.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0381, -0.0615,  0.0291,  ..., -0.0034,  0.0312, -0.0035],\n",
      "        [ 0.0210,  0.0042,  0.0447,  ...,  0.0133, -0.0074, -0.0220],\n",
      "        [ 0.0034, -0.0121,  0.0096,  ..., -0.0273,  0.0334,  0.0037],\n",
      "        ...,\n",
      "        [-0.0162, -0.0199,  0.0100,  ..., -0.0405,  0.0259, -0.0171],\n",
      "        [-0.0186, -0.0109, -0.0016,  ..., -0.0059,  0.0278,  0.0079],\n",
      "        [-0.0325, -0.0054, -0.0081,  ..., -0.0021, -0.0030,  0.0142]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.1.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-3.3691e-02,  1.0498e-02,  1.1520e-03,  ..., -3.5400e-02,\n",
      "          3.3447e-02,  2.3682e-02],\n",
      "        [ 9.5215e-03, -7.2754e-02, -3.3203e-02,  ..., -2.4902e-02,\n",
      "         -1.7090e-02,  3.4180e-02],\n",
      "        [-2.4658e-02, -1.2451e-02, -3.1006e-02,  ...,  6.7383e-02,\n",
      "          3.6011e-03,  1.1368e-03],\n",
      "        ...,\n",
      "        [-5.3711e-03,  7.0801e-03,  4.7913e-03,  ..., -2.4048e-02,\n",
      "         -6.1035e-02,  1.3611e-02],\n",
      "        [ 2.3926e-02,  1.0132e-02, -1.1414e-02,  ...,  9.2773e-03,\n",
      "          4.0527e-02, -1.8677e-02],\n",
      "        [-4.9561e-02,  4.5776e-03,  1.2207e-02,  ...,  3.8624e-05,\n",
      "          3.0884e-02, -2.9785e-02]], requires_grad=True)\n",
      "Layer: model.layers.1.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.1.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0400,  0.0352,  0.0552,  ..., -0.0403, -0.0483, -0.0210],\n",
      "        [ 0.0503,  0.0439,  0.0157,  ...,  0.0245,  0.0198, -0.0052],\n",
      "        [-0.0060,  0.0164,  0.0417,  ..., -0.0133,  0.0150,  0.0133],\n",
      "        ...,\n",
      "        [-0.0215,  0.0096,  0.0308,  ..., -0.0208,  0.0437,  0.0001],\n",
      "        [-0.0025, -0.0157, -0.0091,  ..., -0.0022,  0.0210,  0.0061],\n",
      "        [ 0.0220, -0.0095, -0.0184,  ...,  0.0081, -0.0337,  0.0024]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.1.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0077,  0.0618,  0.0022,  ...,  0.0293,  0.0034,  0.0215],\n",
      "        [ 0.0312,  0.0104,  0.0610,  ...,  0.0035,  0.0262,  0.0104],\n",
      "        [ 0.0288, -0.0244, -0.0027,  ...,  0.1045,  0.0005,  0.0030],\n",
      "        ...,\n",
      "        [-0.0525, -0.0295, -0.0074,  ...,  0.0178,  0.0129,  0.0253],\n",
      "        [-0.0381,  0.0476,  0.0156,  ...,  0.0176, -0.0059, -0.0258],\n",
      "        [-0.0031,  0.0104,  0.0474,  ..., -0.0302,  0.0025,  0.0005]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.1.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0452, -0.0099,  0.0125,  ..., -0.0126,  0.0327,  0.0297],\n",
      "        [-0.0003,  0.0087, -0.0021,  ...,  0.0044, -0.0150, -0.0250],\n",
      "        [-0.0347, -0.0125,  0.0159,  ...,  0.0210, -0.0349,  0.0400],\n",
      "        ...,\n",
      "        [ 0.0297, -0.0757, -0.0374,  ...,  0.0123,  0.0120,  0.0192],\n",
      "        [-0.0206,  0.0117,  0.0261,  ..., -0.0002,  0.0337,  0.0122],\n",
      "        [ 0.0095, -0.0366,  0.0232,  ...,  0.0022,  0.0383,  0.0227]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.1.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0093, -0.0762,  0.0393,  ..., -0.0008, -0.0081,  0.0076],\n",
      "        [ 0.0549,  0.0347,  0.0087,  ...,  0.0212, -0.0493,  0.0315],\n",
      "        [ 0.0242, -0.0098, -0.0762,  ..., -0.0118, -0.0547,  0.0264],\n",
      "        ...,\n",
      "        [-0.0100, -0.0630,  0.0625,  ..., -0.0574, -0.0195,  0.0110],\n",
      "        [-0.0183,  0.0288,  0.0049,  ..., -0.0796, -0.0026, -0.0221],\n",
      "        [ 0.0459,  0.0206, -0.0304,  ..., -0.0310,  0.0146, -0.0240]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.1.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0110,  0.0317,  0.0003,  ..., -0.0251, -0.0430,  0.0635],\n",
      "        [-0.1143,  0.0188,  0.0097,  ..., -0.0303,  0.0028,  0.0247],\n",
      "        [ 0.0615, -0.0015, -0.0425,  ...,  0.0189, -0.0115, -0.0132],\n",
      "        ...,\n",
      "        [ 0.0115,  0.0231,  0.0398,  ..., -0.0391, -0.0625, -0.0083],\n",
      "        [-0.0038, -0.0347, -0.0184,  ..., -0.0415, -0.0144,  0.0172],\n",
      "        [-0.0068,  0.0295,  0.0079,  ...,  0.0386, -0.0084,  0.0020]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.1.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.1.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.2.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0115,  0.0142, -0.0050,  ..., -0.0388, -0.0116, -0.0332],\n",
      "        [ 0.0054, -0.0059,  0.0041,  ..., -0.0250,  0.0032,  0.0403],\n",
      "        [ 0.0242, -0.0132,  0.0159,  ...,  0.0374,  0.0547,  0.0265],\n",
      "        ...,\n",
      "        [-0.0684,  0.0243, -0.0159,  ...,  0.0420,  0.0302,  0.0190],\n",
      "        [ 0.0149,  0.0144, -0.0054,  ..., -0.0032, -0.0034, -0.0214],\n",
      "        [ 0.0045,  0.0303,  0.0134,  ..., -0.0327, -0.0289, -0.0302]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.2.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.2.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0151, -0.0114, -0.0051,  ...,  0.0898, -0.0498, -0.0449],\n",
      "        [ 0.0167,  0.0153,  0.0164,  ...,  0.1226,  0.0159,  0.0247],\n",
      "        [-0.0481,  0.0122, -0.0466,  ...,  0.0228,  0.0090, -0.0269],\n",
      "        ...,\n",
      "        [-0.0096,  0.0107, -0.0128,  ...,  0.0211,  0.0037, -0.0038],\n",
      "        [ 0.0134,  0.0114, -0.0046,  ...,  0.0737,  0.0151, -0.0098],\n",
      "        [ 0.0302,  0.0188,  0.0142,  ..., -0.0022,  0.0146, -0.0752]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.2.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0072, -0.0352, -0.0134,  ..., -0.0195, -0.0337, -0.0096],\n",
      "        [-0.0552, -0.0064,  0.0244,  ...,  0.0352, -0.0272, -0.0212],\n",
      "        [ 0.0420, -0.0140, -0.0342,  ...,  0.0757,  0.0342, -0.0044],\n",
      "        ...,\n",
      "        [-0.0126, -0.0315,  0.0320,  ...,  0.0021, -0.0038, -0.0229],\n",
      "        [-0.0114, -0.0248, -0.0164,  ..., -0.0344,  0.0029, -0.0104],\n",
      "        [ 0.0104, -0.0206,  0.0320,  ...,  0.0216,  0.0327, -0.0102]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.2.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.2.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0187,  0.0437,  0.0070,  ..., -0.0090, -0.0156,  0.0781],\n",
      "        [ 0.0080, -0.1221,  0.0051,  ..., -0.0103, -0.1230,  0.1230],\n",
      "        [-0.0320,  0.0050, -0.0386,  ...,  0.0361, -0.0835,  0.0767],\n",
      "        ...,\n",
      "        [ 0.0260, -0.0004, -0.0359,  ...,  0.0146,  0.0269,  0.0198],\n",
      "        [-0.0493, -0.0012, -0.0400,  ...,  0.0189, -0.0034, -0.0148],\n",
      "        [ 0.0122, -0.0425,  0.0255,  ..., -0.0452, -0.0203,  0.0435]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.2.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0193,  0.0236, -0.0273,  ...,  0.0518, -0.0020, -0.0141],\n",
      "        [-0.0092, -0.0043,  0.0208,  ..., -0.0212, -0.0547, -0.0400],\n",
      "        [ 0.0221,  0.0085, -0.0036,  ..., -0.0094, -0.0508,  0.0405],\n",
      "        ...,\n",
      "        [-0.0111,  0.0050, -0.0135,  ..., -0.0461,  0.0415,  0.0150],\n",
      "        [-0.0078, -0.0118, -0.0116,  ..., -0.0396, -0.0225,  0.0732],\n",
      "        [ 0.0219,  0.0118,  0.0059,  ...,  0.0219, -0.0067, -0.0002]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.2.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-6.5613e-03, -2.5146e-02, -1.3916e-02,  ..., -2.3956e-03,\n",
      "         -3.5645e-02, -1.1169e-02],\n",
      "        [ 7.9346e-03, -4.4556e-03,  3.3691e-02,  ...,  9.6680e-02,\n",
      "          1.7212e-02, -2.8564e-02],\n",
      "        [ 3.2959e-02, -2.3438e-02,  2.3926e-02,  ...,  5.1758e-02,\n",
      "          3.4424e-02,  6.1989e-05],\n",
      "        ...,\n",
      "        [-4.4922e-02,  1.1719e-02,  3.5645e-02,  ..., -4.8637e-05,\n",
      "          7.2266e-02, -7.1289e-02],\n",
      "        [ 2.1729e-02,  1.3062e-02,  1.5015e-02,  ...,  3.6621e-02,\n",
      "          3.2959e-02,  3.1250e-02],\n",
      "        [-8.6212e-04, -1.8311e-02,  7.3853e-03,  ..., -8.5449e-03,\n",
      "         -3.0273e-02, -5.1025e-02]], requires_grad=True)\n",
      "Layer: model.layers.2.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0004, -0.0228, -0.0060,  ..., -0.0454, -0.0439, -0.0031],\n",
      "        [ 0.0217,  0.0420,  0.0181,  ..., -0.0027,  0.0151,  0.0469],\n",
      "        [-0.0020,  0.0067,  0.0181,  ...,  0.0435, -0.0075, -0.0938],\n",
      "        ...,\n",
      "        [-0.0139,  0.0408, -0.0234,  ..., -0.0065, -0.0041,  0.0630],\n",
      "        [-0.0071, -0.0283, -0.0152,  ...,  0.0801, -0.0557,  0.0391],\n",
      "        [ 0.0366, -0.0059, -0.0459,  ..., -0.0776, -0.0562, -0.0177]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.2.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0522,  0.0178, -0.0376,  ..., -0.0028, -0.0166,  0.0272],\n",
      "        [ 0.0009, -0.0201, -0.0128,  ...,  0.0271, -0.0239, -0.0203],\n",
      "        [ 0.0278, -0.0028,  0.0664,  ..., -0.0564, -0.0131, -0.0483],\n",
      "        ...,\n",
      "        [-0.0200, -0.0327,  0.0152,  ..., -0.0188,  0.0542, -0.0613],\n",
      "        [ 0.0042, -0.0132, -0.0588,  ..., -0.0481,  0.0110, -0.0205],\n",
      "        [-0.0430, -0.0003,  0.0149,  ...,  0.0347,  0.0879, -0.0192]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.2.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.2.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.3.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0142,  0.0081, -0.0376,  ...,  0.0275, -0.0024, -0.0039],\n",
      "        [-0.0199,  0.0005, -0.0227,  ..., -0.0317,  0.0410,  0.0022],\n",
      "        [ 0.0147,  0.0210, -0.0042,  ...,  0.0232,  0.0003,  0.0085],\n",
      "        ...,\n",
      "        [ 0.0215,  0.0292,  0.0383,  ..., -0.0337,  0.0054,  0.0138],\n",
      "        [-0.0250, -0.0391, -0.0226,  ...,  0.0153,  0.0098,  0.0272],\n",
      "        [-0.0352, -0.0289,  0.0055,  ..., -0.0044,  0.0049, -0.0210]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.3.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.3.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 2.9297e-02,  6.5430e-02,  6.4697e-03,  ..., -2.8076e-02,\n",
      "          1.2451e-02, -2.7466e-02],\n",
      "        [ 3.5645e-02, -5.5664e-02, -3.8818e-02,  ..., -6.8665e-05,\n",
      "          3.9673e-03,  5.7068e-03],\n",
      "        [-3.1494e-02,  1.3123e-02, -2.2705e-02,  ..., -1.1414e-02,\n",
      "         -4.4678e-02, -7.8125e-03],\n",
      "        ...,\n",
      "        [ 2.3926e-02, -3.3264e-03, -8.2397e-03,  ..., -3.5645e-02,\n",
      "         -1.3000e-02,  2.3926e-02],\n",
      "        [ 1.2817e-02, -2.9449e-03,  3.6621e-02,  ..., -2.0508e-02,\n",
      "          5.0354e-03, -2.4170e-02],\n",
      "        [ 3.8086e-02, -4.7302e-04, -1.3000e-02,  ...,  1.0071e-03,\n",
      "          3.0151e-02,  2.6123e-02]], requires_grad=True)\n",
      "Layer: model.layers.3.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0771,  0.0061, -0.0004,  ..., -0.0119,  0.0200,  0.0099],\n",
      "        [-0.0092, -0.0166, -0.0325,  ..., -0.0381, -0.0140, -0.0425],\n",
      "        [-0.0781, -0.0190, -0.0359,  ...,  0.0364, -0.0312, -0.0176],\n",
      "        ...,\n",
      "        [-0.0396,  0.0190,  0.0195,  ..., -0.0033, -0.0265,  0.0111],\n",
      "        [-0.0109,  0.0058, -0.0098,  ..., -0.0417, -0.0177,  0.0151],\n",
      "        [-0.0292, -0.0167,  0.0145,  ...,  0.0005, -0.0356,  0.0079]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.3.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.3.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0522, -0.0138,  0.0282,  ...,  0.0354,  0.0732,  0.0310],\n",
      "        [-0.0123,  0.0603, -0.0023,  ...,  0.0054,  0.0212, -0.0986],\n",
      "        [-0.0449, -0.0157,  0.0559,  ...,  0.0203,  0.0086,  0.0369],\n",
      "        ...,\n",
      "        [-0.0327, -0.0425, -0.0031,  ...,  0.0143, -0.0080, -0.0242],\n",
      "        [-0.0200, -0.0008, -0.0249,  ...,  0.0118, -0.0114,  0.0295],\n",
      "        [ 0.0114, -0.0332, -0.0267,  ..., -0.0133, -0.0047, -0.0270]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.3.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0044, -0.0109,  0.0398,  ...,  0.0009, -0.0086, -0.0076],\n",
      "        [ 0.0286,  0.0574,  0.0093,  ..., -0.0134,  0.0129,  0.0239],\n",
      "        [ 0.0601, -0.0173, -0.0008,  ..., -0.0108, -0.0283,  0.0014],\n",
      "        ...,\n",
      "        [ 0.0157,  0.0422, -0.0306,  ..., -0.0045,  0.0041, -0.0058],\n",
      "        [ 0.0200,  0.0242,  0.0024,  ..., -0.0047,  0.0200, -0.0317],\n",
      "        [-0.0229, -0.0134, -0.0762,  ...,  0.0040, -0.0342,  0.0081]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.3.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-4.2969e-02, -1.0376e-02,  2.6489e-02,  ...,  1.2283e-03,\n",
      "          2.3560e-02,  2.0508e-02],\n",
      "        [ 7.8678e-05, -1.0452e-03,  2.4048e-02,  ...,  7.1777e-02,\n",
      "          6.1279e-02,  1.7700e-02],\n",
      "        [-5.7129e-02,  8.1787e-03,  6.9336e-02,  ...,  2.3438e-02,\n",
      "         -8.7280e-03,  9.2163e-03],\n",
      "        ...,\n",
      "        [ 5.9814e-03,  9.7656e-03, -2.2949e-02,  ...,  5.4321e-03,\n",
      "         -1.6602e-02, -2.1484e-02],\n",
      "        [ 1.0559e-02, -3.3447e-02,  2.1240e-02,  ..., -2.4170e-02,\n",
      "          4.2725e-02,  1.5259e-02],\n",
      "        [-4.4434e-02, -1.0254e-02,  1.7548e-03,  ..., -3.8818e-02,\n",
      "         -2.2949e-02, -2.3438e-02]], requires_grad=True)\n",
      "Layer: model.layers.3.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0063, -0.0391,  0.0064,  ..., -0.0013,  0.0057,  0.0037],\n",
      "        [-0.0166, -0.0078,  0.0371,  ..., -0.0347,  0.0674,  0.0031],\n",
      "        [-0.0508, -0.0347, -0.0801,  ..., -0.0125, -0.0400,  0.0625],\n",
      "        ...,\n",
      "        [ 0.0693,  0.0126, -0.0515,  ...,  0.0623, -0.0208,  0.0291],\n",
      "        [ 0.0530, -0.0452, -0.0172,  ...,  0.0046, -0.0068, -0.0208],\n",
      "        [ 0.0405, -0.0164,  0.0008,  ...,  0.0369, -0.0286, -0.0420]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.3.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0190, -0.0125, -0.0299,  ...,  0.0232,  0.0645,  0.0581],\n",
      "        [-0.0596, -0.0025, -0.0320,  ..., -0.0150, -0.0220,  0.0137],\n",
      "        [ 0.0118,  0.0125, -0.0923,  ..., -0.0330,  0.0024,  0.0266],\n",
      "        ...,\n",
      "        [ 0.0175, -0.0305, -0.0171,  ...,  0.0366,  0.0176,  0.0151],\n",
      "        [ 0.0216,  0.0192, -0.0003,  ..., -0.0498, -0.0167, -0.0134],\n",
      "        [ 0.0576, -0.0322,  0.0165,  ..., -0.0205,  0.0033, -0.0154]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.3.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.3.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.4.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0302, -0.0189,  0.0574,  ...,  0.0359, -0.0082, -0.0142],\n",
      "        [-0.0100,  0.0050,  0.0330,  ...,  0.0146, -0.0140, -0.0151],\n",
      "        [-0.0071, -0.0347,  0.0019,  ...,  0.0212, -0.0036,  0.0139],\n",
      "        ...,\n",
      "        [-0.0425, -0.0042,  0.0024,  ..., -0.0356, -0.0175, -0.0060],\n",
      "        [ 0.0222, -0.0254,  0.0339,  ...,  0.0159,  0.0181, -0.0205],\n",
      "        [-0.0140, -0.0105, -0.0007,  ...,  0.0459,  0.0052, -0.0237]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.4.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0117, -0.0278,  0.0039,  ...,  0.0249, -0.0337,  0.0513],\n",
      "        [-0.0400,  0.0225, -0.0698,  ..., -0.0118, -0.0286,  0.0610],\n",
      "        [ 0.0231, -0.0043, -0.0192,  ..., -0.0259,  0.0114,  0.0356],\n",
      "        ...,\n",
      "        [-0.0138, -0.0032, -0.0232,  ...,  0.0122, -0.0143,  0.0098],\n",
      "        [-0.0359, -0.0161, -0.0510,  ...,  0.0273,  0.0132,  0.0294],\n",
      "        [ 0.0234, -0.0087,  0.0075,  ..., -0.0159,  0.0393,  0.0280]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0302, -0.0220,  0.0354,  ...,  0.0193,  0.0140, -0.0228],\n",
      "        [-0.0317,  0.0099,  0.0105,  ...,  0.0491,  0.0048, -0.0317],\n",
      "        [-0.0006, -0.0206,  0.0142,  ..., -0.0222, -0.0364, -0.0056],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0197,  0.0045,  ...,  0.0090, -0.0146,  0.0234],\n",
      "        [-0.0211,  0.0059, -0.0177,  ..., -0.0085, -0.0242,  0.0078],\n",
      "        [ 0.0240,  0.0347,  0.0305,  ..., -0.0315, -0.0344,  0.0027]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.4.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0267,  0.0762, -0.0210,  ..., -0.0255, -0.0045,  0.0210],\n",
      "        [-0.0430,  0.0396, -0.0017,  ..., -0.0277, -0.0117, -0.0029],\n",
      "        [ 0.0027, -0.0194,  0.0869,  ..., -0.0096, -0.0103,  0.0208],\n",
      "        ...,\n",
      "        [-0.0032, -0.0161, -0.0586,  ..., -0.0413, -0.0256,  0.0559],\n",
      "        [-0.0417, -0.0112, -0.0168,  ...,  0.0117, -0.0249,  0.0186],\n",
      "        [-0.0019,  0.0145,  0.0195,  ..., -0.0300, -0.0056,  0.0101]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0396,  0.0242,  0.0024,  ...,  0.0366, -0.0261, -0.0072],\n",
      "        [-0.0332,  0.0322,  0.0161,  ..., -0.0006, -0.0564, -0.0172],\n",
      "        [ 0.0183,  0.0171,  0.0198,  ...,  0.0265, -0.0287,  0.0014],\n",
      "        ...,\n",
      "        [-0.0762,  0.0459, -0.0620,  ...,  0.0087,  0.0420, -0.0374],\n",
      "        [ 0.0141, -0.0092,  0.0320,  ..., -0.0084,  0.0229,  0.0073],\n",
      "        [-0.0021,  0.0046,  0.0007,  ...,  0.0081, -0.0295, -0.0067]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0037, -0.0444, -0.0029,  ...,  0.0036,  0.0208,  0.0052],\n",
      "        [ 0.0013, -0.0098, -0.0854,  ..., -0.0027,  0.0255,  0.0640],\n",
      "        [-0.0327,  0.0033,  0.0403,  ..., -0.0781,  0.0076, -0.0041],\n",
      "        ...,\n",
      "        [-0.0011,  0.0503,  0.0128,  ..., -0.0148, -0.0038,  0.0123],\n",
      "        [-0.0330, -0.0273, -0.0195,  ...,  0.0119, -0.0417,  0.0035],\n",
      "        [-0.0002, -0.0141,  0.0041,  ..., -0.0454, -0.0508,  0.0669]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0342, -0.0771,  0.0146,  ...,  0.0227,  0.0270, -0.0481],\n",
      "        [-0.0090,  0.0010, -0.0615,  ...,  0.0240,  0.0042,  0.0918],\n",
      "        [ 0.0352,  0.0195,  0.0400,  ..., -0.0493,  0.0145, -0.0175],\n",
      "        ...,\n",
      "        [-0.0011, -0.0160, -0.0147,  ..., -0.0027, -0.0028, -0.0581],\n",
      "        [-0.0022,  0.0216, -0.0192,  ...,  0.0116,  0.0352,  0.0074],\n",
      "        [ 0.0156,  0.0161,  0.0381,  ..., -0.0003, -0.0121,  0.0498]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0310,  0.0200, -0.0020,  ..., -0.0022,  0.0001,  0.0289],\n",
      "        [-0.0520, -0.0315,  0.0364,  ...,  0.0115, -0.0376,  0.0281],\n",
      "        [-0.0199, -0.0271,  0.0352,  ...,  0.0129,  0.0142,  0.0420],\n",
      "        ...,\n",
      "        [-0.0247,  0.0223, -0.0723,  ...,  0.0483, -0.0188,  0.0444],\n",
      "        [-0.0008, -0.0337,  0.0308,  ..., -0.0269, -0.0080, -0.0266],\n",
      "        [-0.0400,  0.0850, -0.0275,  ..., -0.0596,  0.0053, -0.0181]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.4.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.4.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.5.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0300,  0.0457, -0.0391,  ..., -0.0383,  0.0136, -0.0312],\n",
      "        [ 0.0052,  0.0120,  0.0197,  ...,  0.0223,  0.0176, -0.0309],\n",
      "        [ 0.0123, -0.0193,  0.0352,  ..., -0.0225, -0.0076,  0.0347],\n",
      "        ...,\n",
      "        [-0.0118,  0.0004, -0.0344,  ...,  0.0515,  0.0040, -0.0228],\n",
      "        [-0.0118, -0.0264,  0.0251,  ..., -0.0398, -0.0120, -0.0104],\n",
      "        [ 0.0181,  0.0275,  0.0067,  ...,  0.0483, -0.0256, -0.0286]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.5.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0449,  0.0103, -0.0211,  ..., -0.0513, -0.0320, -0.0111],\n",
      "        [-0.0552, -0.0145, -0.0103,  ...,  0.0232, -0.0349, -0.0042],\n",
      "        [ 0.0164,  0.0244,  0.0327,  ..., -0.0189,  0.0488, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0004,  0.0100, -0.0166,  ..., -0.0085, -0.0066, -0.0123],\n",
      "        [ 0.0167,  0.0050, -0.0172,  ...,  0.0242,  0.0339,  0.0011],\n",
      "        [ 0.0425,  0.0386,  0.0085,  ..., -0.0347, -0.0371,  0.0072]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0128,  0.0127, -0.0020,  ...,  0.0101, -0.0273, -0.0112],\n",
      "        [ 0.0142,  0.0128,  0.0508,  ...,  0.0342, -0.0190, -0.0479],\n",
      "        [-0.0464, -0.0569, -0.0198,  ...,  0.0376, -0.0256, -0.0203],\n",
      "        ...,\n",
      "        [ 0.0386,  0.0288, -0.0261,  ..., -0.0142, -0.0337,  0.0057],\n",
      "        [-0.0239, -0.0214,  0.0195,  ...,  0.0033,  0.0251,  0.0074],\n",
      "        [ 0.0305, -0.0139,  0.0074,  ...,  0.0064, -0.0104,  0.0052]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.5.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0220,  0.0417,  0.0261,  ...,  0.0078, -0.0278,  0.0283],\n",
      "        [-0.0063, -0.0193, -0.0388,  ..., -0.0640,  0.0240,  0.0056],\n",
      "        [ 0.0101,  0.0518,  0.0030,  ..., -0.0576, -0.0061, -0.0036],\n",
      "        ...,\n",
      "        [-0.0118, -0.0090, -0.0018,  ...,  0.0281,  0.0085, -0.0299],\n",
      "        [-0.0116,  0.0002, -0.0287,  ..., -0.0225, -0.0150,  0.0041],\n",
      "        [ 0.0273,  0.0137,  0.0092,  ..., -0.0242,  0.0269, -0.0030]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0113, -0.0217, -0.0053,  ..., -0.0474,  0.0171,  0.0532],\n",
      "        [ 0.0159,  0.0287, -0.0315,  ..., -0.0008, -0.0009,  0.0427],\n",
      "        [-0.0371,  0.0425, -0.0020,  ..., -0.0503, -0.0242, -0.0459],\n",
      "        ...,\n",
      "        [ 0.0002,  0.0459, -0.0199,  ..., -0.0311, -0.0099, -0.0339],\n",
      "        [-0.0356, -0.0747,  0.0153,  ..., -0.0306, -0.0129,  0.0276],\n",
      "        [-0.0481,  0.0155,  0.0388,  ...,  0.0188, -0.0076,  0.0215]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0200, -0.0078, -0.0542,  ..., -0.0162,  0.0679, -0.0737],\n",
      "        [-0.0214,  0.0376,  0.0471,  ..., -0.0028,  0.0520, -0.0171],\n",
      "        [ 0.0674, -0.0337,  0.0062,  ...,  0.0332, -0.0155, -0.0259],\n",
      "        ...,\n",
      "        [-0.0217, -0.0125,  0.0107,  ...,  0.0378,  0.0137,  0.0123],\n",
      "        [-0.0449,  0.0162,  0.0850,  ..., -0.0164,  0.0062,  0.0513],\n",
      "        [-0.0645,  0.0369,  0.0136,  ..., -0.0006,  0.0486, -0.0151]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0029,  0.0225,  0.0066,  ...,  0.0286,  0.0469,  0.0222],\n",
      "        [ 0.0320,  0.0011,  0.0079,  ..., -0.0146, -0.0967,  0.0493],\n",
      "        [-0.0483,  0.0151,  0.0258,  ...,  0.0074, -0.0305,  0.0101],\n",
      "        ...,\n",
      "        [-0.0051,  0.0427,  0.0498,  ...,  0.0022, -0.0095,  0.0605],\n",
      "        [-0.0271, -0.0051,  0.0349,  ..., -0.0193, -0.0122,  0.0159],\n",
      "        [-0.0503,  0.0417, -0.0172,  ...,  0.0086, -0.0143, -0.0559]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0164,  0.0376, -0.0128,  ...,  0.0183, -0.0201, -0.0481],\n",
      "        [ 0.0266,  0.1138,  0.0713,  ...,  0.0250, -0.0162,  0.0306],\n",
      "        [ 0.0349,  0.0237, -0.0342,  ...,  0.0164,  0.0145, -0.0396],\n",
      "        ...,\n",
      "        [ 0.0099, -0.0437, -0.0703,  ..., -0.0317, -0.0300,  0.0352],\n",
      "        [ 0.0601, -0.0537, -0.0212,  ...,  0.0342,  0.0244,  0.0142],\n",
      "        [ 0.0200,  0.0654,  0.0153,  ...,  0.0728,  0.0228, -0.0347]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.5.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.5.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.6.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0115, -0.0024,  0.0093,  ...,  0.0031,  0.0188,  0.0004],\n",
      "        [ 0.0483, -0.0050, -0.0090,  ..., -0.0508, -0.0275, -0.0513],\n",
      "        [ 0.0131,  0.0226, -0.0098,  ...,  0.0194,  0.0030, -0.0215],\n",
      "        ...,\n",
      "        [-0.0175,  0.0020, -0.0415,  ..., -0.0275, -0.0084,  0.0378],\n",
      "        [-0.0251, -0.0366,  0.0082,  ...,  0.0156, -0.0107, -0.0109],\n",
      "        [-0.0286, -0.0049, -0.0625,  ...,  0.0065, -0.0183, -0.0120]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.6.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.6.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0206, -0.0135, -0.0242,  ...,  0.0742, -0.0110,  0.0188],\n",
      "        [-0.0447,  0.0330,  0.0063,  ...,  0.0225,  0.0137,  0.0408],\n",
      "        [ 0.0035,  0.0352, -0.0036,  ..., -0.0123, -0.0610,  0.0309],\n",
      "        ...,\n",
      "        [-0.0009, -0.0152, -0.0347,  ..., -0.0037,  0.0332, -0.0322],\n",
      "        [-0.0237,  0.0089, -0.0432,  ..., -0.0164, -0.0153, -0.0059],\n",
      "        [ 0.0076, -0.0011,  0.0030,  ...,  0.0013, -0.0035, -0.0142]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.6.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0203,  0.0566, -0.0216,  ..., -0.0038, -0.0374,  0.0086],\n",
      "        [ 0.0236,  0.0173, -0.0275,  ..., -0.0806,  0.0332,  0.0610],\n",
      "        [ 0.0160,  0.0270,  0.0583,  ...,  0.0527,  0.0058,  0.0116],\n",
      "        ...,\n",
      "        [ 0.0007, -0.0229, -0.0063,  ...,  0.0027,  0.0432, -0.0229],\n",
      "        [-0.0001, -0.0072, -0.0003,  ...,  0.0064, -0.0245,  0.0020],\n",
      "        [-0.0337, -0.0079, -0.0014,  ..., -0.0786, -0.0322, -0.0253]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.6.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.6.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0276,  0.0201, -0.0620,  ...,  0.0474, -0.0148, -0.0090],\n",
      "        [ 0.0050, -0.0864,  0.0913,  ..., -0.0408, -0.0659, -0.0119],\n",
      "        [-0.0518, -0.0208, -0.0444,  ..., -0.0087,  0.0189,  0.0172],\n",
      "        ...,\n",
      "        [-0.0065, -0.0094, -0.0542,  ..., -0.0393, -0.0483, -0.0102],\n",
      "        [-0.0889, -0.0159, -0.0261,  ...,  0.0062, -0.0026,  0.0410],\n",
      "        [ 0.0308, -0.0123,  0.0079,  ...,  0.0356,  0.0352,  0.1055]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.6.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0498,  0.0366,  0.0073,  ...,  0.0430,  0.0610,  0.0713],\n",
      "        [-0.0152, -0.0232, -0.0410,  ...,  0.0054, -0.0269, -0.0297],\n",
      "        [ 0.0012, -0.0023,  0.0131,  ...,  0.0261,  0.0038,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0537, -0.0074,  0.0052,  ...,  0.0300, -0.0486, -0.0258],\n",
      "        [ 0.0325, -0.0016, -0.0048,  ...,  0.0518,  0.0337, -0.0371],\n",
      "        [-0.0123,  0.0576, -0.0391,  ...,  0.0645,  0.0024,  0.0153]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.6.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0479, -0.0281, -0.0354,  ..., -0.0364,  0.0527,  0.0126],\n",
      "        [ 0.0034, -0.0255,  0.0684,  ...,  0.0081, -0.0051, -0.0133],\n",
      "        [ 0.0269, -0.0310, -0.0405,  ...,  0.0183,  0.0430, -0.0410],\n",
      "        ...,\n",
      "        [ 0.0742,  0.0535,  0.0027,  ...,  0.0066,  0.0234,  0.0427],\n",
      "        [ 0.0879, -0.0243,  0.0352,  ...,  0.0342,  0.0017,  0.0481],\n",
      "        [-0.0635, -0.0142, -0.0027,  ...,  0.0178, -0.0449,  0.0229]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.6.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0047,  0.0347, -0.0591,  ...,  0.0016, -0.0165,  0.0405],\n",
      "        [ 0.0361, -0.0566, -0.0562,  ...,  0.0513,  0.0013,  0.0752],\n",
      "        [ 0.0225,  0.0233,  0.0471,  ..., -0.0388, -0.0327, -0.0369],\n",
      "        ...,\n",
      "        [-0.0771,  0.0227, -0.0493,  ...,  0.0654, -0.0311, -0.0361],\n",
      "        [ 0.0222, -0.0119,  0.0137,  ...,  0.0099,  0.0496, -0.0359],\n",
      "        [ 0.0334, -0.0028,  0.0002,  ...,  0.0060,  0.0220,  0.0513]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.6.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-1.0777e-04,  5.2490e-02, -1.0315e-02,  ..., -1.2402e-01,\n",
      "          1.7090e-02,  7.6660e-02],\n",
      "        [ 3.0396e-02, -5.0537e-02,  5.4321e-03,  ...,  6.2988e-02,\n",
      "          4.0527e-02, -2.0981e-05],\n",
      "        [-2.9785e-02, -4.4189e-02,  3.1250e-02,  ..., -3.4180e-02,\n",
      "          2.0996e-02,  2.0264e-02],\n",
      "        ...,\n",
      "        [-4.8828e-02,  4.2236e-02, -2.3682e-02,  ...,  2.7466e-02,\n",
      "          3.2959e-02, -1.9653e-02],\n",
      "        [-3.1738e-02,  2.9053e-02, -1.3428e-03,  ..., -3.4180e-02,\n",
      "          3.3203e-02,  5.1514e-02],\n",
      "        [ 6.2500e-02,  2.1851e-02, -2.0996e-02,  ..., -7.9346e-03,\n",
      "         -3.5400e-02,  3.0518e-02]], requires_grad=True)\n",
      "Layer: model.layers.6.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.6.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.7.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0471, -0.0148, -0.0474,  ...,  0.0198,  0.0070, -0.0405],\n",
      "        [-0.0393,  0.0786, -0.0105,  ...,  0.0297, -0.0393, -0.0041],\n",
      "        [ 0.0105,  0.0058,  0.0476,  ..., -0.0052,  0.0215,  0.0225],\n",
      "        ...,\n",
      "        [-0.0420,  0.0209,  0.0078,  ..., -0.0452,  0.0240,  0.0352],\n",
      "        [-0.0085, -0.0476, -0.0126,  ...,  0.0221, -0.0055, -0.0183],\n",
      "        [-0.0065,  0.0432,  0.0085,  ..., -0.0193,  0.0040, -0.1001]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.7.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0151, -0.0342,  0.0337,  ..., -0.0601, -0.0347,  0.0684],\n",
      "        [ 0.0140,  0.0093, -0.0214,  ..., -0.0211, -0.0408,  0.0042],\n",
      "        [-0.0237, -0.0025, -0.0034,  ...,  0.0168,  0.0498,  0.0293],\n",
      "        ...,\n",
      "        [-0.0183, -0.0386, -0.0212,  ...,  0.0265,  0.0776,  0.0017],\n",
      "        [-0.0378, -0.0527,  0.0229,  ..., -0.0126,  0.0026,  0.0105],\n",
      "        [ 0.0508,  0.0067,  0.0026,  ...,  0.0176, -0.0142,  0.0435]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0308,  0.0021, -0.0220,  ...,  0.0108,  0.0083, -0.0518],\n",
      "        [-0.0771,  0.0063,  0.0400,  ..., -0.0479,  0.0195, -0.0280],\n",
      "        [ 0.0623, -0.0045, -0.0111,  ...,  0.0065, -0.0240, -0.0152],\n",
      "        ...,\n",
      "        [-0.0054, -0.0295, -0.0269,  ...,  0.0168, -0.0173,  0.0518],\n",
      "        [-0.0161,  0.0044,  0.0037,  ..., -0.0374,  0.0101,  0.0071],\n",
      "        [-0.0029,  0.0035,  0.0002,  ..., -0.0107, -0.0352, -0.0114]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.7.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0498, -0.0172, -0.0591,  ...,  0.0332,  0.0845, -0.0437],\n",
      "        [-0.0569,  0.0048,  0.0048,  ..., -0.0153,  0.0024, -0.0176],\n",
      "        [-0.1240,  0.0588,  0.0312,  ..., -0.0175,  0.0322, -0.0095],\n",
      "        ...,\n",
      "        [ 0.0076,  0.0089,  0.0248,  ..., -0.0048, -0.0121, -0.0986],\n",
      "        [ 0.0403,  0.0222,  0.0588,  ..., -0.0054,  0.0396,  0.0459],\n",
      "        [ 0.0225, -0.0171,  0.0281,  ..., -0.0166,  0.0356, -0.0544]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0132,  0.0469,  0.0229,  ...,  0.0527, -0.0155, -0.0542],\n",
      "        [ 0.0009,  0.0036, -0.0430,  ...,  0.0781, -0.0391,  0.0354],\n",
      "        [ 0.0018, -0.1016,  0.0096,  ...,  0.0525, -0.0457, -0.0114],\n",
      "        ...,\n",
      "        [-0.0515, -0.0308, -0.0459,  ...,  0.0065, -0.0493, -0.0190],\n",
      "        [-0.0156, -0.0295, -0.0376,  ...,  0.0454, -0.0420,  0.0315],\n",
      "        [ 0.0108, -0.0058,  0.0051,  ..., -0.0737,  0.0366, -0.0222]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0160,  0.0090, -0.0317,  ...,  0.0483, -0.0248,  0.0233],\n",
      "        [ 0.0099, -0.0064, -0.0076,  ..., -0.0109,  0.0601, -0.0053],\n",
      "        [-0.0096,  0.0044,  0.0161,  ..., -0.0544, -0.0075,  0.0732],\n",
      "        ...,\n",
      "        [-0.0664, -0.1001, -0.0344,  ...,  0.0258,  0.0265, -0.0097],\n",
      "        [-0.0026, -0.0150,  0.0645,  ..., -0.0211, -0.0234,  0.0147],\n",
      "        [ 0.0649, -0.0630, -0.0108,  ..., -0.0183,  0.0045, -0.0481]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0183,  0.0342, -0.0089,  ..., -0.0396, -0.0081,  0.0047],\n",
      "        [ 0.0400,  0.0036,  0.0630,  ..., -0.0371, -0.0742,  0.0112],\n",
      "        [-0.0527, -0.0047, -0.0247,  ..., -0.0302,  0.0781, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0008, -0.0139, -0.0182,  ...,  0.0153,  0.0571,  0.0042],\n",
      "        [-0.0625, -0.0259,  0.0049,  ..., -0.0649, -0.0048,  0.0096],\n",
      "        [ 0.0305,  0.0679, -0.0723,  ...,  0.0564,  0.0161, -0.0171]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0181,  0.0674, -0.0023,  ...,  0.0189, -0.0447,  0.0269],\n",
      "        [ 0.0500,  0.0023,  0.0261,  ..., -0.0315, -0.0261,  0.0114],\n",
      "        [-0.0139,  0.0581, -0.0131,  ...,  0.0008, -0.0391, -0.0532],\n",
      "        ...,\n",
      "        [-0.0186, -0.0147,  0.0371,  ..., -0.0002, -0.0703,  0.0334],\n",
      "        [ 0.0043, -0.0486, -0.0079,  ...,  0.0288, -0.0019, -0.0053],\n",
      "        [-0.0008,  0.0190, -0.0167,  ...,  0.0131, -0.0021, -0.0214]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.7.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.7.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.8.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0408, -0.0201, -0.0140,  ..., -0.0225,  0.0173, -0.0830],\n",
      "        [ 0.0188,  0.0415,  0.0179,  ..., -0.0688, -0.0126,  0.0383],\n",
      "        [ 0.0220,  0.0056,  0.0165,  ...,  0.0305, -0.0239,  0.0479],\n",
      "        ...,\n",
      "        [-0.0035,  0.0161, -0.0264,  ..., -0.0168,  0.0232, -0.0005],\n",
      "        [ 0.0199,  0.0167, -0.0055,  ..., -0.0186,  0.0317,  0.0087],\n",
      "        [-0.0008, -0.0374, -0.0153,  ..., -0.0032, -0.0232, -0.0188]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.8.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.8.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0449,  0.1543, -0.0654,  ...,  0.0210, -0.0040,  0.0186],\n",
      "        [-0.0732,  0.0244,  0.0200,  ..., -0.0133, -0.0186, -0.0039],\n",
      "        [-0.0447, -0.0349, -0.0608,  ..., -0.0140, -0.0150, -0.0040],\n",
      "        ...,\n",
      "        [-0.0217, -0.0052, -0.0161,  ...,  0.0071,  0.0027, -0.0057],\n",
      "        [-0.0262,  0.0065,  0.0007,  ...,  0.0146,  0.0356, -0.0247],\n",
      "        [-0.0183,  0.0107, -0.0090,  ..., -0.0242, -0.0039, -0.0087]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.8.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 1.9043e-02, -1.5137e-02, -4.1992e-02,  ...,  4.0894e-03,\n",
      "          9.0942e-03,  1.1353e-02],\n",
      "        [ 4.4678e-02,  2.5146e-02, -3.9062e-02,  ..., -2.6733e-02,\n",
      "         -1.4420e-03,  9.7046e-03],\n",
      "        [ 7.6294e-05, -8.4473e-02, -2.9602e-03,  ..., -5.7617e-02,\n",
      "         -2.8320e-02, -1.3611e-02],\n",
      "        ...,\n",
      "        [-3.1982e-02, -7.8735e-03,  1.3550e-02,  ..., -8.3618e-03,\n",
      "         -1.9409e-02, -1.0071e-02],\n",
      "        [ 1.7822e-02, -6.1035e-05,  9.8877e-03,  ..., -6.8359e-03,\n",
      "         -5.6152e-03,  1.8692e-03],\n",
      "        [ 1.1108e-02, -2.1973e-02, -1.6235e-02,  ...,  1.4160e-02,\n",
      "          3.6621e-02,  6.3477e-02]], requires_grad=True)\n",
      "Layer: model.layers.8.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.8.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0977, -0.0684,  0.0023,  ..., -0.0344,  0.0417, -0.0184],\n",
      "        [-0.0422,  0.0825, -0.0161,  ..., -0.0669, -0.0474,  0.0332],\n",
      "        [ 0.0019,  0.0830, -0.0034,  ...,  0.0830, -0.0071, -0.0090],\n",
      "        ...,\n",
      "        [-0.0177, -0.0693,  0.0383,  ...,  0.0098, -0.0085,  0.0278],\n",
      "        [ 0.0233,  0.0094,  0.0287,  ...,  0.0081, -0.0090, -0.0098],\n",
      "        [ 0.0069,  0.0271,  0.0189,  ...,  0.0135, -0.0255, -0.0430]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.8.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0267,  0.0123, -0.0044,  ...,  0.0262, -0.0250,  0.0148],\n",
      "        [-0.0559, -0.0151, -0.0128,  ...,  0.0447, -0.0737,  0.0299],\n",
      "        [ 0.0294, -0.0415, -0.0703,  ...,  0.0027, -0.0029, -0.0255],\n",
      "        ...,\n",
      "        [-0.0417,  0.0449, -0.0205,  ...,  0.0249, -0.0435,  0.0137],\n",
      "        [-0.0035, -0.0413,  0.0564,  ..., -0.0089,  0.0068,  0.0005],\n",
      "        [-0.0425,  0.0076, -0.0046,  ...,  0.0293,  0.0208,  0.0026]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.8.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0542,  0.0286, -0.0464,  ...,  0.0123, -0.0049,  0.0381],\n",
      "        [-0.0742, -0.0991, -0.0342,  ...,  0.0006,  0.0469,  0.0422],\n",
      "        [-0.0369,  0.0115,  0.0049,  ...,  0.0242,  0.0276, -0.0278],\n",
      "        ...,\n",
      "        [-0.0188, -0.0087, -0.0192,  ..., -0.0085,  0.0266, -0.0117],\n",
      "        [ 0.0089, -0.0425,  0.0039,  ...,  0.0378,  0.0046, -0.0239],\n",
      "        [ 0.0096, -0.0576, -0.0554,  ..., -0.0161,  0.0177,  0.0173]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.8.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.1025,  0.0493,  0.0273,  ..., -0.0317, -0.0251, -0.0552],\n",
      "        [-0.0457, -0.0239, -0.0159,  ..., -0.0226,  0.0123, -0.0835],\n",
      "        [-0.0366, -0.0649,  0.0021,  ..., -0.0277, -0.0021, -0.0249],\n",
      "        ...,\n",
      "        [-0.0500, -0.0061,  0.0288,  ..., -0.0002, -0.0071,  0.0327],\n",
      "        [-0.0059,  0.0659,  0.0216,  ..., -0.0469, -0.0035,  0.0239],\n",
      "        [-0.0031, -0.0498, -0.0532,  ...,  0.0197, -0.0161, -0.0349]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.8.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0869, -0.0356,  0.0248,  ..., -0.0166,  0.0094,  0.0128],\n",
      "        [-0.0186, -0.0435, -0.0396,  ...,  0.0056,  0.0737, -0.0183],\n",
      "        [ 0.0762,  0.0038,  0.0260,  ...,  0.0371,  0.0148, -0.0354],\n",
      "        ...,\n",
      "        [-0.0757,  0.0077, -0.0102,  ..., -0.0077,  0.0162, -0.0215],\n",
      "        [-0.0188, -0.0364, -0.0214,  ..., -0.0103,  0.0065,  0.0215],\n",
      "        [-0.0256, -0.0576,  0.0413,  ...,  0.0190, -0.0227, -0.0493]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.8.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.8.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.9.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0283,  0.0188,  0.0398,  ..., -0.0220,  0.0117,  0.0157],\n",
      "        [ 0.0488,  0.0182, -0.0186,  ..., -0.0036, -0.0029,  0.0183],\n",
      "        [-0.0439,  0.0148, -0.0140,  ...,  0.0254,  0.0432,  0.0154],\n",
      "        ...,\n",
      "        [-0.0200, -0.0173, -0.0479,  ...,  0.0178,  0.0058,  0.0244],\n",
      "        [-0.0298, -0.0366,  0.0203,  ..., -0.0591, -0.0132,  0.0332],\n",
      "        [-0.0099,  0.0525,  0.0571,  ...,  0.0233, -0.0261,  0.0334]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.9.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.9.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0212, -0.0132,  0.0119,  ..., -0.0172,  0.0160,  0.0256],\n",
      "        [ 0.0073,  0.0228, -0.0410,  ..., -0.0192, -0.0157,  0.0295],\n",
      "        [-0.0242, -0.0277,  0.0039,  ..., -0.0107, -0.0571, -0.0220],\n",
      "        ...,\n",
      "        [ 0.0315, -0.0309,  0.0153,  ..., -0.0019,  0.0065, -0.0002],\n",
      "        [-0.0288,  0.0006,  0.0261,  ..., -0.0023, -0.0187, -0.0264],\n",
      "        [-0.0038,  0.0287,  0.0183,  ...,  0.0005, -0.0018,  0.0108]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.9.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0286, -0.1270, -0.0977,  ...,  0.0464,  0.0449,  0.0952],\n",
      "        [-0.0525,  0.0466, -0.0515,  ..., -0.0320,  0.0312,  0.0205],\n",
      "        [-0.0075,  0.0070,  0.0039,  ...,  0.0135, -0.0112,  0.0132],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0103, -0.0138,  ..., -0.0084, -0.0488, -0.0228],\n",
      "        [ 0.0142, -0.0031, -0.0371,  ..., -0.0078,  0.0552,  0.0113],\n",
      "        [ 0.0142,  0.0369,  0.0378,  ...,  0.0159,  0.0176, -0.0771]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.9.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.9.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-2.2583e-02,  2.4170e-02,  1.0132e-02,  ..., -1.5076e-02,\n",
      "         -3.2715e-02, -5.0293e-02],\n",
      "        [ 1.7822e-02, -2.4536e-02,  1.6479e-03,  ..., -2.8198e-02,\n",
      "         -1.2085e-02,  9.7656e-03],\n",
      "        [ 6.9336e-02,  1.8311e-02, -2.1484e-02,  ...,  2.0874e-02,\n",
      "          1.5991e-02, -1.7334e-02],\n",
      "        ...,\n",
      "        [ 4.9316e-02,  6.0120e-03, -1.6975e-04,  ...,  4.0283e-02,\n",
      "          1.2085e-02, -2.8931e-02],\n",
      "        [ 1.3367e-02,  7.3547e-03,  6.9336e-02,  ..., -1.9043e-02,\n",
      "          2.0020e-02,  7.0801e-03],\n",
      "        [-3.6377e-02,  5.7678e-03,  1.3550e-02,  ...,  8.8692e-05,\n",
      "         -1.6602e-02, -1.1353e-02]], requires_grad=True)\n",
      "Layer: model.layers.9.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0325, -0.0364, -0.0308,  ..., -0.0645,  0.0027,  0.0125],\n",
      "        [-0.0928,  0.0342, -0.0168,  ...,  0.0047, -0.0432, -0.0239],\n",
      "        [-0.0050, -0.0742,  0.0223,  ...,  0.0067, -0.0188,  0.0066],\n",
      "        ...,\n",
      "        [ 0.0371,  0.0344,  0.0522,  ..., -0.0066, -0.0698, -0.0275],\n",
      "        [ 0.0250, -0.0063,  0.0273,  ..., -0.0435, -0.0454,  0.0148],\n",
      "        [ 0.0195,  0.0327,  0.0264,  ..., -0.0256, -0.0184,  0.0332]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.9.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0006,  0.0210, -0.0703,  ...,  0.0306, -0.0308,  0.0164],\n",
      "        [-0.0259, -0.0051,  0.0122,  ..., -0.0198, -0.0139,  0.0027],\n",
      "        [-0.0496,  0.0165, -0.0048,  ...,  0.0164,  0.0093, -0.0054],\n",
      "        ...,\n",
      "        [-0.0635, -0.0168,  0.0452,  ...,  0.0228, -0.0249, -0.0410],\n",
      "        [ 0.0435, -0.0247,  0.0018,  ...,  0.0366,  0.0559, -0.0051],\n",
      "        [ 0.0150, -0.0090, -0.0023,  ..., -0.0454,  0.0669,  0.0903]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.9.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0134, -0.0193, -0.0361,  ..., -0.0265,  0.0223, -0.0186],\n",
      "        [-0.0520, -0.0747,  0.0376,  ...,  0.0310, -0.0225,  0.0091],\n",
      "        [ 0.0356,  0.0176, -0.0292,  ..., -0.0469,  0.0115, -0.0148],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0019, -0.0098,  ...,  0.0757, -0.0386,  0.0349],\n",
      "        [-0.0276,  0.0364,  0.0097,  ...,  0.0713, -0.0342, -0.0762],\n",
      "        [ 0.0245, -0.0205, -0.0204,  ..., -0.0209, -0.0204,  0.0228]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.9.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0410, -0.0091,  0.0393,  ...,  0.0520, -0.0415, -0.0022],\n",
      "        [ 0.0101, -0.0444,  0.0267,  ..., -0.0206,  0.0299, -0.0209],\n",
      "        [ 0.0128, -0.0012, -0.0464,  ...,  0.0126,  0.0042,  0.0271],\n",
      "        ...,\n",
      "        [-0.0439, -0.0190, -0.0461,  ..., -0.0060,  0.0356,  0.0044],\n",
      "        [ 0.0270,  0.0045, -0.0056,  ..., -0.0144, -0.0601, -0.0271],\n",
      "        [ 0.0515, -0.0295,  0.0100,  ...,  0.0317,  0.0270, -0.0183]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.9.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.9.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.10.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0079,  0.0044, -0.0479,  ..., -0.0410, -0.0120,  0.0256],\n",
      "        [ 0.0175, -0.0028, -0.0317,  ..., -0.0461,  0.0457, -0.0361],\n",
      "        [ 0.0109, -0.0229,  0.0209,  ...,  0.0092, -0.0544, -0.0188],\n",
      "        ...,\n",
      "        [ 0.0366, -0.0132, -0.0461,  ...,  0.0371, -0.0146, -0.0214],\n",
      "        [ 0.0153, -0.0184, -0.0625,  ...,  0.0537,  0.0145, -0.0135],\n",
      "        [ 0.0193, -0.0255,  0.0347,  ..., -0.0508, -0.0050,  0.0669]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.10.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0471,  0.0072, -0.0522,  ..., -0.0334, -0.0058,  0.0403],\n",
      "        [ 0.0204,  0.0128,  0.0400,  ...,  0.0339,  0.1001,  0.0359],\n",
      "        [-0.0332, -0.0183,  0.0083,  ..., -0.0014, -0.0073,  0.0261],\n",
      "        ...,\n",
      "        [ 0.0234, -0.0094, -0.0238,  ...,  0.0091,  0.0094, -0.0036],\n",
      "        [ 0.0154, -0.0177,  0.0222,  ..., -0.0034, -0.0140, -0.0002],\n",
      "        [ 0.0031, -0.0244, -0.0063,  ..., -0.0018, -0.0164,  0.0347]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0376,  0.0344, -0.0146,  ..., -0.0062,  0.0102, -0.0131],\n",
      "        [ 0.0361,  0.0149,  0.0234,  ..., -0.0366, -0.0238, -0.0332],\n",
      "        [ 0.0073,  0.0045, -0.0430,  ..., -0.0108, -0.0850, -0.0591],\n",
      "        ...,\n",
      "        [ 0.0116,  0.0305,  0.0100,  ..., -0.0283,  0.0232, -0.0066],\n",
      "        [ 0.0374,  0.0483,  0.0062,  ...,  0.0090,  0.0195,  0.0442],\n",
      "        [-0.0197,  0.0120,  0.0020,  ..., -0.0073,  0.0267, -0.0107]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.10.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0184, -0.0269, -0.1123,  ..., -0.0486, -0.0216, -0.0532],\n",
      "        [ 0.0182, -0.0376,  0.0518,  ..., -0.0269,  0.1436, -0.0635],\n",
      "        [ 0.0674,  0.0033, -0.0566,  ...,  0.0181,  0.0889,  0.0334],\n",
      "        ...,\n",
      "        [-0.0244,  0.0162,  0.0095,  ..., -0.0303,  0.0374,  0.0146],\n",
      "        [-0.0222,  0.0244, -0.0308,  ...,  0.0251, -0.0045, -0.0083],\n",
      "        [ 0.0225, -0.0211,  0.0161,  ...,  0.0042, -0.0036, -0.0171]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0498,  0.0552, -0.0015,  ..., -0.0060,  0.0026,  0.0092],\n",
      "        [-0.0135,  0.0615, -0.0036,  ..., -0.0114,  0.0004, -0.0103],\n",
      "        [ 0.0267,  0.0067, -0.0422,  ..., -0.0259,  0.0251,  0.0039],\n",
      "        ...,\n",
      "        [-0.0869,  0.0479, -0.0229,  ..., -0.0198, -0.0535, -0.0054],\n",
      "        [-0.0038, -0.0277,  0.0391,  ...,  0.0013, -0.0444,  0.0356],\n",
      "        [ 0.0459,  0.0096, -0.0378,  ...,  0.0254, -0.0118,  0.0112]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0654,  0.0135, -0.0039,  ..., -0.0171,  0.0476, -0.0327],\n",
      "        [ 0.0297,  0.0282,  0.0317,  ...,  0.0193,  0.0018, -0.0304],\n",
      "        [-0.0388, -0.0032,  0.0635,  ..., -0.0325,  0.0132,  0.0018],\n",
      "        ...,\n",
      "        [-0.0452,  0.0079, -0.0002,  ...,  0.0187,  0.0273,  0.0122],\n",
      "        [-0.0337, -0.0378,  0.0292,  ..., -0.0087,  0.0415,  0.0220],\n",
      "        [ 0.0076,  0.0038, -0.0187,  ..., -0.0330,  0.0242, -0.0118]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0249, -0.0090,  0.0493,  ..., -0.0033,  0.0688,  0.0217],\n",
      "        [-0.0014,  0.0381,  0.0430,  ..., -0.0325,  0.0110, -0.0042],\n",
      "        [ 0.0203, -0.0071, -0.0110,  ..., -0.0295,  0.0031,  0.0021],\n",
      "        ...,\n",
      "        [ 0.0640, -0.0122, -0.0474,  ..., -0.0322,  0.0479, -0.0542],\n",
      "        [-0.0199,  0.0244, -0.0119,  ...,  0.0284, -0.0033,  0.0330],\n",
      "        [-0.0535, -0.0081, -0.0189,  ...,  0.0022,  0.0273, -0.0291]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0170,  0.0444, -0.0148,  ...,  0.0583, -0.0190, -0.0151],\n",
      "        [ 0.0131, -0.0025, -0.0400,  ..., -0.0388,  0.0488, -0.0056],\n",
      "        [ 0.0012,  0.0366, -0.0142,  ...,  0.0244,  0.0023,  0.0076],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0227, -0.0206,  ..., -0.0254,  0.0239,  0.0198],\n",
      "        [ 0.0674, -0.0225,  0.0099,  ...,  0.0236,  0.0096,  0.0471],\n",
      "        [ 0.0286,  0.0059, -0.0039,  ..., -0.0222,  0.0820,  0.0208]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.10.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.10.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.11.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0118,  0.0510, -0.0469,  ..., -0.0291, -0.0073, -0.0332],\n",
      "        [-0.0232, -0.0591,  0.0070,  ..., -0.0143,  0.0160, -0.0457],\n",
      "        [ 0.0576, -0.0178, -0.0161,  ...,  0.0208,  0.0008, -0.0420],\n",
      "        ...,\n",
      "        [ 0.0176,  0.0192,  0.0054,  ..., -0.0052,  0.0042, -0.0391],\n",
      "        [ 0.0275, -0.0176,  0.0155,  ..., -0.0055,  0.0046,  0.0078],\n",
      "        [-0.0282, -0.0615,  0.0393,  ..., -0.0527,  0.0476, -0.0275]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.11.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0223, -0.0076, -0.0221,  ..., -0.0153, -0.0503, -0.0063],\n",
      "        [ 0.0121, -0.0225,  0.0238,  ...,  0.0308, -0.0114,  0.0203],\n",
      "        [-0.0049,  0.0101,  0.0223,  ..., -0.0417, -0.0249,  0.0142],\n",
      "        ...,\n",
      "        [ 0.0214,  0.0266,  0.0226,  ...,  0.0190, -0.0325, -0.0199],\n",
      "        [-0.0076,  0.0085, -0.0342,  ..., -0.0081, -0.0270, -0.0186],\n",
      "        [-0.1348, -0.0150,  0.0212,  ...,  0.0386, -0.0552, -0.0298]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0192, -0.0093, -0.0356,  ..., -0.0244,  0.0410,  0.0164],\n",
      "        [-0.0620,  0.0037, -0.0234,  ...,  0.0356,  0.0002,  0.0046],\n",
      "        [-0.0190,  0.0859, -0.0167,  ..., -0.0040, -0.0212,  0.0190],\n",
      "        ...,\n",
      "        [ 0.0139, -0.0054, -0.0015,  ..., -0.0293,  0.0276, -0.0011],\n",
      "        [-0.0079, -0.0177, -0.0233,  ...,  0.0410, -0.0220, -0.0330],\n",
      "        [-0.0154, -0.0119,  0.0258,  ..., -0.0060,  0.0125, -0.0221]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.11.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0771, -0.0154,  0.0039,  ...,  0.0957,  0.0251,  0.0557],\n",
      "        [ 0.0248,  0.0674, -0.0420,  ..., -0.0097,  0.0723, -0.0107],\n",
      "        [ 0.0449, -0.0391, -0.0199,  ...,  0.0557,  0.0129, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0021, -0.0547, -0.0046,  ...,  0.0420,  0.0079, -0.0244],\n",
      "        [ 0.0042,  0.0076, -0.0291,  ...,  0.0454,  0.0435,  0.0337],\n",
      "        [ 0.0322,  0.0294,  0.0200,  ..., -0.0019, -0.0233, -0.0039]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0077, -0.0400, -0.0308,  ...,  0.0109, -0.0096, -0.0518],\n",
      "        [-0.0049,  0.0210, -0.0133,  ..., -0.0212,  0.0334,  0.0425],\n",
      "        [-0.0076, -0.0254, -0.0020,  ...,  0.0155,  0.0022,  0.0123],\n",
      "        ...,\n",
      "        [-0.0294,  0.0422,  0.0148,  ..., -0.0332, -0.0244, -0.0036],\n",
      "        [-0.0112,  0.0040, -0.0193,  ..., -0.0498, -0.0222, -0.0242],\n",
      "        [ 0.0537,  0.0043, -0.0120,  ...,  0.0405, -0.0552, -0.0496]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0039, -0.0217,  0.0126,  ...,  0.0415, -0.0684,  0.0276],\n",
      "        [-0.0383, -0.0143, -0.0193,  ...,  0.0698, -0.0046,  0.0427],\n",
      "        [ 0.0281, -0.0087,  0.0237,  ...,  0.0437, -0.0178,  0.0170],\n",
      "        ...,\n",
      "        [-0.0223,  0.0107, -0.0300,  ...,  0.0459, -0.0161, -0.0151],\n",
      "        [ 0.0330,  0.0095, -0.0182,  ..., -0.0493, -0.0166,  0.0413],\n",
      "        [ 0.0217, -0.0145,  0.0161,  ...,  0.0232,  0.0051,  0.0108]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0354,  0.0200, -0.0054,  ..., -0.0104,  0.0181,  0.0625],\n",
      "        [ 0.0371,  0.0157,  0.0344,  ...,  0.0105,  0.0161, -0.0349],\n",
      "        [-0.0032,  0.0121, -0.0220,  ..., -0.0669,  0.0449, -0.0130],\n",
      "        ...,\n",
      "        [-0.0157,  0.0371,  0.0776,  ..., -0.0006, -0.0080, -0.0295],\n",
      "        [-0.0140, -0.0011,  0.0276,  ..., -0.0295,  0.0496, -0.0361],\n",
      "        [-0.0155, -0.0222, -0.0110,  ...,  0.0442, -0.0105, -0.0050]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0439, -0.0102,  0.0461,  ...,  0.0023, -0.0234,  0.0045],\n",
      "        [ 0.0170, -0.0308,  0.0649,  ...,  0.0146, -0.0054, -0.0850],\n",
      "        [-0.0532,  0.0332, -0.0113,  ...,  0.0703, -0.0062, -0.0396],\n",
      "        ...,\n",
      "        [ 0.0237,  0.0383,  0.0220,  ...,  0.0007, -0.0050,  0.0197],\n",
      "        [ 0.0461,  0.0454,  0.0330,  ..., -0.0060,  0.0115, -0.0098],\n",
      "        [ 0.0742, -0.0513, -0.0354,  ..., -0.0381,  0.0083, -0.0220]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.11.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.11.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.12.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0508,  0.0449, -0.0232,  ...,  0.0371, -0.0148, -0.0144],\n",
      "        [-0.0099,  0.0332, -0.0420,  ..., -0.0262, -0.0320, -0.0082],\n",
      "        [ 0.0104,  0.0156, -0.0330,  ..., -0.0339, -0.0007, -0.0240],\n",
      "        ...,\n",
      "        [-0.0019,  0.0019, -0.0410,  ...,  0.0292, -0.0184,  0.0442],\n",
      "        [ 0.0082, -0.0259, -0.0098,  ...,  0.0183,  0.0238, -0.0393],\n",
      "        [-0.0143,  0.0030,  0.0254,  ...,  0.0183,  0.0136,  0.0243]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.12.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0183, -0.0012,  0.0126,  ...,  0.0557, -0.0251, -0.0635],\n",
      "        [-0.0049, -0.0042, -0.0520,  ..., -0.0444,  0.0101, -0.0503],\n",
      "        [-0.0728,  0.0459,  0.0332,  ..., -0.0237, -0.0212, -0.0171],\n",
      "        ...,\n",
      "        [ 0.0952, -0.0093, -0.0045,  ...,  0.0162, -0.1050,  0.0133],\n",
      "        [ 0.0082,  0.0046,  0.0337,  ...,  0.0182, -0.0232, -0.0131],\n",
      "        [ 0.0249,  0.0151, -0.0391,  ..., -0.0197, -0.0100, -0.0099]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0131, -0.0405,  0.0109,  ...,  0.0400, -0.0179, -0.0162],\n",
      "        [-0.0179, -0.0058, -0.0298,  ...,  0.0212,  0.0166, -0.0151],\n",
      "        [ 0.0439,  0.0603, -0.0038,  ..., -0.0596, -0.0137,  0.0610],\n",
      "        ...,\n",
      "        [-0.0127,  0.0041, -0.0007,  ...,  0.0041, -0.0103,  0.0038],\n",
      "        [-0.0056,  0.0003, -0.0165,  ..., -0.0295,  0.0215, -0.0048],\n",
      "        [-0.0254, -0.0008, -0.0075,  ...,  0.0139, -0.0078,  0.0474]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.12.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0178, -0.0210, -0.0066,  ...,  0.0078, -0.0065, -0.0032],\n",
      "        [ 0.0176, -0.0349,  0.0220,  ...,  0.0192,  0.0192,  0.0854],\n",
      "        [ 0.0510, -0.0386,  0.0099,  ..., -0.1152,  0.0581, -0.0001],\n",
      "        ...,\n",
      "        [ 0.0258,  0.0334, -0.0339,  ..., -0.0027,  0.0371,  0.0300],\n",
      "        [ 0.0256,  0.0019,  0.0089,  ..., -0.0188, -0.0073,  0.0026],\n",
      "        [-0.0391, -0.0106, -0.0043,  ...,  0.0029, -0.0193,  0.0131]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0452, -0.0591,  0.0074,  ..., -0.0114,  0.0275, -0.0033],\n",
      "        [-0.0031,  0.0364, -0.0305,  ..., -0.0197,  0.0144,  0.0270],\n",
      "        [ 0.0542,  0.0258, -0.0048,  ...,  0.0312,  0.0049, -0.0260],\n",
      "        ...,\n",
      "        [-0.0674,  0.0457,  0.0554,  ...,  0.0076,  0.0025,  0.0177],\n",
      "        [ 0.0376,  0.0114,  0.0199,  ..., -0.0066, -0.0461,  0.0063],\n",
      "        [-0.0464, -0.0129, -0.0830,  ...,  0.0138,  0.0099, -0.0067]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0210, -0.0125, -0.0354,  ...,  0.0232,  0.0204, -0.0272],\n",
      "        [-0.0152,  0.0840,  0.0063,  ...,  0.0193,  0.0518,  0.0159],\n",
      "        [-0.0344,  0.0786,  0.0530,  ..., -0.0186,  0.0591,  0.0598],\n",
      "        ...,\n",
      "        [-0.0378,  0.0574, -0.0071,  ...,  0.0253, -0.0476,  0.0041],\n",
      "        [-0.0114,  0.0242, -0.0255,  ...,  0.0170,  0.0518,  0.0408],\n",
      "        [-0.0369,  0.0078,  0.0498,  ..., -0.0160,  0.0781, -0.0596]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0110,  0.0603,  0.0049,  ...,  0.0046,  0.0366,  0.0145],\n",
      "        [-0.0272,  0.0498,  0.0564,  ...,  0.0311, -0.0192,  0.0317],\n",
      "        [ 0.0134,  0.0649, -0.0069,  ...,  0.0305, -0.0150,  0.0223],\n",
      "        ...,\n",
      "        [-0.0265,  0.0074,  0.0337,  ..., -0.0140, -0.0371,  0.0228],\n",
      "        [-0.0544,  0.0330, -0.0400,  ..., -0.0141,  0.0089, -0.0894],\n",
      "        [ 0.0522, -0.0488, -0.0212,  ...,  0.0513, -0.0518,  0.0096]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0330,  0.0383,  0.0037,  ..., -0.0018, -0.0297,  0.0369],\n",
      "        [ 0.0645, -0.0312,  0.0420,  ..., -0.0435, -0.0082, -0.0376],\n",
      "        [-0.0284,  0.0096,  0.0205,  ...,  0.0261, -0.0239, -0.0244],\n",
      "        ...,\n",
      "        [-0.0430, -0.0229, -0.0198,  ...,  0.0283, -0.0181,  0.0291],\n",
      "        [ 0.0161, -0.0201, -0.0184,  ...,  0.0322,  0.0143, -0.0298],\n",
      "        [ 0.0312, -0.0100,  0.0239,  ..., -0.0239, -0.0400,  0.0178]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.12.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.12.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.13.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0413, -0.0530, -0.0400,  ...,  0.0145, -0.0259,  0.0405],\n",
      "        [ 0.0087, -0.0140, -0.0232,  ...,  0.0107, -0.0200, -0.0237],\n",
      "        [-0.0101, -0.0718,  0.0315,  ...,  0.0275,  0.0016, -0.0041],\n",
      "        ...,\n",
      "        [-0.0096, -0.0267,  0.0114,  ..., -0.0510, -0.0312,  0.0134],\n",
      "        [ 0.0474,  0.0415,  0.0173,  ..., -0.0024,  0.0752, -0.0103],\n",
      "        [ 0.0255, -0.0214,  0.0145,  ..., -0.0378,  0.0259,  0.0391]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.13.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.13.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 2.7771e-03,  3.2959e-03,  1.2939e-02,  ...,  6.6895e-02,\n",
      "          6.3477e-02,  7.3730e-02],\n",
      "        [-1.4587e-02, -7.4219e-02, -2.6733e-02,  ...,  2.0020e-02,\n",
      "         -3.4424e-02,  4.3945e-02],\n",
      "        [-4.0436e-04, -2.3926e-02,  1.3306e-02,  ...,  4.4678e-02,\n",
      "         -1.5747e-02,  1.5015e-02],\n",
      "        ...,\n",
      "        [-3.0670e-03, -2.5757e-02,  7.1411e-03,  ...,  1.1108e-02,\n",
      "         -1.1353e-02, -1.2146e-02],\n",
      "        [-4.2480e-02,  1.9043e-02,  6.0120e-03,  ..., -3.3264e-03,\n",
      "          8.9111e-03, -1.9287e-02],\n",
      "        [ 1.4038e-02, -1.1292e-03,  3.2349e-03,  ..., -1.9775e-02,\n",
      "         -4.1962e-05, -1.8555e-02]], requires_grad=True)\n",
      "Layer: model.layers.13.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0400, -0.0190, -0.0928,  ..., -0.0413,  0.0437, -0.0193],\n",
      "        [-0.0381, -0.0034,  0.0359,  ..., -0.0459, -0.0723,  0.0598],\n",
      "        [-0.0410,  0.0184,  0.0557,  ..., -0.0162,  0.0017, -0.0060],\n",
      "        ...,\n",
      "        [ 0.0291,  0.0272, -0.0339,  ..., -0.0342,  0.0811,  0.0027],\n",
      "        [-0.0269, -0.0170, -0.0249,  ...,  0.0037,  0.0222,  0.0081],\n",
      "        [-0.0154, -0.0069,  0.0134,  ...,  0.0197, -0.0265,  0.0029]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.13.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.13.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0303, -0.0176, -0.0176,  ...,  0.0305, -0.0106,  0.0112],\n",
      "        [-0.0090,  0.0437,  0.0136,  ..., -0.0093,  0.0155, -0.0386],\n",
      "        [ 0.0100,  0.0459, -0.0420,  ...,  0.0003,  0.0027,  0.0118],\n",
      "        ...,\n",
      "        [-0.0300, -0.0190,  0.0103,  ..., -0.0532, -0.0269, -0.0149],\n",
      "        [ 0.0100,  0.0127, -0.0002,  ...,  0.1133, -0.0090,  0.0762],\n",
      "        [ 0.0020, -0.0544, -0.0374,  ..., -0.0243,  0.0090,  0.0469]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.13.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0127, -0.0137, -0.0586,  ..., -0.0064, -0.0007, -0.0287],\n",
      "        [-0.0396, -0.0232, -0.0282,  ..., -0.0157, -0.0216, -0.0265],\n",
      "        [ 0.0266, -0.0225, -0.0374,  ...,  0.0374, -0.0967, -0.0101],\n",
      "        ...,\n",
      "        [-0.0049,  0.0250, -0.0008,  ...,  0.0077,  0.0337, -0.0088],\n",
      "        [-0.0261,  0.0137, -0.0354,  ..., -0.0527,  0.0057,  0.0138],\n",
      "        [-0.0056, -0.0090,  0.0197,  ...,  0.0100,  0.0077,  0.0032]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.13.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 9.6436e-03, -4.3030e-03,  8.3008e-03,  ...,  4.5410e-02,\n",
      "         -4.5166e-02,  2.1484e-02],\n",
      "        [ 1.4465e-02,  4.4823e-05, -3.0762e-02,  ..., -2.5024e-02,\n",
      "         -9.2163e-03,  4.6631e-02],\n",
      "        [ 5.1514e-02, -6.2866e-03, -4.5898e-02,  ...,  4.1992e-02,\n",
      "          7.6904e-03, -4.3945e-02],\n",
      "        ...,\n",
      "        [ 4.6875e-02,  1.8433e-02,  2.9785e-02,  ..., -8.6670e-03,\n",
      "          8.3984e-02, -4.3945e-02],\n",
      "        [ 3.2227e-02,  6.2561e-03,  4.7607e-02,  ..., -2.7710e-02,\n",
      "         -2.7710e-02,  8.8867e-02],\n",
      "        [-4.8828e-02,  4.0283e-03, -3.3203e-02,  ...,  2.9053e-02,\n",
      "          1.0620e-02,  2.5635e-02]], requires_grad=True)\n",
      "Layer: model.layers.13.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0059, -0.0422, -0.0126,  ...,  0.0013, -0.0039,  0.0156],\n",
      "        [-0.0058, -0.0075, -0.0405,  ...,  0.0107,  0.0140, -0.0098],\n",
      "        [-0.0325,  0.0547,  0.0045,  ...,  0.0009, -0.0256,  0.0166],\n",
      "        ...,\n",
      "        [ 0.0038, -0.0120,  0.0168,  ..., -0.0007,  0.0170, -0.0251],\n",
      "        [ 0.0586,  0.0325, -0.0364,  ..., -0.0082,  0.0150, -0.0337],\n",
      "        [ 0.0019,  0.0031,  0.0188,  ..., -0.0132,  0.0099,  0.0014]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.13.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0206,  0.0068, -0.0420,  ..., -0.0206, -0.0337, -0.0393],\n",
      "        [-0.0508,  0.0116,  0.0515,  ..., -0.0148,  0.0432, -0.0188],\n",
      "        [-0.0041, -0.0206, -0.0160,  ...,  0.0028, -0.0171,  0.0537],\n",
      "        ...,\n",
      "        [-0.0364,  0.0128,  0.0525,  ..., -0.0300, -0.0347,  0.0034],\n",
      "        [ 0.0439,  0.0278, -0.0535,  ...,  0.0193, -0.0155, -0.0317],\n",
      "        [ 0.0271,  0.0068,  0.0189,  ..., -0.0295, -0.0256,  0.0576]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.13.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.13.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.14.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0977, -0.0032, -0.0159,  ..., -0.0400,  0.0532, -0.0483],\n",
      "        [-0.0048,  0.0408,  0.0552,  ..., -0.0041,  0.0282,  0.0386],\n",
      "        [ 0.0264,  0.0023, -0.0143,  ...,  0.0033, -0.0068, -0.0057],\n",
      "        ...,\n",
      "        [-0.0283,  0.0079, -0.0265,  ..., -0.0022,  0.0605, -0.0045],\n",
      "        [-0.0006, -0.0030,  0.0096,  ..., -0.0415,  0.0747,  0.0532],\n",
      "        [ 0.0059,  0.0210, -0.0129,  ..., -0.0320, -0.0215,  0.0593]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.14.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.14.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0159,  0.0079,  0.0374,  ...,  0.0029,  0.0177,  0.0124],\n",
      "        [-0.0620,  0.0215,  0.0684,  ...,  0.0488, -0.0243, -0.0122],\n",
      "        [-0.0041, -0.0121, -0.0425,  ..., -0.0500,  0.0352,  0.0073],\n",
      "        ...,\n",
      "        [ 0.0034, -0.0101, -0.0014,  ...,  0.0005, -0.0081,  0.0027],\n",
      "        [ 0.0278, -0.0234,  0.0170,  ..., -0.0261, -0.0649,  0.0342],\n",
      "        [-0.0088,  0.0044,  0.0130,  ..., -0.0248, -0.0134, -0.0053]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.14.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-2.0264e-02,  6.6406e-02, -4.0588e-03,  ...,  3.8605e-03,\n",
      "         -1.5411e-03, -3.5889e-02],\n",
      "        [-3.0823e-03, -7.5073e-03, -3.4180e-02,  ...,  4.3030e-03,\n",
      "         -3.7384e-04,  9.9487e-03],\n",
      "        [ 1.6357e-02, -1.8433e-02, -4.1016e-02,  ..., -2.8610e-05,\n",
      "          3.0273e-02,  2.7344e-02],\n",
      "        ...,\n",
      "        [ 3.0151e-02,  3.7109e-02,  3.0151e-02,  ..., -4.2480e-02,\n",
      "          2.3560e-02,  6.1340e-03],\n",
      "        [ 1.1414e-02, -2.6733e-02, -1.0864e-02,  ..., -6.7139e-03,\n",
      "         -4.4922e-02, -4.0283e-02],\n",
      "        [-3.5400e-02,  3.0762e-02,  1.9897e-02,  ..., -3.6621e-02,\n",
      "         -4.3701e-02,  2.5024e-02]], requires_grad=True)\n",
      "Layer: model.layers.14.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.14.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0452,  0.0209, -0.0259,  ..., -0.0327,  0.0027,  0.0386],\n",
      "        [-0.0747, -0.0251, -0.0515,  ..., -0.0459, -0.0204, -0.0618],\n",
      "        [ 0.0103, -0.0092, -0.0126,  ...,  0.0118, -0.0035, -0.0056],\n",
      "        ...,\n",
      "        [-0.0322, -0.0330,  0.0859,  ...,  0.0139, -0.0315,  0.0139],\n",
      "        [ 0.0486,  0.0190,  0.0107,  ...,  0.0820,  0.0067,  0.0532],\n",
      "        [-0.0013, -0.0332,  0.0258,  ...,  0.0093,  0.0150, -0.0342]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.14.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 1.8555e-02, -4.3945e-02, -4.9805e-02,  ..., -5.4626e-03,\n",
      "          9.9609e-02, -5.1514e-02],\n",
      "        [-4.4434e-02, -2.6703e-04,  1.8692e-03,  ..., -1.2146e-02,\n",
      "          1.5991e-02, -8.9355e-02],\n",
      "        [ 3.8574e-02, -2.0508e-02, -1.6937e-03,  ..., -2.3071e-02,\n",
      "         -4.7363e-02, -2.9785e-02],\n",
      "        ...,\n",
      "        [ 9.3384e-03,  1.5259e-02,  1.2939e-02,  ...,  2.2949e-02,\n",
      "         -2.4658e-02,  1.7319e-03],\n",
      "        [ 4.4922e-02, -1.1353e-02, -6.0547e-02,  ..., -5.8105e-02,\n",
      "         -7.7148e-02,  5.5664e-02],\n",
      "        [ 1.3794e-02,  2.8931e-02, -2.0630e-02,  ...,  4.2419e-03,\n",
      "          2.0508e-02, -7.6294e-06]], requires_grad=True)\n",
      "Layer: model.layers.14.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0425, -0.0317, -0.0315,  ...,  0.0019,  0.0364, -0.0244],\n",
      "        [-0.0908, -0.0025,  0.0087,  ...,  0.0271,  0.0189,  0.0238],\n",
      "        [ 0.0442, -0.0053,  0.0052,  ...,  0.0173, -0.0067, -0.0238],\n",
      "        ...,\n",
      "        [ 0.0391,  0.0432, -0.0265,  ..., -0.0109,  0.0038,  0.0408],\n",
      "        [ 0.0120, -0.0101, -0.0092,  ..., -0.0125,  0.0132, -0.0693],\n",
      "        [-0.0190,  0.0014, -0.0192,  ..., -0.0366,  0.0522,  0.0309]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.14.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0072,  0.0123,  0.0035,  ..., -0.0005,  0.0178, -0.0117],\n",
      "        [ 0.0183,  0.0135,  0.0236,  ..., -0.0024,  0.0476, -0.0014],\n",
      "        [-0.0120, -0.0136,  0.0205,  ...,  0.0059, -0.0596,  0.0027],\n",
      "        ...,\n",
      "        [-0.0103, -0.0057, -0.0598,  ...,  0.0422, -0.0542, -0.0284],\n",
      "        [ 0.0056,  0.0488,  0.0182,  ...,  0.0327,  0.0337,  0.0374],\n",
      "        [-0.0820,  0.0188,  0.0288,  ..., -0.0430,  0.0376, -0.0908]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.14.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0205, -0.0061,  0.0103,  ..., -0.0334,  0.0303, -0.0308],\n",
      "        [ 0.0300,  0.0107, -0.0320,  ..., -0.0161, -0.0076, -0.0408],\n",
      "        [ 0.0250,  0.0077, -0.0051,  ..., -0.0405,  0.0043, -0.0176],\n",
      "        ...,\n",
      "        [-0.0008,  0.0066, -0.0347,  ...,  0.0295, -0.0062, -0.0364],\n",
      "        [-0.0405,  0.0496, -0.0186,  ..., -0.0474,  0.0197,  0.0014],\n",
      "        [ 0.0071, -0.0132,  0.0275,  ..., -0.0381,  0.0128, -0.0591]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.14.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.14.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.15.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0171, -0.0454,  0.0251,  ...,  0.0221,  0.0076,  0.0498],\n",
      "        [ 0.0287, -0.0344,  0.0309,  ..., -0.0635, -0.0059, -0.0096],\n",
      "        [-0.0366,  0.0244,  0.0703,  ..., -0.0342, -0.0391,  0.0020],\n",
      "        ...,\n",
      "        [ 0.0103,  0.0114, -0.0146,  ...,  0.0092, -0.0029,  0.0430],\n",
      "        [ 0.0067,  0.0055,  0.0150,  ..., -0.1035, -0.0219,  0.0432],\n",
      "        [-0.0299,  0.0101,  0.0527,  ..., -0.0369, -0.0500,  0.0474]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.15.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0022, -0.0183, -0.0481,  ...,  0.0212,  0.0386, -0.0044],\n",
      "        [-0.0190,  0.0173,  0.0260,  ...,  0.0113,  0.0071,  0.0181],\n",
      "        [ 0.0037, -0.0176, -0.0118,  ..., -0.0173, -0.0198,  0.0129],\n",
      "        ...,\n",
      "        [ 0.0315, -0.0239,  0.0087,  ...,  0.0116, -0.0154,  0.0029],\n",
      "        [-0.0074,  0.0178,  0.0271,  ...,  0.0562, -0.0064,  0.0479],\n",
      "        [ 0.0103, -0.0322, -0.0339,  ...,  0.0184, -0.0366,  0.0008]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0197, -0.0069, -0.0557,  ..., -0.0347,  0.0542, -0.0255],\n",
      "        [-0.0386,  0.0005,  0.0474,  ..., -0.0153,  0.0308, -0.0535],\n",
      "        [-0.0040, -0.0073,  0.0444,  ...,  0.0410, -0.0087,  0.0276],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0017,  0.0025,  ..., -0.0086,  0.0513,  0.0413],\n",
      "        [-0.0009, -0.0077, -0.0041,  ...,  0.0378,  0.0427, -0.0159],\n",
      "        [-0.0162,  0.0156, -0.0171,  ...,  0.0222, -0.0067, -0.0255]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.15.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0459,  0.0610, -0.0070,  ..., -0.0035,  0.0133,  0.0140],\n",
      "        [-0.0115,  0.0144, -0.0032,  ...,  0.0066,  0.0225,  0.0146],\n",
      "        [ 0.0400,  0.0037,  0.0352,  ...,  0.0608, -0.0454, -0.0107],\n",
      "        ...,\n",
      "        [-0.0053,  0.0586,  0.0452,  ..., -0.0376, -0.0830, -0.0457],\n",
      "        [-0.0479, -0.0192,  0.0342,  ...,  0.0339,  0.0215, -0.0933],\n",
      "        [ 0.0098,  0.0014, -0.0253,  ...,  0.0781, -0.0013, -0.0203]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0124,  0.0366, -0.0261,  ..., -0.0466,  0.0035, -0.0131],\n",
      "        [-0.0781,  0.0014, -0.0405,  ...,  0.0229,  0.0211, -0.0420],\n",
      "        [ 0.0309, -0.0713, -0.0026,  ...,  0.0210, -0.0152, -0.0063],\n",
      "        ...,\n",
      "        [ 0.0227, -0.0732,  0.0041,  ..., -0.0493,  0.0220,  0.0134],\n",
      "        [ 0.0082, -0.0273,  0.0317,  ...,  0.0244,  0.0383, -0.0317],\n",
      "        [ 0.0110,  0.0082, -0.0139,  ...,  0.0255,  0.0009,  0.0036]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0674, -0.0381, -0.0466,  ...,  0.0183, -0.0145,  0.0425],\n",
      "        [-0.0225, -0.0330, -0.0232,  ...,  0.0229, -0.0703,  0.0046],\n",
      "        [ 0.0513, -0.0166, -0.0008,  ..., -0.0073, -0.0356,  0.0508],\n",
      "        ...,\n",
      "        [-0.0036, -0.0106, -0.0217,  ..., -0.0361,  0.0293,  0.0383],\n",
      "        [-0.0664,  0.0264, -0.0154,  ..., -0.0349,  0.0242,  0.0398],\n",
      "        [ 0.0038, -0.0173, -0.0204,  ..., -0.0742, -0.0183, -0.0265]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0304,  0.0142, -0.0150,  ..., -0.0209,  0.0466, -0.0008],\n",
      "        [ 0.0435,  0.0347,  0.0334,  ...,  0.0065,  0.0051,  0.0181],\n",
      "        [ 0.0125,  0.0168,  0.0327,  ...,  0.0481,  0.0342,  0.0082],\n",
      "        ...,\n",
      "        [-0.0342,  0.0479,  0.0078,  ...,  0.0030,  0.0016,  0.0240],\n",
      "        [-0.0322, -0.0115, -0.0247,  ..., -0.0420, -0.0265,  0.0284],\n",
      "        [-0.0045,  0.0045, -0.0156,  ..., -0.0403,  0.0310,  0.0124]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0299,  0.0625,  0.0018,  ...,  0.0325, -0.0479, -0.0444],\n",
      "        [-0.0159,  0.0388,  0.0684,  ...,  0.0742, -0.0139, -0.0254],\n",
      "        [ 0.0245,  0.0109,  0.0850,  ..., -0.0070, -0.0167,  0.0164],\n",
      "        ...,\n",
      "        [ 0.0200, -0.0225,  0.0231,  ...,  0.0194,  0.0332,  0.0085],\n",
      "        [-0.0137, -0.0155, -0.0022,  ..., -0.0400, -0.0072,  0.0209],\n",
      "        [ 0.0261,  0.0173, -0.0107,  ...,  0.0117,  0.0361,  0.0391]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.15.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.15.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.16.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0122, -0.0134, -0.0090,  ..., -0.0036, -0.0101, -0.0139],\n",
      "        [-0.0069, -0.0260, -0.0017,  ...,  0.0075,  0.0209, -0.0157],\n",
      "        [ 0.0092, -0.0864, -0.0342,  ..., -0.0227,  0.0732,  0.0143],\n",
      "        ...,\n",
      "        [-0.0420,  0.0064,  0.0019,  ..., -0.0248,  0.0615,  0.0101],\n",
      "        [ 0.0070, -0.0106,  0.0199,  ...,  0.0098, -0.0011, -0.0187],\n",
      "        [-0.0254, -0.0066, -0.0259,  ...,  0.0312, -0.0361,  0.0137]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.16.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.16.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0087,  0.0131,  0.0135,  ...,  0.0057, -0.0250,  0.0184],\n",
      "        [-0.0752,  0.0356, -0.0094,  ..., -0.0157,  0.0210,  0.0023],\n",
      "        [ 0.0231, -0.0254,  0.0222,  ...,  0.0003, -0.0050,  0.0435],\n",
      "        ...,\n",
      "        [-0.0297, -0.0264, -0.0723,  ...,  0.0157, -0.0090,  0.0376],\n",
      "        [ 0.0010,  0.0432,  0.0110,  ...,  0.0052,  0.0096, -0.0197],\n",
      "        [-0.0098,  0.0039,  0.0157,  ...,  0.0371,  0.0425, -0.0098]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.16.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0383,  0.0396, -0.0366,  ...,  0.0221,  0.0209,  0.0281],\n",
      "        [ 0.0471, -0.0086, -0.0439,  ..., -0.0503, -0.0815,  0.0330],\n",
      "        [ 0.0151, -0.0076, -0.0178,  ..., -0.0022, -0.0122,  0.0527],\n",
      "        ...,\n",
      "        [ 0.0013, -0.0164, -0.0064,  ..., -0.0065, -0.0247,  0.0366],\n",
      "        [ 0.0034,  0.0160, -0.0208,  ..., -0.0204, -0.0023,  0.0282],\n",
      "        [ 0.0005,  0.0183,  0.0153,  ..., -0.0466, -0.0327,  0.0007]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.16.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.16.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0101,  0.0051, -0.0069,  ..., -0.0017, -0.0162,  0.0186],\n",
      "        [ 0.0033, -0.0030,  0.0610,  ..., -0.0420,  0.0371,  0.0193],\n",
      "        [ 0.0115, -0.0242, -0.0087,  ...,  0.0142,  0.0029, -0.0266],\n",
      "        ...,\n",
      "        [ 0.0181,  0.0121,  0.0229,  ...,  0.0156, -0.0061, -0.0148],\n",
      "        [-0.0289,  0.0098,  0.0581,  ...,  0.0374, -0.0420, -0.0454],\n",
      "        [-0.0366,  0.0320,  0.0190,  ..., -0.0603,  0.0126,  0.0183]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.16.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0145, -0.0547, -0.0026,  ..., -0.0109, -0.0610,  0.0248],\n",
      "        [ 0.0111, -0.0732,  0.0249,  ..., -0.0247,  0.0137, -0.0498],\n",
      "        [ 0.0732, -0.0425,  0.0151,  ..., -0.0121,  0.0286,  0.0806],\n",
      "        ...,\n",
      "        [-0.0270, -0.0081,  0.0825,  ..., -0.0271,  0.0098, -0.0160],\n",
      "        [-0.0161, -0.0046, -0.0073,  ...,  0.0132, -0.0464,  0.0439],\n",
      "        [-0.0190, -0.0491, -0.0157,  ...,  0.0014,  0.0535,  0.0168]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.16.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0179,  0.0114, -0.0151,  ..., -0.0188,  0.0198,  0.0618],\n",
      "        [-0.0204, -0.0186,  0.0087,  ...,  0.0271,  0.0366,  0.0361],\n",
      "        [ 0.0031,  0.0312,  0.0072,  ..., -0.0437,  0.0111, -0.0249],\n",
      "        ...,\n",
      "        [-0.0488, -0.0300,  0.0430,  ...,  0.0315, -0.0459, -0.0215],\n",
      "        [ 0.0649,  0.0525,  0.0189,  ..., -0.0293,  0.0090, -0.0261],\n",
      "        [-0.0605,  0.0239, -0.0391,  ..., -0.0179,  0.0381,  0.0439]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.16.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-2.5482e-03, -8.3008e-03,  3.9978e-03,  ...,  3.1494e-02,\n",
      "         -1.4282e-02, -7.0312e-02],\n",
      "        [ 7.9590e-02, -5.9814e-02,  4.6875e-02,  ..., -1.2085e-02,\n",
      "         -2.7344e-02, -5.0781e-02],\n",
      "        [-2.0264e-02,  3.8147e-03, -5.4688e-02,  ..., -3.6621e-02,\n",
      "          3.1006e-02, -4.5776e-05],\n",
      "        ...,\n",
      "        [-7.8613e-02, -6.6406e-02,  3.1982e-02,  ...,  3.2959e-02,\n",
      "          1.2512e-02, -2.5635e-02],\n",
      "        [-1.9684e-03,  1.5503e-02,  8.4229e-03,  ...,  1.0864e-02,\n",
      "          8.6670e-03,  8.4229e-03],\n",
      "        [ 1.5869e-02, -5.3223e-02, -5.2490e-03,  ..., -2.8198e-02,\n",
      "         -3.5156e-02, -1.6113e-02]], requires_grad=True)\n",
      "Layer: model.layers.16.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0249,  0.0297, -0.0212,  ..., -0.0330,  0.0640,  0.0129],\n",
      "        [ 0.0083, -0.0654, -0.0117,  ..., -0.0781,  0.0403, -0.0562],\n",
      "        [ 0.0057, -0.0010, -0.0055,  ...,  0.0088, -0.0562,  0.0096],\n",
      "        ...,\n",
      "        [ 0.0265, -0.0537, -0.0464,  ..., -0.0129, -0.0003,  0.0018],\n",
      "        [-0.0557, -0.0515, -0.0034,  ..., -0.0334,  0.0003, -0.0527],\n",
      "        [-0.0771, -0.0215, -0.0302,  ..., -0.0118, -0.0092, -0.0269]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.16.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.16.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.17.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0128,  0.0669, -0.0022,  ...,  0.0190,  0.0317, -0.0137],\n",
      "        [-0.0286,  0.0008,  0.0040,  ...,  0.0134,  0.0178, -0.0115],\n",
      "        [-0.0018,  0.0025,  0.0130,  ...,  0.0713,  0.0664,  0.0635],\n",
      "        ...,\n",
      "        [ 0.0084, -0.0327, -0.0089,  ...,  0.0011,  0.0046, -0.0033],\n",
      "        [-0.0193,  0.0055,  0.0052,  ..., -0.0181, -0.0364,  0.0125],\n",
      "        [ 0.0383, -0.0069, -0.0364,  ...,  0.0033, -0.0018, -0.0114]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.17.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.17.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0273, -0.1055,  0.0425,  ...,  0.0302,  0.0168, -0.0432],\n",
      "        [-0.0161, -0.0244, -0.0272,  ..., -0.0552,  0.0015, -0.0688],\n",
      "        [-0.0178,  0.0096, -0.0101,  ...,  0.0117,  0.0315, -0.0425],\n",
      "        ...,\n",
      "        [ 0.0055, -0.0151, -0.0072,  ..., -0.0293, -0.0237,  0.0060],\n",
      "        [ 0.0019, -0.0017, -0.0031,  ...,  0.0002, -0.0050,  0.0005],\n",
      "        [ 0.0420, -0.0381,  0.0143,  ...,  0.0145,  0.0124, -0.0039]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.17.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0366,  0.0006,  0.0232,  ...,  0.0198, -0.0109,  0.0352],\n",
      "        [-0.0073, -0.0564,  0.0193,  ...,  0.0150, -0.0094,  0.0254],\n",
      "        [-0.0417,  0.0242,  0.0391,  ...,  0.0581, -0.0070,  0.0337],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0130, -0.0128,  ...,  0.0016,  0.0270,  0.0425],\n",
      "        [-0.0132,  0.0272, -0.0076,  ..., -0.0131,  0.0030,  0.0391],\n",
      "        [ 0.0039, -0.0349,  0.0026,  ...,  0.0125, -0.0515, -0.0203]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.17.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.17.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 3.7842e-02,  3.3203e-02, -4.9438e-03,  ..., -1.8555e-02,\n",
      "          2.3682e-02,  4.0283e-02],\n",
      "        [ 4.4823e-04,  1.2207e-02, -3.3203e-02,  ...,  1.6602e-02,\n",
      "         -3.6621e-02,  2.7008e-03],\n",
      "        [-7.4158e-03,  5.8350e-02, -5.2002e-02,  ..., -2.8809e-02,\n",
      "         -3.8574e-02, -7.0312e-02],\n",
      "        ...,\n",
      "        [-1.0376e-02,  1.0559e-02,  6.5430e-02,  ...,  5.7129e-02,\n",
      "         -3.8086e-02,  6.4453e-02],\n",
      "        [ 2.0508e-02, -1.3306e-02,  9.8705e-05,  ...,  2.3193e-02,\n",
      "          5.0293e-02,  2.5513e-02],\n",
      "        [-3.3203e-02,  5.3955e-02,  1.0498e-01,  ..., -3.6621e-03,\n",
      "         -1.8311e-02,  1.5503e-02]], requires_grad=True)\n",
      "Layer: model.layers.17.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0251, -0.0273,  0.0098,  ...,  0.0322,  0.0261, -0.0049],\n",
      "        [-0.0193, -0.0183, -0.0479,  ..., -0.0192, -0.0425, -0.0664],\n",
      "        [-0.0187, -0.0393, -0.0221,  ..., -0.0286,  0.0312,  0.0113],\n",
      "        ...,\n",
      "        [-0.0069,  0.0396, -0.0732,  ...,  0.0205,  0.0078,  0.0586],\n",
      "        [-0.0830,  0.0159,  0.0178,  ..., -0.0127,  0.0063,  0.0339],\n",
      "        [ 0.0281, -0.0405,  0.0432,  ..., -0.0327,  0.0352,  0.0064]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.17.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0157,  0.0073, -0.0243,  ...,  0.0275,  0.0059,  0.0043],\n",
      "        [ 0.0112,  0.0598, -0.0106,  ..., -0.0187, -0.0151,  0.0347],\n",
      "        [ 0.0255, -0.0031,  0.0112,  ...,  0.0366,  0.0064,  0.0209],\n",
      "        ...,\n",
      "        [-0.0112, -0.0369,  0.0352,  ..., -0.0889,  0.0591, -0.0177],\n",
      "        [-0.0160, -0.0265, -0.0295,  ...,  0.0153, -0.0569, -0.0085],\n",
      "        [ 0.0168,  0.0304,  0.0330,  ...,  0.0371,  0.0630, -0.0439]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.17.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0366,  0.0242, -0.0742,  ...,  0.0190,  0.0212,  0.0398],\n",
      "        [-0.0588,  0.0308, -0.0146,  ..., -0.0408, -0.0371,  0.0239],\n",
      "        [-0.0009,  0.0199,  0.0223,  ...,  0.0300, -0.0229, -0.0195],\n",
      "        ...,\n",
      "        [-0.0226,  0.0791, -0.0002,  ..., -0.0369, -0.0393, -0.0140],\n",
      "        [ 0.0010, -0.0020, -0.0269,  ...,  0.0178, -0.0540,  0.0065],\n",
      "        [ 0.0137,  0.0017, -0.0664,  ...,  0.0150,  0.0298,  0.0186]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.17.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0396,  0.0210, -0.0197,  ..., -0.0557, -0.0208,  0.0153],\n",
      "        [-0.0006,  0.0197, -0.0403,  ...,  0.0698,  0.0116,  0.0222],\n",
      "        [-0.0256,  0.0137,  0.0189,  ..., -0.0439, -0.0322, -0.0435],\n",
      "        ...,\n",
      "        [ 0.0156, -0.0245, -0.0205,  ..., -0.0342, -0.0148, -0.0038],\n",
      "        [ 0.0242, -0.0605, -0.0057,  ..., -0.0742,  0.0113, -0.0135],\n",
      "        [ 0.0222, -0.0212, -0.0244,  ..., -0.0099, -0.0203,  0.0074]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.17.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.17.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.18.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0356, -0.0172,  0.0005,  ..., -0.0072, -0.0223, -0.0125],\n",
      "        [ 0.0449, -0.0009, -0.0107,  ...,  0.0522,  0.0188, -0.0728],\n",
      "        [ 0.0208,  0.0077,  0.0269,  ...,  0.0212,  0.0186,  0.0050],\n",
      "        ...,\n",
      "        [-0.0138, -0.0273,  0.0074,  ..., -0.0432,  0.0094, -0.0454],\n",
      "        [ 0.0032, -0.0408,  0.0352,  ...,  0.0072, -0.0270, -0.0571],\n",
      "        [ 0.0100,  0.0146,  0.0219,  ..., -0.0559,  0.0055,  0.0276]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.18.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0038, -0.0162,  0.0449,  ...,  0.0569, -0.0266, -0.0176],\n",
      "        [ 0.0129, -0.0206, -0.0007,  ...,  0.0571,  0.0830, -0.0674],\n",
      "        [-0.0064, -0.0520, -0.0043,  ..., -0.0020, -0.0054, -0.0078],\n",
      "        ...,\n",
      "        [-0.0079, -0.0020,  0.0547,  ...,  0.0415,  0.0630,  0.0601],\n",
      "        [ 0.0004,  0.0042, -0.0262,  ..., -0.0312, -0.0449,  0.0074],\n",
      "        [-0.0001,  0.0325,  0.0579,  ...,  0.0159, -0.0190, -0.0141]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0540,  0.0496,  0.0610,  ...,  0.0003,  0.0027, -0.0117],\n",
      "        [ 0.0003, -0.0204, -0.0101,  ..., -0.0598,  0.0114,  0.0171],\n",
      "        [-0.0122, -0.0128, -0.0796,  ..., -0.0310,  0.0376, -0.0520],\n",
      "        ...,\n",
      "        [ 0.0009, -0.0459,  0.0112,  ..., -0.0035,  0.0139, -0.0287],\n",
      "        [-0.0010, -0.0293,  0.0166,  ...,  0.0063, -0.0161,  0.0056],\n",
      "        [ 0.0361,  0.0356,  0.0007,  ...,  0.0112,  0.0292, -0.0459]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.18.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0142,  0.0097,  0.0400,  ..., -0.0220, -0.0245,  0.0242],\n",
      "        [-0.0645, -0.0242, -0.0063,  ..., -0.0649, -0.0258, -0.0016],\n",
      "        [ 0.0120, -0.0413, -0.0122,  ...,  0.0179,  0.0557, -0.0322],\n",
      "        ...,\n",
      "        [ 0.1133, -0.0437,  0.0150,  ..., -0.0381,  0.0349,  0.0127],\n",
      "        [-0.0234,  0.0527, -0.0330,  ..., -0.0298,  0.0520,  0.0461],\n",
      "        [-0.0037, -0.0322, -0.0255,  ...,  0.0028,  0.0388, -0.0153]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0056,  0.0050, -0.0918,  ..., -0.0498, -0.0282,  0.0308],\n",
      "        [-0.0043,  0.0088, -0.0498,  ..., -0.0079,  0.0132, -0.0003],\n",
      "        [ 0.0001, -0.0134, -0.0508,  ...,  0.0282, -0.0459, -0.0493],\n",
      "        ...,\n",
      "        [ 0.0143, -0.0036, -0.0273,  ..., -0.0298,  0.0859,  0.0771],\n",
      "        [ 0.0312, -0.0286, -0.0145,  ...,  0.0043, -0.0094, -0.0238],\n",
      "        [-0.0618, -0.0364,  0.0282,  ..., -0.0159,  0.0444, -0.0243]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0962,  0.0605, -0.0366,  ..., -0.0099, -0.0518, -0.0557],\n",
      "        [-0.0036, -0.0586,  0.0021,  ...,  0.0187,  0.0076,  0.0327],\n",
      "        [ 0.0188,  0.0165, -0.0281,  ...,  0.0203,  0.0408, -0.0488],\n",
      "        ...,\n",
      "        [-0.0294, -0.0310, -0.0518,  ...,  0.0483,  0.0054,  0.0347],\n",
      "        [ 0.0150,  0.0664, -0.0015,  ...,  0.0153, -0.0237, -0.0293],\n",
      "        [-0.0332,  0.0258,  0.0630,  ...,  0.0025, -0.0170,  0.0015]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0074, -0.0051,  0.0220,  ..., -0.0146,  0.0002, -0.0087],\n",
      "        [-0.0289, -0.0447,  0.0074,  ...,  0.0047,  0.0364, -0.0688],\n",
      "        [-0.0181, -0.0031, -0.0026,  ...,  0.0010,  0.0215, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0232, -0.0059,  0.0206,  ..., -0.0219, -0.0012, -0.0225],\n",
      "        [-0.0139,  0.0129, -0.0007,  ...,  0.0344,  0.0457,  0.0056],\n",
      "        [-0.0698,  0.0194,  0.0317,  ..., -0.0172,  0.0747, -0.0126]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0271, -0.0349, -0.0334,  ...,  0.0181, -0.0208, -0.0131],\n",
      "        [-0.0138, -0.0488,  0.0168,  ..., -0.0156, -0.0820,  0.0223],\n",
      "        [ 0.0192,  0.0383,  0.0127,  ...,  0.0391, -0.0065,  0.0161],\n",
      "        ...,\n",
      "        [-0.0645, -0.0082, -0.0383,  ..., -0.0276,  0.0054,  0.0029],\n",
      "        [ 0.0073,  0.0325, -0.0098,  ..., -0.0178,  0.0505,  0.0564],\n",
      "        [ 0.0037, -0.0332,  0.0091,  ..., -0.0239,  0.0364,  0.0232]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.18.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.18.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.19.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0221,  0.0104,  0.0046,  ...,  0.0544,  0.0042,  0.0079],\n",
      "        [ 0.0408,  0.0884,  0.0177,  ..., -0.0388, -0.0173,  0.0233],\n",
      "        [ 0.0085, -0.0449,  0.0033,  ..., -0.0376, -0.0253,  0.0293],\n",
      "        ...,\n",
      "        [-0.0023, -0.0004,  0.0066,  ..., -0.0178, -0.0576,  0.0011],\n",
      "        [-0.0378,  0.0045,  0.0145,  ..., -0.0104, -0.0171,  0.0013],\n",
      "        [-0.0286,  0.0198, -0.0245,  ..., -0.0160,  0.0141,  0.0298]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.19.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0115, -0.0273, -0.0332,  ...,  0.0398,  0.0295, -0.0723],\n",
      "        [ 0.0238, -0.0123, -0.0352,  ...,  0.0403, -0.0038, -0.0466],\n",
      "        [-0.0608, -0.0025,  0.0226,  ..., -0.0217, -0.0236, -0.0469],\n",
      "        ...,\n",
      "        [-0.0201,  0.0134, -0.0065,  ..., -0.0159,  0.0199,  0.0111],\n",
      "        [ 0.0269,  0.0184, -0.0018,  ..., -0.0586,  0.0654, -0.0347],\n",
      "        [-0.0045,  0.0092, -0.0075,  ..., -0.0063, -0.0060, -0.0212]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0133, -0.0442,  0.0068,  ...,  0.0139,  0.0106, -0.0237],\n",
      "        [ 0.0476, -0.0398, -0.0432,  ..., -0.0157, -0.0422, -0.0148],\n",
      "        [-0.0408,  0.0028, -0.0051,  ..., -0.0444, -0.1270, -0.0248],\n",
      "        ...,\n",
      "        [ 0.0210,  0.0106,  0.0046,  ..., -0.0200, -0.0193,  0.0078],\n",
      "        [-0.0337,  0.0081,  0.0115,  ...,  0.0078,  0.0322, -0.0141],\n",
      "        [-0.0186,  0.0085,  0.0011,  ..., -0.0205,  0.0007,  0.0400]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.19.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0466, -0.0088, -0.0488,  ..., -0.0145, -0.0371, -0.0087],\n",
      "        [-0.0186,  0.0282, -0.0266,  ...,  0.0305,  0.0947, -0.0221],\n",
      "        [-0.0156, -0.0095, -0.0085,  ..., -0.0141,  0.0050,  0.0033],\n",
      "        ...,\n",
      "        [ 0.0219,  0.0234, -0.0107,  ..., -0.0061,  0.0069, -0.0138],\n",
      "        [ 0.0118, -0.0193, -0.0439,  ..., -0.0178, -0.0874,  0.0037],\n",
      "        [ 0.0120,  0.0010,  0.0266,  ..., -0.0645,  0.0542,  0.0488]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0669,  0.0270,  0.0052,  ..., -0.0038, -0.0014,  0.0270],\n",
      "        [-0.0835,  0.0156,  0.0176,  ...,  0.0249,  0.0195, -0.0295],\n",
      "        [ 0.0245,  0.0012, -0.0698,  ...,  0.0031, -0.0430,  0.0256],\n",
      "        ...,\n",
      "        [-0.0356, -0.0271,  0.0237,  ..., -0.0282, -0.0425,  0.0032],\n",
      "        [ 0.0055,  0.0254, -0.0186,  ...,  0.0145, -0.0381, -0.0093],\n",
      "        [ 0.0070, -0.0168,  0.0233,  ..., -0.0354, -0.0122, -0.0057]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0845, -0.0067,  0.0378,  ..., -0.0393, -0.0172,  0.0479],\n",
      "        [-0.0488,  0.0422,  0.0006,  ..., -0.0164,  0.0776, -0.0374],\n",
      "        [ 0.0366, -0.0154, -0.0020,  ...,  0.0500,  0.0317,  0.0830],\n",
      "        ...,\n",
      "        [ 0.0581, -0.0064, -0.0366,  ...,  0.0449, -0.0208, -0.0242],\n",
      "        [-0.0664,  0.0364, -0.0253,  ...,  0.0093, -0.0281,  0.0825],\n",
      "        [-0.0364, -0.0253,  0.0022,  ...,  0.0131, -0.0262, -0.0557]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0635,  0.0151,  0.0344,  ..., -0.0542,  0.0327, -0.0153],\n",
      "        [ 0.0111,  0.0645,  0.0361,  ..., -0.0273,  0.0044, -0.0143],\n",
      "        [ 0.0039, -0.0092, -0.0381,  ..., -0.0212, -0.0305, -0.0228],\n",
      "        ...,\n",
      "        [-0.0205,  0.0425, -0.0259,  ..., -0.0454, -0.0498,  0.0474],\n",
      "        [ 0.0225,  0.0193, -0.0598,  ...,  0.0227,  0.0223,  0.0400],\n",
      "        [ 0.0143,  0.0796, -0.0215,  ...,  0.0074,  0.0674,  0.0244]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0349,  0.0238, -0.0312,  ..., -0.0077,  0.0240, -0.0022],\n",
      "        [ 0.0120,  0.0264, -0.0060,  ...,  0.0664, -0.0016,  0.0898],\n",
      "        [ 0.0265,  0.0757,  0.0311,  ...,  0.0236, -0.0139, -0.0050],\n",
      "        ...,\n",
      "        [-0.0518, -0.0236,  0.0189,  ..., -0.0469,  0.0439, -0.0058],\n",
      "        [ 0.0430, -0.0649,  0.0178,  ...,  0.0104, -0.0140,  0.0292],\n",
      "        [ 0.0052,  0.0146,  0.0039,  ...,  0.0061,  0.0479,  0.0242]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.19.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.19.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.20.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0483,  0.0288, -0.0334,  ..., -0.0488,  0.0093,  0.0175],\n",
      "        [ 0.0093,  0.0040,  0.0258,  ..., -0.0222,  0.0166,  0.0128],\n",
      "        [-0.0273, -0.0330, -0.0410,  ..., -0.0254,  0.0182, -0.0159],\n",
      "        ...,\n",
      "        [-0.0070, -0.0339,  0.0322,  ..., -0.0041,  0.0105,  0.0413],\n",
      "        [-0.0137,  0.0250, -0.0018,  ...,  0.0435,  0.0408,  0.0153],\n",
      "        [-0.0239, -0.0352,  0.0615,  ..., -0.0137, -0.0254, -0.0371]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.20.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.20.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 1.0156e-01,  8.3008e-02,  4.6631e-02,  ..., -9.2773e-02,\n",
      "          4.4189e-02,  3.4912e-02],\n",
      "        [ 1.1597e-02, -1.3855e-02,  4.0771e-02,  ...,  2.8198e-02,\n",
      "         -3.8574e-02,  1.2329e-02],\n",
      "        [ 6.0059e-02, -1.0315e-02,  1.0132e-02,  ...,  9.7275e-05,\n",
      "         -2.5391e-02,  1.3916e-02],\n",
      "        ...,\n",
      "        [-7.7515e-03, -1.6724e-02,  2.3193e-02,  ...,  4.0527e-02,\n",
      "          5.1025e-02,  2.8564e-02],\n",
      "        [-6.6528e-03,  1.1749e-03,  3.2959e-02,  ..., -7.4768e-03,\n",
      "         -4.8096e-02,  5.6152e-03],\n",
      "        [ 3.9307e-02,  2.2583e-02, -9.4238e-02,  ...,  3.2959e-02,\n",
      "          1.6357e-02,  2.1240e-02]], requires_grad=True)\n",
      "Layer: model.layers.20.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0410, -0.0096, -0.0085,  ...,  0.0044, -0.0659, -0.0459],\n",
      "        [ 0.0208,  0.0053, -0.0177,  ..., -0.0208,  0.0083,  0.0503],\n",
      "        [-0.0342, -0.0231, -0.0476,  ..., -0.0557,  0.0116,  0.0254],\n",
      "        ...,\n",
      "        [-0.0183,  0.0036,  0.0209,  ..., -0.0031, -0.0284, -0.0140],\n",
      "        [ 0.0227,  0.0112,  0.0249,  ..., -0.0032, -0.0168, -0.0177],\n",
      "        [ 0.0014,  0.0420, -0.0393,  ...,  0.0515,  0.0144,  0.0029]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.20.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.20.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0190, -0.0449,  0.1064,  ...,  0.0898, -0.0162,  0.1396],\n",
      "        [-0.0366, -0.0928,  0.0121,  ..., -0.0193, -0.0286,  0.0125],\n",
      "        [-0.0028,  0.0583, -0.0008,  ..., -0.0101, -0.0047,  0.0986],\n",
      "        ...,\n",
      "        [ 0.0022,  0.0347,  0.0342,  ..., -0.0312, -0.0481,  0.0300],\n",
      "        [ 0.0118, -0.0105, -0.0018,  ...,  0.0085, -0.0042, -0.0123],\n",
      "        [-0.0952,  0.0383,  0.0099,  ..., -0.0181,  0.0137, -0.0079]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.20.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-4.8828e-02,  6.6528e-03,  6.4453e-02,  ...,  2.8133e-05,\n",
      "          6.0791e-02, -1.4526e-02],\n",
      "        [ 2.8809e-02,  1.2939e-02, -3.2227e-02,  ..., -3.7109e-02,\n",
      "         -2.6733e-02,  4.1504e-02],\n",
      "        [-1.7700e-02, -2.0142e-02, -4.1260e-02,  ...,  9.6436e-03,\n",
      "         -5.1514e-02,  1.4771e-02],\n",
      "        ...,\n",
      "        [-1.2817e-02, -6.1798e-04, -8.8501e-03,  ...,  1.6846e-02,\n",
      "          3.8574e-02,  1.7334e-02],\n",
      "        [ 6.9275e-03, -3.8086e-02, -3.8330e-02,  ..., -2.2949e-02,\n",
      "          1.0376e-02,  2.1729e-02],\n",
      "        [ 4.1260e-02,  1.8311e-02,  3.0151e-02,  ...,  1.5869e-02,\n",
      "         -8.1177e-03,  4.0894e-03]], requires_grad=True)\n",
      "Layer: model.layers.20.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0064,  0.0210,  0.0601,  ...,  0.0430,  0.0103, -0.0023],\n",
      "        [-0.0282,  0.0060,  0.0029,  ...,  0.0164, -0.0056,  0.0082],\n",
      "        [ 0.0079, -0.0312, -0.0115,  ...,  0.0003, -0.0064, -0.0137],\n",
      "        ...,\n",
      "        [-0.0359, -0.0334, -0.0234,  ..., -0.0140,  0.0300,  0.0586],\n",
      "        [ 0.0693, -0.0508,  0.0442,  ..., -0.0068, -0.0138,  0.0187],\n",
      "        [ 0.0302, -0.0508,  0.0204,  ..., -0.0337, -0.0869, -0.0106]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.20.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0254,  0.0227,  0.0605,  ...,  0.0273, -0.0179,  0.0505],\n",
      "        [-0.0280, -0.0121,  0.0204,  ...,  0.0156,  0.0004,  0.0115],\n",
      "        [-0.0275,  0.0391,  0.0369,  ...,  0.0084,  0.0016, -0.0030],\n",
      "        ...,\n",
      "        [-0.0128, -0.0178,  0.0109,  ..., -0.0240,  0.0479,  0.0051],\n",
      "        [-0.0371, -0.0063, -0.0200,  ..., -0.0330,  0.0035,  0.0020],\n",
      "        [-0.0378,  0.0255, -0.0352,  ..., -0.0203, -0.0635,  0.0151]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.20.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0091, -0.0693, -0.0459,  ..., -0.0029, -0.0021, -0.0271],\n",
      "        [ 0.0300, -0.0118, -0.0259,  ..., -0.0251, -0.0415,  0.0072],\n",
      "        [ 0.0518, -0.0449,  0.0172,  ...,  0.0217,  0.0070, -0.0571],\n",
      "        ...,\n",
      "        [ 0.0317, -0.0413,  0.0457,  ..., -0.0271, -0.0132,  0.0275],\n",
      "        [-0.0361,  0.0128, -0.0016,  ...,  0.0591,  0.0004, -0.0723],\n",
      "        [ 0.0693, -0.0295,  0.0133,  ..., -0.0168,  0.0030, -0.0150]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.20.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.20.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.21.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0154,  0.0337,  0.0133,  ..., -0.0083,  0.0063,  0.0047],\n",
      "        [-0.0153,  0.0075,  0.0342,  ...,  0.0134,  0.0153,  0.0732],\n",
      "        [ 0.0498, -0.0005, -0.0327,  ..., -0.0114, -0.0435, -0.0381],\n",
      "        ...,\n",
      "        [-0.0135,  0.0121,  0.0320,  ..., -0.0195, -0.0349, -0.0289],\n",
      "        [-0.0396, -0.0116,  0.0493,  ..., -0.0212,  0.0126, -0.0030],\n",
      "        [-0.0066,  0.0111,  0.1060,  ...,  0.0315, -0.0393,  0.0292]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.21.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0009,  0.0269, -0.0469,  ..., -0.0625, -0.0043, -0.0254],\n",
      "        [-0.0135,  0.0194,  0.0007,  ..., -0.0061,  0.0530,  0.0135],\n",
      "        [-0.0179, -0.0105, -0.0106,  ...,  0.0140, -0.0210, -0.0654],\n",
      "        ...,\n",
      "        [ 0.0347,  0.0029, -0.0047,  ...,  0.0030, -0.0104, -0.0294],\n",
      "        [ 0.0547,  0.0021,  0.0205,  ..., -0.0306, -0.0015,  0.0038],\n",
      "        [-0.0405, -0.0031,  0.0522,  ..., -0.0041,  0.1143,  0.0287]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0117, -0.0210, -0.0024,  ..., -0.0503, -0.0292, -0.0005],\n",
      "        [-0.0164,  0.0933,  0.0278,  ..., -0.0388,  0.0160,  0.0525],\n",
      "        [-0.0581, -0.0156, -0.0481,  ...,  0.0430, -0.0201, -0.0613],\n",
      "        ...,\n",
      "        [-0.0176, -0.0366,  0.0035,  ...,  0.0041,  0.0542,  0.0427],\n",
      "        [ 0.0118, -0.0105, -0.0199,  ...,  0.0111, -0.0142, -0.0371],\n",
      "        [ 0.0005,  0.0220, -0.0118,  ...,  0.0281,  0.0085, -0.0361]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.21.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0156, -0.0308, -0.0023,  ..., -0.0025, -0.0298,  0.0249],\n",
      "        [-0.0154, -0.0036,  0.0376,  ...,  0.0123, -0.0029,  0.0170],\n",
      "        [-0.0061, -0.0286, -0.0183,  ...,  0.0098, -0.0148,  0.0281],\n",
      "        ...,\n",
      "        [-0.0205,  0.0166, -0.0247,  ..., -0.0630, -0.0281, -0.0043],\n",
      "        [-0.0085,  0.0271, -0.1162,  ..., -0.0250,  0.0106, -0.0732],\n",
      "        [-0.0679, -0.0053,  0.0322,  ...,  0.1104,  0.0811,  0.0322]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0376, -0.0415, -0.0212,  ...,  0.0295,  0.0059, -0.0008],\n",
      "        [-0.0012,  0.0035,  0.0060,  ...,  0.0159,  0.0166,  0.0127],\n",
      "        [ 0.0018, -0.0014, -0.0229,  ...,  0.0124, -0.0420, -0.0208],\n",
      "        ...,\n",
      "        [ 0.0227, -0.0461, -0.0354,  ..., -0.0184, -0.0157, -0.0115],\n",
      "        [ 0.0189,  0.0132,  0.0522,  ...,  0.0025,  0.0195,  0.0264],\n",
      "        [ 0.0211,  0.0286, -0.0129,  ...,  0.0071,  0.0095, -0.0079]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0410, -0.0542, -0.0811,  ...,  0.0148,  0.0216,  0.0483],\n",
      "        [ 0.0225,  0.0396, -0.0212,  ...,  0.0215,  0.0010,  0.0334],\n",
      "        [-0.0513, -0.0031, -0.0007,  ...,  0.0327, -0.0282, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0220,  0.0243,  0.0171,  ..., -0.0361, -0.0093, -0.0144],\n",
      "        [ 0.0452, -0.0284,  0.0242,  ..., -0.0454,  0.0342,  0.0242],\n",
      "        [ 0.0094, -0.0396,  0.0532,  ..., -0.0427, -0.0535,  0.0154]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0312,  0.0618,  0.0088,  ...,  0.0035,  0.0327, -0.0364],\n",
      "        [ 0.0262, -0.0129, -0.0430,  ...,  0.0508, -0.0298, -0.0260],\n",
      "        [ 0.0312, -0.0347,  0.0938,  ...,  0.0093,  0.0503, -0.0520],\n",
      "        ...,\n",
      "        [-0.0046, -0.0752, -0.0537,  ...,  0.0006,  0.0303,  0.0212],\n",
      "        [ 0.0038, -0.0081, -0.0299,  ..., -0.0374, -0.0549,  0.0229],\n",
      "        [-0.0021, -0.0186,  0.0260,  ...,  0.0187, -0.0140, -0.0168]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0234,  0.0190, -0.0017,  ...,  0.0016,  0.0366, -0.0330],\n",
      "        [ 0.0466, -0.0156, -0.0557,  ...,  0.0225,  0.0337, -0.0388],\n",
      "        [-0.0087, -0.0288,  0.0576,  ..., -0.0089, -0.0439,  0.0204],\n",
      "        ...,\n",
      "        [ 0.0454,  0.0002, -0.0247,  ..., -0.0095, -0.0330,  0.0337],\n",
      "        [ 0.0466, -0.0181,  0.0192,  ..., -0.0449,  0.0238, -0.0117],\n",
      "        [-0.0259,  0.0141, -0.0222,  ..., -0.0160,  0.0359,  0.0166]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.21.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.21.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.22.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0188, -0.0090, -0.0046,  ...,  0.0142, -0.0233, -0.0233],\n",
      "        [-0.0212,  0.0166,  0.0056,  ..., -0.0076, -0.0332,  0.0188],\n",
      "        [-0.0178, -0.0051,  0.0049,  ...,  0.0199,  0.0264, -0.0422],\n",
      "        ...,\n",
      "        [-0.0354,  0.0121,  0.0265,  ...,  0.0017, -0.0261, -0.0135],\n",
      "        [ 0.0138, -0.0187, -0.0064,  ..., -0.0415, -0.0376, -0.0159],\n",
      "        [-0.0129, -0.0094,  0.0022,  ...,  0.0038,  0.0021, -0.0272]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.22.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0110, -0.0366, -0.0337,  ...,  0.0518,  0.0217,  0.0432],\n",
      "        [-0.0811,  0.0322, -0.0035,  ...,  0.0146, -0.0337,  0.0032],\n",
      "        [-0.0168, -0.0327,  0.0474,  ...,  0.0121,  0.0669, -0.0469],\n",
      "        ...,\n",
      "        [ 0.0053,  0.0046, -0.0054,  ..., -0.0027, -0.0053,  0.0031],\n",
      "        [-0.0220, -0.0193, -0.0289,  ...,  0.0483, -0.0303, -0.0107],\n",
      "        [ 0.0435, -0.0713,  0.0205,  ..., -0.0410, -0.0684, -0.0048]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0156,  0.0050, -0.0209,  ...,  0.0013, -0.0581,  0.0216],\n",
      "        [-0.0256,  0.0117,  0.0503,  ...,  0.0708,  0.0479,  0.0322],\n",
      "        [ 0.0054,  0.0123, -0.0132,  ..., -0.0287,  0.0089,  0.0620],\n",
      "        ...,\n",
      "        [ 0.0037, -0.0001, -0.0095,  ...,  0.0192,  0.0361, -0.0148],\n",
      "        [-0.0142,  0.0022,  0.0344,  ..., -0.0352,  0.0292, -0.0244],\n",
      "        [ 0.0142, -0.0286,  0.0119,  ...,  0.0159,  0.0234, -0.0282]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.22.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0031, -0.0564, -0.0859,  ..., -0.0104, -0.0422,  0.0175],\n",
      "        [-0.0032, -0.0070,  0.0083,  ...,  0.0173,  0.0137, -0.0071],\n",
      "        [-0.0071,  0.0654,  0.0471,  ..., -0.0771,  0.0825, -0.1475],\n",
      "        ...,\n",
      "        [ 0.0041,  0.0177, -0.0415,  ..., -0.0167,  0.0146, -0.0356],\n",
      "        [ 0.0215,  0.0040, -0.0086,  ..., -0.0183, -0.0259, -0.0041],\n",
      "        [-0.0004,  0.0659, -0.0039,  ...,  0.0295, -0.0503, -0.0042]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0654, -0.0245,  0.0084,  ..., -0.0334, -0.0503, -0.0109],\n",
      "        [ 0.0176, -0.0208, -0.0166,  ..., -0.0571,  0.0086,  0.0081],\n",
      "        [ 0.0151, -0.0135,  0.0259,  ...,  0.0464, -0.0403, -0.0549],\n",
      "        ...,\n",
      "        [ 0.0364,  0.0092, -0.0630,  ..., -0.0417, -0.0248, -0.0073],\n",
      "        [ 0.0132,  0.0215, -0.0527,  ...,  0.0156, -0.0145,  0.0007],\n",
      "        [ 0.0130,  0.0226,  0.0064,  ..., -0.0317, -0.0037,  0.0273]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0223,  0.0201, -0.0159,  ...,  0.0334, -0.0117, -0.0115],\n",
      "        [-0.0076,  0.0684,  0.0129,  ..., -0.0464,  0.1016,  0.0327],\n",
      "        [ 0.0164,  0.0085,  0.0098,  ..., -0.0488, -0.0693,  0.0055],\n",
      "        ...,\n",
      "        [ 0.0508, -0.0054, -0.0359,  ...,  0.0105,  0.0967,  0.0081],\n",
      "        [ 0.0189, -0.0442, -0.0164,  ..., -0.0092, -0.0261,  0.0439],\n",
      "        [ 0.0493, -0.0154,  0.0085,  ...,  0.0623,  0.0121, -0.0752]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0121,  0.0157,  0.0287,  ...,  0.0205,  0.0225,  0.0518],\n",
      "        [ 0.0625,  0.0771,  0.0400,  ...,  0.0039,  0.0415, -0.0251],\n",
      "        [ 0.0203, -0.0183, -0.0152,  ..., -0.0337, -0.0035,  0.0476],\n",
      "        ...,\n",
      "        [-0.0405, -0.0253, -0.0227,  ..., -0.0204,  0.0146, -0.0077],\n",
      "        [-0.0322, -0.0250,  0.0640,  ..., -0.0220, -0.0483,  0.0327],\n",
      "        [-0.0098,  0.0276,  0.0310,  ...,  0.0588, -0.0547,  0.0049]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0144,  0.0728,  0.0527,  ..., -0.0050, -0.0150, -0.0097],\n",
      "        [ 0.0017,  0.0962, -0.0283,  ..., -0.0100, -0.0031, -0.0048],\n",
      "        [ 0.0417,  0.0361,  0.0093,  ..., -0.0098,  0.0393,  0.0227],\n",
      "        ...,\n",
      "        [-0.0137,  0.0264,  0.0033,  ...,  0.0078, -0.0276,  0.0439],\n",
      "        [-0.0041, -0.0116,  0.0244,  ...,  0.0264, -0.0874,  0.0128],\n",
      "        [ 0.0227, -0.0557, -0.0115,  ...,  0.0080,  0.0312, -0.0532]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.22.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.22.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.23.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.1108,  0.0522,  0.0051,  ...,  0.0117, -0.0201,  0.0776],\n",
      "        [ 0.0009,  0.0168,  0.0234,  ..., -0.0488,  0.0086,  0.0114],\n",
      "        [-0.0742,  0.0007, -0.0270,  ..., -0.0210, -0.0104,  0.0237],\n",
      "        ...,\n",
      "        [-0.0417, -0.0308,  0.0291,  ..., -0.0143, -0.0149, -0.0013],\n",
      "        [ 0.0215,  0.0240,  0.0432,  ...,  0.0830,  0.0068,  0.0219],\n",
      "        [ 0.0275, -0.0023, -0.0244,  ...,  0.0065, -0.0182,  0.0432]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.23.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0096, -0.0229,  0.0332,  ..., -0.0238, -0.0035,  0.0005],\n",
      "        [ 0.0869,  0.0488, -0.0383,  ...,  0.0147,  0.0630,  0.0232],\n",
      "        [-0.0518,  0.0771,  0.0016,  ..., -0.0166, -0.0225, -0.0261],\n",
      "        ...,\n",
      "        [-0.0052,  0.0461,  0.0138,  ..., -0.0156, -0.0679, -0.0967],\n",
      "        [-0.0267, -0.0010, -0.0109,  ..., -0.0063, -0.1191, -0.0040],\n",
      "        [ 0.0120,  0.0352,  0.0093,  ..., -0.0488, -0.0649, -0.0305]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0615,  0.0752,  0.0583,  ...,  0.0050, -0.0006,  0.0277],\n",
      "        [ 0.0757,  0.0554, -0.0120,  ...,  0.0026, -0.0068,  0.0256],\n",
      "        [-0.0317,  0.0182, -0.0371,  ..., -0.0308, -0.0104,  0.0125],\n",
      "        ...,\n",
      "        [-0.0005, -0.0078, -0.0060,  ...,  0.0045,  0.0044, -0.0049],\n",
      "        [ 0.0181,  0.0131, -0.0713,  ..., -0.0176, -0.0021,  0.0513],\n",
      "        [ 0.0115, -0.0212, -0.0168,  ...,  0.0396, -0.0386,  0.0400]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.23.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0444, -0.0469,  0.0586,  ..., -0.0144,  0.0664,  0.0483],\n",
      "        [ 0.0023, -0.0057, -0.0510,  ..., -0.0771, -0.0405,  0.0325],\n",
      "        [-0.0522, -0.0127,  0.0002,  ..., -0.0659, -0.0291,  0.0559],\n",
      "        ...,\n",
      "        [-0.0111,  0.0425,  0.0302,  ..., -0.0190,  0.0542,  0.0369],\n",
      "        [ 0.0060,  0.0049, -0.0317,  ..., -0.0583,  0.0625, -0.0135],\n",
      "        [ 0.0143, -0.0261, -0.0625,  ..., -0.0518,  0.0376,  0.0703]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0283, -0.0283,  0.0659,  ..., -0.0103,  0.0019,  0.0068],\n",
      "        [-0.0142, -0.0266,  0.0352,  ..., -0.0815, -0.0237, -0.0408],\n",
      "        [ 0.0259, -0.0752,  0.0309,  ...,  0.0547,  0.0557,  0.0094],\n",
      "        ...,\n",
      "        [-0.0266,  0.0261,  0.0057,  ..., -0.0087, -0.0259, -0.0082],\n",
      "        [ 0.0288,  0.0757, -0.0054,  ...,  0.0535,  0.0757,  0.0183],\n",
      "        [ 0.0149, -0.0479,  0.0559,  ...,  0.0317,  0.0018,  0.0164]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0408, -0.0058, -0.0132,  ..., -0.0177,  0.0398,  0.0471],\n",
      "        [-0.0286,  0.0044, -0.0080,  ..., -0.0542,  0.0059, -0.0610],\n",
      "        [-0.0378,  0.0030,  0.0099,  ..., -0.0330, -0.0322, -0.0216],\n",
      "        ...,\n",
      "        [-0.0029, -0.0236,  0.0325,  ..., -0.0535,  0.0022,  0.0645],\n",
      "        [-0.0059,  0.0164, -0.0381,  ..., -0.0483, -0.0112, -0.0081],\n",
      "        [-0.0001, -0.0142,  0.0488,  ...,  0.0557, -0.0109,  0.0104]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0125, -0.0009,  0.0065,  ...,  0.0011,  0.0623,  0.0469],\n",
      "        [ 0.0073, -0.0231, -0.0123,  ..., -0.0325,  0.0064,  0.0153],\n",
      "        [ 0.0330,  0.0160,  0.0171,  ...,  0.0240, -0.0339,  0.0001],\n",
      "        ...,\n",
      "        [ 0.0014,  0.0762,  0.0332,  ...,  0.0889,  0.0371, -0.0327],\n",
      "        [ 0.0342, -0.0284, -0.0095,  ...,  0.0466,  0.0227, -0.0513],\n",
      "        [-0.0371, -0.0002, -0.0099,  ...,  0.0098, -0.0337,  0.0244]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0067, -0.0062, -0.0342,  ..., -0.0439,  0.0092,  0.0273],\n",
      "        [-0.0542, -0.0204,  0.0513,  ...,  0.0347, -0.0200,  0.0176],\n",
      "        [ 0.0400, -0.0806,  0.0228,  ...,  0.0264, -0.0181,  0.0275],\n",
      "        ...,\n",
      "        [ 0.0046, -0.0330, -0.0280,  ...,  0.0403,  0.0001,  0.0106],\n",
      "        [ 0.0771, -0.0043, -0.0344,  ...,  0.0757,  0.0035, -0.0308],\n",
      "        [ 0.0432,  0.0075, -0.0195,  ..., -0.0103, -0.0405,  0.0132]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.23.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.23.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.24.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0006,  0.0557,  0.0221,  ..., -0.0410, -0.0168,  0.0048],\n",
      "        [-0.0266,  0.0032, -0.0203,  ...,  0.0058, -0.0250,  0.0146],\n",
      "        [-0.0002, -0.0175, -0.0110,  ..., -0.0117, -0.0417, -0.0393],\n",
      "        ...,\n",
      "        [-0.0693,  0.0493, -0.0317,  ..., -0.0265, -0.0310, -0.0544],\n",
      "        [ 0.0403,  0.0508,  0.0325,  ..., -0.0574,  0.0071,  0.0474],\n",
      "        [-0.0115, -0.0557, -0.0532,  ...,  0.0107, -0.0457, -0.0092]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.24.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0234, -0.0045,  0.0625,  ..., -0.0344, -0.0723, -0.0008],\n",
      "        [ 0.0217,  0.0356,  0.0447,  ...,  0.0227,  0.0933,  0.0010],\n",
      "        [-0.0361,  0.0684,  0.0172,  ..., -0.0276, -0.0742,  0.0256],\n",
      "        ...,\n",
      "        [-0.0014, -0.0008, -0.0062,  ...,  0.0068,  0.0055,  0.0050],\n",
      "        [-0.0010, -0.0173,  0.0364,  ..., -0.0217,  0.0003, -0.0011],\n",
      "        [ 0.0048,  0.0327,  0.0718,  ...,  0.0028, -0.0400,  0.0286]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0171,  0.0547,  0.0144,  ...,  0.0067, -0.0159, -0.0129],\n",
      "        [-0.0078,  0.0425,  0.0408,  ..., -0.0811, -0.0583, -0.0184],\n",
      "        [-0.0140,  0.0040,  0.0294,  ..., -0.0317, -0.0359,  0.0579],\n",
      "        ...,\n",
      "        [ 0.0106,  0.0190,  0.0286,  ..., -0.0048, -0.0034,  0.0186],\n",
      "        [-0.0035,  0.0188, -0.0050,  ..., -0.0088, -0.0256,  0.0183],\n",
      "        [-0.0200, -0.0737,  0.0035,  ...,  0.0251,  0.0107,  0.0273]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.24.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0069, -0.0052, -0.0005,  ...,  0.0089, -0.0623, -0.0234],\n",
      "        [-0.0043, -0.0181,  0.0049,  ...,  0.0381,  0.0466,  0.0203],\n",
      "        [-0.0505,  0.0132,  0.0391,  ...,  0.0718, -0.0189,  0.0649],\n",
      "        ...,\n",
      "        [ 0.0264, -0.0322,  0.0109,  ..., -0.0100,  0.0067,  0.0220],\n",
      "        [ 0.0225,  0.0199,  0.0322,  ..., -0.0864, -0.0374, -0.0488],\n",
      "        [-0.1006, -0.0820,  0.0386,  ..., -0.0051, -0.0400,  0.0386]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0325,  0.0094,  0.0154,  ..., -0.0088,  0.0146,  0.0752],\n",
      "        [-0.0732, -0.0195, -0.0356,  ..., -0.0269,  0.0444,  0.0283],\n",
      "        [ 0.0281, -0.0010,  0.0215,  ..., -0.0009, -0.0364, -0.0342],\n",
      "        ...,\n",
      "        [ 0.0684,  0.0564, -0.0055,  ..., -0.0237,  0.0752,  0.0278],\n",
      "        [-0.0066, -0.0327,  0.0155,  ...,  0.0132,  0.0139, -0.0205],\n",
      "        [ 0.0109,  0.0141, -0.0376,  ..., -0.0525, -0.0659,  0.0352]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0226, -0.0069, -0.0918,  ...,  0.0039, -0.0171,  0.0297],\n",
      "        [-0.0469, -0.0128,  0.0540,  ..., -0.0214, -0.0391,  0.0006],\n",
      "        [ 0.0014, -0.0396,  0.0300,  ..., -0.0275,  0.0352,  0.0032],\n",
      "        ...,\n",
      "        [ 0.0231,  0.0045, -0.0383,  ..., -0.0225,  0.0327,  0.0221],\n",
      "        [ 0.0278,  0.0086,  0.0300,  ...,  0.0075,  0.0214, -0.0420],\n",
      "        [-0.0325,  0.0219,  0.0498,  ..., -0.0093,  0.0132, -0.0391]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0140, -0.0630, -0.0723,  ...,  0.0571,  0.0067,  0.0250],\n",
      "        [-0.0483, -0.0058,  0.0182,  ...,  0.0004,  0.0583,  0.0332],\n",
      "        [-0.0271,  0.0376, -0.0038,  ...,  0.0113, -0.0269, -0.0356],\n",
      "        ...,\n",
      "        [ 0.0259, -0.0184,  0.0366,  ...,  0.0179, -0.0101, -0.0178],\n",
      "        [-0.0293,  0.0693,  0.0339,  ..., -0.0161, -0.0081, -0.0052],\n",
      "        [ 0.0413, -0.0061, -0.0135,  ..., -0.0315,  0.0145,  0.0293]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0322, -0.0574, -0.0079,  ...,  0.0119,  0.0126,  0.0469],\n",
      "        [-0.0391, -0.0259, -0.0292,  ..., -0.0369, -0.0181,  0.0254],\n",
      "        [-0.0571,  0.0232,  0.0219,  ..., -0.0322, -0.0087,  0.0386],\n",
      "        ...,\n",
      "        [ 0.0130,  0.0165, -0.0154,  ..., -0.0073,  0.0087, -0.0094],\n",
      "        [ 0.0444,  0.0317, -0.0654,  ..., -0.0035,  0.0542, -0.0201],\n",
      "        [ 0.0305,  0.0635, -0.0864,  ...,  0.0150, -0.0049, -0.0089]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.24.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.24.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.25.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0101,  0.0092, -0.0078,  ..., -0.0742, -0.0171,  0.0256],\n",
      "        [-0.0283,  0.0072, -0.0449,  ...,  0.0079,  0.0464,  0.0796],\n",
      "        [ 0.0266,  0.0332, -0.0116,  ...,  0.0035, -0.0051, -0.0234],\n",
      "        ...,\n",
      "        [-0.0342, -0.0508, -0.0208,  ...,  0.0471, -0.0547,  0.0010],\n",
      "        [-0.0603, -0.0354,  0.0366,  ...,  0.0145, -0.0082, -0.0483],\n",
      "        [-0.0688,  0.0261,  0.0089,  ..., -0.0115,  0.0155, -0.0243]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.25.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.25.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 3.2959e-02,  1.2146e-02,  2.0996e-02,  ...,  2.0264e-02,\n",
      "          3.3203e-02, -2.9053e-02],\n",
      "        [-2.5879e-02, -7.0095e-05, -3.6377e-02,  ..., -2.5513e-02,\n",
      "         -3.7842e-02,  7.9590e-02],\n",
      "        [-1.3245e-02, -8.5449e-03, -2.1606e-02,  ...,  1.0254e-01,\n",
      "          1.3123e-03,  6.7383e-02],\n",
      "        ...,\n",
      "        [-2.1118e-02, -5.0293e-02, -4.7363e-02,  ..., -3.6621e-02,\n",
      "         -2.9785e-02,  6.6833e-03],\n",
      "        [ 2.6123e-02,  1.2573e-02, -1.5625e-02,  ..., -1.6357e-02,\n",
      "          8.4961e-02, -3.8086e-02],\n",
      "        [-3.6316e-03,  2.0752e-02,  8.3618e-03,  ...,  2.6611e-02,\n",
      "         -3.0640e-02, -4.1504e-03]], requires_grad=True)\n",
      "Layer: model.layers.25.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0120,  0.0031,  0.0217,  ...,  0.0679, -0.0101,  0.0148],\n",
      "        [ 0.0276,  0.0151,  0.0260,  ..., -0.1050, -0.0481, -0.0113],\n",
      "        [ 0.0398,  0.0187, -0.0232,  ..., -0.0153, -0.0164,  0.0164],\n",
      "        ...,\n",
      "        [-0.0195,  0.0063,  0.0074,  ...,  0.0019, -0.0080, -0.0110],\n",
      "        [-0.0215, -0.0332,  0.0010,  ..., -0.0085, -0.0093, -0.0391],\n",
      "        [-0.0102,  0.0179, -0.0342,  ...,  0.0041, -0.0250,  0.0254]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.25.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.25.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0014, -0.0508, -0.0469,  ...,  0.0479, -0.0099,  0.0625],\n",
      "        [ 0.0461, -0.0167, -0.0161,  ..., -0.0110,  0.0488, -0.0398],\n",
      "        [ 0.0425, -0.0251,  0.0182,  ...,  0.0393, -0.0317,  0.0009],\n",
      "        ...,\n",
      "        [-0.0139,  0.0078,  0.0649,  ..., -0.0522,  0.0240,  0.0095],\n",
      "        [-0.0040, -0.0226, -0.0352,  ..., -0.0090, -0.0159,  0.0591],\n",
      "        [ 0.0171, -0.0275, -0.0222,  ..., -0.0654, -0.0510, -0.0289]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.25.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0303, -0.0130,  0.0306,  ...,  0.0354,  0.0082, -0.0254],\n",
      "        [ 0.0096, -0.0425,  0.0077,  ..., -0.0532,  0.0457, -0.0884],\n",
      "        [-0.0139, -0.0300, -0.0133,  ..., -0.0535,  0.0422, -0.0147],\n",
      "        ...,\n",
      "        [-0.0610,  0.0097,  0.0239,  ..., -0.0374,  0.0028, -0.0078],\n",
      "        [-0.0128,  0.0176, -0.0669,  ..., -0.0135,  0.0113, -0.0564],\n",
      "        [-0.0093, -0.0214,  0.0100,  ..., -0.0259, -0.0308, -0.0287]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.25.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0223,  0.0198,  0.0195,  ..., -0.0466,  0.0096, -0.0527],\n",
      "        [ 0.0166,  0.0079,  0.0198,  ...,  0.0381, -0.0069,  0.0013],\n",
      "        [ 0.0046, -0.0112,  0.0047,  ...,  0.0537,  0.0249,  0.0344],\n",
      "        ...,\n",
      "        [-0.0352, -0.0288, -0.0006,  ..., -0.0183,  0.0466, -0.0002],\n",
      "        [-0.0041, -0.0332, -0.0261,  ...,  0.0020,  0.0087, -0.0825],\n",
      "        [-0.0615, -0.0172,  0.0674,  ..., -0.0410, -0.0003, -0.0039]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.25.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0046,  0.0562, -0.0386,  ...,  0.0283,  0.0146,  0.0352],\n",
      "        [ 0.0203, -0.0518,  0.1094,  ..., -0.0684,  0.0238,  0.0099],\n",
      "        [ 0.0060, -0.0771, -0.0425,  ...,  0.0488,  0.0177, -0.0113],\n",
      "        ...,\n",
      "        [ 0.0215, -0.0282,  0.0094,  ...,  0.0189, -0.0256, -0.0205],\n",
      "        [-0.0393, -0.0172, -0.0157,  ...,  0.0234, -0.0381, -0.0031],\n",
      "        [ 0.0073, -0.0439, -0.0297,  ..., -0.0430,  0.0045,  0.0265]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.25.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0659, -0.0275, -0.0203,  ...,  0.0688, -0.0610,  0.0197],\n",
      "        [ 0.0334,  0.0193, -0.0659,  ...,  0.0125, -0.0048,  0.0093],\n",
      "        [-0.0031,  0.0903, -0.0566,  ..., -0.0203, -0.0229, -0.0039],\n",
      "        ...,\n",
      "        [-0.0144,  0.0081,  0.0332,  ...,  0.0122,  0.0349, -0.0352],\n",
      "        [ 0.0062,  0.0425,  0.0400,  ..., -0.0217, -0.0356, -0.0518],\n",
      "        [ 0.0077,  0.0410, -0.0020,  ..., -0.0193,  0.0040, -0.0031]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.25.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.25.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.26.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0009, -0.0143, -0.0217,  ..., -0.0168,  0.0437,  0.0024],\n",
      "        [ 0.0342, -0.0226,  0.0099,  ...,  0.0133,  0.0061,  0.0091],\n",
      "        [-0.0167, -0.0520, -0.0103,  ...,  0.0128,  0.0503,  0.0074],\n",
      "        ...,\n",
      "        [-0.0065, -0.0216,  0.0304,  ..., -0.0330, -0.0215, -0.0811],\n",
      "        [-0.0074,  0.0625,  0.0150,  ...,  0.0247,  0.0400, -0.0366],\n",
      "        [-0.0510, -0.0439,  0.0332,  ..., -0.0066, -0.0062,  0.0449]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.26.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.26.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0236,  0.0151,  0.0060,  ..., -0.0493, -0.0835, -0.0427],\n",
      "        [-0.0310,  0.0008, -0.0021,  ...,  0.0216,  0.0188, -0.0181],\n",
      "        [-0.0293, -0.0437,  0.0200,  ...,  0.0309, -0.0498,  0.0173],\n",
      "        ...,\n",
      "        [-0.0048, -0.0378,  0.0273,  ...,  0.0181, -0.0281,  0.0030],\n",
      "        [ 0.0018,  0.0145,  0.0029,  ...,  0.0249,  0.0193,  0.0161],\n",
      "        [-0.0156, -0.0129, -0.0028,  ...,  0.0006, -0.0481, -0.0386]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.26.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-5.3406e-03, -2.3926e-02,  1.7822e-02,  ...,  7.7820e-03,\n",
      "          8.1177e-03,  1.7212e-02],\n",
      "        [ 7.2937e-03,  5.5542e-03,  5.5542e-03,  ..., -2.6855e-02,\n",
      "         -6.2988e-02,  4.4678e-02],\n",
      "        [ 1.1169e-02,  3.8528e-04, -4.1016e-02,  ...,  2.9785e-02,\n",
      "         -1.8677e-02, -2.3438e-02],\n",
      "        ...,\n",
      "        [ 5.6152e-03,  6.6833e-03,  4.3457e-02,  ...,  7.8201e-04,\n",
      "         -6.1035e-05, -2.7588e-02],\n",
      "        [-1.3306e-02, -2.5757e-02, -1.1414e-02,  ...,  9.0408e-04,\n",
      "          3.4790e-03,  2.3315e-02],\n",
      "        [ 2.6001e-02,  1.0986e-02,  2.5391e-02,  ..., -2.5391e-02,\n",
      "          3.3691e-02, -1.5381e-02]], requires_grad=True)\n",
      "Layer: model.layers.26.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.26.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0166,  0.0427, -0.0064,  ..., -0.0332, -0.0752,  0.0258],\n",
      "        [ 0.0134,  0.0850, -0.0058,  ...,  0.0493,  0.0479,  0.0410],\n",
      "        [ 0.0566, -0.0215, -0.0084,  ..., -0.0913, -0.0369, -0.0752],\n",
      "        ...,\n",
      "        [-0.0391,  0.0654, -0.0125,  ...,  0.0056, -0.0237, -0.0488],\n",
      "        [ 0.0016, -0.0625, -0.0264,  ...,  0.0571, -0.0459,  0.0422],\n",
      "        [-0.0111,  0.0283, -0.0065,  ..., -0.0894,  0.0239, -0.0254]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.26.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0310, -0.0300,  0.0391,  ..., -0.0272,  0.0089, -0.0194],\n",
      "        [-0.0057, -0.0649, -0.0581,  ..., -0.0005,  0.0073, -0.0308],\n",
      "        [-0.0103,  0.0286, -0.0474,  ..., -0.0493, -0.0271, -0.1045],\n",
      "        ...,\n",
      "        [ 0.0118,  0.0493, -0.0781,  ..., -0.0070, -0.0776,  0.0143],\n",
      "        [ 0.0164, -0.0144,  0.0270,  ..., -0.0188, -0.0327,  0.0269],\n",
      "        [-0.0145, -0.0413,  0.0129,  ...,  0.0369, -0.0127,  0.0046]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.26.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0513,  0.0576, -0.0210,  ...,  0.0024, -0.0317, -0.0229],\n",
      "        [-0.0042, -0.0119, -0.0432,  ...,  0.0291,  0.0469, -0.0420],\n",
      "        [ 0.0140,  0.0040,  0.0070,  ...,  0.0425, -0.0547,  0.0038],\n",
      "        ...,\n",
      "        [-0.0361, -0.0016, -0.0225,  ..., -0.0178, -0.0288,  0.0114],\n",
      "        [ 0.0513,  0.0513, -0.0454,  ...,  0.0625, -0.0273,  0.0200],\n",
      "        [-0.0294, -0.1011, -0.0806,  ...,  0.0203, -0.0132, -0.0388]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.26.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0559,  0.0447,  0.0034,  ...,  0.0103, -0.0537,  0.0095],\n",
      "        [ 0.0172, -0.0049,  0.0151,  ..., -0.0153,  0.0173, -0.0330],\n",
      "        [ 0.0186,  0.0042,  0.0669,  ...,  0.0084, -0.0073, -0.0222],\n",
      "        ...,\n",
      "        [-0.0016, -0.0898,  0.0075,  ..., -0.0991, -0.0239, -0.0049],\n",
      "        [-0.0525, -0.0457, -0.0002,  ..., -0.0042, -0.0303,  0.0393],\n",
      "        [ 0.0439, -0.0250,  0.0330,  ..., -0.0427, -0.0645,  0.0286]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.26.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0581, -0.0170, -0.0258,  ..., -0.0298,  0.0280,  0.0386],\n",
      "        [ 0.0308, -0.0457, -0.0297,  ..., -0.0074, -0.0330, -0.0069],\n",
      "        [ 0.0371, -0.0186,  0.0229,  ...,  0.0164, -0.0128,  0.0059],\n",
      "        ...,\n",
      "        [ 0.0205, -0.0221, -0.0151,  ..., -0.0305, -0.0190, -0.0270],\n",
      "        [-0.0535,  0.0203,  0.0082,  ...,  0.0145, -0.0272, -0.0090],\n",
      "        [ 0.0025, -0.0260,  0.0220,  ...,  0.0019,  0.0786,  0.0356]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.26.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.26.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.27.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0237, -0.0113,  0.0168,  ...,  0.0693, -0.0228,  0.0359],\n",
      "        [ 0.0074,  0.0215,  0.0277,  ..., -0.0041, -0.0674, -0.0510],\n",
      "        [-0.0045,  0.0080, -0.0073,  ...,  0.0420,  0.0203, -0.0044],\n",
      "        ...,\n",
      "        [ 0.0415, -0.0220, -0.0297,  ..., -0.0957,  0.0500,  0.0479],\n",
      "        [ 0.0156, -0.0781, -0.0014,  ..., -0.0479, -0.0317,  0.0295],\n",
      "        [-0.0417, -0.0159,  0.0190,  ..., -0.0452, -0.0522,  0.0437]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.27.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.27.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0479, -0.0273,  0.0415,  ...,  0.0396, -0.0396,  0.0383],\n",
      "        [-0.0071,  0.0198, -0.0043,  ..., -0.0273, -0.0771,  0.0092],\n",
      "        [-0.0059,  0.0184,  0.0203,  ..., -0.0664, -0.0148,  0.0361],\n",
      "        ...,\n",
      "        [ 0.0669,  0.0037,  0.0308,  ...,  0.0542,  0.0115, -0.1104],\n",
      "        [ 0.0254, -0.0164, -0.0190,  ..., -0.0159, -0.0564, -0.0060],\n",
      "        [-0.0245, -0.0400,  0.0073,  ..., -0.0425,  0.0388,  0.0068]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.27.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0215,  0.0410,  0.0659,  ..., -0.0464, -0.0031,  0.0361],\n",
      "        [ 0.0376, -0.0167,  0.0146,  ...,  0.0535, -0.0393, -0.0082],\n",
      "        [ 0.0562,  0.0221,  0.0376,  ..., -0.0525, -0.0547,  0.0126],\n",
      "        ...,\n",
      "        [-0.0173,  0.0104,  0.0090,  ..., -0.0137,  0.0122, -0.0055],\n",
      "        [ 0.0303, -0.0020,  0.0157,  ..., -0.0491,  0.0239, -0.0059],\n",
      "        [ 0.0071,  0.0074, -0.0195,  ..., -0.0107, -0.0170,  0.0082]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.27.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.27.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0258, -0.0356, -0.0090,  ..., -0.0098,  0.0171,  0.0032],\n",
      "        [-0.0342, -0.0046, -0.0120,  ...,  0.0108,  0.0312,  0.0070],\n",
      "        [-0.0090,  0.0037,  0.0050,  ..., -0.0294, -0.0125,  0.0247],\n",
      "        ...,\n",
      "        [-0.0356,  0.0073, -0.0325,  ...,  0.0126, -0.0679, -0.0352],\n",
      "        [ 0.0177,  0.0315, -0.0396,  ...,  0.0121, -0.0332,  0.0815],\n",
      "        [-0.0009,  0.0164, -0.0742,  ...,  0.0046, -0.0354,  0.0781]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.27.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0708,  0.0276,  0.0153,  ...,  0.0459,  0.0659, -0.0303],\n",
      "        [-0.0645, -0.0138,  0.0288,  ..., -0.0115,  0.0172, -0.0043],\n",
      "        [ 0.0708, -0.0569, -0.0542,  ...,  0.0605, -0.0013, -0.0261],\n",
      "        ...,\n",
      "        [ 0.0449, -0.0449, -0.0266,  ...,  0.0747,  0.0693,  0.0054],\n",
      "        [-0.0079, -0.0132, -0.0283,  ..., -0.0069, -0.0032, -0.0044],\n",
      "        [ 0.0527,  0.0508,  0.0008,  ...,  0.0457, -0.0649,  0.0038]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.27.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0264,  0.0410, -0.0464,  ..., -0.0041,  0.0342,  0.0454],\n",
      "        [-0.0258,  0.0291,  0.0201,  ...,  0.0092,  0.0115,  0.0070],\n",
      "        [-0.0069, -0.0322,  0.0500,  ...,  0.0339,  0.0137, -0.0579],\n",
      "        ...,\n",
      "        [-0.0332,  0.0260, -0.0106,  ...,  0.0427,  0.0003,  0.0114],\n",
      "        [-0.0013,  0.0684, -0.0325,  ...,  0.0172,  0.0181, -0.0226],\n",
      "        [ 0.0693, -0.0081, -0.0349,  ..., -0.0396,  0.0058,  0.0264]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.27.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-6.1951e-03, -3.6133e-02, -8.4839e-03,  ..., -2.0142e-02,\n",
      "         -1.6724e-02, -3.8086e-02],\n",
      "        [-7.2754e-02, -1.4404e-02,  2.8687e-03,  ...,  6.1035e-03,\n",
      "         -4.8828e-02,  2.5635e-02],\n",
      "        [-1.8677e-02, -5.2734e-02,  7.9102e-02,  ...,  4.2969e-02,\n",
      "         -1.2793e-01, -3.3691e-02],\n",
      "        ...,\n",
      "        [-1.1475e-02,  4.7684e-06, -6.7520e-04,  ..., -2.6489e-02,\n",
      "         -1.0071e-02,  2.3193e-02],\n",
      "        [-6.4373e-05, -6.4453e-02,  3.2959e-03,  ..., -1.1230e-02,\n",
      "          8.3923e-04, -5.6152e-02],\n",
      "        [-7.2266e-02,  1.2756e-02, -4.7852e-02,  ..., -1.9775e-02,\n",
      "         -1.5503e-02,  2.8931e-02]], requires_grad=True)\n",
      "Layer: model.layers.27.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0118, -0.0566, -0.0011,  ...,  0.0176, -0.0016, -0.0693],\n",
      "        [-0.0476, -0.0142,  0.0498,  ..., -0.0039, -0.0479, -0.0518],\n",
      "        [ 0.0165, -0.0302,  0.0513,  ...,  0.0771,  0.0400, -0.0238],\n",
      "        ...,\n",
      "        [-0.0566, -0.0352,  0.0012,  ...,  0.0144, -0.0232,  0.0376],\n",
      "        [-0.0020, -0.0581, -0.0840,  ..., -0.0089, -0.0247, -0.0129],\n",
      "        [ 0.0008,  0.0664, -0.0229,  ...,  0.0361, -0.0547,  0.0491]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.27.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.27.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.28.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0415, -0.0161, -0.0240,  ..., -0.0378, -0.0126, -0.0276],\n",
      "        [ 0.0791,  0.0038, -0.0146,  ...,  0.0439,  0.0520, -0.0378],\n",
      "        [ 0.0234,  0.1250, -0.0435,  ...,  0.0508,  0.0305, -0.0898],\n",
      "        ...,\n",
      "        [ 0.0269, -0.0303, -0.0271,  ...,  0.0023, -0.0266, -0.0272],\n",
      "        [ 0.0349,  0.0172, -0.0442,  ...,  0.0014,  0.0166,  0.0317],\n",
      "        [-0.0283,  0.0615,  0.0757,  ..., -0.0156,  0.0918, -0.0151]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.28.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.28.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0447, -0.0547,  0.0002,  ...,  0.0483,  0.0635, -0.0195],\n",
      "        [ 0.0126, -0.0361,  0.0532,  ...,  0.0586, -0.0393, -0.0069],\n",
      "        [-0.0003, -0.0713,  0.0215,  ...,  0.0330,  0.0299, -0.0080],\n",
      "        ...,\n",
      "        [-0.0103,  0.0173, -0.0265,  ...,  0.0129,  0.0033,  0.1230],\n",
      "        [-0.0315,  0.0254, -0.0449,  ...,  0.0449,  0.0014,  0.0352],\n",
      "        [ 0.0021,  0.0044, -0.0155,  ..., -0.0025,  0.0062,  0.0278]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.28.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0092, -0.0053,  0.0089,  ...,  0.0076, -0.0043,  0.0615],\n",
      "        [-0.0083,  0.0073, -0.0347,  ...,  0.0078,  0.0796,  0.0077],\n",
      "        [ 0.0195,  0.0190, -0.0586,  ...,  0.0437,  0.0072, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0067,  0.0004,  0.0049,  ..., -0.0082, -0.0099, -0.0069],\n",
      "        [ 0.0466,  0.0070,  0.0311,  ...,  0.0425, -0.0311,  0.0396],\n",
      "        [-0.0166, -0.0206,  0.0208,  ..., -0.0337,  0.0067,  0.0457]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.28.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.28.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0098, -0.0309, -0.0283,  ...,  0.0383, -0.0493, -0.0209],\n",
      "        [ 0.0096, -0.0292, -0.0306,  ...,  0.0195,  0.0342,  0.0095],\n",
      "        [ 0.0508,  0.0184, -0.0030,  ...,  0.0471, -0.0664,  0.0669],\n",
      "        ...,\n",
      "        [ 0.0019,  0.0306, -0.0767,  ...,  0.0403, -0.0129, -0.0593],\n",
      "        [ 0.0386, -0.0082, -0.0708,  ...,  0.0058,  0.0056,  0.0153],\n",
      "        [-0.0347,  0.0071, -0.0598,  ..., -0.1064,  0.0801,  0.0200]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.28.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0304,  0.0898,  0.0674,  ...,  0.0435,  0.0168,  0.0173],\n",
      "        [ 0.0579,  0.0101,  0.0430,  ..., -0.0723, -0.0520, -0.0291],\n",
      "        [-0.0069,  0.0108, -0.0122,  ..., -0.0269, -0.0008,  0.0206],\n",
      "        ...,\n",
      "        [-0.0400,  0.0272, -0.0033,  ...,  0.0266,  0.0242, -0.0586],\n",
      "        [ 0.0244, -0.0081, -0.0349,  ...,  0.0217,  0.0615, -0.0562],\n",
      "        [-0.0074, -0.0234, -0.0381,  ...,  0.0036,  0.0481, -0.0306]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.28.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 1.2756e-02, -2.4902e-02,  3.4912e-02,  ..., -1.2878e-02,\n",
      "          6.5918e-02,  2.0264e-02],\n",
      "        [ 1.9287e-02, -2.2736e-03, -1.5991e-02,  ..., -1.7090e-02,\n",
      "         -2.7100e-02,  1.9043e-02],\n",
      "        [-3.5095e-03,  3.0273e-02,  1.4526e-02,  ...,  2.3682e-02,\n",
      "         -2.9175e-02,  7.9956e-03],\n",
      "        ...,\n",
      "        [ 2.2583e-02, -4.9744e-03, -1.4465e-02,  ..., -1.1230e-02,\n",
      "          1.2573e-02,  2.8381e-03],\n",
      "        [ 1.5259e-03, -4.0527e-02,  3.8818e-02,  ...,  4.6875e-02,\n",
      "         -4.0283e-02,  1.4801e-03],\n",
      "        [-1.0437e-02,  7.3433e-05,  1.6113e-02,  ...,  4.4922e-02,\n",
      "          8.1787e-03, -3.9978e-03]], requires_grad=True)\n",
      "Layer: model.layers.28.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0903,  0.0063, -0.0344,  ..., -0.1206, -0.0172,  0.0084],\n",
      "        [ 0.0571,  0.0791, -0.0069,  ...,  0.0481, -0.0586, -0.0128],\n",
      "        [ 0.0183,  0.0547, -0.0046,  ...,  0.0347,  0.0128, -0.0325],\n",
      "        ...,\n",
      "        [-0.0053,  0.0023, -0.0099,  ..., -0.0019,  0.0014,  0.0023],\n",
      "        [ 0.0518, -0.0176,  0.0289,  ..., -0.0282, -0.0376, -0.0564],\n",
      "        [ 0.0435,  0.0120, -0.0312,  ...,  0.0222, -0.0273, -0.0222]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.28.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0212,  0.0040,  0.0044,  ..., -0.0044,  0.0625,  0.0018],\n",
      "        [ 0.0654, -0.0420,  0.0282,  ...,  0.0088,  0.0049,  0.0016],\n",
      "        [-0.0544,  0.0289, -0.0496,  ..., -0.0123,  0.0171, -0.0464],\n",
      "        ...,\n",
      "        [-0.0684,  0.0221,  0.0361,  ...,  0.0557, -0.0535, -0.0479],\n",
      "        [-0.0026, -0.0070,  0.0359,  ..., -0.0095, -0.0356, -0.0181],\n",
      "        [ 0.0010, -0.0403, -0.0562,  ..., -0.0249, -0.0403,  0.0420]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.28.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.28.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.29.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0119, -0.0518,  0.1074,  ..., -0.0608,  0.0110, -0.0217],\n",
      "        [-0.0425,  0.0737, -0.0079,  ...,  0.0303, -0.0356,  0.0017],\n",
      "        [-0.0474, -0.0449, -0.0310,  ..., -0.0088, -0.0071, -0.0014],\n",
      "        ...,\n",
      "        [ 0.0222,  0.0190,  0.0179,  ..., -0.0422,  0.0141, -0.0150],\n",
      "        [-0.0209,  0.0138, -0.0151,  ...,  0.0513,  0.0151, -0.0527],\n",
      "        [ 0.0209,  0.0452,  0.0222,  ..., -0.0110,  0.0055,  0.0452]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.29.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.29.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0149,  0.0312, -0.0498,  ..., -0.0317,  0.0430, -0.0396],\n",
      "        [ 0.0588, -0.0004,  0.0684,  ..., -0.0236, -0.0466,  0.0327],\n",
      "        [-0.0488, -0.0396,  0.0098,  ...,  0.0203,  0.0260,  0.0664],\n",
      "        ...,\n",
      "        [ 0.0087, -0.0161, -0.0013,  ..., -0.0076,  0.0008, -0.0054],\n",
      "        [ 0.0041, -0.0376,  0.0483,  ...,  0.0206,  0.0127,  0.0159],\n",
      "        [ 0.0403,  0.0079, -0.0322,  ..., -0.0227,  0.0439,  0.0270]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.29.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-1.8066e-02,  4.4434e-02,  1.8066e-02,  ..., -6.4697e-03,\n",
      "          2.9663e-02,  2.0630e-02],\n",
      "        [ 6.3477e-02,  5.2246e-02, -4.3945e-02,  ..., -1.1292e-03,\n",
      "         -4.9316e-02, -1.9775e-02],\n",
      "        [ 8.4229e-03,  1.0010e-02,  6.4392e-03,  ...,  1.4832e-02,\n",
      "         -2.1240e-02,  4.0054e-05],\n",
      "        ...,\n",
      "        [ 5.5542e-03,  3.4424e-02,  5.0293e-02,  ...,  2.8076e-02,\n",
      "         -3.1891e-03,  2.0752e-02],\n",
      "        [ 5.3711e-02, -4.3335e-03, -4.7607e-02,  ...,  3.3691e-02,\n",
      "          2.8442e-02,  1.6968e-02],\n",
      "        [-5.1880e-03,  3.0029e-02,  3.6621e-02,  ..., -2.0142e-02,\n",
      "          3.1128e-02,  3.2471e-02]], requires_grad=True)\n",
      "Layer: model.layers.29.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.29.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0095, -0.0591,  0.1309,  ...,  0.0845,  0.0143, -0.0040],\n",
      "        [ 0.0281,  0.0006,  0.0342,  ...,  0.0082,  0.0737, -0.0505],\n",
      "        [ 0.0312,  0.0198, -0.0557,  ..., -0.0242, -0.0562, -0.0027],\n",
      "        ...,\n",
      "        [-0.0293,  0.0096,  0.0259,  ...,  0.0143,  0.0405,  0.0210],\n",
      "        [ 0.0276, -0.0264, -0.0928,  ..., -0.0058, -0.0026,  0.0101],\n",
      "        [-0.0066,  0.0493,  0.0635,  ...,  0.0244, -0.0039,  0.0396]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.29.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0070, -0.0325, -0.0286,  ...,  0.0225,  0.0220, -0.0391],\n",
      "        [ 0.0143,  0.0090, -0.0051,  ...,  0.0256, -0.0115,  0.0220],\n",
      "        [ 0.0393, -0.0273, -0.0217,  ..., -0.0172, -0.0312, -0.0366],\n",
      "        ...,\n",
      "        [-0.0505, -0.0035, -0.0198,  ...,  0.0209,  0.0053, -0.0182],\n",
      "        [ 0.0067,  0.0099,  0.0293,  ..., -0.0591,  0.0498, -0.0227],\n",
      "        [-0.0767,  0.0459, -0.0874,  ...,  0.0200,  0.0226, -0.0135]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.29.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0510, -0.0171,  0.0081,  ..., -0.0128, -0.0149, -0.0088],\n",
      "        [ 0.0791,  0.0220, -0.0078,  ...,  0.0183,  0.0649, -0.0566],\n",
      "        [ 0.0250,  0.0454,  0.0193,  ..., -0.0791,  0.0596,  0.0732],\n",
      "        ...,\n",
      "        [-0.0125,  0.0035, -0.0864,  ...,  0.0391, -0.0168, -0.0366],\n",
      "        [ 0.0266,  0.0054, -0.0087,  ...,  0.0236, -0.0139,  0.0310],\n",
      "        [-0.0164,  0.0693, -0.0305,  ..., -0.0208,  0.0693, -0.0266]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.29.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0454,  0.0889,  0.0625,  ...,  0.0238, -0.0393, -0.0659],\n",
      "        [-0.0483, -0.0510, -0.0013,  ...,  0.0128, -0.0090,  0.0042],\n",
      "        [-0.0071,  0.0151, -0.0703,  ...,  0.0425, -0.0615, -0.0210],\n",
      "        ...,\n",
      "        [-0.0043,  0.0140, -0.0086,  ..., -0.0464,  0.0072, -0.0271],\n",
      "        [-0.0879,  0.0361, -0.0085,  ...,  0.0205, -0.0234, -0.0381],\n",
      "        [-0.0068,  0.0050,  0.0220,  ...,  0.0004, -0.0210, -0.0620]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.29.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0302, -0.0155,  0.0620,  ..., -0.0132,  0.0051, -0.0186],\n",
      "        [ 0.0820, -0.0098, -0.0208,  ...,  0.0069,  0.0300,  0.0571],\n",
      "        [ 0.0288, -0.0112, -0.0381,  ..., -0.0176,  0.0091, -0.0542],\n",
      "        ...,\n",
      "        [ 0.0476,  0.0006,  0.0386,  ...,  0.0204,  0.0114, -0.0194],\n",
      "        [-0.0028,  0.0144, -0.0376,  ..., -0.0215, -0.0054,  0.0496],\n",
      "        [-0.0801,  0.0076, -0.0282,  ..., -0.0145, -0.0074,  0.0219]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.29.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.29.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.30.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0199, -0.0239,  0.0535,  ...,  0.0129, -0.0077,  0.0089],\n",
      "        [-0.0082, -0.0415,  0.0454,  ...,  0.0186,  0.0066, -0.0120],\n",
      "        [-0.0069,  0.0292, -0.0045,  ...,  0.0339,  0.0532,  0.0488],\n",
      "        ...,\n",
      "        [ 0.0557, -0.0056, -0.0203,  ...,  0.0359, -0.0576, -0.0031],\n",
      "        [-0.0049,  0.0135, -0.0332,  ..., -0.0981, -0.0723, -0.0381],\n",
      "        [-0.0154, -0.0635, -0.0469,  ..., -0.0311,  0.0220,  0.0232]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.30.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0111,  0.0095,  0.0908,  ...,  0.0728, -0.0283, -0.0508],\n",
      "        [ 0.0032,  0.0276, -0.0801,  ..., -0.1074,  0.0557, -0.0713],\n",
      "        [-0.0057,  0.0557,  0.0098,  ...,  0.0184,  0.0227,  0.0210],\n",
      "        ...,\n",
      "        [ 0.0019, -0.1416, -0.0085,  ..., -0.0415,  0.0435,  0.0051],\n",
      "        [-0.0005,  0.0101, -0.0786,  ..., -0.0513,  0.0004,  0.0084],\n",
      "        [-0.0693, -0.0248,  0.0206,  ..., -0.0035,  0.0342,  0.0176]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0417, -0.0035,  0.0237,  ..., -0.0237, -0.0530, -0.0239],\n",
      "        [ 0.0306, -0.0033,  0.0588,  ...,  0.0569,  0.0205, -0.0522],\n",
      "        [ 0.0265, -0.0054,  0.0518,  ...,  0.0142, -0.0459, -0.0064],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0011,  0.0115,  ...,  0.0126, -0.0039,  0.0096],\n",
      "        [-0.0032, -0.0267, -0.0198,  ..., -0.0256,  0.0083,  0.0078],\n",
      "        [ 0.0067, -0.0096, -0.0522,  ...,  0.0222,  0.0198,  0.0156]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.30.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0208, -0.0674, -0.0513,  ..., -0.0023,  0.0630, -0.0576],\n",
      "        [ 0.0069,  0.0282,  0.0874,  ..., -0.0679, -0.0096,  0.0425],\n",
      "        [ 0.0063,  0.0444,  0.0092,  ...,  0.0015, -0.0103, -0.0325],\n",
      "        ...,\n",
      "        [-0.0093,  0.0747, -0.0209,  ...,  0.0017, -0.0027, -0.0208],\n",
      "        [ 0.0400, -0.0249, -0.0381,  ..., -0.0093,  0.0262, -0.0024],\n",
      "        [ 0.0120, -0.0092,  0.0386,  ..., -0.0222, -0.0128, -0.0247]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0168,  0.0229, -0.0254,  ...,  0.0064,  0.0381,  0.0215],\n",
      "        [-0.0041, -0.0444,  0.0332,  ..., -0.0123,  0.0204, -0.0439],\n",
      "        [ 0.0315, -0.0010,  0.0723,  ...,  0.0128,  0.0674,  0.0065],\n",
      "        ...,\n",
      "        [ 0.0116, -0.0228,  0.0320,  ...,  0.0410,  0.0322,  0.0012],\n",
      "        [-0.0115,  0.0077,  0.0198,  ..., -0.0728,  0.0222,  0.0138],\n",
      "        [-0.0063,  0.0033,  0.0145,  ...,  0.0123, -0.0479,  0.0615]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0151, -0.0237,  0.0095,  ...,  0.0295,  0.0020, -0.0471],\n",
      "        [-0.0459,  0.0310, -0.0276,  ..., -0.0304,  0.0396,  0.0299],\n",
      "        [ 0.0242, -0.0300,  0.0518,  ..., -0.0383, -0.0134, -0.0085],\n",
      "        ...,\n",
      "        [ 0.0173, -0.0009, -0.0057,  ...,  0.0679,  0.0027,  0.0272],\n",
      "        [-0.0435,  0.0447, -0.0179,  ..., -0.0874, -0.0449,  0.0181],\n",
      "        [ 0.0118, -0.0425,  0.0179,  ..., -0.0160, -0.0220, -0.0078]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0060, -0.0388,  0.0398,  ...,  0.0496, -0.0157, -0.0172],\n",
      "        [-0.0269, -0.0101,  0.0076,  ..., -0.0615, -0.0435,  0.0325],\n",
      "        [-0.0400, -0.0215, -0.0069,  ...,  0.0099, -0.0219, -0.0006],\n",
      "        ...,\n",
      "        [-0.0101,  0.0006,  0.0190,  ..., -0.0190,  0.0327, -0.0254],\n",
      "        [ 0.0366, -0.0281, -0.0486,  ...,  0.0732,  0.0625,  0.0376],\n",
      "        [ 0.0107,  0.0109,  0.0664,  ...,  0.0069, -0.0352, -0.0008]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0128, -0.0908, -0.0277,  ...,  0.0264,  0.0359, -0.0091],\n",
      "        [-0.0040, -0.0192, -0.0469,  ...,  0.0293, -0.0415,  0.0214],\n",
      "        [ 0.0300,  0.0381, -0.0381,  ...,  0.0302, -0.0128,  0.0200],\n",
      "        ...,\n",
      "        [ 0.0266, -0.0062,  0.0361,  ..., -0.0459,  0.1104, -0.0474],\n",
      "        [-0.0078, -0.0250,  0.0042,  ..., -0.0051,  0.0410, -0.0281],\n",
      "        [-0.0050,  0.0015, -0.0010,  ..., -0.0391,  0.0114,  0.0125]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.30.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.30.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.31.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0234, -0.0408, -0.0053,  ..., -0.0171, -0.0004,  0.0292],\n",
      "        [ 0.0247, -0.0046,  0.0161,  ...,  0.0165,  0.0183,  0.0088],\n",
      "        [-0.0562,  0.0315, -0.0162,  ..., -0.0449,  0.0164, -0.0327],\n",
      "        ...,\n",
      "        [ 0.0483,  0.0396,  0.0200,  ..., -0.0410,  0.0337,  0.0069],\n",
      "        [ 0.0522, -0.0004,  0.0308,  ...,  0.0593,  0.0098, -0.0304],\n",
      "        [-0.0432, -0.0140,  0.0004,  ..., -0.0061, -0.0308, -0.0393]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.31.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0747, -0.0432, -0.0262,  ...,  0.0547, -0.0469,  0.0047],\n",
      "        [ 0.0123, -0.0654, -0.0352,  ..., -0.0153, -0.0012,  0.0850],\n",
      "        [-0.0415, -0.0459,  0.0294,  ...,  0.0063,  0.0255,  0.0221],\n",
      "        ...,\n",
      "        [-0.0398, -0.0033, -0.0249,  ..., -0.0327,  0.0449,  0.0496],\n",
      "        [ 0.0025, -0.0098,  0.0171,  ..., -0.0026, -0.0109,  0.0002],\n",
      "        [-0.0291,  0.0033, -0.0090,  ...,  0.0004, -0.0095, -0.0232]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0195, -0.0072, -0.0569,  ...,  0.0093, -0.0265,  0.0188],\n",
      "        [-0.0085, -0.0571, -0.0049,  ...,  0.0157, -0.0608,  0.0664],\n",
      "        [-0.0398,  0.0261, -0.0664,  ...,  0.0356, -0.0569, -0.0017],\n",
      "        ...,\n",
      "        [ 0.0001, -0.0391, -0.0173,  ...,  0.0654, -0.0388, -0.0276],\n",
      "        [ 0.0149,  0.0199,  0.0059,  ...,  0.0036, -0.0128,  0.0209],\n",
      "        [-0.0271,  0.0300,  0.0605,  ...,  0.0173, -0.0552, -0.0267]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.31.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0640, -0.0008,  0.0471,  ..., -0.0168,  0.0067,  0.0356],\n",
      "        [ 0.0060,  0.0139,  0.0293,  ...,  0.0073, -0.0295, -0.0349],\n",
      "        [-0.0067,  0.0581,  0.0547,  ...,  0.0125,  0.0645, -0.0145],\n",
      "        ...,\n",
      "        [-0.0430, -0.0291,  0.0071,  ...,  0.0188, -0.0703, -0.0238],\n",
      "        [ 0.0144,  0.0099, -0.0267,  ..., -0.0874, -0.0840,  0.0620],\n",
      "        [-0.0087,  0.0723, -0.0291,  ...,  0.0222, -0.0072,  0.0090]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0074, -0.0444,  0.0010,  ..., -0.0081, -0.0317,  0.0176],\n",
      "        [-0.0240,  0.0112,  0.0361,  ...,  0.0425,  0.0471, -0.0125],\n",
      "        [ 0.0239,  0.0168, -0.0074,  ..., -0.0361,  0.0962, -0.0359],\n",
      "        ...,\n",
      "        [ 0.0344, -0.0059,  0.0227,  ...,  0.0483,  0.0074,  0.0471],\n",
      "        [-0.0413, -0.0122, -0.0295,  ...,  0.0488,  0.0208,  0.0145],\n",
      "        [-0.0649,  0.0138, -0.0164,  ...,  0.0148, -0.0179, -0.0327]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0276,  0.0215,  0.0259,  ..., -0.0093, -0.0073, -0.0400],\n",
      "        [-0.0303, -0.0703,  0.0317,  ...,  0.0117, -0.0164,  0.0117],\n",
      "        [-0.0145,  0.0042,  0.0146,  ...,  0.0713, -0.0610,  0.0013],\n",
      "        ...,\n",
      "        [-0.0004,  0.0195,  0.0197,  ...,  0.0208,  0.0552,  0.0001],\n",
      "        [ 0.0247, -0.0236, -0.0498,  ..., -0.0200, -0.0315, -0.0366],\n",
      "        [-0.0131, -0.0117,  0.0059,  ...,  0.0386,  0.0145,  0.0275]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0542,  0.0024, -0.0266,  ...,  0.0444, -0.0201, -0.0054],\n",
      "        [ 0.0223, -0.0413,  0.0579,  ..., -0.0019, -0.0244, -0.0171],\n",
      "        [ 0.0693,  0.0576,  0.0234,  ..., -0.0933, -0.0310,  0.0016],\n",
      "        ...,\n",
      "        [ 0.0513, -0.0234,  0.0703,  ...,  0.0229, -0.0337,  0.0059],\n",
      "        [-0.0164,  0.0090,  0.0172,  ...,  0.0237, -0.0508,  0.0396],\n",
      "        [-0.0327, -0.0157,  0.0437,  ...,  0.0129, -0.0581,  0.0732]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0085, -0.0371, -0.0060,  ...,  0.0405, -0.0286, -0.0030],\n",
      "        [ 0.0199, -0.0215,  0.0077,  ...,  0.0011,  0.0189,  0.0142],\n",
      "        [ 0.0464,  0.0312, -0.0058,  ...,  0.0447, -0.0147, -0.0432],\n",
      "        ...,\n",
      "        [ 0.0315,  0.0469, -0.0674,  ...,  0.0515,  0.0820, -0.0204],\n",
      "        [-0.0459,  0.0176, -0.0569,  ..., -0.0645, -0.0081,  0.0376],\n",
      "        [-0.0312, -0.0034, -0.0225,  ...,  0.0133,  0.0332,  0.0022]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.31.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.31.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.32.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0474, -0.0089,  0.0640,  ...,  0.0305,  0.0159, -0.0177],\n",
      "        [-0.0265, -0.0141,  0.0371,  ...,  0.0200, -0.0054, -0.0103],\n",
      "        [ 0.0190, -0.0028,  0.0042,  ..., -0.0559, -0.0164,  0.0591],\n",
      "        ...,\n",
      "        [ 0.0209, -0.0234, -0.0491,  ...,  0.0344, -0.0042, -0.0239],\n",
      "        [-0.0152,  0.0444, -0.0011,  ..., -0.0293,  0.0430, -0.0845],\n",
      "        [ 0.0182, -0.0009,  0.0184,  ..., -0.0184,  0.0034,  0.0014]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.32.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.32.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0308, -0.0854, -0.0530,  ...,  0.0234, -0.0605,  0.0010],\n",
      "        [ 0.0566,  0.0139, -0.0253,  ..., -0.0087,  0.0151, -0.0123],\n",
      "        [-0.0388,  0.0625, -0.0703,  ..., -0.1167,  0.0737, -0.0520],\n",
      "        ...,\n",
      "        [ 0.0060,  0.0068, -0.0173,  ...,  0.0028, -0.0171,  0.0089],\n",
      "        [ 0.0171, -0.0500,  0.0461,  ..., -0.0620,  0.0530,  0.0571],\n",
      "        [ 0.0148, -0.0010, -0.0141,  ...,  0.0405,  0.0281,  0.0042]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.32.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0215,  0.0649, -0.0009,  ...,  0.0126, -0.0415, -0.0117],\n",
      "        [-0.0281, -0.0122,  0.0143,  ...,  0.0178, -0.0654, -0.0254],\n",
      "        [ 0.0021, -0.0322,  0.0393,  ..., -0.0222,  0.0128,  0.0121],\n",
      "        ...,\n",
      "        [ 0.0079, -0.0092,  0.0022,  ...,  0.0194, -0.0261, -0.0439],\n",
      "        [-0.0231,  0.0165,  0.0386,  ...,  0.0273,  0.0220, -0.0393],\n",
      "        [ 0.0070,  0.0026, -0.0089,  ...,  0.0117, -0.0197,  0.0012]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.32.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.32.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0349, -0.0347, -0.0491,  ...,  0.0645, -0.0240, -0.0359],\n",
      "        [ 0.0469,  0.0278,  0.0205,  ...,  0.0214, -0.0114,  0.0087],\n",
      "        [ 0.0132,  0.0347, -0.0038,  ..., -0.0898, -0.0178, -0.1035],\n",
      "        ...,\n",
      "        [-0.0200,  0.0620, -0.0064,  ..., -0.0347, -0.0171,  0.0508],\n",
      "        [ 0.0674,  0.0137, -0.0129,  ...,  0.0173, -0.0454, -0.0403],\n",
      "        [-0.0041,  0.0166, -0.0244,  ..., -0.0261, -0.0289,  0.0031]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.32.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0425,  0.0703,  0.0245,  ..., -0.0168, -0.0305, -0.0596],\n",
      "        [-0.0054,  0.0266, -0.0142,  ..., -0.0055,  0.0170, -0.0038],\n",
      "        [ 0.0332, -0.0036, -0.0010,  ...,  0.0332,  0.0498,  0.0967],\n",
      "        ...,\n",
      "        [ 0.0063, -0.0830,  0.0069,  ...,  0.1006,  0.0361,  0.0557],\n",
      "        [ 0.0203,  0.0928,  0.0908,  ...,  0.0165,  0.0825, -0.0215],\n",
      "        [ 0.0232,  0.0311,  0.0103,  ..., -0.0079,  0.0009, -0.0022]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.32.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 3.9368e-03,  6.2500e-02,  3.2227e-02,  ...,  1.3062e-02,\n",
      "          3.6316e-03, -4.6875e-02],\n",
      "        [-3.4912e-02,  2.0386e-02,  7.6172e-02,  ..., -3.3203e-02,\n",
      "         -1.2634e-02, -5.6641e-02],\n",
      "        [-5.0537e-02, -4.0039e-02,  3.4668e-02,  ...,  6.2500e-02,\n",
      "          7.8125e-03,  4.7684e-06],\n",
      "        ...,\n",
      "        [-8.1787e-03, -3.8086e-02,  3.6621e-02,  ..., -8.5449e-03,\n",
      "          9.2163e-03,  1.0620e-02],\n",
      "        [ 7.5195e-02,  2.1118e-02, -8.4839e-03,  ..., -3.9307e-02,\n",
      "          4.2969e-02,  1.5381e-02],\n",
      "        [-1.0193e-02, -3.2715e-02, -1.4038e-02,  ...,  1.3794e-02,\n",
      "          2.7847e-04,  1.8311e-02]], requires_grad=True)\n",
      "Layer: model.layers.32.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0188, -0.0361,  0.0103,  ...,  0.0181, -0.0242, -0.0193],\n",
      "        [-0.0413, -0.0114,  0.0167,  ...,  0.0164,  0.0056,  0.0344],\n",
      "        [ 0.0145,  0.0223,  0.0820,  ...,  0.0070, -0.0435, -0.0242],\n",
      "        ...,\n",
      "        [-0.0374,  0.0151,  0.0359,  ..., -0.0869, -0.0718,  0.0240],\n",
      "        [-0.0688,  0.0684, -0.0339,  ..., -0.0137,  0.0186, -0.0405],\n",
      "        [-0.0234,  0.0212, -0.0176,  ..., -0.0229, -0.0396, -0.0219]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.32.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0225, -0.0152,  0.0111,  ..., -0.0435, -0.0762, -0.0292],\n",
      "        [-0.0420, -0.0130,  0.0918,  ...,  0.0265,  0.0076,  0.0457],\n",
      "        [-0.0447, -0.0393,  0.0510,  ...,  0.0021, -0.0151, -0.0190],\n",
      "        ...,\n",
      "        [ 0.0464, -0.0193, -0.0114,  ...,  0.0176,  0.0065, -0.0693],\n",
      "        [ 0.0146,  0.0322, -0.0192,  ...,  0.0173,  0.0078, -0.0109],\n",
      "        [-0.0349,  0.0062,  0.0093,  ...,  0.0058, -0.0166,  0.0231]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.32.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.32.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.33.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0016, -0.0271,  0.0073,  ...,  0.0276, -0.0288, -0.0187],\n",
      "        [-0.0206,  0.0159, -0.0327,  ...,  0.0581,  0.0018, -0.0260],\n",
      "        [ 0.0141, -0.0045,  0.0160,  ...,  0.0262,  0.0062,  0.0508],\n",
      "        ...,\n",
      "        [ 0.0092,  0.0007,  0.0041,  ...,  0.0586, -0.0330, -0.0115],\n",
      "        [ 0.0142,  0.0413, -0.0125,  ..., -0.0121, -0.0398, -0.0122],\n",
      "        [ 0.0332,  0.0879,  0.0835,  ...,  0.0381, -0.0084,  0.0021]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.33.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0303, -0.0117,  0.0128,  ..., -0.0175, -0.0164,  0.0012],\n",
      "        [ 0.0625,  0.0055, -0.0366,  ...,  0.0103, -0.0601, -0.0278],\n",
      "        [ 0.0361,  0.0184, -0.0518,  ..., -0.0601,  0.0417,  0.0225],\n",
      "        ...,\n",
      "        [-0.0295,  0.0195, -0.0110,  ...,  0.0967, -0.0193, -0.0435],\n",
      "        [ 0.0461,  0.0510,  0.0103,  ...,  0.0087, -0.0065, -0.0037],\n",
      "        [ 0.0034,  0.0070,  0.0031,  ..., -0.0337,  0.0361,  0.0078]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0303,  0.0217,  0.0109,  ..., -0.0352,  0.0265, -0.0449],\n",
      "        [ 0.0361,  0.0889,  0.0337,  ..., -0.0203, -0.0014, -0.0342],\n",
      "        [-0.0571, -0.0018, -0.0703,  ..., -0.0154,  0.0024, -0.0063],\n",
      "        ...,\n",
      "        [-0.0109, -0.0113,  0.0354,  ..., -0.0254, -0.0347, -0.0286],\n",
      "        [-0.0035, -0.0046, -0.0408,  ...,  0.0479,  0.0021, -0.0147],\n",
      "        [-0.0302, -0.0064, -0.0354,  ...,  0.0137, -0.0289, -0.0117]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.33.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0708, -0.0115,  0.0522,  ..., -0.0026, -0.0211,  0.0273],\n",
      "        [ 0.0457,  0.0067, -0.0435,  ..., -0.1445,  0.0608, -0.0004],\n",
      "        [ 0.0173,  0.0295,  0.0050,  ..., -0.0569, -0.0500,  0.0444],\n",
      "        ...,\n",
      "        [-0.0033, -0.0464,  0.0361,  ..., -0.0312,  0.0283, -0.0037],\n",
      "        [ 0.0116, -0.0143, -0.0212,  ...,  0.0344,  0.0383, -0.0620],\n",
      "        [ 0.0415, -0.0464, -0.0347,  ...,  0.0054, -0.0006,  0.0084]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0108,  0.0226, -0.0081,  ..., -0.0356,  0.0349,  0.0069],\n",
      "        [ 0.0086,  0.0007,  0.0217,  ..., -0.0004,  0.0107, -0.0183],\n",
      "        [-0.0302, -0.0317, -0.0232,  ..., -0.0342,  0.0249, -0.0854],\n",
      "        ...,\n",
      "        [-0.0041, -0.0317, -0.0193,  ...,  0.0110,  0.0630,  0.0098],\n",
      "        [ 0.0018,  0.0542,  0.0149,  ...,  0.0152, -0.0342, -0.0103],\n",
      "        [-0.0085, -0.0544, -0.0093,  ...,  0.0064,  0.0032, -0.0359]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0155, -0.0239,  0.0503,  ..., -0.0302,  0.0205,  0.0393],\n",
      "        [-0.0008, -0.0126,  0.0728,  ..., -0.0048, -0.0674, -0.0259],\n",
      "        [-0.0184, -0.0364,  0.0188,  ..., -0.0325, -0.0112,  0.0232],\n",
      "        ...,\n",
      "        [ 0.0262, -0.0040, -0.0439,  ..., -0.0194, -0.0254,  0.0479],\n",
      "        [-0.0145,  0.0154, -0.0142,  ...,  0.0251, -0.0231,  0.0146],\n",
      "        [-0.0461,  0.0177,  0.0122,  ..., -0.0295, -0.0388,  0.0249]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0271,  0.0251,  0.0312,  ..., -0.0398, -0.0212, -0.0138],\n",
      "        [-0.0009,  0.0620,  0.0781,  ..., -0.0422, -0.0903, -0.0130],\n",
      "        [ 0.0498, -0.0238, -0.0007,  ..., -0.0417, -0.0061, -0.0718],\n",
      "        ...,\n",
      "        [ 0.0115, -0.0199, -0.0515,  ...,  0.0128, -0.0251, -0.0146],\n",
      "        [ 0.0034, -0.0371, -0.0171,  ..., -0.0183,  0.0239, -0.0091],\n",
      "        [ 0.0181,  0.0400, -0.0791,  ...,  0.0135, -0.0664, -0.0728]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0181,  0.0352,  0.0474,  ..., -0.0095,  0.0393, -0.0143],\n",
      "        [-0.0149,  0.0242,  0.0062,  ...,  0.0198, -0.0576,  0.0776],\n",
      "        [-0.0515,  0.0928, -0.0464,  ...,  0.0046, -0.0081, -0.0283],\n",
      "        ...,\n",
      "        [-0.0317,  0.0737, -0.0305,  ..., -0.0039,  0.0019, -0.0259],\n",
      "        [ 0.0210, -0.0645,  0.0071,  ..., -0.0062,  0.0243, -0.0437],\n",
      "        [ 0.0081,  0.0381,  0.0076,  ...,  0.0039, -0.0200, -0.0583]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.33.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.33.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.34.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0248, -0.0193,  0.0216,  ..., -0.0114,  0.0464, -0.0571],\n",
      "        [-0.0549, -0.0022, -0.0195,  ..., -0.0131,  0.0427, -0.0540],\n",
      "        [-0.0303, -0.1299, -0.0249,  ...,  0.0825,  0.0066, -0.0181],\n",
      "        ...,\n",
      "        [ 0.0425,  0.0388,  0.0201,  ..., -0.0234, -0.0044,  0.0022],\n",
      "        [-0.0168, -0.0454, -0.0079,  ..., -0.0508,  0.0742,  0.0164],\n",
      "        [-0.0056, -0.0036,  0.0596,  ...,  0.0347,  0.0503,  0.0131]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.34.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.34.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0194,  0.0009, -0.0532,  ...,  0.0732, -0.0557,  0.0104],\n",
      "        [ 0.0195,  0.0223, -0.0266,  ...,  0.0087, -0.0075, -0.0096],\n",
      "        [-0.0054, -0.0115,  0.0383,  ..., -0.0167,  0.0332,  0.0532],\n",
      "        ...,\n",
      "        [-0.0267, -0.0112, -0.0124,  ..., -0.0142, -0.0032,  0.0249],\n",
      "        [-0.0312,  0.0030, -0.0297,  ..., -0.0425,  0.0042,  0.0205],\n",
      "        [ 0.0045, -0.0015, -0.0079,  ...,  0.0085,  0.0043, -0.0459]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.34.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0164, -0.0173, -0.0957,  ..., -0.0013,  0.0176,  0.0078],\n",
      "        [ 0.0364, -0.0101,  0.0234,  ..., -0.0248, -0.0093, -0.0625],\n",
      "        [-0.0236, -0.0688, -0.0413,  ..., -0.0552, -0.0466, -0.0070],\n",
      "        ...,\n",
      "        [ 0.0503,  0.0182,  0.0547,  ...,  0.0166,  0.0186,  0.0630],\n",
      "        [ 0.0215, -0.0171,  0.0010,  ..., -0.0071,  0.0106,  0.0200],\n",
      "        [ 0.0108, -0.0144, -0.0259,  ..., -0.0124,  0.0276,  0.0121]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.34.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.34.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0137,  0.0283,  0.0615,  ...,  0.0327,  0.0378,  0.0096],\n",
      "        [ 0.0026,  0.0269, -0.0261,  ...,  0.0530,  0.0654, -0.0444],\n",
      "        [ 0.0679, -0.0371, -0.0199,  ..., -0.0121, -0.1055,  0.0165],\n",
      "        ...,\n",
      "        [ 0.0771, -0.0508,  0.0444,  ..., -0.0205, -0.0840,  0.0066],\n",
      "        [ 0.0162,  0.0317,  0.0289,  ..., -0.0703, -0.0097, -0.0342],\n",
      "        [ 0.0176,  0.0315,  0.1387,  ...,  0.0645, -0.0703,  0.0195]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.34.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-3.8605e-03,  5.6641e-02,  8.7891e-03,  ..., -6.0303e-02,\n",
      "          3.5889e-02, -9.6680e-02],\n",
      "        [-5.3955e-02,  2.4536e-02,  2.5787e-03,  ...,  3.4180e-02,\n",
      "          2.5024e-02,  9.2506e-05],\n",
      "        [-6.1523e-02, -3.7109e-02, -2.0996e-02,  ..., -1.2988e-01,\n",
      "         -1.5015e-02,  6.5918e-02],\n",
      "        ...,\n",
      "        [-1.1353e-02,  5.8838e-02, -3.6133e-02,  ...,  1.4954e-03,\n",
      "          4.1260e-02,  4.8828e-02],\n",
      "        [ 6.2012e-02,  8.5938e-02,  1.2283e-03,  ...,  2.3499e-03,\n",
      "          5.7617e-02,  4.8340e-02],\n",
      "        [-6.2012e-02, -1.3672e-02,  4.9072e-02,  ..., -2.5391e-02,\n",
      "          5.2185e-03,  6.1523e-02]], requires_grad=True)\n",
      "Layer: model.layers.34.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0048, -0.0098, -0.0017,  ...,  0.0640, -0.0728, -0.0854],\n",
      "        [-0.0090,  0.0088,  0.0173,  ..., -0.0469, -0.0396, -0.0179],\n",
      "        [ 0.0344,  0.0047, -0.0178,  ..., -0.0625,  0.0302,  0.0153],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0339,  0.0339,  ..., -0.0171,  0.0284,  0.0071],\n",
      "        [ 0.0038,  0.0493,  0.0079,  ...,  0.0219,  0.0150,  0.0031],\n",
      "        [ 0.0435, -0.0294, -0.0082,  ...,  0.0102, -0.0562,  0.0101]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.34.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0500, -0.0203, -0.0023,  ..., -0.0396,  0.0006, -0.0254],\n",
      "        [ 0.0208,  0.0149,  0.0192,  ...,  0.0077,  0.0211, -0.0102],\n",
      "        [ 0.0200,  0.0024, -0.0242,  ...,  0.0131,  0.0591, -0.0447],\n",
      "        ...,\n",
      "        [-0.0596,  0.0505, -0.0361,  ..., -0.0186, -0.0166, -0.0023],\n",
      "        [ 0.0781,  0.0610, -0.0099,  ...,  0.0674,  0.0576,  0.0474],\n",
      "        [ 0.0337, -0.0136,  0.0198,  ..., -0.0042, -0.0295,  0.0415]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.34.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0442,  0.0060, -0.0339,  ..., -0.0170, -0.0024,  0.0159],\n",
      "        [-0.0152, -0.0266, -0.0004,  ..., -0.0034,  0.0162, -0.0053],\n",
      "        [ 0.0062,  0.0161,  0.0276,  ..., -0.0540,  0.0146,  0.0222],\n",
      "        ...,\n",
      "        [-0.0023, -0.0427,  0.0168,  ...,  0.0159,  0.0325, -0.0208],\n",
      "        [-0.0216, -0.0391, -0.0297,  ...,  0.0439,  0.0264,  0.0259],\n",
      "        [-0.0422, -0.0471, -0.0231,  ...,  0.0204, -0.0469,  0.0014]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.34.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.34.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.35.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0391, -0.0347,  0.0101,  ..., -0.0232, -0.0339, -0.0349],\n",
      "        [-0.0864, -0.0159, -0.0188,  ..., -0.0308,  0.0204,  0.0393],\n",
      "        [-0.0085,  0.0227,  0.0398,  ..., -0.0325, -0.0996, -0.0041],\n",
      "        ...,\n",
      "        [-0.0181,  0.0226, -0.0113,  ...,  0.0317, -0.0349, -0.0227],\n",
      "        [-0.0330,  0.0322, -0.0066,  ...,  0.0034, -0.0618, -0.0195],\n",
      "        [ 0.0013, -0.0605,  0.0116,  ..., -0.0510,  0.0126,  0.0339]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.35.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0391, -0.0179,  0.0049,  ..., -0.0035, -0.0219,  0.0339],\n",
      "        [ 0.0085,  0.0133, -0.0115,  ..., -0.0364, -0.0183,  0.0337],\n",
      "        [-0.0074,  0.0825,  0.0156,  ...,  0.0598,  0.0457,  0.0923],\n",
      "        ...,\n",
      "        [-0.0217,  0.0140, -0.0327,  ...,  0.0109, -0.0422,  0.0256],\n",
      "        [ 0.0210,  0.0315, -0.0236,  ...,  0.0188, -0.0209, -0.0356],\n",
      "        [ 0.0303,  0.0179,  0.0077,  ...,  0.0067,  0.0186,  0.0200]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0693,  0.0248,  0.0165,  ..., -0.0017,  0.0046, -0.0249],\n",
      "        [-0.0051, -0.0294,  0.0060,  ..., -0.0598, -0.0236, -0.0068],\n",
      "        [ 0.0203, -0.0183, -0.0298,  ...,  0.0593, -0.0134, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0019, -0.0177,  ...,  0.0110, -0.0115, -0.0205],\n",
      "        [ 0.0031,  0.0400,  0.0221,  ..., -0.0244, -0.0320, -0.0286],\n",
      "        [ 0.0175, -0.0090, -0.0184,  ...,  0.0016, -0.0039,  0.0457]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.35.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0601, -0.0527, -0.0151,  ..., -0.1289,  0.0176, -0.0105],\n",
      "        [-0.0488,  0.0182,  0.0146,  ...,  0.0038, -0.0364, -0.0452],\n",
      "        [-0.0483, -0.0474, -0.0064,  ..., -0.0069,  0.0008, -0.0420],\n",
      "        ...,\n",
      "        [ 0.0352, -0.0201,  0.0359,  ...,  0.0134, -0.0101,  0.0620],\n",
      "        [ 0.0171, -0.0173, -0.0474,  ..., -0.0150,  0.0075,  0.0114],\n",
      "        [-0.0525, -0.0010,  0.0439,  ..., -0.0442, -0.0173,  0.0623]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0131, -0.0078,  0.0378,  ..., -0.0623,  0.0356,  0.0422],\n",
      "        [-0.0008,  0.0229,  0.0156,  ..., -0.0006,  0.0072,  0.0239],\n",
      "        [-0.0801,  0.0244, -0.0623,  ..., -0.0315, -0.0139,  0.0121],\n",
      "        ...,\n",
      "        [-0.0052, -0.0112,  0.0383,  ...,  0.0579,  0.0020,  0.0344],\n",
      "        [-0.0065, -0.0214, -0.0364,  ..., -0.0261, -0.0248, -0.0698],\n",
      "        [-0.0171, -0.0481,  0.0099,  ...,  0.0143, -0.0198, -0.0021]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0747,  0.1191,  0.0410,  ..., -0.0110, -0.0010,  0.0154],\n",
      "        [ 0.0216, -0.0112,  0.0043,  ...,  0.0354,  0.0039, -0.0522],\n",
      "        [-0.0115, -0.0192, -0.0186,  ...,  0.0084, -0.0571, -0.0135],\n",
      "        ...,\n",
      "        [ 0.0635, -0.0153,  0.0010,  ...,  0.0009,  0.0110,  0.0270],\n",
      "        [ 0.0014,  0.0215,  0.0254,  ...,  0.0045, -0.0182,  0.0118],\n",
      "        [ 0.0325, -0.0020, -0.0055,  ..., -0.0012,  0.0101, -0.0271]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0225, -0.0117, -0.0072,  ...,  0.0190,  0.0127,  0.0405],\n",
      "        [-0.0583, -0.0171,  0.0105,  ...,  0.0056, -0.0286, -0.0386],\n",
      "        [ 0.0001,  0.0396,  0.0457,  ...,  0.0097, -0.0933, -0.0173],\n",
      "        ...,\n",
      "        [-0.0264,  0.0092, -0.0114,  ..., -0.0322, -0.0474, -0.0293],\n",
      "        [-0.0552, -0.0089, -0.0129,  ...,  0.0225, -0.0146,  0.0400],\n",
      "        [-0.0535, -0.0684,  0.0070,  ...,  0.0140, -0.0271, -0.0184]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0153,  0.0133,  0.0654,  ..., -0.0430, -0.0479, -0.0223],\n",
      "        [ 0.0142, -0.0391, -0.0006,  ...,  0.0283,  0.0264, -0.0020],\n",
      "        [ 0.0259,  0.0117,  0.0179,  ..., -0.0125, -0.0505,  0.0276],\n",
      "        ...,\n",
      "        [-0.0145,  0.0049, -0.0186,  ..., -0.0574,  0.0121, -0.0075],\n",
      "        [-0.0261, -0.0352, -0.0188,  ..., -0.0486,  0.0222, -0.0076],\n",
      "        [-0.0250, -0.0084,  0.0093,  ...,  0.0073,  0.0369, -0.0101]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.35.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.35.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.36.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0420,  0.0393,  0.0386,  ...,  0.0253, -0.0150,  0.0172],\n",
      "        [ 0.0237,  0.0014,  0.0698,  ..., -0.0162,  0.1162, -0.0879],\n",
      "        [ 0.0145, -0.0153,  0.0099,  ...,  0.0008, -0.0216,  0.0249],\n",
      "        ...,\n",
      "        [-0.0177, -0.0027,  0.0288,  ...,  0.0315, -0.0210,  0.0239],\n",
      "        [ 0.0330,  0.0089,  0.0505,  ...,  0.0469, -0.0388,  0.0170],\n",
      "        [ 0.0137, -0.0102,  0.0192,  ...,  0.0312,  0.0238, -0.0048]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.36.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0023, -0.0023,  0.0708,  ..., -0.0280, -0.0242, -0.0271],\n",
      "        [ 0.0310, -0.0036,  0.0075,  ..., -0.0166,  0.0913, -0.0077],\n",
      "        [-0.0107,  0.0012,  0.0149,  ..., -0.0155,  0.0864, -0.0481],\n",
      "        ...,\n",
      "        [ 0.0270,  0.0090,  0.0486,  ...,  0.0013, -0.0269, -0.0135],\n",
      "        [ 0.0259, -0.0137, -0.0474,  ...,  0.0050,  0.0140,  0.0197],\n",
      "        [-0.0070, -0.0454,  0.0030,  ..., -0.0067, -0.0008,  0.0159]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0116, -0.0187, -0.0101,  ..., -0.0312, -0.0004,  0.0361],\n",
      "        [-0.0229, -0.0117, -0.0008,  ..., -0.0070, -0.0542,  0.0596],\n",
      "        [ 0.0049,  0.0176,  0.0503,  ...,  0.0219, -0.0217, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0811, -0.0239,  0.0212,  ..., -0.0281,  0.0352,  0.0054],\n",
      "        [-0.0165, -0.0583, -0.0408,  ...,  0.0003,  0.0043,  0.0483],\n",
      "        [ 0.0226,  0.0381, -0.0089,  ...,  0.0095, -0.0212,  0.0270]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.36.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0427, -0.0403,  0.0193,  ...,  0.0056,  0.0088,  0.0347],\n",
      "        [-0.0588, -0.0108, -0.0747,  ...,  0.0280, -0.0016,  0.0542],\n",
      "        [ 0.0098,  0.0311, -0.0664,  ...,  0.0337, -0.0208,  0.0415],\n",
      "        ...,\n",
      "        [ 0.1152, -0.0403, -0.0127,  ...,  0.0280,  0.0061,  0.0723],\n",
      "        [-0.0278, -0.1021, -0.0008,  ..., -0.0072, -0.0957,  0.0938],\n",
      "        [ 0.1426, -0.0102,  0.1152,  ...,  0.0405, -0.0092, -0.0153]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0031,  0.0106, -0.0103,  ..., -0.0076, -0.0111, -0.0060],\n",
      "        [-0.0342,  0.0483,  0.0747,  ...,  0.0173,  0.0236, -0.0186],\n",
      "        [ 0.1079,  0.0967, -0.0369,  ..., -0.0337,  0.0145,  0.0161],\n",
      "        ...,\n",
      "        [ 0.0069, -0.0201,  0.0024,  ..., -0.0136, -0.0025,  0.0082],\n",
      "        [-0.0693,  0.0175, -0.0031,  ..., -0.0102,  0.0127, -0.0264],\n",
      "        [-0.0117,  0.0112, -0.0053,  ...,  0.0393, -0.0067, -0.0067]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0009, -0.0126,  0.0042,  ..., -0.0167,  0.0259,  0.0486],\n",
      "        [-0.0282, -0.0422, -0.0014,  ..., -0.0064,  0.0156,  0.0056],\n",
      "        [ 0.0620, -0.0243, -0.0217,  ...,  0.0095,  0.0033,  0.0289],\n",
      "        ...,\n",
      "        [-0.0040, -0.0894, -0.0107,  ..., -0.0126, -0.0518,  0.0374],\n",
      "        [ 0.0058, -0.0574, -0.0757,  ..., -0.0035,  0.0386,  0.0547],\n",
      "        [ 0.0194,  0.0058, -0.0211,  ...,  0.0089,  0.0028,  0.0052]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0427,  0.0378,  0.0339,  ...,  0.0248,  0.0226, -0.0260],\n",
      "        [ 0.0064, -0.0068, -0.0086,  ...,  0.0192, -0.0195,  0.0030],\n",
      "        [-0.0203, -0.1230, -0.0077,  ...,  0.0288,  0.0400, -0.0312],\n",
      "        ...,\n",
      "        [-0.0610,  0.0359,  0.0154,  ..., -0.0250,  0.0006,  0.0217],\n",
      "        [ 0.0281,  0.0095, -0.0625,  ..., -0.0212,  0.0327,  0.0266],\n",
      "        [ 0.0131,  0.0396, -0.0049,  ...,  0.0493, -0.0175,  0.0016]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0032, -0.0134, -0.0376,  ..., -0.0177, -0.0197,  0.0166],\n",
      "        [ 0.0015,  0.0095, -0.0505,  ..., -0.0070, -0.0356, -0.0566],\n",
      "        [-0.0342, -0.0147, -0.0082,  ..., -0.0747, -0.0796, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0063, -0.0513,  0.0525,  ..., -0.0317, -0.0089, -0.0513],\n",
      "        [-0.0105,  0.0036, -0.0069,  ..., -0.0103,  0.0198,  0.0100],\n",
      "        [-0.0654,  0.0118, -0.0374,  ...,  0.0200, -0.0325, -0.0437]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.36.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.36.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.37.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0435, -0.0043, -0.0136,  ...,  0.0208,  0.0043,  0.0043],\n",
      "        [-0.0151, -0.0051,  0.0225,  ...,  0.0147,  0.0112, -0.0388],\n",
      "        [ 0.0183, -0.0222,  0.0275,  ...,  0.0247,  0.0786, -0.0879],\n",
      "        ...,\n",
      "        [-0.0598,  0.0199, -0.0038,  ..., -0.0312,  0.0011,  0.0231],\n",
      "        [-0.0688, -0.0041, -0.0259,  ...,  0.0278, -0.0049, -0.0698],\n",
      "        [-0.0325,  0.0601, -0.1206,  ...,  0.0273, -0.0093,  0.0113]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.37.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.37.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0417, -0.0352, -0.0269,  ...,  0.0028,  0.0159,  0.0654],\n",
      "        [ 0.0225,  0.0035, -0.0272,  ..., -0.0615,  0.0146, -0.0439],\n",
      "        [ 0.0183, -0.1006, -0.0815,  ..., -0.0089, -0.0474, -0.0864],\n",
      "        ...,\n",
      "        [-0.0046,  0.0240,  0.0525,  ..., -0.0266,  0.0247, -0.0352],\n",
      "        [-0.0116,  0.0220,  0.0020,  ..., -0.0603, -0.0215, -0.0327],\n",
      "        [-0.0488,  0.0225,  0.0082,  ...,  0.0132,  0.0234,  0.0025]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.37.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0278, -0.0115,  0.0317,  ...,  0.0070,  0.0171,  0.0027],\n",
      "        [-0.0251, -0.0762,  0.0208,  ...,  0.0496, -0.0547,  0.0116],\n",
      "        [ 0.0432, -0.0806,  0.0605,  ..., -0.0610, -0.0596,  0.0391],\n",
      "        ...,\n",
      "        [-0.0179, -0.0009,  0.0053,  ...,  0.0232, -0.0167, -0.0006],\n",
      "        [ 0.0139,  0.0342, -0.0047,  ...,  0.0071, -0.0337,  0.0378],\n",
      "        [-0.0228,  0.0025, -0.0080,  ..., -0.0099, -0.0101, -0.0356]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.37.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.37.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0037,  0.0225, -0.1055,  ..., -0.0220, -0.0242, -0.0820],\n",
      "        [ 0.0025,  0.0181,  0.0396,  ..., -0.0640,  0.0525,  0.0121],\n",
      "        [-0.0435,  0.0093, -0.1406,  ...,  0.0330, -0.0021,  0.0859],\n",
      "        ...,\n",
      "        [ 0.0203, -0.0312, -0.0762,  ...,  0.0155, -0.0352,  0.0275],\n",
      "        [-0.0830,  0.0327, -0.0610,  ...,  0.0547, -0.0515, -0.0118],\n",
      "        [ 0.0552,  0.0232,  0.0215,  ..., -0.0215, -0.0152,  0.0184]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.37.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0225, -0.0309,  0.0552,  ..., -0.0204,  0.0742,  0.0021],\n",
      "        [ 0.0562, -0.0201,  0.0166,  ...,  0.0503, -0.0187, -0.0092],\n",
      "        [ 0.0018,  0.0398, -0.0065,  ...,  0.0206, -0.0188, -0.0132],\n",
      "        ...,\n",
      "        [ 0.0194,  0.0381,  0.0037,  ...,  0.0166, -0.0032,  0.0542],\n",
      "        [ 0.0173,  0.0131, -0.0020,  ...,  0.0297,  0.0288, -0.0537],\n",
      "        [ 0.0059, -0.0143,  0.0698,  ...,  0.0117,  0.0182,  0.0072]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.37.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0332,  0.0303, -0.0273,  ..., -0.0483,  0.0378,  0.0102],\n",
      "        [ 0.0009, -0.0457, -0.0342,  ..., -0.0068, -0.0518, -0.0430],\n",
      "        [ 0.0048,  0.0209, -0.0186,  ...,  0.0013, -0.0334,  0.0251],\n",
      "        ...,\n",
      "        [ 0.0156, -0.0479, -0.0439,  ..., -0.0413,  0.0097, -0.0072],\n",
      "        [ 0.0374, -0.0420,  0.0145,  ..., -0.0618,  0.0569,  0.0222],\n",
      "        [-0.0190,  0.0067,  0.0089,  ..., -0.0003,  0.0108,  0.0054]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.37.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0352,  0.0840,  0.0125,  ..., -0.0505,  0.0713, -0.0339],\n",
      "        [-0.0171,  0.0305,  0.0259,  ..., -0.0004,  0.0388,  0.0127],\n",
      "        [-0.0229, -0.0183, -0.0200,  ..., -0.0099, -0.0046,  0.0928],\n",
      "        ...,\n",
      "        [ 0.0142, -0.0469,  0.0220,  ..., -0.0011,  0.0518,  0.0249],\n",
      "        [-0.0396, -0.0032,  0.0112,  ...,  0.0410, -0.0283,  0.0256],\n",
      "        [ 0.0036,  0.0089,  0.0219,  ..., -0.1040,  0.0067,  0.0405]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.37.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 3.6621e-02, -4.3945e-02,  5.9204e-03,  ...,  4.0771e-02,\n",
      "          1.8433e-02,  2.2705e-02],\n",
      "        [ 2.2888e-03,  5.0537e-02, -9.5367e-04,  ..., -4.3213e-02,\n",
      "         -2.6489e-02, -9.5215e-03],\n",
      "        [-1.3428e-02,  5.4932e-02,  1.3428e-02,  ..., -2.2095e-02,\n",
      "         -6.7139e-03,  4.8096e-02],\n",
      "        ...,\n",
      "        [ 1.9409e-02, -4.1748e-02,  3.4332e-05,  ..., -2.9449e-03,\n",
      "         -2.9907e-03,  2.2949e-02],\n",
      "        [-1.1841e-02,  9.5703e-02,  3.2471e-02,  ...,  2.2095e-02,\n",
      "          1.4038e-02,  4.8523e-03],\n",
      "        [ 3.2715e-02,  9.1553e-03,  2.2461e-02,  ...,  1.8677e-02,\n",
      "         -3.4180e-02, -2.0905e-03]], requires_grad=True)\n",
      "Layer: model.layers.37.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.37.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.38.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-6.2500e-02, -4.9591e-05, -2.6245e-02,  ..., -5.6885e-02,\n",
      "          3.6469e-03, -3.2227e-02],\n",
      "        [ 5.7617e-02, -7.3242e-02,  9.7656e-03,  ..., -2.4170e-02,\n",
      "         -4.3335e-03,  5.9204e-03],\n",
      "        [ 2.2736e-03, -5.3711e-02, -6.1035e-02,  ...,  1.0376e-02,\n",
      "          2.5635e-02, -6.2256e-02],\n",
      "        ...,\n",
      "        [ 7.6294e-03,  2.2888e-03,  5.3711e-02,  ..., -1.4771e-02,\n",
      "          1.0681e-02,  6.5430e-02],\n",
      "        [ 1.2939e-02,  3.9978e-03, -2.0752e-02,  ...,  2.8320e-02,\n",
      "          2.4902e-02, -2.6855e-02],\n",
      "        [ 5.5664e-02, -3.7109e-02, -6.5430e-02,  ...,  5.0049e-02,\n",
      "          8.0566e-03, -3.7109e-02]], requires_grad=True)\n",
      "Layer: model.layers.38.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.38.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0493,  0.0053, -0.0781,  ...,  0.0112, -0.0123, -0.0219],\n",
      "        [ 0.0089, -0.0031,  0.0140,  ..., -0.0386, -0.0610,  0.0223],\n",
      "        [-0.0212, -0.0454, -0.0134,  ..., -0.0186,  0.0320, -0.0029],\n",
      "        ...,\n",
      "        [ 0.0430, -0.0371, -0.0222,  ...,  0.0105,  0.0057,  0.0168],\n",
      "        [ 0.0308,  0.0430, -0.0459,  ..., -0.0293, -0.0315, -0.0649],\n",
      "        [-0.0239,  0.0186, -0.0195,  ..., -0.0101,  0.0791, -0.0364]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.38.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0703, -0.0381,  0.0073,  ..., -0.0164,  0.0222,  0.0398],\n",
      "        [ 0.0173, -0.0238,  0.0112,  ..., -0.0021,  0.0330, -0.0253],\n",
      "        [-0.0261, -0.0076, -0.0244,  ..., -0.0723, -0.0322,  0.0022],\n",
      "        ...,\n",
      "        [ 0.0168,  0.0025,  0.0133,  ..., -0.0035,  0.0062, -0.0005],\n",
      "        [ 0.0317, -0.0157, -0.0293,  ..., -0.0142, -0.0325,  0.0659],\n",
      "        [ 0.0204,  0.0254,  0.0295,  ..., -0.0137, -0.0732,  0.0288]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.38.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.38.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0674,  0.0008, -0.0045,  ..., -0.0251,  0.0102,  0.0371],\n",
      "        [ 0.0219, -0.0850,  0.0134,  ...,  0.0269,  0.0273,  0.0271],\n",
      "        [ 0.0596,  0.0001,  0.0540,  ...,  0.0552, -0.0461,  0.0078],\n",
      "        ...,\n",
      "        [ 0.0364, -0.0005, -0.0040,  ..., -0.0366,  0.0051,  0.0176],\n",
      "        [-0.0249, -0.0498, -0.0415,  ...,  0.0488,  0.0090, -0.0210],\n",
      "        [ 0.0278,  0.0150,  0.0645,  ...,  0.0055, -0.0620, -0.0271]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.38.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0317, -0.0640, -0.0080,  ..., -0.0879,  0.0107,  0.0089],\n",
      "        [-0.0608,  0.0247,  0.0444,  ..., -0.0405,  0.0052, -0.0054],\n",
      "        [-0.0386,  0.0021, -0.0454,  ..., -0.0447, -0.0542,  0.0209],\n",
      "        ...,\n",
      "        [-0.0081, -0.0148,  0.0776,  ...,  0.1001,  0.0092,  0.0063],\n",
      "        [-0.0498, -0.0068,  0.0148,  ..., -0.0239, -0.0398, -0.0620],\n",
      "        [ 0.0471, -0.0066,  0.0178,  ..., -0.0076, -0.0276, -0.0108]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.38.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0186, -0.0105,  0.0425,  ..., -0.0315, -0.0276, -0.0155],\n",
      "        [-0.0161, -0.0703,  0.0042,  ...,  0.0190,  0.0122, -0.0284],\n",
      "        [ 0.0189, -0.0132, -0.0018,  ..., -0.0137,  0.0046,  0.0094],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0048, -0.0261,  ...,  0.0045, -0.0222, -0.0205],\n",
      "        [-0.0192,  0.0179, -0.0292,  ..., -0.0081, -0.0078, -0.0408],\n",
      "        [-0.0078,  0.0752,  0.0669,  ...,  0.0728,  0.0103, -0.0143]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.38.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0413,  0.0215,  0.0135,  ...,  0.0579,  0.0596, -0.0044],\n",
      "        [-0.0081, -0.0265,  0.0344,  ..., -0.0049, -0.0679,  0.0029],\n",
      "        [-0.0131, -0.0344,  0.0253,  ..., -0.0012,  0.0439, -0.0104],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0016, -0.0205,  ..., -0.0378,  0.0679, -0.0171],\n",
      "        [-0.0645, -0.0479,  0.0245,  ...,  0.0601, -0.0254, -0.0062],\n",
      "        [-0.0459, -0.0247,  0.0258,  ...,  0.0571,  0.0085, -0.0002]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.38.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0018,  0.0493,  0.0518,  ...,  0.0317, -0.0253,  0.0109],\n",
      "        [ 0.0193, -0.0076, -0.0408,  ..., -0.0164, -0.0669,  0.0342],\n",
      "        [ 0.0029,  0.0767,  0.0840,  ...,  0.0010, -0.0140,  0.0150],\n",
      "        ...,\n",
      "        [ 0.0067, -0.0820, -0.0356,  ...,  0.0154,  0.0469,  0.0796],\n",
      "        [ 0.0408, -0.0547,  0.0078,  ...,  0.0327, -0.0070, -0.0222],\n",
      "        [ 0.0047,  0.0070, -0.0138,  ..., -0.0061,  0.0096, -0.0107]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.38.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.38.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.39.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0071,  0.0908,  0.0317,  ...,  0.0075, -0.0105, -0.0041],\n",
      "        [-0.0811,  0.0217, -0.0149,  ...,  0.0281,  0.0056, -0.0586],\n",
      "        [-0.0197, -0.0093, -0.0283,  ...,  0.0114, -0.0232, -0.0035],\n",
      "        ...,\n",
      "        [-0.0128, -0.0439,  0.0615,  ..., -0.0535,  0.0114, -0.0184],\n",
      "        [-0.0078, -0.0400, -0.0615,  ...,  0.0408,  0.0205,  0.0214],\n",
      "        [-0.0444, -0.0024,  0.0364,  ...,  0.0464, -0.0074, -0.0139]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.39.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0051,  0.0110,  0.0266,  ..., -0.0142, -0.0040, -0.0131],\n",
      "        [-0.0146, -0.0305, -0.0154,  ..., -0.0154,  0.0107,  0.0249],\n",
      "        [ 0.0176,  0.0244, -0.0095,  ..., -0.0786, -0.0500, -0.0371],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0251,  0.0806,  ..., -0.0242,  0.0288, -0.0236],\n",
      "        [-0.0125,  0.0206,  0.0068,  ..., -0.0063,  0.0067, -0.0125],\n",
      "        [-0.0471, -0.0223, -0.0040,  ..., -0.0161,  0.0066,  0.0039]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0077,  0.0153, -0.0183,  ...,  0.0258,  0.0505,  0.0126],\n",
      "        [-0.0352,  0.0132, -0.0251,  ...,  0.0040,  0.0518, -0.0029],\n",
      "        [-0.0041,  0.0148, -0.0376,  ..., -0.0115, -0.0134, -0.0396],\n",
      "        ...,\n",
      "        [-0.0020,  0.0016, -0.0226,  ..., -0.0334, -0.0287,  0.0474],\n",
      "        [-0.0228, -0.0049, -0.0056,  ...,  0.0262,  0.0019, -0.0248],\n",
      "        [-0.0223, -0.0591, -0.0109,  ...,  0.0236,  0.0422,  0.0210]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.39.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0132, -0.0249, -0.0142,  ..., -0.0189,  0.0090, -0.0012],\n",
      "        [-0.0083, -0.0223, -0.0154,  ..., -0.0305, -0.0552, -0.0530],\n",
      "        [-0.0106,  0.0090,  0.0267,  ..., -0.0498,  0.0537, -0.0071],\n",
      "        ...,\n",
      "        [-0.0688,  0.0347,  0.0581,  ...,  0.0247,  0.0025, -0.0454],\n",
      "        [-0.0223,  0.0009,  0.0071,  ..., -0.0047,  0.0342, -0.0444],\n",
      "        [ 0.0669, -0.0008,  0.1826,  ...,  0.0073,  0.0142,  0.0167]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0342,  0.0032,  0.0130,  ..., -0.0332, -0.0284, -0.0045],\n",
      "        [ 0.0041,  0.0033, -0.0679,  ..., -0.0437,  0.0090,  0.0020],\n",
      "        [ 0.0977,  0.0369, -0.0093,  ..., -0.0562, -0.0400,  0.0077],\n",
      "        ...,\n",
      "        [-0.0654, -0.0359, -0.0102,  ...,  0.0718, -0.0221,  0.0306],\n",
      "        [ 0.0075, -0.0165, -0.0300,  ..., -0.0192, -0.0159, -0.0325],\n",
      "        [ 0.0728, -0.0099, -0.0295,  ...,  0.0742, -0.0132, -0.0479]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0104, -0.0654,  0.0282,  ...,  0.0420,  0.0059, -0.0603],\n",
      "        [-0.0109, -0.0393,  0.0251,  ...,  0.0037, -0.0420,  0.0303],\n",
      "        [-0.0806, -0.0148,  0.0081,  ...,  0.0527,  0.0120,  0.0693],\n",
      "        ...,\n",
      "        [ 0.0359,  0.0132, -0.0442,  ..., -0.0234,  0.0059, -0.0347],\n",
      "        [ 0.0025,  0.0503,  0.0393,  ..., -0.0025,  0.0640,  0.0066],\n",
      "        [ 0.0771,  0.0203,  0.0269,  ..., -0.0452,  0.0110, -0.0376]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0002,  0.0513, -0.0078,  ..., -0.0075,  0.0449, -0.0559],\n",
      "        [-0.0304,  0.0229,  0.0356,  ...,  0.0026, -0.0167, -0.0103],\n",
      "        [-0.0043, -0.0282, -0.0110,  ..., -0.0537, -0.0059, -0.0442],\n",
      "        ...,\n",
      "        [-0.0054,  0.0250,  0.0791,  ..., -0.0205,  0.0635, -0.0359],\n",
      "        [ 0.0354, -0.0361,  0.0479,  ...,  0.0325, -0.0288,  0.0466],\n",
      "        [ 0.0337,  0.0479, -0.0177,  ...,  0.0020, -0.0289,  0.0327]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0147,  0.0157,  0.0674,  ..., -0.0479,  0.0041, -0.0361],\n",
      "        [-0.1064, -0.0288,  0.0086,  ..., -0.0311, -0.0684, -0.0203],\n",
      "        [ 0.0281,  0.0083, -0.0139,  ...,  0.0806, -0.0164, -0.0510],\n",
      "        ...,\n",
      "        [ 0.0061,  0.0454, -0.0295,  ...,  0.0518, -0.0101, -0.0435],\n",
      "        [ 0.0396, -0.0127, -0.0176,  ...,  0.0013, -0.0071, -0.0195],\n",
      "        [-0.0479, -0.0352, -0.0105,  ...,  0.0288,  0.0002,  0.0718]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.39.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.39.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.40.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0179,  0.0227, -0.0126,  ...,  0.0615, -0.0513, -0.0226],\n",
      "        [-0.0471, -0.0260,  0.0388,  ..., -0.0046, -0.0547,  0.0066],\n",
      "        [ 0.0103, -0.0162,  0.0562,  ..., -0.0033,  0.0162, -0.0184],\n",
      "        ...,\n",
      "        [-0.0227,  0.0537, -0.0459,  ...,  0.0308, -0.0295, -0.0483],\n",
      "        [ 0.0306, -0.0232, -0.0050,  ...,  0.0192, -0.0068, -0.0410],\n",
      "        [-0.0334, -0.0066, -0.0043,  ...,  0.0032,  0.0049, -0.0635]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.40.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0264,  0.0137,  0.0166,  ..., -0.0400,  0.0527, -0.0019],\n",
      "        [-0.0557, -0.0337,  0.0417,  ..., -0.0114,  0.0118,  0.0132],\n",
      "        [-0.0342, -0.0620,  0.0449,  ...,  0.0145,  0.0041,  0.0315],\n",
      "        ...,\n",
      "        [-0.0256, -0.0121,  0.0366,  ..., -0.1157, -0.0055,  0.0410],\n",
      "        [ 0.0106, -0.0391,  0.0275,  ..., -0.0223,  0.0044,  0.0376],\n",
      "        [-0.0134, -0.0090,  0.0089,  ..., -0.0151, -0.0089,  0.0148]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0334, -0.0064,  0.0094,  ..., -0.0209,  0.0017, -0.0518],\n",
      "        [ 0.0173, -0.0133, -0.0309,  ..., -0.0117,  0.0422, -0.0520],\n",
      "        [ 0.0240,  0.0139,  0.0120,  ..., -0.0036, -0.0106,  0.0128],\n",
      "        ...,\n",
      "        [-0.0100, -0.0087, -0.0093,  ..., -0.0101, -0.0114, -0.0166],\n",
      "        [-0.0110,  0.0116,  0.0099,  ..., -0.0173,  0.0119, -0.0097],\n",
      "        [ 0.0220,  0.0072,  0.0251,  ..., -0.0302,  0.0271,  0.0378]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.40.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0771, -0.0742, -0.0118,  ...,  0.0006, -0.0732, -0.0310],\n",
      "        [ 0.0188,  0.0408, -0.0139,  ...,  0.0537,  0.0181,  0.0289],\n",
      "        [-0.0481, -0.0047, -0.0186,  ...,  0.0078,  0.0488,  0.0016],\n",
      "        ...,\n",
      "        [ 0.0112,  0.0435, -0.0806,  ...,  0.0361, -0.0359,  0.0021],\n",
      "        [-0.0237, -0.0132,  0.0119,  ...,  0.0547, -0.0581, -0.0164],\n",
      "        [-0.0547,  0.0547,  0.0732,  ...,  0.0190,  0.0332, -0.0320]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0295, -0.0067,  0.0540,  ..., -0.0139, -0.0554, -0.0210],\n",
      "        [ 0.0593, -0.0018,  0.0245,  ..., -0.0320,  0.0255, -0.0295],\n",
      "        [-0.0182, -0.0591, -0.0048,  ..., -0.0200,  0.0229,  0.0242],\n",
      "        ...,\n",
      "        [-0.0282,  0.0332, -0.0317,  ..., -0.0317, -0.0101, -0.0459],\n",
      "        [ 0.0220, -0.0474,  0.0315,  ..., -0.0400,  0.0322, -0.0403],\n",
      "        [-0.0030,  0.0092, -0.0576,  ..., -0.0591, -0.0256,  0.0186]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0554, -0.0104,  0.0320,  ...,  0.1074, -0.0280, -0.0281],\n",
      "        [ 0.0527, -0.0461, -0.0444,  ...,  0.0674,  0.0708,  0.0444],\n",
      "        [-0.0183,  0.0126, -0.0073,  ...,  0.0049, -0.0118, -0.0063],\n",
      "        ...,\n",
      "        [ 0.0138, -0.0223, -0.0583,  ...,  0.0300, -0.0244,  0.0199],\n",
      "        [-0.0137, -0.0118,  0.0170,  ..., -0.0199,  0.0216,  0.0144],\n",
      "        [-0.0043, -0.0007, -0.0089,  ...,  0.0030,  0.0273,  0.0030]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0151,  0.0250,  0.0090,  ..., -0.0074,  0.0056,  0.0166],\n",
      "        [-0.0103, -0.0019,  0.0498,  ...,  0.0059,  0.0002, -0.0069],\n",
      "        [ 0.0071, -0.0374, -0.0344,  ...,  0.0203,  0.0090, -0.0166],\n",
      "        ...,\n",
      "        [ 0.0114,  0.0527,  0.0161,  ...,  0.0476,  0.0771,  0.0544],\n",
      "        [-0.0247, -0.0150,  0.0640,  ..., -0.0234,  0.0060,  0.0542],\n",
      "        [ 0.0522, -0.0014, -0.0177,  ...,  0.0140,  0.0168,  0.0311]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0085,  0.0056, -0.0469,  ...,  0.0138,  0.0081,  0.0015],\n",
      "        [-0.0457, -0.0427, -0.0090,  ...,  0.0195,  0.0217, -0.0228],\n",
      "        [ 0.0027, -0.0503, -0.0425,  ...,  0.0408, -0.0200,  0.0084],\n",
      "        ...,\n",
      "        [-0.0060, -0.0029, -0.0410,  ..., -0.0223,  0.0209,  0.0104],\n",
      "        [-0.0405, -0.0135, -0.0371,  ...,  0.0454,  0.0432,  0.0065],\n",
      "        [ 0.0542,  0.0361, -0.0199,  ..., -0.0086,  0.0327, -0.0039]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.40.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.40.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.41.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0018,  0.0075,  0.0613,  ..., -0.0374,  0.0654,  0.0099],\n",
      "        [ 0.0121, -0.0078, -0.0654,  ..., -0.0055,  0.0261, -0.0167],\n",
      "        [ 0.0181,  0.0398, -0.0317,  ...,  0.0189, -0.0471, -0.0322],\n",
      "        ...,\n",
      "        [ 0.0366, -0.0488,  0.0693,  ...,  0.0352,  0.1069, -0.0522],\n",
      "        [ 0.0449,  0.0762, -0.0928,  ..., -0.0093, -0.0269,  0.0422],\n",
      "        [-0.1138,  0.1484,  0.1250,  ...,  0.1348,  0.0518, -0.1299]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.41.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0013, -0.0044, -0.0305,  ...,  0.0393, -0.0569,  0.0003],\n",
      "        [-0.0131, -0.0542, -0.0151,  ...,  0.0073,  0.0188, -0.0029],\n",
      "        [-0.0481, -0.0396, -0.0157,  ..., -0.0259, -0.0021,  0.0044],\n",
      "        ...,\n",
      "        [-0.0142,  0.0103, -0.0134,  ..., -0.0352,  0.0081, -0.0007],\n",
      "        [-0.0027, -0.0305,  0.0435,  ...,  0.0447,  0.0369, -0.0583],\n",
      "        [ 0.0147,  0.0378,  0.0281,  ..., -0.0359, -0.0938,  0.0332]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0398, -0.0094,  0.0571,  ...,  0.0140, -0.0003,  0.0103],\n",
      "        [ 0.0262, -0.0171, -0.0303,  ..., -0.0217, -0.0221, -0.0057],\n",
      "        [ 0.0197, -0.0308, -0.0032,  ..., -0.0444,  0.0271,  0.0167],\n",
      "        ...,\n",
      "        [ 0.0825, -0.0204,  0.0160,  ...,  0.0212,  0.0295,  0.0576],\n",
      "        [-0.0430, -0.0160, -0.0576,  ..., -0.0181, -0.0320, -0.0139],\n",
      "        [-0.0013, -0.0017,  0.0266,  ..., -0.0085, -0.0435,  0.0273]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.41.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0518, -0.0234,  0.0009,  ..., -0.0330,  0.0317, -0.0405],\n",
      "        [ 0.0723,  0.1089,  0.0167,  ..., -0.0107,  0.0364, -0.0454],\n",
      "        [ 0.0132, -0.0078,  0.0198,  ..., -0.1104,  0.0237,  0.0737],\n",
      "        ...,\n",
      "        [ 0.0225,  0.0598, -0.0203,  ..., -0.0020, -0.0096, -0.0109],\n",
      "        [ 0.0598, -0.1084,  0.0410,  ..., -0.0283, -0.0459, -0.0801],\n",
      "        [-0.0488,  0.0135, -0.0386,  ...,  0.0354, -0.1172,  0.0415]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0356,  0.0374, -0.0371,  ..., -0.0303, -0.0140,  0.0464],\n",
      "        [-0.0376,  0.0079,  0.0109,  ...,  0.0117, -0.0674, -0.0069],\n",
      "        [-0.0986, -0.0864,  0.0309,  ...,  0.0371, -0.0427,  0.0199],\n",
      "        ...,\n",
      "        [-0.0282,  0.0273, -0.0298,  ...,  0.0209, -0.0255,  0.0062],\n",
      "        [-0.0349, -0.0063, -0.0033,  ...,  0.0571,  0.0159, -0.0020],\n",
      "        [ 0.0064,  0.0115, -0.0342,  ...,  0.0023, -0.0664,  0.0034]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0062,  0.0200,  0.0035,  ...,  0.0216,  0.0198,  0.0309],\n",
      "        [ 0.0452,  0.0659, -0.0476,  ..., -0.0072, -0.0181, -0.0109],\n",
      "        [ 0.0654, -0.0532,  0.0459,  ..., -0.0422,  0.0157,  0.0153],\n",
      "        ...,\n",
      "        [-0.0188, -0.0188,  0.0352,  ..., -0.0026, -0.0037,  0.0242],\n",
      "        [ 0.0254, -0.0625, -0.0078,  ...,  0.0205,  0.0481, -0.0449],\n",
      "        [-0.0583,  0.0209,  0.0183,  ...,  0.0236, -0.0193, -0.0135]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0342,  0.0405,  0.0386,  ...,  0.0045, -0.0698, -0.0014],\n",
      "        [ 0.0283,  0.0084,  0.0471,  ...,  0.0388, -0.0288, -0.0505],\n",
      "        [-0.0079, -0.0114, -0.0942,  ..., -0.0140, -0.0036,  0.0099],\n",
      "        ...,\n",
      "        [-0.0023, -0.0178, -0.0898,  ...,  0.0040, -0.0295,  0.0126],\n",
      "        [ 0.0042,  0.0017, -0.0135,  ..., -0.0178, -0.0233, -0.0303],\n",
      "        [ 0.0013, -0.0029,  0.0014,  ...,  0.0469, -0.0189,  0.0150]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0376,  0.0198, -0.0283,  ..., -0.0308, -0.0210, -0.0540],\n",
      "        [-0.0591,  0.0171, -0.0156,  ..., -0.0381,  0.0415,  0.0155],\n",
      "        [-0.0114, -0.0249,  0.0042,  ...,  0.0605,  0.0518,  0.0317],\n",
      "        ...,\n",
      "        [ 0.0133, -0.0059, -0.0221,  ..., -0.0742, -0.0068,  0.0474],\n",
      "        [-0.0361, -0.0055,  0.0527,  ...,  0.0092, -0.0352, -0.0347],\n",
      "        [-0.0347, -0.0179, -0.0260,  ...,  0.0527,  0.0605,  0.0542]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.41.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.41.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.42.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0645,  0.0025,  0.0234,  ...,  0.0295, -0.0522,  0.0332],\n",
      "        [-0.0008,  0.0376,  0.0479,  ...,  0.0203,  0.0067,  0.0483],\n",
      "        [ 0.0427,  0.0072,  0.0107,  ...,  0.0220, -0.0454, -0.0469],\n",
      "        ...,\n",
      "        [-0.0237, -0.0031, -0.0082,  ..., -0.0566,  0.0452,  0.0019],\n",
      "        [ 0.0074,  0.0249,  0.0052,  ..., -0.0527,  0.0408,  0.0069],\n",
      "        [ 0.0114, -0.0228, -0.0586,  ...,  0.0254,  0.0247, -0.0063]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.42.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0276,  0.0369,  0.0698,  ...,  0.0033, -0.0461, -0.0152],\n",
      "        [-0.0518,  0.0430, -0.0002,  ...,  0.0815,  0.0184, -0.0032],\n",
      "        [-0.0322, -0.0215, -0.0087,  ...,  0.0063, -0.0562,  0.0120],\n",
      "        ...,\n",
      "        [-0.0086,  0.0157,  0.0099,  ..., -0.0014,  0.0013, -0.0161],\n",
      "        [ 0.0033, -0.0164,  0.0157,  ...,  0.0396,  0.0058, -0.0071],\n",
      "        [-0.0099,  0.0157,  0.0137,  ..., -0.0334,  0.0400,  0.0083]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0236,  0.0261, -0.0105,  ...,  0.0217, -0.0703,  0.0376],\n",
      "        [-0.0195,  0.0004, -0.0053,  ..., -0.0272, -0.0259, -0.0103],\n",
      "        [ 0.0057, -0.0272,  0.0417,  ...,  0.0420, -0.0200,  0.0229],\n",
      "        ...,\n",
      "        [ 0.0098,  0.0557,  0.0515,  ...,  0.0640,  0.0063, -0.0123],\n",
      "        [ 0.0117,  0.0525,  0.0330,  ..., -0.0243, -0.0239, -0.0215],\n",
      "        [-0.0082, -0.0150, -0.0072,  ..., -0.0048, -0.0041,  0.0046]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.42.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0219,  0.0830,  0.0996,  ..., -0.0034,  0.0177,  0.0718],\n",
      "        [ 0.0403, -0.0186, -0.0305,  ...,  0.0405, -0.0271, -0.0510],\n",
      "        [-0.0381,  0.0197,  0.0503,  ...,  0.0288,  0.0059, -0.0986],\n",
      "        ...,\n",
      "        [-0.0173, -0.0342,  0.0659,  ..., -0.0459,  0.0070,  0.0297],\n",
      "        [-0.0344,  0.0625, -0.0544,  ..., -0.0099, -0.0016,  0.0510],\n",
      "        [ 0.0214,  0.0581,  0.0356,  ...,  0.0625, -0.0217,  0.0620]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0135, -0.0291, -0.0094,  ...,  0.0461, -0.0255, -0.0035],\n",
      "        [-0.0278,  0.0801, -0.0320,  ...,  0.0369,  0.0339, -0.0033],\n",
      "        [ 0.0011, -0.0146,  0.0566,  ...,  0.0293, -0.0327, -0.0304],\n",
      "        ...,\n",
      "        [ 0.0311, -0.0186,  0.0354,  ..., -0.0625,  0.0049,  0.0200],\n",
      "        [-0.0273,  0.0148,  0.0007,  ..., -0.0090,  0.0327,  0.0298],\n",
      "        [ 0.0483,  0.0149, -0.0134,  ...,  0.0041, -0.0188,  0.0154]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0090,  0.0137,  0.0205,  ..., -0.0066,  0.0094,  0.0168],\n",
      "        [-0.0469,  0.0144, -0.0471,  ...,  0.0005,  0.0273,  0.0140],\n",
      "        [-0.0244,  0.0479,  0.0057,  ..., -0.0086, -0.0347,  0.0164],\n",
      "        ...,\n",
      "        [-0.0356,  0.0552, -0.0315,  ...,  0.0038, -0.0396,  0.0304],\n",
      "        [ 0.0157, -0.0120, -0.0242,  ...,  0.0674, -0.0125,  0.0325],\n",
      "        [-0.0046,  0.0315, -0.0187,  ..., -0.0457,  0.0136, -0.0107]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0767,  0.0179,  0.0312,  ..., -0.0232, -0.0510,  0.0187],\n",
      "        [ 0.0166,  0.0200, -0.0454,  ...,  0.0036,  0.0027, -0.0151],\n",
      "        [-0.0240, -0.0505,  0.0623,  ..., -0.0664,  0.0364, -0.0013],\n",
      "        ...,\n",
      "        [-0.0327, -0.0133,  0.0623,  ...,  0.0442,  0.0052, -0.0190],\n",
      "        [-0.0032,  0.0483,  0.0403,  ...,  0.0038, -0.0674, -0.0588],\n",
      "        [-0.0527, -0.0188, -0.0136,  ...,  0.0283,  0.0087, -0.0110]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0048, -0.0439,  0.0366,  ...,  0.0219, -0.0228,  0.0420],\n",
      "        [ 0.0284, -0.0718,  0.0400,  ..., -0.0498, -0.0063,  0.0172],\n",
      "        [-0.0066,  0.0674,  0.0396,  ...,  0.0732, -0.0079, -0.0547],\n",
      "        ...,\n",
      "        [-0.0011,  0.0444, -0.0073,  ...,  0.0435, -0.0189, -0.0052],\n",
      "        [ 0.0518, -0.0262, -0.0256,  ..., -0.0236,  0.0320, -0.0282],\n",
      "        [-0.0092,  0.0033, -0.0103,  ..., -0.0269, -0.0315, -0.0337]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.42.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.42.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.43.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0322,  0.0334,  0.0137,  ..., -0.0087,  0.0430, -0.0055],\n",
      "        [ 0.0366,  0.0193,  0.0074,  ...,  0.0376,  0.0025,  0.0109],\n",
      "        [-0.0339,  0.0045, -0.0251,  ...,  0.0173, -0.0259, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0168,  0.0459, -0.0142,  ..., -0.0413,  0.0444,  0.0121],\n",
      "        [-0.0007,  0.0186,  0.0080,  ..., -0.0020,  0.0859,  0.0073],\n",
      "        [ 0.0248, -0.0349, -0.0547,  ..., -0.0354, -0.0093,  0.0243]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.43.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.1289,  0.0850,  0.0640,  ..., -0.0033,  0.0038, -0.0474],\n",
      "        [-0.0117,  0.0330,  0.0135,  ..., -0.0845,  0.0120, -0.0019],\n",
      "        [ 0.1006,  0.0266, -0.0413,  ..., -0.0253, -0.0342,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0110, -0.0156, -0.0115,  ...,  0.0167,  0.0140,  0.0859],\n",
      "        [-0.0339, -0.0292,  0.0052,  ...,  0.0320,  0.0035,  0.0479],\n",
      "        [ 0.0503, -0.0088,  0.0322,  ...,  0.0135, -0.0099, -0.0537]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0166,  0.0132,  0.0337,  ...,  0.0284, -0.0347,  0.0229],\n",
      "        [-0.0242, -0.0195,  0.0179,  ...,  0.0220,  0.0339, -0.0303],\n",
      "        [ 0.0022, -0.0049,  0.0056,  ...,  0.0356,  0.0193,  0.0135],\n",
      "        ...,\n",
      "        [ 0.0117, -0.0364,  0.0332,  ...,  0.0464, -0.0459, -0.0184],\n",
      "        [ 0.0474,  0.0153,  0.0203,  ...,  0.0071,  0.0310,  0.0613],\n",
      "        [-0.0283,  0.0066, -0.0176,  ...,  0.0250, -0.0127, -0.0029]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.43.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0337,  0.0308,  0.0369,  ..., -0.0160,  0.0227, -0.0038],\n",
      "        [-0.1191, -0.0369, -0.0491,  ..., -0.0056,  0.0211, -0.0038],\n",
      "        [-0.0139, -0.0157, -0.0620,  ...,  0.0099,  0.0708,  0.0016],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0913, -0.0023,  ..., -0.0339,  0.1094, -0.0027],\n",
      "        [ 0.0508,  0.0410,  0.0713,  ..., -0.0222,  0.0295,  0.0052],\n",
      "        [-0.0664,  0.0583, -0.0586,  ..., -0.0100, -0.0245, -0.0006]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0024, -0.0713,  0.0242,  ...,  0.0048, -0.0256, -0.0381],\n",
      "        [ 0.0273, -0.0042,  0.0767,  ...,  0.1089, -0.0537, -0.0297],\n",
      "        [-0.0087, -0.0669,  0.0186,  ..., -0.0291,  0.0425, -0.0659],\n",
      "        ...,\n",
      "        [-0.0190, -0.0684, -0.0060,  ...,  0.0094,  0.0044,  0.0547],\n",
      "        [-0.0006, -0.0110, -0.0850,  ..., -0.0654,  0.0255, -0.0193],\n",
      "        [-0.0120,  0.0093, -0.0420,  ..., -0.0574,  0.0420,  0.0498]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0172,  0.0566, -0.0036,  ..., -0.0498, -0.0303, -0.0186],\n",
      "        [-0.0155, -0.0052,  0.0205,  ...,  0.0593, -0.0356, -0.0056],\n",
      "        [ 0.0100,  0.0082,  0.0398,  ..., -0.0044, -0.0256,  0.0306],\n",
      "        ...,\n",
      "        [-0.0046,  0.0212, -0.0011,  ..., -0.0001,  0.0566,  0.0275],\n",
      "        [ 0.0077,  0.0417,  0.0752,  ..., -0.0278,  0.0294,  0.0527],\n",
      "        [-0.0129,  0.0072, -0.0168,  ..., -0.0166,  0.0208,  0.0581]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0297, -0.0182, -0.0170,  ..., -0.0015,  0.0033,  0.0033],\n",
      "        [ 0.0371, -0.0209, -0.0095,  ...,  0.0164,  0.0170, -0.0579],\n",
      "        [ 0.0322, -0.0011,  0.0047,  ...,  0.0447, -0.0223,  0.0161],\n",
      "        ...,\n",
      "        [ 0.0471, -0.0742, -0.0391,  ..., -0.0242,  0.0193,  0.0032],\n",
      "        [ 0.0532,  0.0121, -0.0256,  ...,  0.0087, -0.0486,  0.0374],\n",
      "        [-0.0522,  0.0466,  0.0679,  ..., -0.0046,  0.0243, -0.0045]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0193, -0.0101,  0.0586,  ..., -0.0114,  0.0659,  0.0415],\n",
      "        [ 0.0178, -0.0325, -0.0111,  ..., -0.0239,  0.0282, -0.0112],\n",
      "        [-0.0334, -0.0566,  0.0444,  ..., -0.0064, -0.0148, -0.0693],\n",
      "        ...,\n",
      "        [-0.0439,  0.0125,  0.0013,  ..., -0.0801, -0.0391,  0.0276],\n",
      "        [-0.0410, -0.0118, -0.0432,  ..., -0.0430,  0.0238, -0.0237],\n",
      "        [ 0.0018, -0.0172, -0.0062,  ..., -0.0598,  0.0281, -0.0012]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.43.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.43.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.44.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0562,  0.0137, -0.0232,  ...,  0.0237, -0.0066, -0.0129],\n",
      "        [-0.0258,  0.0249, -0.0112,  ..., -0.0101,  0.0527, -0.0151],\n",
      "        [ 0.0181, -0.0182, -0.0184,  ..., -0.0737,  0.0122, -0.0119],\n",
      "        ...,\n",
      "        [-0.0293, -0.0417,  0.0437,  ...,  0.0090,  0.0554,  0.0269],\n",
      "        [ 0.0198, -0.0142,  0.0005,  ..., -0.0544,  0.0226,  0.0226],\n",
      "        [-0.0135,  0.0186,  0.0562,  ..., -0.0327, -0.0393, -0.0361]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.44.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.44.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0208, -0.0327,  0.0216,  ...,  0.0649, -0.0015,  0.0183],\n",
      "        [ 0.0449,  0.0006, -0.0339,  ..., -0.0286, -0.0138,  0.0591],\n",
      "        [-0.0186, -0.0049,  0.0042,  ...,  0.0173,  0.0093, -0.0535],\n",
      "        ...,\n",
      "        [-0.0099,  0.0298,  0.0156,  ...,  0.0013,  0.0251, -0.0021],\n",
      "        [ 0.0063,  0.0199,  0.0117,  ...,  0.0254, -0.0327, -0.0193],\n",
      "        [ 0.0065, -0.0153, -0.0039,  ...,  0.0366, -0.0444,  0.0427]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.44.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-2.2705e-02, -4.0283e-02, -3.9551e-02,  ..., -1.7578e-02,\n",
      "         -2.2217e-02,  1.6357e-02],\n",
      "        [-6.0425e-03, -9.9182e-05,  1.5137e-02,  ..., -4.8828e-02,\n",
      "          8.1055e-02, -1.5442e-02],\n",
      "        [ 1.7578e-02,  1.5991e-02, -3.8528e-04,  ...,  1.4099e-02,\n",
      "          2.8076e-03, -2.9755e-04],\n",
      "        ...,\n",
      "        [ 3.7598e-02,  8.9722e-03,  2.7954e-02,  ..., -8.0566e-03,\n",
      "          6.3477e-02,  7.8125e-02],\n",
      "        [ 2.3926e-02, -1.4099e-02, -4.4678e-02,  ..., -2.0630e-02,\n",
      "         -3.4912e-02,  9.7046e-03],\n",
      "        [ 2.2583e-03,  3.0151e-02,  2.5177e-04,  ...,  2.3193e-03,\n",
      "          5.1514e-02,  2.9053e-02]], requires_grad=True)\n",
      "Layer: model.layers.44.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.44.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0420,  0.0190, -0.0146,  ...,  0.0330,  0.0408,  0.0269],\n",
      "        [-0.0337, -0.0835, -0.0752,  ...,  0.0106, -0.0574, -0.0557],\n",
      "        [ 0.0115, -0.0114,  0.0078,  ...,  0.0157,  0.0118, -0.0074],\n",
      "        ...,\n",
      "        [-0.0264, -0.0088,  0.0157,  ..., -0.0098, -0.0537, -0.0732],\n",
      "        [ 0.0048,  0.0067, -0.0330,  ..., -0.0791, -0.0114,  0.0522],\n",
      "        [-0.0552,  0.0820, -0.0236,  ...,  0.0068,  0.0243, -0.0332]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.44.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0342,  0.0554, -0.0179,  ...,  0.0859,  0.0542, -0.0216],\n",
      "        [ 0.0542,  0.0337,  0.0354,  ...,  0.0062,  0.0320, -0.0089],\n",
      "        [-0.0081, -0.0266,  0.0381,  ..., -0.0102, -0.0297,  0.0211],\n",
      "        ...,\n",
      "        [-0.0049,  0.0635,  0.0286,  ...,  0.0413,  0.0220, -0.0148],\n",
      "        [ 0.0554, -0.0013, -0.0293,  ...,  0.0001, -0.0028,  0.0025],\n",
      "        [ 0.0898,  0.0101,  0.0126,  ...,  0.0161, -0.0723, -0.0130]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.44.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0082,  0.0001, -0.0055,  ..., -0.0184, -0.0229, -0.0270],\n",
      "        [-0.0063,  0.0045,  0.0186,  ..., -0.0388, -0.0166, -0.0086],\n",
      "        [ 0.0452,  0.0131, -0.0596,  ...,  0.0454,  0.0018,  0.0056],\n",
      "        ...,\n",
      "        [ 0.0242,  0.0233, -0.0364,  ..., -0.0132,  0.0537, -0.0245],\n",
      "        [-0.0674,  0.0168, -0.0107,  ...,  0.0212, -0.0034,  0.0094],\n",
      "        [ 0.0240,  0.0106,  0.0337,  ..., -0.0170,  0.0125, -0.0327]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.44.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0303, -0.0159,  0.0075,  ..., -0.0201,  0.0537, -0.0237],\n",
      "        [ 0.0082,  0.0034,  0.0143,  ..., -0.0149, -0.0698,  0.0037],\n",
      "        [ 0.0464,  0.0275, -0.0110,  ..., -0.0330,  0.0140,  0.0508],\n",
      "        ...,\n",
      "        [ 0.0247, -0.0297, -0.0649,  ..., -0.0234,  0.0500, -0.0210],\n",
      "        [-0.1123, -0.0244, -0.0408,  ...,  0.0079,  0.0008, -0.0569],\n",
      "        [ 0.0742, -0.0269, -0.0400,  ..., -0.0427,  0.0034, -0.0283]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.44.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0227, -0.0267,  0.0272,  ...,  0.0771, -0.0337,  0.0283],\n",
      "        [ 0.0035, -0.0173, -0.0742,  ...,  0.0044, -0.0265,  0.0253],\n",
      "        [-0.0242, -0.0025, -0.0195,  ...,  0.0075, -0.0276, -0.0122],\n",
      "        ...,\n",
      "        [ 0.0004,  0.0203, -0.0002,  ..., -0.0270,  0.0422,  0.0065],\n",
      "        [ 0.0396,  0.0003, -0.0026,  ...,  0.0225,  0.0708,  0.0022],\n",
      "        [ 0.0364,  0.0012,  0.0554,  ..., -0.0226, -0.0215, -0.0220]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.44.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.44.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.45.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0483,  0.0178, -0.0513,  ...,  0.0312, -0.0032, -0.0615],\n",
      "        [-0.0337,  0.0074, -0.0488,  ..., -0.0435,  0.0334, -0.0173],\n",
      "        [ 0.0106,  0.0034, -0.0469,  ...,  0.0266,  0.0123, -0.0265],\n",
      "        ...,\n",
      "        [-0.0381, -0.0183, -0.0193,  ..., -0.0408,  0.0239,  0.0170],\n",
      "        [ 0.0273, -0.0276,  0.0227,  ..., -0.0308,  0.0483,  0.0069],\n",
      "        [-0.0171,  0.0422, -0.0098,  ...,  0.0625,  0.0148, -0.0063]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.45.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.45.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0025, -0.0391, -0.0081,  ..., -0.0884,  0.0082, -0.0223],\n",
      "        [-0.0664, -0.0464,  0.0195,  ..., -0.0645,  0.0289,  0.0048],\n",
      "        [ 0.0092, -0.0601, -0.0243,  ...,  0.0210, -0.0231,  0.0143],\n",
      "        ...,\n",
      "        [-0.0079, -0.0094,  0.0099,  ...,  0.0009,  0.0057,  0.0042],\n",
      "        [-0.0205,  0.0175,  0.0156,  ..., -0.0188, -0.0262, -0.0635],\n",
      "        [-0.0476,  0.0138,  0.0276,  ...,  0.0149,  0.0130,  0.0184]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.45.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0157, -0.0066, -0.0028,  ..., -0.0664,  0.0206, -0.0028],\n",
      "        [ 0.0079, -0.0449, -0.0303,  ..., -0.0371, -0.0096,  0.0116],\n",
      "        [-0.0581, -0.0092,  0.0684,  ..., -0.0513, -0.0015, -0.0299],\n",
      "        ...,\n",
      "        [-0.0403, -0.0273, -0.0097,  ..., -0.0094, -0.0045, -0.0330],\n",
      "        [-0.0247, -0.0154,  0.0066,  ...,  0.0104, -0.0291, -0.0320],\n",
      "        [ 0.0300, -0.0019,  0.0115,  ...,  0.0405, -0.0072,  0.0449]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.45.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.45.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0420, -0.0469, -0.0183,  ..., -0.0006, -0.0070, -0.0417],\n",
      "        [ 0.0898,  0.0183,  0.0106,  ..., -0.0386, -0.0349, -0.0806],\n",
      "        [ 0.0177,  0.0001, -0.0527,  ..., -0.0075,  0.0220, -0.0459],\n",
      "        ...,\n",
      "        [-0.0248,  0.0186,  0.0302,  ...,  0.0815, -0.0121,  0.0064],\n",
      "        [ 0.0269, -0.0510, -0.0294,  ..., -0.0182, -0.0354,  0.0757],\n",
      "        [-0.0173,  0.0277,  0.0039,  ...,  0.0674,  0.0079,  0.0176]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.45.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0159, -0.0238,  0.0898,  ...,  0.0134, -0.0405,  0.0028],\n",
      "        [ 0.0364,  0.0398,  0.0540,  ...,  0.0018,  0.0327, -0.0391],\n",
      "        [ 0.0391,  0.0347, -0.0132,  ..., -0.0236, -0.0013, -0.0278],\n",
      "        ...,\n",
      "        [-0.0231, -0.0067, -0.0369,  ..., -0.0029, -0.0025, -0.0109],\n",
      "        [-0.0091, -0.0310, -0.0505,  ..., -0.0630, -0.0062, -0.0128],\n",
      "        [ 0.0322, -0.0571, -0.0315,  ..., -0.0957, -0.0244,  0.0476]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.45.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 7.8125e-03,  2.4780e-02,  9.0942e-03,  ..., -9.5215e-03,\n",
      "          3.7109e-02, -5.9509e-03],\n",
      "        [ 3.2471e-02,  9.5703e-02, -2.0264e-02,  ...,  1.2634e-02,\n",
      "          6.3477e-03, -3.6133e-02],\n",
      "        [-5.9814e-03, -8.6426e-02,  1.3199e-03,  ...,  5.0781e-02,\n",
      "          5.2734e-02,  1.6357e-02],\n",
      "        ...,\n",
      "        [-9.8267e-03, -9.8267e-03, -1.7334e-02,  ..., -1.9409e-02,\n",
      "         -2.3193e-02, -1.5106e-03],\n",
      "        [ 4.2236e-02, -2.8320e-02,  1.6602e-02,  ...,  2.2125e-03,\n",
      "         -6.3477e-03, -3.3203e-02],\n",
      "        [-2.8564e-02,  3.2806e-03, -4.2677e-05,  ..., -7.0312e-02,\n",
      "          2.9755e-03,  9.0942e-03]], requires_grad=True)\n",
      "Layer: model.layers.45.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0273,  0.0273, -0.0124,  ..., -0.0176, -0.0283,  0.0371],\n",
      "        [-0.0354, -0.0256,  0.0522,  ..., -0.0157, -0.0491,  0.0161],\n",
      "        [ 0.0327,  0.0110,  0.0273,  ..., -0.0123,  0.0003,  0.0084],\n",
      "        ...,\n",
      "        [-0.0245,  0.0150, -0.0001,  ..., -0.0659,  0.0253, -0.0703],\n",
      "        [ 0.0425, -0.0381,  0.0073,  ..., -0.0013, -0.0417, -0.0259],\n",
      "        [-0.0154, -0.0062,  0.0011,  ...,  0.0066, -0.0320,  0.0171]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.45.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0427, -0.0149, -0.0791,  ..., -0.0596, -0.0266, -0.0508],\n",
      "        [ 0.0278, -0.0581, -0.0332,  ..., -0.0240, -0.0036,  0.0114],\n",
      "        [-0.0231,  0.0217,  0.0718,  ...,  0.0215,  0.0513, -0.0008],\n",
      "        ...,\n",
      "        [-0.0244, -0.0052,  0.0486,  ..., -0.0815, -0.0074,  0.0869],\n",
      "        [ 0.0104, -0.0396, -0.0588,  ...,  0.0135, -0.0250, -0.0437],\n",
      "        [ 0.0018, -0.0280, -0.0027,  ..., -0.0747,  0.0786,  0.0493]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.45.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.45.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.46.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0405,  0.0442,  0.0292,  ...,  0.0322, -0.0242, -0.0166],\n",
      "        [ 0.0194,  0.0286,  0.0183,  ...,  0.0166, -0.0190, -0.0591],\n",
      "        [-0.0054,  0.0242, -0.0023,  ..., -0.0104,  0.0104, -0.0129],\n",
      "        ...,\n",
      "        [-0.0040,  0.0022, -0.0542,  ..., -0.0226,  0.0261, -0.0081],\n",
      "        [-0.0269, -0.0051,  0.0442,  ..., -0.0100, -0.0135,  0.0413],\n",
      "        [-0.0156, -0.0281, -0.0552,  ..., -0.0084,  0.0825, -0.0266]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.46.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0289,  0.0947,  0.0078,  ...,  0.0562,  0.0092, -0.0342],\n",
      "        [ 0.0165,  0.0288, -0.0184,  ..., -0.0635, -0.0776, -0.0752],\n",
      "        [-0.0898, -0.0413, -0.0227,  ..., -0.0146,  0.0092,  0.0228],\n",
      "        ...,\n",
      "        [ 0.0101,  0.0033,  0.0079,  ...,  0.0028, -0.0369,  0.0144],\n",
      "        [-0.0156, -0.0442,  0.0261,  ..., -0.0260, -0.0645,  0.0479],\n",
      "        [ 0.0635,  0.0086, -0.0156,  ...,  0.0162, -0.0034,  0.0087]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0522, -0.0038, -0.0007,  ..., -0.0210, -0.0212,  0.0354],\n",
      "        [-0.0004,  0.0150,  0.0432,  ..., -0.0025,  0.0010,  0.0277],\n",
      "        [-0.0225,  0.0135,  0.0610,  ...,  0.0029, -0.0078, -0.0239],\n",
      "        ...,\n",
      "        [ 0.0444,  0.0009,  0.0135,  ...,  0.0108,  0.0117,  0.0334],\n",
      "        [ 0.0044, -0.0332,  0.0120,  ...,  0.0150, -0.0302, -0.0209],\n",
      "        [-0.0161, -0.0267,  0.0094,  ..., -0.0242, -0.0405, -0.0081]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.46.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0042, -0.0449, -0.0107,  ...,  0.0131,  0.0713, -0.0142],\n",
      "        [ 0.0386,  0.0038, -0.0801,  ..., -0.1064,  0.0096,  0.0518],\n",
      "        [-0.0845, -0.0889, -0.0291,  ..., -0.0150,  0.0200,  0.0625],\n",
      "        ...,\n",
      "        [ 0.0237,  0.0195,  0.0520,  ...,  0.0127, -0.0110, -0.0781],\n",
      "        [ 0.0444, -0.0781,  0.0308,  ..., -0.0306,  0.0432,  0.0415],\n",
      "        [ 0.0986,  0.1045,  0.0188,  ...,  0.0183,  0.0376,  0.0276]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0197,  0.0742, -0.0322,  ...,  0.0079, -0.0200, -0.0603],\n",
      "        [ 0.0293, -0.0386,  0.0236,  ...,  0.0237,  0.0366, -0.0146],\n",
      "        [-0.0454,  0.0801,  0.0396,  ...,  0.0339, -0.0277,  0.0444],\n",
      "        ...,\n",
      "        [ 0.0461,  0.0254, -0.0126,  ...,  0.0052,  0.0176,  0.0091],\n",
      "        [-0.0079,  0.0089,  0.0928,  ..., -0.0439, -0.0095,  0.0032],\n",
      "        [-0.0581, -0.0620, -0.0366,  ...,  0.0251, -0.0476,  0.0479]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0171, -0.0183, -0.0242,  ..., -0.0095, -0.0272,  0.0146],\n",
      "        [-0.0090,  0.0640,  0.0167,  ..., -0.0162, -0.0264,  0.0027],\n",
      "        [-0.0439, -0.0586,  0.0386,  ...,  0.0366, -0.0012,  0.0330],\n",
      "        ...,\n",
      "        [-0.0359,  0.0317, -0.0610,  ..., -0.0815, -0.0150,  0.0032],\n",
      "        [-0.0193,  0.0171, -0.0293,  ...,  0.0464,  0.0023, -0.0088],\n",
      "        [-0.0214,  0.0369,  0.0106,  ...,  0.0074,  0.0240,  0.0005]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0425, -0.0542, -0.0117,  ...,  0.0192, -0.0159,  0.0444],\n",
      "        [ 0.0625,  0.0498, -0.0242,  ..., -0.0144, -0.0043,  0.0674],\n",
      "        [-0.0227,  0.0131, -0.0513,  ..., -0.0315, -0.0208,  0.0181],\n",
      "        ...,\n",
      "        [ 0.0242,  0.0491, -0.0381,  ..., -0.0292,  0.0029, -0.0610],\n",
      "        [-0.0074, -0.0073, -0.0024,  ...,  0.0430, -0.0513,  0.0471],\n",
      "        [ 0.0043, -0.0064,  0.0322,  ...,  0.0356,  0.0036,  0.0220]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0094,  0.0425, -0.0152,  ..., -0.0282, -0.0079,  0.0228],\n",
      "        [ 0.0067, -0.0063, -0.0038,  ..., -0.0071,  0.0282,  0.0258],\n",
      "        [-0.0630, -0.0074, -0.0369,  ..., -0.0393,  0.0081, -0.0042],\n",
      "        ...,\n",
      "        [-0.0038, -0.0115,  0.0398,  ..., -0.0312, -0.0305, -0.0118],\n",
      "        [ 0.0172,  0.0156, -0.0070,  ..., -0.0089,  0.0601, -0.0172],\n",
      "        [ 0.0156,  0.0023, -0.0381,  ...,  0.0500,  0.0214,  0.0486]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.46.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.46.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.47.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0079,  0.0801, -0.0273,  ...,  0.0669, -0.0498, -0.0327],\n",
      "        [ 0.0210,  0.0126,  0.0199,  ...,  0.0500,  0.0054,  0.0300],\n",
      "        [-0.0762,  0.0181,  0.0444,  ...,  0.0072,  0.0569, -0.0142],\n",
      "        ...,\n",
      "        [-0.0099, -0.0092, -0.0292,  ...,  0.0020, -0.0425, -0.0449],\n",
      "        [ 0.0405, -0.0231,  0.0038,  ...,  0.0732,  0.0253,  0.0198],\n",
      "        [-0.0415,  0.0118,  0.0118,  ..., -0.0222, -0.0225, -0.0330]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.47.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.47.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0266,  0.0098, -0.0160,  ..., -0.0435, -0.0049, -0.0530],\n",
      "        [-0.0398,  0.0015,  0.0645,  ...,  0.0557, -0.0309, -0.0308],\n",
      "        [-0.0947, -0.0151,  0.0591,  ...,  0.0156, -0.0244,  0.0259],\n",
      "        ...,\n",
      "        [ 0.0371,  0.0069,  0.0488,  ..., -0.0170, -0.0308, -0.0454],\n",
      "        [-0.0009, -0.0012, -0.0150,  ..., -0.0089, -0.0024, -0.0069],\n",
      "        [ 0.0025,  0.0113,  0.0110,  ..., -0.0129, -0.0330,  0.0129]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.47.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0354, -0.0420,  0.0112,  ...,  0.0160, -0.0153,  0.0444],\n",
      "        [ 0.0454, -0.0271, -0.0625,  ..., -0.0737, -0.0347,  0.0825],\n",
      "        [ 0.0977,  0.0781,  0.0564,  ...,  0.0557, -0.0061, -0.0251],\n",
      "        ...,\n",
      "        [-0.0464, -0.0007,  0.0055,  ..., -0.0276, -0.0005, -0.0104],\n",
      "        [ 0.0124,  0.0096, -0.0046,  ...,  0.0159, -0.0166,  0.0294],\n",
      "        [ 0.0039,  0.0132, -0.0045,  ..., -0.0045,  0.0250,  0.0203]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.47.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.47.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0270, -0.0161, -0.0229,  ..., -0.0625,  0.0752, -0.0417],\n",
      "        [ 0.0233, -0.0679,  0.0151,  ...,  0.0282,  0.0464,  0.0923],\n",
      "        [-0.0297, -0.0050,  0.0635,  ...,  0.0217, -0.0067,  0.0503],\n",
      "        ...,\n",
      "        [ 0.0303, -0.0253,  0.1289,  ...,  0.0413, -0.0094,  0.0559],\n",
      "        [ 0.0065,  0.1221,  0.0325,  ..., -0.0356, -0.0630, -0.0044],\n",
      "        [ 0.0125,  0.0293,  0.0415,  ...,  0.0479,  0.0466, -0.0508]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.47.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 7.0190e-03, -9.5215e-03,  8.8867e-02,  ...,  1.0791e-01,\n",
      "          2.9907e-03, -2.3682e-02],\n",
      "        [-1.1658e-02,  1.9653e-02, -9.0332e-03,  ..., -1.9653e-02,\n",
      "          2.8931e-02, -1.4648e-02],\n",
      "        [-1.4526e-02, -3.1494e-02, -2.1973e-02,  ...,  6.3965e-02,\n",
      "         -3.6621e-02, -2.9564e-05],\n",
      "        ...,\n",
      "        [-4.8340e-02, -2.4170e-02, -7.0312e-02,  ..., -3.9551e-02,\n",
      "         -2.4780e-02, -5.2979e-02],\n",
      "        [ 2.1362e-03,  8.1177e-03,  1.4160e-02,  ...,  5.0781e-02,\n",
      "         -1.0254e-01,  3.8330e-02],\n",
      "        [ 9.1553e-03,  6.3477e-02, -4.7363e-02,  ...,  2.1729e-02,\n",
      "          9.5825e-03,  3.2715e-02]], requires_grad=True)\n",
      "Layer: model.layers.47.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 1.1536e-02, -8.1787e-03, -3.7354e-02,  ..., -6.1279e-02,\n",
      "         -1.1292e-02,  2.6245e-02],\n",
      "        [ 2.7710e-02, -2.0874e-02,  3.1250e-02,  ...,  2.5513e-02,\n",
      "          2.3193e-02,  5.7373e-03],\n",
      "        [ 1.1353e-02,  4.1962e-05,  4.0894e-03,  ..., -2.5024e-02,\n",
      "          1.7334e-02, -2.7344e-02],\n",
      "        ...,\n",
      "        [ 6.2012e-02,  2.6733e-02,  7.4219e-02,  ...,  8.9355e-02,\n",
      "         -2.6855e-02, -4.7302e-03],\n",
      "        [ 1.0757e-03, -2.1973e-03,  1.3306e-02,  ...,  2.8320e-02,\n",
      "         -1.8311e-02, -2.1667e-03],\n",
      "        [-2.1973e-02, -3.4424e-02, -2.6978e-02,  ..., -1.7334e-02,\n",
      "         -6.3171e-03,  6.5430e-02]], requires_grad=True)\n",
      "Layer: model.layers.47.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0168,  0.0080,  0.0649,  ...,  0.0154,  0.0020, -0.0018],\n",
      "        [ 0.0208, -0.0498,  0.0106,  ..., -0.0217, -0.0342, -0.0151],\n",
      "        [ 0.0366, -0.0197,  0.0089,  ...,  0.0176, -0.0447,  0.0947],\n",
      "        ...,\n",
      "        [-0.0031, -0.0488,  0.0474,  ..., -0.0154,  0.0023, -0.0304],\n",
      "        [-0.0391, -0.0420, -0.0261,  ..., -0.0015, -0.0325,  0.0043],\n",
      "        [-0.0061,  0.0413,  0.0056,  ...,  0.0146,  0.0310,  0.0120]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.47.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0017,  0.0140,  0.0337,  ..., -0.0131, -0.0503, -0.0437],\n",
      "        [ 0.0295,  0.0157,  0.0089,  ..., -0.0118, -0.0327,  0.0142],\n",
      "        [ 0.0228,  0.0449,  0.0205,  ...,  0.0072,  0.0302,  0.0427],\n",
      "        ...,\n",
      "        [ 0.0225,  0.0447,  0.0099,  ..., -0.0019, -0.0742, -0.0674],\n",
      "        [-0.0437, -0.0449, -0.0259,  ..., -0.0173, -0.0283,  0.0242],\n",
      "        [-0.0110, -0.0405,  0.0034,  ..., -0.0255,  0.0535, -0.0063]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.47.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.47.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.48.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0522, -0.0244, -0.0039,  ..., -0.0144,  0.0248,  0.0006],\n",
      "        [ 0.0167,  0.0023, -0.0120,  ...,  0.0171, -0.0303,  0.0220],\n",
      "        [ 0.0137, -0.0283,  0.0035,  ..., -0.0115, -0.0081,  0.0315],\n",
      "        ...,\n",
      "        [-0.0098, -0.0104,  0.0496,  ...,  0.0566,  0.0286,  0.0474],\n",
      "        [ 0.0075, -0.0439,  0.0203,  ...,  0.0009, -0.0063, -0.0051],\n",
      "        [-0.0129, -0.0188, -0.0016,  ..., -0.0073,  0.0142, -0.0159]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.48.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0197,  0.0195, -0.0083,  ...,  0.0078, -0.0144,  0.0593],\n",
      "        [ 0.0403,  0.0198,  0.0179,  ..., -0.0165, -0.0310, -0.0043],\n",
      "        [-0.0138,  0.0295, -0.0222,  ...,  0.0630, -0.0408, -0.0176],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0157, -0.0270,  ..., -0.0001, -0.0405, -0.0034],\n",
      "        [ 0.0030,  0.0103, -0.0189,  ..., -0.0134,  0.0327, -0.0209],\n",
      "        [-0.0286, -0.0022,  0.0008,  ...,  0.0031, -0.0160, -0.0153]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0479,  0.0289, -0.0237,  ..., -0.0405, -0.0649,  0.0469],\n",
      "        [-0.0184, -0.0114,  0.0214,  ...,  0.0048,  0.0135,  0.0148],\n",
      "        [ 0.0143,  0.0417,  0.0157,  ..., -0.0254,  0.0364,  0.0635],\n",
      "        ...,\n",
      "        [ 0.0131, -0.0049, -0.0115,  ...,  0.0013,  0.0048, -0.0121],\n",
      "        [-0.0203,  0.0075,  0.0161,  ..., -0.0038,  0.0183,  0.0574],\n",
      "        [ 0.0112,  0.0105,  0.0391,  ...,  0.0170, -0.0200, -0.0327]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.48.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.1060, -0.0535,  0.0859,  ...,  0.0703,  0.0430,  0.0098],\n",
      "        [ 0.0059,  0.0145,  0.0072,  ...,  0.0211, -0.0476,  0.0308],\n",
      "        [ 0.0068,  0.0232,  0.0184,  ..., -0.0120, -0.0449,  0.0664],\n",
      "        ...,\n",
      "        [ 0.0376, -0.0801,  0.0444,  ...,  0.0435,  0.0188, -0.0017],\n",
      "        [-0.0139, -0.0132, -0.0435,  ..., -0.0071,  0.0525,  0.0123],\n",
      "        [-0.0143, -0.0322,  0.0542,  ..., -0.0161,  0.1533,  0.0549]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0625, -0.0167,  0.0413,  ..., -0.0199,  0.0146,  0.0293],\n",
      "        [-0.0747, -0.0031, -0.0737,  ..., -0.0356, -0.0259,  0.0099],\n",
      "        [-0.0522, -0.0188,  0.1128,  ...,  0.0075, -0.0171, -0.0776],\n",
      "        ...,\n",
      "        [-0.0435,  0.0258, -0.0131,  ...,  0.0386, -0.0898, -0.0601],\n",
      "        [-0.0120,  0.0233,  0.0349,  ...,  0.0674,  0.0630, -0.0571],\n",
      "        [-0.0227, -0.0266,  0.0393,  ..., -0.0723,  0.0277, -0.0693]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0430, -0.0028,  0.0337,  ..., -0.0086,  0.0327, -0.0129],\n",
      "        [-0.0162, -0.0236, -0.0635,  ..., -0.0144, -0.0222,  0.0014],\n",
      "        [ 0.0120, -0.0030, -0.0168,  ..., -0.0420, -0.0115,  0.0898],\n",
      "        ...,\n",
      "        [-0.0234, -0.0205, -0.0065,  ..., -0.0126, -0.0106, -0.0209],\n",
      "        [ 0.0302,  0.0086, -0.0157,  ...,  0.0684,  0.0051, -0.0947],\n",
      "        [ 0.0150,  0.0035,  0.0022,  ...,  0.0388,  0.0144, -0.0128]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0177, -0.0234,  0.0479,  ...,  0.0239, -0.0618,  0.0081],\n",
      "        [-0.0217, -0.0923,  0.0281,  ...,  0.0204,  0.0400,  0.0237],\n",
      "        [-0.0496,  0.0036,  0.0146,  ...,  0.0476,  0.0298,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0159,  0.0002, -0.0199,  ...,  0.0049,  0.0156,  0.0236],\n",
      "        [-0.0483, -0.0078, -0.0698,  ..., -0.0011,  0.0148, -0.0469],\n",
      "        [ 0.0339,  0.0352,  0.0095,  ...,  0.0371,  0.0155, -0.0776]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0544, -0.0271, -0.0030,  ..., -0.0371,  0.0496, -0.0398],\n",
      "        [-0.0200, -0.0062, -0.0339,  ...,  0.0190, -0.0291,  0.0151],\n",
      "        [ 0.0286,  0.0087,  0.0077,  ..., -0.0090,  0.0067,  0.0066],\n",
      "        ...,\n",
      "        [ 0.0347,  0.0140,  0.0089,  ..., -0.0109, -0.0110,  0.0537],\n",
      "        [ 0.0198, -0.0024, -0.0251,  ...,  0.0825,  0.0022, -0.0442],\n",
      "        [ 0.0115, -0.0244,  0.0322,  ...,  0.0449, -0.0247,  0.0156]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.48.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.48.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.49.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0352, -0.0459, -0.0076,  ..., -0.0286,  0.0123,  0.0071],\n",
      "        [-0.0087,  0.0097, -0.0164,  ..., -0.0273, -0.0247, -0.0044],\n",
      "        [ 0.0493, -0.0825,  0.0154,  ..., -0.0079,  0.0162, -0.0181],\n",
      "        ...,\n",
      "        [-0.0081,  0.0396,  0.0359,  ..., -0.0483, -0.0164,  0.0253],\n",
      "        [-0.0403, -0.0271,  0.0586,  ...,  0.0110,  0.0095, -0.0386],\n",
      "        [ 0.0332, -0.0146,  0.0310,  ...,  0.0143, -0.0298, -0.0588]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.49.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.49.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0703, -0.0503, -0.0330,  ...,  0.0005, -0.0137,  0.0164],\n",
      "        [ 0.0190, -0.0693, -0.0117,  ...,  0.0195,  0.0289, -0.0811],\n",
      "        [ 0.0220,  0.0116,  0.0052,  ..., -0.0381, -0.0146,  0.0430],\n",
      "        ...,\n",
      "        [ 0.0356,  0.0022,  0.0292,  ..., -0.0068, -0.0281,  0.0664],\n",
      "        [-0.0425, -0.0265, -0.0253,  ..., -0.0366, -0.0219,  0.0278],\n",
      "        [-0.0056, -0.0258, -0.0199,  ...,  0.0030, -0.0142,  0.0635]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.49.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 3.9062e-03, -2.8564e-02,  1.7578e-02,  ...,  2.6855e-02,\n",
      "          1.4954e-03,  4.2480e-02],\n",
      "        [-1.1673e-03,  3.8330e-02,  4.6082e-03,  ..., -3.0273e-02,\n",
      "          2.7847e-04, -2.8076e-02],\n",
      "        [-3.3936e-02,  6.7139e-03,  2.3804e-02,  ...,  7.6294e-05,\n",
      "         -1.5381e-02, -2.6245e-02],\n",
      "        ...,\n",
      "        [-5.6152e-03, -4.6997e-03,  2.7161e-03,  ..., -1.2741e-03,\n",
      "         -4.8218e-03, -1.0925e-02],\n",
      "        [ 1.8387e-03,  1.9165e-02, -2.7954e-02,  ..., -9.5215e-03,\n",
      "         -1.5137e-02,  6.1768e-02],\n",
      "        [-2.9297e-02,  2.6245e-03, -2.9602e-03,  ..., -1.2695e-02,\n",
      "          8.9111e-03, -5.0049e-03]], requires_grad=True)\n",
      "Layer: model.layers.49.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.49.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0104, -0.0430, -0.0381,  ...,  0.0317,  0.0664, -0.0167],\n",
      "        [-0.0356, -0.0396, -0.0137,  ..., -0.0757, -0.0508, -0.0708],\n",
      "        [ 0.0044, -0.0254,  0.0496,  ...,  0.0640, -0.0195,  0.0330],\n",
      "        ...,\n",
      "        [ 0.0378,  0.0302,  0.0132,  ..., -0.0033,  0.0408, -0.0957],\n",
      "        [ 0.0069, -0.0242, -0.0044,  ..., -0.0030,  0.0017,  0.0156],\n",
      "        [-0.0588, -0.0596,  0.0256,  ...,  0.0009, -0.0356, -0.0270]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.49.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 1.7212e-02,  1.4954e-02,  2.5757e-02,  ...,  1.3351e-04,\n",
      "          1.7090e-02, -2.8076e-02],\n",
      "        [-2.2278e-03,  7.7148e-02, -2.4536e-02,  ...,  1.5564e-03,\n",
      "         -2.2949e-02,  4.6539e-04],\n",
      "        [-9.0332e-02,  2.1973e-03, -4.9805e-02,  ..., -5.0293e-02,\n",
      "         -3.5400e-02, -4.3640e-03],\n",
      "        ...,\n",
      "        [ 2.7588e-02, -5.4169e-04, -8.1062e-06,  ..., -7.9956e-03,\n",
      "          5.6763e-03,  7.9102e-02],\n",
      "        [ 1.8555e-02, -6.2256e-02,  7.6294e-03,  ..., -1.6235e-02,\n",
      "         -3.4912e-02, -5.7617e-02],\n",
      "        [ 4.7363e-02, -3.5889e-02, -4.4922e-02,  ...,  1.8311e-02,\n",
      "          3.3203e-02, -1.4038e-02]], requires_grad=True)\n",
      "Layer: model.layers.49.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 1.9653e-02, -4.1260e-02, -1.9409e-02,  ...,  7.1777e-02,\n",
      "         -5.5176e-02, -2.2583e-03],\n",
      "        [-2.4658e-02, -2.3438e-02, -1.0864e-02,  ..., -8.5449e-03,\n",
      "          2.7832e-02,  3.2959e-02],\n",
      "        [ 4.2236e-02, -2.0996e-02,  1.4191e-03,  ..., -1.8677e-02,\n",
      "          2.0752e-02,  3.9062e-02],\n",
      "        ...,\n",
      "        [ 4.6631e-02, -4.8096e-02,  3.6316e-03,  ...,  5.3711e-03,\n",
      "          6.0425e-03,  1.9287e-02],\n",
      "        [ 5.7617e-02, -1.5747e-02, -6.8665e-05,  ...,  2.6367e-02,\n",
      "         -3.7109e-02, -1.1670e-01],\n",
      "        [ 2.0874e-02,  4.7852e-02, -2.0142e-02,  ...,  5.1514e-02,\n",
      "          3.8086e-02, -3.5645e-02]], requires_grad=True)\n",
      "Layer: model.layers.49.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 6.5308e-03,  7.0801e-02,  1.3306e-02,  ...,  3.8818e-02,\n",
      "         -8.8501e-03,  5.6396e-02],\n",
      "        [-7.8125e-03,  2.2095e-02, -2.9419e-02,  ...,  8.7738e-05,\n",
      "         -2.5757e-02, -1.3489e-02],\n",
      "        [ 2.2095e-02,  1.8799e-02,  3.0396e-02,  ..., -3.2715e-02,\n",
      "         -2.5269e-02, -5.3223e-02],\n",
      "        ...,\n",
      "        [ 2.0020e-02,  4.3457e-02, -2.7710e-02,  ..., -1.3123e-03,\n",
      "          2.5879e-02,  4.9561e-02],\n",
      "        [-6.2256e-03, -1.3977e-02,  1.0132e-02,  ...,  1.6235e-02,\n",
      "          1.6357e-02, -1.5381e-02],\n",
      "        [ 1.0620e-02,  2.1973e-03, -3.7598e-02,  ...,  6.6895e-02,\n",
      "         -2.1240e-02, -4.7607e-03]], requires_grad=True)\n",
      "Layer: model.layers.49.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0008, -0.0703, -0.0405,  ..., -0.0121,  0.0469, -0.1040],\n",
      "        [ 0.0048, -0.0133, -0.0135,  ...,  0.0240,  0.0193,  0.0002],\n",
      "        [-0.0237, -0.0496, -0.0317,  ..., -0.0014,  0.0053, -0.0121],\n",
      "        ...,\n",
      "        [-0.0339, -0.0302,  0.0148,  ..., -0.0068,  0.0688,  0.0203],\n",
      "        [-0.0454, -0.0040,  0.0022,  ...,  0.0112,  0.0123, -0.0459],\n",
      "        [ 0.0359, -0.0249,  0.0144,  ..., -0.0149, -0.0079,  0.0297]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.49.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.49.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.50.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0339,  0.0449, -0.0073,  ...,  0.0039, -0.0181, -0.0352],\n",
      "        [ 0.0025,  0.0176, -0.0215,  ...,  0.0095,  0.0830,  0.0080],\n",
      "        [ 0.0459,  0.0182,  0.0486,  ..., -0.0311,  0.0278,  0.0654],\n",
      "        ...,\n",
      "        [-0.0239, -0.0057, -0.0102,  ...,  0.0157, -0.0216,  0.0552],\n",
      "        [-0.0206, -0.0049, -0.0115,  ...,  0.0176, -0.0364,  0.0178],\n",
      "        [-0.0099, -0.0354,  0.0410,  ..., -0.0293, -0.0498, -0.0201]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.50.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0217, -0.0036, -0.0239,  ..., -0.0012,  0.0344,  0.0194],\n",
      "        [ 0.0271, -0.0374, -0.0325,  ...,  0.0278,  0.0145,  0.0089],\n",
      "        [ 0.0586, -0.0396, -0.0005,  ..., -0.0208, -0.0011,  0.0312],\n",
      "        ...,\n",
      "        [-0.0032, -0.0038, -0.0068,  ..., -0.0132, -0.0099, -0.0047],\n",
      "        [-0.0114,  0.0048, -0.0240,  ..., -0.0342, -0.0554, -0.0121],\n",
      "        [-0.0095,  0.0214, -0.0295,  ..., -0.0236, -0.0315,  0.0001]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0299, -0.0081, -0.0090,  ...,  0.0393,  0.0361,  0.0117],\n",
      "        [ 0.0065, -0.0135,  0.0225,  ..., -0.0437,  0.0026, -0.0364],\n",
      "        [ 0.0150, -0.0177, -0.0266,  ..., -0.0349,  0.0023, -0.0269],\n",
      "        ...,\n",
      "        [-0.0112, -0.0144, -0.0199,  ..., -0.0317, -0.0099, -0.0095],\n",
      "        [-0.0039, -0.0305,  0.0107,  ...,  0.0275, -0.0255, -0.0148],\n",
      "        [ 0.0011,  0.0049,  0.0118,  ..., -0.0074, -0.0123,  0.0063]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.50.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0552, -0.0037, -0.0613,  ..., -0.0874,  0.0249, -0.0864],\n",
      "        [ 0.0371,  0.0908, -0.0330,  ...,  0.0674, -0.0020,  0.0074],\n",
      "        [ 0.0286, -0.0299,  0.0376,  ..., -0.0159,  0.0282, -0.0317],\n",
      "        ...,\n",
      "        [-0.0232, -0.0061,  0.0674,  ..., -0.0986, -0.0630, -0.0703],\n",
      "        [ 0.1387,  0.0181, -0.0040,  ...,  0.0645, -0.0347, -0.0190],\n",
      "        [-0.0090, -0.0151,  0.0139,  ..., -0.0266, -0.0864,  0.0047]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0315, -0.0679,  0.0474,  ..., -0.0403, -0.0094,  0.0308],\n",
      "        [ 0.0410, -0.0554, -0.0112,  ...,  0.0503, -0.0046,  0.0366],\n",
      "        [ 0.0444, -0.0708, -0.0157,  ..., -0.0393,  0.0181, -0.0315],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0410,  0.0547,  ...,  0.0080,  0.0574,  0.0342],\n",
      "        [ 0.0664,  0.0264,  0.0249,  ..., -0.0120, -0.0193,  0.0378],\n",
      "        [-0.0300, -0.0693, -0.0238,  ...,  0.0008, -0.0057, -0.0400]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0217, -0.0197,  0.0004,  ...,  0.0225,  0.0815, -0.0270],\n",
      "        [ 0.0115,  0.0229,  0.0265,  ..., -0.0199, -0.0391,  0.0176],\n",
      "        [ 0.0178,  0.0347, -0.0089,  ..., -0.0014, -0.0173,  0.0154],\n",
      "        ...,\n",
      "        [-0.0142,  0.0142, -0.0164,  ...,  0.0214,  0.0718, -0.0071],\n",
      "        [ 0.0087, -0.0287,  0.0299,  ..., -0.0032, -0.0435,  0.0203],\n",
      "        [-0.0547,  0.0140, -0.0037,  ...,  0.0082,  0.0249, -0.0320]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0610, -0.0601, -0.0101,  ..., -0.0391,  0.0129,  0.0359],\n",
      "        [ 0.0284,  0.0361, -0.0342,  ...,  0.0435, -0.0016,  0.0071],\n",
      "        [ 0.0181, -0.0265, -0.0009,  ...,  0.0894, -0.0444, -0.0752],\n",
      "        ...,\n",
      "        [ 0.0277, -0.0298,  0.0234,  ...,  0.0569, -0.0557, -0.0659],\n",
      "        [ 0.0143, -0.0308,  0.0172,  ..., -0.0247,  0.0291, -0.0089],\n",
      "        [ 0.0203,  0.0140, -0.0400,  ..., -0.0400, -0.0242, -0.0146]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0071, -0.0276,  0.0136,  ..., -0.0430, -0.0371,  0.0229],\n",
      "        [ 0.0238,  0.0017, -0.0003,  ..., -0.0267,  0.0063, -0.0221],\n",
      "        [ 0.0101,  0.0693,  0.0075,  ...,  0.0084, -0.0613, -0.0322],\n",
      "        ...,\n",
      "        [-0.0110,  0.0229,  0.0518,  ...,  0.0337,  0.0547, -0.0181],\n",
      "        [ 0.0057,  0.0108,  0.0058,  ...,  0.0337, -0.0009, -0.0009],\n",
      "        [-0.0028, -0.0786,  0.0771,  ..., -0.0111,  0.0317, -0.0459]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.50.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.50.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.51.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-1.6357e-02, -3.7109e-02,  1.7456e-02,  ...,  5.8594e-02,\n",
      "          2.9297e-02,  2.1851e-02],\n",
      "        [-3.9062e-02, -1.0254e-02,  1.4771e-02,  ...,  1.2146e-02,\n",
      "          3.2227e-02,  3.9368e-03],\n",
      "        [ 3.3203e-02,  1.2329e-02, -2.4292e-02,  ...,  1.8555e-02,\n",
      "         -5.3223e-02, -5.7220e-05],\n",
      "        ...,\n",
      "        [-1.6968e-02,  1.9775e-02,  3.1250e-02,  ...,  6.8665e-03,\n",
      "          9.0942e-03,  3.5156e-02],\n",
      "        [ 1.4343e-03, -2.7100e-02, -6.6406e-02,  ..., -5.2979e-02,\n",
      "         -5.1270e-02, -1.5381e-02],\n",
      "        [-7.0801e-03, -7.5195e-02,  2.6367e-02,  ..., -2.1973e-02,\n",
      "          1.0437e-02, -2.3071e-02]], requires_grad=True)\n",
      "Layer: model.layers.51.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.51.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0508, -0.0430,  0.0552,  ...,  0.0120, -0.0182, -0.0581],\n",
      "        [ 0.0811, -0.0109,  0.0361,  ...,  0.0464, -0.0552,  0.0023],\n",
      "        [-0.0457, -0.0204,  0.0104,  ..., -0.0439, -0.0430, -0.0264],\n",
      "        ...,\n",
      "        [-0.0054, -0.0059,  0.0114,  ...,  0.0151, -0.0067,  0.0090],\n",
      "        [-0.0044,  0.0078, -0.0156,  ..., -0.0222,  0.0102, -0.0776],\n",
      "        [-0.0132, -0.0144,  0.0286,  ...,  0.0013, -0.0315, -0.0253]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.51.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 2.1973e-03, -3.5645e-02,  2.2888e-03,  ..., -4.7302e-03,\n",
      "         -2.4536e-02,  4.5410e-02],\n",
      "        [-2.9663e-02, -3.1738e-02, -2.0020e-02,  ...,  4.5898e-02,\n",
      "         -2.0020e-02,  1.2268e-02],\n",
      "        [ 1.5625e-02,  3.0396e-02,  4.4556e-03,  ...,  2.0386e-02,\n",
      "         -3.8818e-02,  2.8198e-02],\n",
      "        ...,\n",
      "        [-7.0312e-02, -4.0527e-02,  5.7068e-03,  ..., -3.4424e-02,\n",
      "         -2.1240e-02, -2.8564e-02],\n",
      "        [ 2.1118e-02, -2.5391e-02,  5.0049e-03,  ...,  6.2500e-02,\n",
      "          1.6479e-03, -1.3550e-02],\n",
      "        [-9.5825e-03,  1.8066e-02,  2.5513e-02,  ..., -4.8637e-05,\n",
      "         -2.6855e-02, -1.4648e-02]], requires_grad=True)\n",
      "Layer: model.layers.51.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.51.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0189, -0.0075, -0.0103,  ..., -0.0167, -0.0439, -0.0400],\n",
      "        [-0.0095, -0.0483, -0.0128,  ..., -0.0435, -0.0325, -0.0122],\n",
      "        [ 0.0026, -0.0503, -0.0037,  ...,  0.0291, -0.0004,  0.0270],\n",
      "        ...,\n",
      "        [ 0.0126, -0.0723,  0.0635,  ..., -0.0002,  0.0457,  0.0466],\n",
      "        [ 0.0674,  0.0542,  0.0596,  ..., -0.0645,  0.0266,  0.0107],\n",
      "        [ 0.0537,  0.0020, -0.0471,  ...,  0.0457, -0.0376, -0.0043]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.51.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0483, -0.0293, -0.0498,  ..., -0.0070, -0.0259, -0.0303],\n",
      "        [-0.0195,  0.0016, -0.0236,  ...,  0.0723, -0.0376,  0.0027],\n",
      "        [-0.0386, -0.0217,  0.0245,  ...,  0.0208, -0.0562, -0.0376],\n",
      "        ...,\n",
      "        [ 0.0156,  0.0337, -0.0297,  ...,  0.0820, -0.0420,  0.0444],\n",
      "        [ 0.0513, -0.0018, -0.0096,  ..., -0.0190,  0.0219, -0.0393],\n",
      "        [-0.0201, -0.0178, -0.0486,  ..., -0.0020,  0.0007,  0.0356]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.51.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0232, -0.0077,  0.0217,  ...,  0.0479,  0.0317, -0.0132],\n",
      "        [-0.0830, -0.0312, -0.0222,  ...,  0.0337, -0.0164,  0.0549],\n",
      "        [ 0.0630, -0.0137, -0.0493,  ..., -0.0118, -0.0051, -0.0146],\n",
      "        ...,\n",
      "        [ 0.0483,  0.0298,  0.0172,  ..., -0.0417, -0.0125, -0.0535],\n",
      "        [-0.0566,  0.0086, -0.0103,  ..., -0.0276, -0.0547, -0.0228],\n",
      "        [-0.0576,  0.0522, -0.0703,  ..., -0.0240,  0.0444,  0.1069]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.51.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0198,  0.0544, -0.0147,  ...,  0.0194, -0.0084, -0.0508],\n",
      "        [ 0.0330, -0.0410, -0.0121,  ..., -0.0840,  0.0066,  0.0201],\n",
      "        [ 0.0215,  0.0381, -0.0172,  ..., -0.0148,  0.0002,  0.0160],\n",
      "        ...,\n",
      "        [-0.0231, -0.0043, -0.0017,  ..., -0.0308, -0.0100, -0.0181],\n",
      "        [-0.0522, -0.0161, -0.0211,  ..., -0.0317,  0.0255, -0.0884],\n",
      "        [-0.0062, -0.0143,  0.0503,  ..., -0.0104,  0.0347, -0.0178]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.51.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-2.5391e-02, -7.6172e-02, -1.8799e-02,  ..., -9.6680e-02,\n",
      "         -7.2632e-03,  6.3965e-02],\n",
      "        [-1.0645e-01, -2.4536e-02,  1.8799e-02,  ..., -2.9541e-02,\n",
      "         -2.0142e-02,  5.8594e-02],\n",
      "        [-3.6316e-03, -4.1992e-02,  3.7109e-02,  ..., -5.0293e-02,\n",
      "          2.5879e-02,  7.1106e-03],\n",
      "        ...,\n",
      "        [-6.2256e-03,  5.2246e-02, -4.2725e-02,  ..., -4.1992e-02,\n",
      "          3.9795e-02,  1.2451e-02],\n",
      "        [ 3.4424e-02,  5.6885e-02, -3.7354e-02,  ..., -3.2959e-03,\n",
      "          1.4648e-02,  3.5156e-02],\n",
      "        [-3.8574e-02,  3.1250e-02,  2.3438e-02,  ..., -1.3275e-03,\n",
      "         -4.8161e-05,  1.5991e-02]], requires_grad=True)\n",
      "Layer: model.layers.51.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.51.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.52.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0014,  0.0342,  0.0025,  ..., -0.0254, -0.0322,  0.0466],\n",
      "        [ 0.0342, -0.0292,  0.0211,  ..., -0.0173,  0.0437,  0.0231],\n",
      "        [ 0.0505, -0.0140, -0.0542,  ...,  0.0264, -0.0247, -0.0381],\n",
      "        ...,\n",
      "        [ 0.0112, -0.0126,  0.0229,  ...,  0.0364, -0.0194, -0.0090],\n",
      "        [ 0.0767, -0.0242, -0.0063,  ...,  0.0347,  0.0118,  0.0194],\n",
      "        [-0.0051, -0.0001,  0.0205,  ...,  0.0265, -0.0117, -0.0205]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.52.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0275, -0.0141, -0.0266,  ...,  0.0332, -0.0352,  0.0240],\n",
      "        [ 0.0417, -0.0012, -0.0369,  ...,  0.0498, -0.0535, -0.0723],\n",
      "        [-0.0126, -0.0334,  0.0190,  ..., -0.0493, -0.0562,  0.0605],\n",
      "        ...,\n",
      "        [-0.0300,  0.0850,  0.0045,  ...,  0.0201,  0.0138,  0.0130],\n",
      "        [-0.0157, -0.0082,  0.0012,  ...,  0.0038,  0.0034, -0.0222],\n",
      "        [-0.0170, -0.0077,  0.0277,  ..., -0.0198,  0.0289,  0.0131]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0054, -0.0092,  0.0186,  ...,  0.0620,  0.0061, -0.0425],\n",
      "        [-0.0065,  0.0056, -0.0166,  ...,  0.0179, -0.0059,  0.0684],\n",
      "        [ 0.0066,  0.0101,  0.0035,  ..., -0.0342,  0.0320,  0.0195],\n",
      "        ...,\n",
      "        [-0.0016,  0.0286, -0.0087,  ..., -0.0250,  0.0049, -0.0002],\n",
      "        [ 0.0271,  0.0193, -0.0021,  ...,  0.0141,  0.0084,  0.0771],\n",
      "        [ 0.0134, -0.0039,  0.0176,  ...,  0.0146, -0.0159, -0.0101]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.52.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0255, -0.0044,  0.0171,  ..., -0.0405,  0.0520,  0.0693],\n",
      "        [ 0.0023, -0.0062,  0.0239,  ..., -0.0101,  0.0058,  0.0552],\n",
      "        [-0.0432, -0.0245, -0.0184,  ..., -0.0063, -0.0728,  0.0089],\n",
      "        ...,\n",
      "        [ 0.1230,  0.0121, -0.1226,  ..., -0.0574,  0.1406, -0.0381],\n",
      "        [-0.0488, -0.0625,  0.1270,  ...,  0.0535, -0.0815,  0.0123],\n",
      "        [ 0.0410,  0.0306, -0.0488,  ..., -0.0444, -0.1055,  0.0277]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0265,  0.0344,  0.0586,  ...,  0.0044,  0.0175, -0.0105],\n",
      "        [-0.0320,  0.1006,  0.0493,  ..., -0.0094,  0.0182,  0.0062],\n",
      "        [-0.0786,  0.0591,  0.0371,  ...,  0.0135, -0.0045, -0.0479],\n",
      "        ...,\n",
      "        [-0.0032,  0.0320, -0.0378,  ..., -0.0045,  0.0684, -0.0508],\n",
      "        [-0.0171, -0.0305,  0.0781,  ...,  0.0425, -0.0069,  0.0342],\n",
      "        [ 0.0530,  0.0072, -0.0203,  ...,  0.0430, -0.0425,  0.0037]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0281, -0.0214, -0.0195,  ..., -0.0020,  0.0234, -0.0266],\n",
      "        [ 0.0320, -0.0374, -0.0469,  ..., -0.0240, -0.0036, -0.0046],\n",
      "        [ 0.0077,  0.0231,  0.0349,  ...,  0.0623,  0.0135, -0.0149],\n",
      "        ...,\n",
      "        [ 0.0234,  0.0096,  0.0239,  ..., -0.0300, -0.0145,  0.0498],\n",
      "        [-0.0059,  0.0742, -0.0215,  ..., -0.0732, -0.0320, -0.0110],\n",
      "        [ 0.0294,  0.0245,  0.0430,  ...,  0.0053,  0.0603,  0.0292]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0322, -0.0430,  0.0381,  ...,  0.0153, -0.0192,  0.0845],\n",
      "        [ 0.0106, -0.0576, -0.0306,  ..., -0.0544, -0.0464,  0.0133],\n",
      "        [ 0.0352, -0.0293, -0.0566,  ...,  0.0133, -0.0796, -0.0554],\n",
      "        ...,\n",
      "        [ 0.0339, -0.0028, -0.0288,  ...,  0.0265,  0.0171,  0.0344],\n",
      "        [ 0.0053,  0.1309, -0.0405,  ...,  0.0605, -0.0474,  0.0322],\n",
      "        [-0.0427, -0.0386, -0.0278,  ..., -0.0483,  0.0596,  0.0483]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0171,  0.0859,  0.0154,  ..., -0.0045, -0.0161, -0.0513],\n",
      "        [ 0.0393,  0.0123, -0.0265,  ...,  0.0283, -0.0449,  0.0371],\n",
      "        [ 0.0300,  0.0356, -0.0138,  ...,  0.0437,  0.0239, -0.0198],\n",
      "        ...,\n",
      "        [-0.0133,  0.0243, -0.0156,  ..., -0.0025,  0.0126,  0.0278],\n",
      "        [-0.0581,  0.0383, -0.0334,  ...,  0.0150,  0.0330,  0.0201],\n",
      "        [-0.0112, -0.0067,  0.0232,  ...,  0.0400, -0.0082,  0.0039]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.52.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.52.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.53.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-1.7456e-02,  7.7515e-03,  2.1484e-02,  ..., -3.0151e-02,\n",
      "          2.0504e-05,  1.0986e-02],\n",
      "        [ 1.5381e-02, -2.3071e-02,  3.6377e-02,  ..., -2.6978e-02,\n",
      "         -7.1716e-04, -4.1748e-02],\n",
      "        [ 3.0899e-04,  2.1057e-03,  7.8613e-02,  ..., -3.3936e-02,\n",
      "         -2.8076e-02, -3.4912e-02],\n",
      "        ...,\n",
      "        [-7.1411e-03, -6.0425e-03, -1.2207e-02,  ..., -6.8665e-03,\n",
      "         -5.4199e-02,  5.0781e-02],\n",
      "        [ 1.0254e-02, -1.2573e-02,  1.0559e-02,  ...,  6.8054e-03,\n",
      "         -9.8267e-03, -9.0820e-02],\n",
      "        [ 4.5776e-04, -5.2002e-02,  1.1719e-02,  ..., -1.5869e-03,\n",
      "          4.7607e-02,  3.0518e-02]], requires_grad=True)\n",
      "Layer: model.layers.53.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.53.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 3.5553e-03,  2.1118e-02,  1.1841e-02,  ...,  2.3560e-02,\n",
      "         -9.3994e-03,  9.3994e-03],\n",
      "        [ 4.2969e-02,  6.2256e-02,  3.6865e-02,  ...,  2.4048e-02,\n",
      "          1.0620e-02, -1.6098e-03],\n",
      "        [-3.1982e-02,  1.2695e-02,  1.2756e-02,  ...,  2.2583e-02,\n",
      "          2.1240e-02, -6.1523e-02],\n",
      "        ...,\n",
      "        [-1.9226e-03,  1.4954e-02, -7.8125e-03,  ...,  5.1575e-03,\n",
      "          4.5166e-03, -2.4796e-05],\n",
      "        [ 1.4771e-02, -1.1841e-02,  1.9897e-02,  ..., -3.5400e-02,\n",
      "         -8.9355e-02, -2.8931e-02],\n",
      "        [ 2.2461e-02, -5.7678e-03,  2.7588e-02,  ...,  2.0996e-02,\n",
      "          4.9561e-02, -1.8066e-02]], requires_grad=True)\n",
      "Layer: model.layers.53.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0037, -0.0283, -0.0118,  ..., -0.0312, -0.0461, -0.0337],\n",
      "        [ 0.0283, -0.0491,  0.1221,  ..., -0.0002, -0.0505,  0.0012],\n",
      "        [-0.0271,  0.0148,  0.0228,  ..., -0.0077, -0.0020, -0.0266],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0035,  0.0231,  ...,  0.0374,  0.0115, -0.0094],\n",
      "        [ 0.0118, -0.0006, -0.0042,  ...,  0.0009, -0.0164,  0.0001],\n",
      "        [-0.0087, -0.0145, -0.0371,  ...,  0.0159,  0.0122, -0.0110]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.53.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.53.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0099, -0.0173,  0.0996,  ...,  0.0476, -0.0432, -0.0126],\n",
      "        [-0.0471,  0.0306,  0.0284,  ...,  0.0239, -0.0566, -0.0435],\n",
      "        [-0.0757,  0.0275,  0.0781,  ...,  0.0508, -0.0491, -0.0491],\n",
      "        ...,\n",
      "        [ 0.0605,  0.0032,  0.0061,  ..., -0.0396,  0.0028, -0.0056],\n",
      "        [ 0.0854,  0.0381,  0.1221,  ...,  0.0053, -0.0287, -0.0026],\n",
      "        [-0.0089,  0.0698, -0.0366,  ..., -0.0067,  0.0125, -0.0752]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.53.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0088, -0.0562,  0.0272,  ...,  0.0190, -0.0177, -0.0549],\n",
      "        [-0.0190,  0.0275, -0.0684,  ...,  0.0483, -0.0161,  0.0601],\n",
      "        [-0.0830, -0.0159,  0.0010,  ...,  0.0684, -0.0143,  0.0142],\n",
      "        ...,\n",
      "        [ 0.0420,  0.0425,  0.0208,  ..., -0.0410,  0.0066,  0.0027],\n",
      "        [ 0.0057,  0.0091,  0.0366,  ..., -0.0159,  0.0108,  0.0055],\n",
      "        [ 0.0159,  0.0178,  0.0184,  ..., -0.0167,  0.0170,  0.0232]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.53.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0137,  0.0082,  0.0247,  ..., -0.0085,  0.0618,  0.0432],\n",
      "        [-0.0210,  0.0229, -0.0168,  ...,  0.0125,  0.0383,  0.0339],\n",
      "        [ 0.0052,  0.0107, -0.0007,  ...,  0.0378,  0.0537,  0.0154],\n",
      "        ...,\n",
      "        [ 0.0322,  0.0371,  0.0449,  ...,  0.0012, -0.0082, -0.0212],\n",
      "        [ 0.0275,  0.0292, -0.0269,  ...,  0.0219,  0.0165, -0.0332],\n",
      "        [-0.0272,  0.0275, -0.0187,  ...,  0.0095,  0.0139,  0.0095]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.53.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0232,  0.0449,  0.0183,  ..., -0.0234,  0.0605,  0.0097],\n",
      "        [ 0.0801,  0.0376, -0.0198,  ..., -0.0155,  0.0171,  0.0361],\n",
      "        [-0.0106,  0.0042,  0.0063,  ..., -0.0108,  0.0649,  0.0571],\n",
      "        ...,\n",
      "        [ 0.0023, -0.0074, -0.0308,  ...,  0.0097, -0.0101,  0.0284],\n",
      "        [ 0.0459, -0.0684,  0.0305,  ...,  0.0476,  0.0850,  0.0234],\n",
      "        [ 0.0312, -0.0327,  0.0378,  ..., -0.0405, -0.0583, -0.0248]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.53.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0177, -0.0083,  0.0267,  ..., -0.0104, -0.0116,  0.0264],\n",
      "        [ 0.0228,  0.0032, -0.0232,  ...,  0.0106, -0.0272,  0.0403],\n",
      "        [-0.0040,  0.0493, -0.0106,  ...,  0.0542,  0.0291, -0.0044],\n",
      "        ...,\n",
      "        [-0.0264, -0.0247,  0.0576,  ...,  0.0154,  0.0068, -0.0356],\n",
      "        [ 0.0017, -0.0400, -0.0044,  ...,  0.0664, -0.0552,  0.0142],\n",
      "        [-0.0308, -0.0303, -0.0771,  ..., -0.0164, -0.0125, -0.0059]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.53.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.53.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.54.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0283,  0.0080,  0.0588,  ...,  0.0198, -0.0094, -0.0139],\n",
      "        [ 0.0116, -0.0200, -0.0199,  ..., -0.0038, -0.0240, -0.0192],\n",
      "        [-0.0023, -0.0176, -0.0006,  ..., -0.0265, -0.0129, -0.0339],\n",
      "        ...,\n",
      "        [-0.0159,  0.0718,  0.0430,  ...,  0.0175, -0.0303, -0.0640],\n",
      "        [ 0.0054,  0.0182,  0.0073,  ...,  0.0117, -0.0010, -0.0518],\n",
      "        [-0.0444,  0.0239,  0.0287,  ...,  0.0192,  0.0079, -0.0273]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.54.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.54.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0405, -0.0192, -0.0918,  ...,  0.0007, -0.0040,  0.0210],\n",
      "        [-0.0229, -0.0176, -0.0408,  ...,  0.0342, -0.0168, -0.0045],\n",
      "        [-0.0234, -0.0840,  0.0356,  ..., -0.0566,  0.0215,  0.0096],\n",
      "        ...,\n",
      "        [ 0.0055, -0.0031,  0.0085,  ...,  0.0112, -0.0292, -0.0059],\n",
      "        [-0.0138,  0.0092, -0.0089,  ...,  0.0381,  0.0859, -0.0165],\n",
      "        [ 0.0160,  0.0513, -0.0410,  ...,  0.0552, -0.0322, -0.0295]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.54.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0062, -0.0337, -0.0315,  ..., -0.1050, -0.0088, -0.0254],\n",
      "        [ 0.0154, -0.0135,  0.0327,  ..., -0.0222, -0.0256, -0.0498],\n",
      "        [-0.0210, -0.0131, -0.0356,  ...,  0.0087, -0.0085, -0.0120],\n",
      "        ...,\n",
      "        [-0.0132, -0.0106, -0.1035,  ..., -0.0591,  0.0089, -0.0225],\n",
      "        [-0.0206,  0.0097, -0.0047,  ..., -0.0179, -0.0164,  0.0052],\n",
      "        [-0.0120,  0.0222, -0.0157,  ...,  0.0157, -0.0132,  0.0120]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.54.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.54.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0215,  0.0243, -0.0203,  ...,  0.0420, -0.0664,  0.0051],\n",
      "        [-0.0454, -0.0136,  0.0014,  ...,  0.0510, -0.0271,  0.0349],\n",
      "        [ 0.0099, -0.0238, -0.0030,  ...,  0.0476, -0.0050,  0.0339],\n",
      "        ...,\n",
      "        [ 0.0229,  0.0757,  0.0532,  ..., -0.0559, -0.1167, -0.0349],\n",
      "        [-0.0684, -0.0184, -0.0405,  ..., -0.0132, -0.0060, -0.0157],\n",
      "        [ 0.0072, -0.0625, -0.0552,  ...,  0.0221, -0.0342, -0.0723]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.54.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 3.7354e-02,  4.1260e-02, -4.1992e-02,  ...,  7.3242e-03,\n",
      "         -2.0874e-02,  6.2500e-02],\n",
      "        [ 4.1992e-02, -2.9785e-02,  1.4709e-02,  ..., -5.1758e-02,\n",
      "         -4.5898e-02, -3.9551e-02],\n",
      "        [ 6.8970e-03,  4.2969e-02,  4.2480e-02,  ...,  4.9072e-02,\n",
      "         -2.0264e-02, -2.4128e-04],\n",
      "        ...,\n",
      "        [-8.1787e-03, -9.5367e-05, -4.6631e-02,  ..., -9.3994e-03,\n",
      "          2.2583e-02,  5.1758e-02],\n",
      "        [ 3.3203e-02, -6.7749e-03, -3.7842e-02,  ..., -6.6223e-03,\n",
      "          2.3438e-02, -8.9355e-02],\n",
      "        [-6.3782e-03,  4.8584e-02,  1.6235e-02,  ...,  1.4282e-02,\n",
      "         -1.2573e-02, -7.0801e-03]], requires_grad=True)\n",
      "Layer: model.layers.54.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0177, -0.0214,  0.0378,  ...,  0.0248,  0.0391, -0.0284],\n",
      "        [ 0.0481,  0.0133, -0.0569,  ..., -0.0077, -0.0371,  0.0075],\n",
      "        [-0.0186,  0.0061,  0.0092,  ..., -0.0312, -0.0060, -0.0050],\n",
      "        ...,\n",
      "        [-0.0159,  0.0013,  0.0864,  ..., -0.0408,  0.0030,  0.0248],\n",
      "        [ 0.0003,  0.0344,  0.0525,  ..., -0.0239, -0.0021,  0.0728],\n",
      "        [ 0.0085,  0.0181,  0.0259,  ..., -0.0137,  0.0264, -0.0586]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.54.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0371, -0.0248, -0.0103,  ..., -0.0086,  0.0027, -0.0028],\n",
      "        [-0.0374, -0.0123,  0.0012,  ...,  0.0413,  0.0157, -0.0605],\n",
      "        [-0.0029, -0.0277, -0.0050,  ...,  0.0249,  0.0225, -0.0391],\n",
      "        ...,\n",
      "        [ 0.0170,  0.0532,  0.0221,  ..., -0.0073,  0.0276, -0.0405],\n",
      "        [-0.0623, -0.0120,  0.0195,  ...,  0.0104,  0.0369,  0.0713],\n",
      "        [-0.0840,  0.0227, -0.0052,  ...,  0.0234,  0.0029, -0.0388]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.54.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0186, -0.0048,  0.0874,  ...,  0.0090, -0.0571,  0.0067],\n",
      "        [-0.0164, -0.0317, -0.0366,  ...,  0.0177,  0.0327, -0.0162],\n",
      "        [-0.0112, -0.0149,  0.0525,  ..., -0.0112, -0.0051,  0.0105],\n",
      "        ...,\n",
      "        [-0.0400,  0.0537, -0.0043,  ..., -0.0084,  0.0283, -0.0415],\n",
      "        [-0.0040,  0.0100, -0.0011,  ...,  0.0216, -0.0374,  0.0364],\n",
      "        [ 0.0371, -0.0398,  0.0293,  ...,  0.0415,  0.0200,  0.0168]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.54.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.54.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.55.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0291, -0.0452, -0.0042,  ..., -0.0060,  0.0244,  0.0151],\n",
      "        [-0.0047,  0.0094,  0.0211,  ...,  0.0488, -0.0576,  0.0200],\n",
      "        [-0.0454, -0.0378,  0.0133,  ...,  0.0020, -0.0291,  0.0007],\n",
      "        ...,\n",
      "        [-0.0194, -0.0157, -0.0239,  ...,  0.0089,  0.0090, -0.0203],\n",
      "        [-0.0332, -0.0156,  0.0037,  ...,  0.0060, -0.0119, -0.0072],\n",
      "        [ 0.0063,  0.0315,  0.0522,  ...,  0.0378,  0.0410,  0.0303]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.55.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.55.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0508,  0.0515,  0.0435,  ..., -0.0115, -0.0176, -0.0142],\n",
      "        [ 0.0084,  0.0130,  0.0217,  ...,  0.0099, -0.0442,  0.0515],\n",
      "        [-0.0564, -0.0222,  0.0684,  ..., -0.0310,  0.0325,  0.0393],\n",
      "        ...,\n",
      "        [ 0.0093, -0.0067, -0.0125,  ..., -0.0028, -0.0089, -0.0101],\n",
      "        [-0.0146,  0.0247,  0.0003,  ...,  0.0283, -0.0254, -0.0112],\n",
      "        [ 0.0024,  0.0073, -0.0222,  ...,  0.0352, -0.0415,  0.0527]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.55.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0354, -0.0188, -0.0052,  ..., -0.0084,  0.0121, -0.0280],\n",
      "        [-0.0008, -0.0143, -0.0137,  ...,  0.0031, -0.0249,  0.0148],\n",
      "        [ 0.0251,  0.0356,  0.0260,  ..., -0.0386,  0.0410, -0.0271],\n",
      "        ...,\n",
      "        [-0.0027,  0.0070,  0.0030,  ..., -0.0014, -0.0031, -0.0002],\n",
      "        [ 0.0025, -0.0123,  0.0154,  ...,  0.0051, -0.0148, -0.0137],\n",
      "        [ 0.0200,  0.0075, -0.0254,  ...,  0.0203, -0.0143,  0.0096]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.55.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.55.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0278, -0.0332,  0.0220,  ...,  0.0014,  0.0352, -0.0330],\n",
      "        [ 0.0256, -0.0601, -0.0605,  ..., -0.0051, -0.0154, -0.0083],\n",
      "        [ 0.0168,  0.0210,  0.0030,  ...,  0.0077, -0.0103,  0.0679],\n",
      "        ...,\n",
      "        [ 0.0123,  0.0327,  0.1777,  ...,  0.1035,  0.1709, -0.1533],\n",
      "        [ 0.0508,  0.0334, -0.0562,  ...,  0.0508, -0.1045, -0.0179],\n",
      "        [-0.0498,  0.0003, -0.1387,  ..., -0.0014,  0.1562,  0.0903]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.55.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0042, -0.0481, -0.0186,  ..., -0.0347, -0.0161,  0.0378],\n",
      "        [ 0.0233,  0.0493,  0.0295,  ...,  0.0596, -0.0159, -0.0698],\n",
      "        [-0.0047, -0.0330,  0.0835,  ..., -0.0080, -0.0092,  0.0050],\n",
      "        ...,\n",
      "        [-0.0454, -0.0110, -0.0060,  ...,  0.0173, -0.0197, -0.0498],\n",
      "        [-0.0615, -0.0791, -0.1147,  ..., -0.0211, -0.0195, -0.0143],\n",
      "        [-0.0231,  0.0625, -0.0049,  ...,  0.0525, -0.0019, -0.0002]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.55.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-3.4180e-02, -2.3071e-02, -9.2773e-03,  ..., -1.6235e-02,\n",
      "         -7.1289e-02, -1.2283e-03],\n",
      "        [-5.5420e-02, -6.8359e-02, -1.6602e-02,  ..., -3.8574e-02,\n",
      "          8.1055e-02, -1.4526e-02],\n",
      "        [ 1.1475e-02,  4.1260e-02, -1.1169e-02,  ..., -4.3335e-03,\n",
      "         -3.8818e-02,  2.5635e-02],\n",
      "        ...,\n",
      "        [-2.6123e-02, -2.5749e-05, -6.9580e-03,  ..., -9.1553e-03,\n",
      "         -3.5706e-03, -1.8921e-02],\n",
      "        [-2.4414e-02, -1.7822e-02,  2.6367e-02,  ..., -1.7944e-02,\n",
      "         -3.1982e-02, -6.7871e-02],\n",
      "        [-8.5449e-02,  4.0894e-03, -3.1586e-03,  ...,  1.4725e-03,\n",
      "          2.4658e-02, -2.5787e-03]], requires_grad=True)\n",
      "Layer: model.layers.55.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0183,  0.0121,  0.0544,  ...,  0.0457,  0.0703,  0.0110],\n",
      "        [-0.0317, -0.0037,  0.0068,  ..., -0.0225,  0.0228, -0.0294],\n",
      "        [ 0.0811, -0.0493,  0.0025,  ...,  0.0576, -0.0140,  0.0535],\n",
      "        ...,\n",
      "        [ 0.0815,  0.0630,  0.0415,  ..., -0.0300,  0.0410, -0.0422],\n",
      "        [ 0.0070,  0.0381,  0.0259,  ..., -0.0022,  0.0317, -0.0117],\n",
      "        [ 0.0292,  0.0327, -0.0025,  ...,  0.0157, -0.0035,  0.0254]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.55.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0220, -0.0645, -0.0266,  ..., -0.0125, -0.0232,  0.0040],\n",
      "        [ 0.0287,  0.0361, -0.0121,  ...,  0.0576,  0.0047,  0.0150],\n",
      "        [ 0.0006,  0.0081, -0.0195,  ..., -0.0165,  0.0125, -0.0030],\n",
      "        ...,\n",
      "        [-0.0488,  0.0184, -0.0249,  ..., -0.0197, -0.0503,  0.0126],\n",
      "        [-0.0176, -0.0635, -0.0112,  ..., -0.0273, -0.0410,  0.0242],\n",
      "        [ 0.0190,  0.0591, -0.0371,  ...,  0.0352,  0.0212,  0.0369]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.55.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.55.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.56.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0001, -0.0021, -0.0454,  ..., -0.0176, -0.0151, -0.0052],\n",
      "        [-0.0132,  0.0625, -0.0064,  ...,  0.0220, -0.0107, -0.0087],\n",
      "        [ 0.0055,  0.0148, -0.0216,  ...,  0.0649, -0.0513, -0.0057],\n",
      "        ...,\n",
      "        [ 0.0640, -0.0233,  0.0449,  ...,  0.0016, -0.0486,  0.0109],\n",
      "        [ 0.0378, -0.0124, -0.0225,  ..., -0.0520, -0.0293, -0.0278],\n",
      "        [-0.0077, -0.0090,  0.0104,  ...,  0.0084,  0.0240,  0.0349]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.56.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0153, -0.0571, -0.0142,  ...,  0.0175, -0.0369, -0.0508],\n",
      "        [-0.0208, -0.0361, -0.0396,  ...,  0.0215,  0.0056,  0.0153],\n",
      "        [-0.0452, -0.0015, -0.0074,  ..., -0.0454,  0.0009, -0.0247],\n",
      "        ...,\n",
      "        [-0.0041, -0.0059, -0.0087,  ..., -0.0049, -0.0059,  0.0065],\n",
      "        [-0.0342,  0.0303,  0.0427,  ...,  0.0030,  0.0114,  0.0113],\n",
      "        [ 0.0175,  0.0087,  0.0016,  ..., -0.0303, -0.0096, -0.0240]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0186, -0.0206,  0.0160,  ...,  0.0142, -0.0028, -0.0291],\n",
      "        [ 0.0217, -0.0023, -0.0231,  ...,  0.0153,  0.1123,  0.0447],\n",
      "        [-0.0034,  0.0006,  0.0073,  ..., -0.0099, -0.0134, -0.0159],\n",
      "        ...,\n",
      "        [ 0.0557,  0.0043,  0.0023,  ...,  0.0176,  0.0007,  0.0457],\n",
      "        [-0.0126,  0.0049,  0.0204,  ..., -0.0222,  0.0134, -0.0415],\n",
      "        [-0.0085, -0.0097,  0.0126,  ..., -0.0050,  0.0013, -0.0041]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.56.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0038,  0.0060, -0.0012,  ..., -0.0046,  0.0608, -0.0723],\n",
      "        [-0.0215,  0.0142,  0.0057,  ..., -0.0361, -0.0315, -0.0026],\n",
      "        [-0.0162,  0.0879,  0.0126,  ...,  0.1016,  0.0137, -0.0009],\n",
      "        ...,\n",
      "        [-0.0806,  0.1016,  0.0083,  ...,  0.0148,  0.1562, -0.0591],\n",
      "        [-0.0520,  0.1348, -0.0520,  ...,  0.0664,  0.0967,  0.0220],\n",
      "        [-0.0879, -0.0034,  0.0258,  ...,  0.0247, -0.1475, -0.1436]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0027,  0.0079,  0.0337,  ..., -0.0060,  0.0032,  0.0050],\n",
      "        [ 0.0034,  0.0413,  0.0396,  ..., -0.0026, -0.0554, -0.0771],\n",
      "        [ 0.0364, -0.0354,  0.0361,  ...,  0.0070, -0.0579, -0.0522],\n",
      "        ...,\n",
      "        [ 0.0228, -0.0273, -0.0610,  ...,  0.0574, -0.0320, -0.0317],\n",
      "        [ 0.0056,  0.0048, -0.0209,  ..., -0.0308, -0.0483, -0.0017],\n",
      "        [ 0.0135,  0.0143, -0.0447,  ...,  0.0239,  0.0184,  0.0208]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0066,  0.0228,  0.0330,  ...,  0.0054,  0.0300, -0.0664],\n",
      "        [ 0.0058, -0.0356,  0.0181,  ..., -0.0383, -0.0078,  0.0530],\n",
      "        [ 0.0322, -0.0295,  0.0549,  ..., -0.0164, -0.0044,  0.0542],\n",
      "        ...,\n",
      "        [ 0.0182,  0.0283,  0.0366,  ..., -0.0065, -0.0081,  0.0089],\n",
      "        [-0.0254,  0.0256,  0.0101,  ...,  0.0170, -0.0120,  0.0225],\n",
      "        [ 0.0201, -0.0337, -0.0410,  ...,  0.0552,  0.0347, -0.0253]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0679, -0.0386, -0.0300,  ...,  0.0356,  0.0229, -0.0284],\n",
      "        [-0.0415,  0.0177,  0.0232,  ...,  0.0254, -0.0310,  0.0564],\n",
      "        [ 0.0349, -0.0225, -0.0076,  ..., -0.0417,  0.0864,  0.0139],\n",
      "        ...,\n",
      "        [ 0.0200,  0.0251, -0.0344,  ..., -0.0106, -0.0254, -0.0117],\n",
      "        [ 0.0596,  0.0625, -0.0094,  ...,  0.0089, -0.0133,  0.0085],\n",
      "        [ 0.0469, -0.0010,  0.0126,  ...,  0.0322, -0.0144,  0.0225]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0012,  0.0031,  0.0112,  ..., -0.0192,  0.0059,  0.0006],\n",
      "        [ 0.0327,  0.0022, -0.0190,  ..., -0.0054, -0.0674, -0.0159],\n",
      "        [ 0.0144,  0.0046, -0.0280,  ...,  0.0476,  0.0378, -0.0002],\n",
      "        ...,\n",
      "        [ 0.0109, -0.0062,  0.0405,  ...,  0.0201, -0.0229,  0.0767],\n",
      "        [-0.0530,  0.0189,  0.0044,  ...,  0.0244, -0.0386, -0.0476],\n",
      "        [-0.0108, -0.0178, -0.0615,  ..., -0.0408,  0.0004, -0.0212]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.56.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.56.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.57.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0164, -0.0435,  0.0057,  ..., -0.0040,  0.0217, -0.0430],\n",
      "        [-0.0288, -0.0292,  0.0166,  ...,  0.0198, -0.0447,  0.0085],\n",
      "        [-0.0278, -0.0371,  0.0055,  ..., -0.0067, -0.0518, -0.0005],\n",
      "        ...,\n",
      "        [ 0.0042,  0.0121,  0.0513,  ...,  0.0366, -0.0098, -0.0493],\n",
      "        [ 0.0165,  0.0245, -0.0413,  ..., -0.0581,  0.0208,  0.0435],\n",
      "        [-0.0327,  0.0047, -0.0425,  ..., -0.0479, -0.0500, -0.0115]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.57.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0150,  0.0146,  0.0330,  ..., -0.0266,  0.0236, -0.0442],\n",
      "        [ 0.0366, -0.0075,  0.0035,  ...,  0.0254, -0.0044,  0.0043],\n",
      "        [-0.0332,  0.0208, -0.0459,  ..., -0.0042,  0.0127,  0.0061],\n",
      "        ...,\n",
      "        [ 0.0012, -0.0267,  0.0150,  ...,  0.0138, -0.0068, -0.0171],\n",
      "        [ 0.0496, -0.0049, -0.0054,  ...,  0.0031, -0.0160,  0.0194],\n",
      "        [-0.0149, -0.0042,  0.0109,  ...,  0.0040,  0.0386, -0.0291]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0216,  0.0068,  0.0074,  ...,  0.0045,  0.0038,  0.0469],\n",
      "        [ 0.0239, -0.0161, -0.0054,  ..., -0.0112,  0.0039,  0.0038],\n",
      "        [-0.0869, -0.0212,  0.0046,  ..., -0.0430, -0.0030, -0.0013],\n",
      "        ...,\n",
      "        [-0.0065, -0.0069,  0.0596,  ...,  0.0674, -0.0013,  0.0092],\n",
      "        [-0.0369,  0.0105, -0.0189,  ...,  0.0062, -0.0018,  0.0466],\n",
      "        [ 0.0154, -0.0127,  0.0164,  ..., -0.0199, -0.0125,  0.0092]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.57.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0216,  0.0532,  0.0188,  ..., -0.0293,  0.0366,  0.0391],\n",
      "        [-0.0205,  0.0030, -0.0369,  ...,  0.0179, -0.0187, -0.0352],\n",
      "        [-0.0040,  0.0198, -0.0223,  ...,  0.0674, -0.0320,  0.0150],\n",
      "        ...,\n",
      "        [ 0.0354,  0.1221,  0.0811,  ...,  0.0255, -0.0613, -0.0004],\n",
      "        [ 0.0150, -0.0601,  0.0337,  ...,  0.0728, -0.0250,  0.0114],\n",
      "        [ 0.0097,  0.0552, -0.0231,  ...,  0.0923, -0.0013,  0.0408]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0688,  0.0199, -0.0020,  ..., -0.0033,  0.0540,  0.0669],\n",
      "        [-0.0405, -0.0148,  0.0527,  ..., -0.0479,  0.0253,  0.0208],\n",
      "        [ 0.0771,  0.0059, -0.0255,  ...,  0.0249, -0.0442, -0.0315],\n",
      "        ...,\n",
      "        [-0.0173,  0.0437,  0.0184,  ...,  0.0037, -0.0166,  0.0410],\n",
      "        [-0.0081, -0.0398, -0.0334,  ..., -0.0703,  0.0559,  0.0566],\n",
      "        [-0.0410,  0.0066, -0.0532,  ..., -0.0698, -0.0188,  0.0048]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0410, -0.0037, -0.0192,  ..., -0.0654, -0.0242,  0.0591],\n",
      "        [-0.0500,  0.0027,  0.0192,  ..., -0.0325, -0.0229,  0.0913],\n",
      "        [-0.0292,  0.0029, -0.0569,  ..., -0.0115,  0.0928, -0.0276],\n",
      "        ...,\n",
      "        [ 0.0160, -0.0259, -0.0435,  ..., -0.0010,  0.0420, -0.0148],\n",
      "        [-0.0178, -0.0175, -0.0147,  ...,  0.0122,  0.0342,  0.0337],\n",
      "        [ 0.0046, -0.0117, -0.0300,  ...,  0.0742,  0.0017,  0.0327]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0630,  0.0364,  0.0552,  ...,  0.0205, -0.0457, -0.0193],\n",
      "        [ 0.0177, -0.0019, -0.0056,  ..., -0.0530,  0.0103,  0.0084],\n",
      "        [-0.0117,  0.0280, -0.0439,  ...,  0.0054, -0.0038,  0.0383],\n",
      "        ...,\n",
      "        [-0.0688, -0.0028, -0.0076,  ...,  0.0060, -0.0549,  0.0110],\n",
      "        [ 0.0249,  0.0251,  0.0190,  ..., -0.0045, -0.0488, -0.0464],\n",
      "        [-0.0640, -0.0197,  0.0071,  ..., -0.0447, -0.0220,  0.0216]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0201,  0.0137,  0.0278,  ...,  0.0106, -0.0222,  0.0217],\n",
      "        [ 0.0055, -0.0056,  0.0229,  ...,  0.0383, -0.0222,  0.0024],\n",
      "        [-0.0023,  0.0194, -0.0119,  ...,  0.0330, -0.0410, -0.0098],\n",
      "        ...,\n",
      "        [ 0.0192,  0.0104, -0.0554,  ...,  0.0540,  0.0337,  0.0371],\n",
      "        [ 0.0442,  0.0244, -0.0209,  ...,  0.0625,  0.0374, -0.0128],\n",
      "        [-0.0107, -0.0066,  0.0337,  ...,  0.0010,  0.0066,  0.0198]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.57.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.57.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.58.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0186, -0.0194,  0.0320,  ...,  0.0087,  0.0077,  0.0019],\n",
      "        [-0.0518, -0.0089, -0.0327,  ..., -0.0476,  0.0415, -0.0097],\n",
      "        [ 0.0101, -0.0281,  0.0093,  ...,  0.0074,  0.0093, -0.0483],\n",
      "        ...,\n",
      "        [-0.0063,  0.0047,  0.0210,  ..., -0.0118, -0.0337, -0.0339],\n",
      "        [ 0.0112,  0.0211,  0.0366,  ..., -0.0162,  0.0640,  0.0110],\n",
      "        [-0.0004, -0.0305,  0.0447,  ...,  0.0593, -0.0466,  0.0349]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.58.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.58.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 2.5482e-03, -1.3733e-02, -1.9836e-03,  ...,  3.3447e-02,\n",
      "          9.6436e-03, -1.8799e-02],\n",
      "        [ 7.3853e-03, -6.2866e-03, -4.1016e-02,  ..., -6.8054e-03,\n",
      "          5.9326e-02, -5.1758e-02],\n",
      "        [ 1.9531e-02,  1.5503e-02,  1.6968e-02,  ..., -5.9814e-03,\n",
      "         -2.2583e-02, -1.0925e-02],\n",
      "        ...,\n",
      "        [-1.3794e-02, -1.9287e-02, -3.4790e-03,  ...,  1.2573e-02,\n",
      "          3.1738e-02,  7.5073e-03],\n",
      "        [-7.1106e-03, -2.0996e-02,  7.9956e-03,  ...,  1.8921e-02,\n",
      "         -9.8877e-03, -1.0376e-02],\n",
      "        [-9.9487e-03, -3.2654e-03, -6.8665e-05,  ...,  1.8066e-02,\n",
      "         -5.3101e-03, -4.3335e-03]], requires_grad=True)\n",
      "Layer: model.layers.58.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0156, -0.0018, -0.0008,  ...,  0.0115, -0.0020,  0.0486],\n",
      "        [-0.0160, -0.0640,  0.0008,  ...,  0.0002,  0.0040,  0.0144],\n",
      "        [ 0.0087, -0.0306,  0.0092,  ..., -0.0217, -0.0391, -0.0147],\n",
      "        ...,\n",
      "        [ 0.0510,  0.0254,  0.0007,  ...,  0.0378,  0.0181,  0.0703],\n",
      "        [ 0.0022, -0.0033, -0.0138,  ..., -0.0074,  0.0043, -0.0086],\n",
      "        [ 0.0234,  0.0140,  0.0036,  ...,  0.0187,  0.0183,  0.0148]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.58.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.58.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0288, -0.0035,  0.0076,  ...,  0.0024,  0.0262, -0.0016],\n",
      "        [-0.0317, -0.0042, -0.0977,  ...,  0.0140, -0.0177, -0.0471],\n",
      "        [ 0.0693, -0.0225, -0.0239,  ..., -0.0898,  0.0425,  0.0654],\n",
      "        ...,\n",
      "        [ 0.1245,  0.2275, -0.0713,  ...,  0.0272, -0.1699, -0.1934],\n",
      "        [ 0.0210, -0.0038,  0.1250,  ..., -0.0454,  0.0170, -0.0315],\n",
      "        [-0.0859, -0.0104, -0.0400,  ..., -0.0304,  0.0115,  0.1426]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.58.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0376,  0.0282,  0.0273,  ..., -0.0117,  0.0923, -0.0815],\n",
      "        [-0.0564,  0.0410, -0.0737,  ...,  0.0079, -0.0942,  0.0464],\n",
      "        [ 0.0454,  0.0562, -0.0571,  ..., -0.0640,  0.0065,  0.0107],\n",
      "        ...,\n",
      "        [-0.0155,  0.0060, -0.0278,  ...,  0.0150,  0.0183, -0.0562],\n",
      "        [-0.0022, -0.1387, -0.0107,  ..., -0.0243,  0.0161, -0.0017],\n",
      "        [ 0.0042, -0.0063, -0.0135,  ..., -0.0623, -0.0635, -0.0189]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.58.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0209, -0.0168,  0.0153,  ...,  0.0493,  0.0060, -0.0051],\n",
      "        [-0.0237, -0.0126, -0.0012,  ..., -0.0056, -0.0315,  0.0264],\n",
      "        [ 0.0659,  0.0167,  0.0403,  ...,  0.0150, -0.0242,  0.0688],\n",
      "        ...,\n",
      "        [ 0.0280,  0.0083, -0.0106,  ...,  0.0286, -0.0058,  0.0427],\n",
      "        [ 0.0212,  0.0747, -0.0154,  ..., -0.0289, -0.0337,  0.0393],\n",
      "        [-0.0938,  0.0376,  0.0286,  ..., -0.0898, -0.0105, -0.0208]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.58.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0018, -0.0305, -0.0065,  ..., -0.0552,  0.0134,  0.0437],\n",
      "        [ 0.0205,  0.0415,  0.0182,  ...,  0.0566,  0.0024, -0.1025],\n",
      "        [-0.0571,  0.0040, -0.0103,  ..., -0.0796,  0.0420, -0.0046],\n",
      "        ...,\n",
      "        [ 0.0559,  0.0100, -0.0459,  ...,  0.0031, -0.0138, -0.0122],\n",
      "        [ 0.0312, -0.0562, -0.0081,  ..., -0.0143,  0.0444,  0.0669],\n",
      "        [-0.0422,  0.0147, -0.0996,  ..., -0.0129, -0.0291,  0.0092]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.58.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0284, -0.0234,  0.0074,  ..., -0.0069, -0.0175, -0.0233],\n",
      "        [-0.0170, -0.0364, -0.0128,  ..., -0.0220, -0.0138,  0.0049],\n",
      "        [ 0.0757, -0.0659,  0.0135,  ...,  0.0347, -0.0396,  0.0164],\n",
      "        ...,\n",
      "        [ 0.0635, -0.0474,  0.0084,  ..., -0.0048, -0.0386, -0.0540],\n",
      "        [-0.0137,  0.0254, -0.0366,  ...,  0.0352, -0.0442, -0.0056],\n",
      "        [ 0.0084,  0.0356,  0.0693,  ..., -0.0306, -0.0079, -0.0117]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.58.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.58.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.59.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0183,  0.0408, -0.0293,  ...,  0.0175, -0.0087,  0.0151],\n",
      "        [-0.0070, -0.0356, -0.0378,  ...,  0.0182, -0.0474,  0.0579],\n",
      "        [ 0.0137,  0.0273, -0.0060,  ..., -0.0179,  0.0245, -0.0074],\n",
      "        ...,\n",
      "        [ 0.0259,  0.0181,  0.0201,  ..., -0.0454,  0.0354, -0.0791],\n",
      "        [-0.0087, -0.0121, -0.0042,  ..., -0.0229, -0.0193, -0.0012],\n",
      "        [ 0.0659,  0.0160, -0.0109,  ..., -0.0371, -0.0016,  0.0096]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.59.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.59.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[-0.0659, -0.0281, -0.0093,  ...,  0.0359, -0.0072,  0.0173],\n",
      "        [ 0.0283, -0.0216, -0.0095,  ...,  0.0752,  0.0079, -0.0171],\n",
      "        [-0.0095,  0.0299,  0.0693,  ...,  0.0752,  0.0552,  0.0420],\n",
      "        ...,\n",
      "        [-0.0190,  0.0020,  0.0157,  ...,  0.1030, -0.0172, -0.0403],\n",
      "        [ 0.0425,  0.0030, -0.0586,  ..., -0.0082,  0.0312, -0.0388],\n",
      "        [ 0.0121, -0.0342, -0.0035,  ...,  0.0156, -0.0011, -0.0354]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.59.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0151, -0.0364, -0.0055,  ..., -0.0420,  0.0219,  0.0109],\n",
      "        [ 0.0557, -0.0208, -0.0168,  ...,  0.0535, -0.0366,  0.0197],\n",
      "        [-0.0063, -0.0520, -0.0006,  ..., -0.0586,  0.0022,  0.0073],\n",
      "        ...,\n",
      "        [-0.0027, -0.0045, -0.0019,  ...,  0.0096, -0.0033, -0.0033],\n",
      "        [-0.0090, -0.0449,  0.0047,  ..., -0.0030,  0.0095, -0.0356],\n",
      "        [ 0.0178,  0.0291,  0.0113,  ..., -0.0188,  0.0099, -0.0075]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.59.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.59.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[-0.0371,  0.0430, -0.0574,  ...,  0.0391,  0.0630,  0.0762],\n",
      "        [ 0.0097, -0.0106, -0.0278,  ..., -0.0312,  0.0128, -0.0085],\n",
      "        [ 0.0093, -0.0107,  0.0708,  ..., -0.1045, -0.0266, -0.0327],\n",
      "        ...,\n",
      "        [-0.0003,  0.0106,  0.0074,  ...,  0.0317, -0.0234,  0.0126],\n",
      "        [ 0.0500,  0.0320, -0.0417,  ...,  0.0947,  0.0203,  0.1406],\n",
      "        [ 0.0371,  0.0513, -0.1006,  ..., -0.0312, -0.1309, -0.1099]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.59.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-2.2949e-02,  1.2451e-02, -8.0566e-02,  ..., -4.6631e-02,\n",
      "          3.5156e-02,  8.0566e-03],\n",
      "        [-1.5354e-04, -3.8574e-02, -2.0142e-02,  ...,  5.5664e-02,\n",
      "         -5.4688e-02, -3.9307e-02],\n",
      "        [ 7.8125e-02,  3.6621e-02, -8.3496e-02,  ..., -3.9062e-02,\n",
      "          2.7954e-02, -9.1553e-05],\n",
      "        ...,\n",
      "        [-1.9775e-02,  4.5166e-02,  3.1494e-02,  ...,  1.3977e-02,\n",
      "          9.3460e-04,  4.1992e-02],\n",
      "        [-3.5889e-02, -2.7100e-02,  6.6406e-02,  ..., -5.3711e-02,\n",
      "         -3.1982e-02,  1.0059e-01],\n",
      "        [-1.4648e-02,  4.7852e-02,  7.8735e-03,  ..., -4.7607e-03,\n",
      "         -1.0986e-02, -7.1289e-02]], requires_grad=True)\n",
      "Layer: model.layers.59.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0515, -0.0332,  0.0143,  ..., -0.0127,  0.0245,  0.0498],\n",
      "        [ 0.0134, -0.0371, -0.0156,  ...,  0.0464, -0.0415, -0.0297],\n",
      "        [-0.0164, -0.0070,  0.0776,  ..., -0.0129,  0.0005, -0.0469],\n",
      "        ...,\n",
      "        [-0.0303, -0.0002,  0.0173,  ..., -0.0062, -0.0042,  0.0206],\n",
      "        [ 0.0126, -0.0195,  0.0297,  ..., -0.0054,  0.0898,  0.0601],\n",
      "        [-0.0039,  0.0491, -0.0040,  ...,  0.0010, -0.0737,  0.0077]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.59.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0267,  0.0337,  0.0292,  ...,  0.0023, -0.0273,  0.0400],\n",
      "        [-0.0253,  0.0415, -0.0908,  ...,  0.0371,  0.0645, -0.0417],\n",
      "        [ 0.0073,  0.0522,  0.0095,  ...,  0.0182, -0.0688, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0137,  0.0479,  0.0396,  ...,  0.0286, -0.0767, -0.0157],\n",
      "        [-0.0566, -0.0259, -0.0244,  ..., -0.0082,  0.0242,  0.0215],\n",
      "        [ 0.0209,  0.0150,  0.0549,  ...,  0.0079,  0.0033,  0.0811]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.59.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0077, -0.0645,  0.0067,  ...,  0.0159,  0.0198, -0.0566],\n",
      "        [-0.0259,  0.0243,  0.0093,  ..., -0.0216,  0.0215,  0.0215],\n",
      "        [ 0.0148,  0.0309,  0.0366,  ...,  0.0300,  0.0035, -0.0242],\n",
      "        ...,\n",
      "        [-0.0405, -0.0352,  0.0498,  ...,  0.0225, -0.0352, -0.0435],\n",
      "        [ 0.0245, -0.0369,  0.0186,  ...,  0.0618, -0.0151,  0.0038],\n",
      "        [-0.0112,  0.0166,  0.0247,  ..., -0.0312,  0.0320,  0.0732]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.59.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.59.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.60.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-1.7700e-03, -3.2715e-02,  5.9082e-02,  ...,  1.5869e-02,\n",
      "          1.4465e-02, -2.5879e-02],\n",
      "        [ 4.7119e-02, -1.3199e-03, -3.1006e-02,  ..., -2.8564e-02,\n",
      "         -2.2705e-02,  5.0659e-03],\n",
      "        [ 1.6602e-02,  2.3682e-02,  3.7537e-03,  ..., -4.2480e-02,\n",
      "          3.1982e-02,  4.3457e-02],\n",
      "        ...,\n",
      "        [-3.2715e-02,  5.2002e-02, -2.2888e-05,  ...,  2.3804e-02,\n",
      "          2.4658e-02, -2.3193e-02],\n",
      "        [-3.4912e-02, -1.2573e-02,  4.7852e-02,  ..., -3.6377e-02,\n",
      "          2.7588e-02,  3.3203e-02],\n",
      "        [ 6.4697e-03, -3.8757e-03,  2.6245e-02,  ...,  3.6377e-02,\n",
      "         -4.5898e-02, -4.1504e-02]], requires_grad=True)\n",
      "Layer: model.layers.60.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.60.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0461,  0.0278, -0.0047,  ...,  0.0400,  0.0374, -0.0527],\n",
      "        [-0.0079,  0.0305, -0.0148,  ...,  0.0439,  0.0233, -0.0403],\n",
      "        [-0.0010, -0.0052, -0.0747,  ..., -0.0270,  0.0869,  0.0361],\n",
      "        ...,\n",
      "        [ 0.0168,  0.0025, -0.0669,  ..., -0.0337,  0.0383, -0.0312],\n",
      "        [ 0.0183,  0.0197, -0.0060,  ..., -0.0052,  0.0089, -0.0040],\n",
      "        [ 0.0162, -0.0001,  0.0045,  ...,  0.0339,  0.0222, -0.0166]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.60.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0194, -0.0105, -0.0615,  ..., -0.0679, -0.0332,  0.0008],\n",
      "        [ 0.0069,  0.0178,  0.0075,  ...,  0.0151, -0.0154,  0.0374],\n",
      "        [-0.0220,  0.0461,  0.0476,  ..., -0.0242,  0.0181,  0.0413],\n",
      "        ...,\n",
      "        [-0.0094,  0.0003,  0.0115,  ...,  0.0004,  0.0214, -0.0140],\n",
      "        [ 0.0277, -0.0003,  0.0237,  ..., -0.0060,  0.0057, -0.0009],\n",
      "        [-0.0052,  0.0079,  0.0039,  ...,  0.0092, -0.0087,  0.0031]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.60.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.60.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0786,  0.0654,  0.0198,  ...,  0.1006,  0.0151,  0.0019],\n",
      "        [ 0.0079, -0.0097, -0.0364,  ...,  0.0031,  0.0186, -0.0270],\n",
      "        [-0.0835, -0.0303, -0.0459,  ..., -0.0188, -0.0005,  0.0055],\n",
      "        ...,\n",
      "        [ 0.0510,  0.0117,  0.1094,  ..., -0.0796,  0.0371,  0.0308],\n",
      "        [-0.0444,  0.0040, -0.0063,  ..., -0.0122,  0.0557, -0.0238],\n",
      "        [-0.0006,  0.0923,  0.0928,  ...,  0.0132, -0.0215, -0.0449]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.60.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 2.4902e-02, -6.1989e-06, -6.8359e-02,  ...,  3.3691e-02,\n",
      "          7.2754e-02,  6.8359e-02],\n",
      "        [ 4.6631e-02,  1.1414e-02,  4.6082e-03,  ..., -1.3428e-02,\n",
      "         -2.3926e-02,  1.2695e-02],\n",
      "        [-4.9072e-02, -1.3794e-02,  2.1118e-02,  ...,  2.9297e-02,\n",
      "          2.0752e-02,  2.2705e-02],\n",
      "        ...,\n",
      "        [-1.3367e-02,  2.9449e-03, -1.6968e-02,  ..., -4.6387e-02,\n",
      "         -1.2146e-02, -3.6011e-03],\n",
      "        [ 9.2773e-03, -9.0027e-04,  1.0840e-01,  ...,  6.3477e-03,\n",
      "          4.3945e-02, -6.4941e-02],\n",
      "        [ 2.2217e-02, -1.7944e-02, -3.7842e-02,  ...,  3.1738e-02,\n",
      "          1.6357e-02,  5.2979e-02]], requires_grad=True)\n",
      "Layer: model.layers.60.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0415, -0.0284, -0.0089,  ...,  0.0437,  0.0400, -0.0222],\n",
      "        [ 0.0090, -0.0359, -0.0212,  ...,  0.0649, -0.0045,  0.0684],\n",
      "        [ 0.0378,  0.0232, -0.0664,  ...,  0.0210,  0.0586, -0.0250],\n",
      "        ...,\n",
      "        [-0.0791, -0.0186,  0.0078,  ..., -0.0195, -0.0527,  0.0306],\n",
      "        [ 0.0270,  0.0928, -0.0074,  ...,  0.0157, -0.0147, -0.0157],\n",
      "        [-0.0189,  0.0120,  0.0033,  ..., -0.0012,  0.0138,  0.0352]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.60.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0127, -0.0630, -0.0052,  ..., -0.0020, -0.0072, -0.0254],\n",
      "        [-0.0282,  0.0199,  0.0071,  ..., -0.0092, -0.0056, -0.0437],\n",
      "        [-0.0066,  0.0205,  0.0142,  ..., -0.0055, -0.0237, -0.0162],\n",
      "        ...,\n",
      "        [ 0.0145, -0.0623,  0.0513,  ...,  0.0454,  0.0464, -0.0156],\n",
      "        [-0.0215, -0.0396, -0.0215,  ...,  0.0918,  0.0001,  0.0071],\n",
      "        [ 0.0024,  0.0420,  0.0058,  ..., -0.0043, -0.0459,  0.0320]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.60.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0121,  0.0217, -0.0189,  ..., -0.0259,  0.0265, -0.0796],\n",
      "        [ 0.0457, -0.0229,  0.0239,  ...,  0.0096, -0.0300, -0.0098],\n",
      "        [-0.0115, -0.0101,  0.0151,  ..., -0.0157,  0.0417,  0.0366],\n",
      "        ...,\n",
      "        [ 0.0364,  0.0187, -0.0037,  ...,  0.0376, -0.0064, -0.0046],\n",
      "        [ 0.0471, -0.0090, -0.0052,  ..., -0.0150, -0.0295,  0.0052],\n",
      "        [-0.0125,  0.0347, -0.0337,  ...,  0.0229, -0.0159, -0.0007]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.60.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.60.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.61.self_attn.q_a_proj.weight | Shape Type: torch.Size([768, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0339, -0.0425, -0.0381,  ...,  0.0008, -0.0206,  0.0183],\n",
      "        [ 0.0280,  0.0459,  0.0432,  ..., -0.0076,  0.0272, -0.0215],\n",
      "        [-0.0236, -0.0415,  0.0129,  ...,  0.0069,  0.0415,  0.0008],\n",
      "        ...,\n",
      "        [ 0.1113,  0.0095, -0.0608,  ...,  0.0250, -0.0308,  0.0305],\n",
      "        [-0.0225, -0.0157,  0.0204,  ...,  0.0588,  0.0256,  0.0093],\n",
      "        [ 0.0137,  0.0079, -0.0117,  ...,  0.0513, -0.0027,  0.0366]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.61.self_attn.q_a_layernorm.weight | Shape Type: torch.Size([768])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.61.self_attn.q_b_proj.weight | Shape Type: torch.Size([3840, 768])| Data Type: Parameter containing:\n",
      "tensor([[ 5.3101e-03,  1.1047e-02, -1.5076e-02,  ..., -3.1250e-02,\n",
      "          2.1729e-02,  2.6611e-02],\n",
      "        [-1.5015e-02,  2.9053e-02, -3.5156e-02,  ...,  2.4658e-02,\n",
      "         -5.7678e-03, -5.7617e-02],\n",
      "        [ 2.8809e-02, -1.8433e-02,  2.3804e-02,  ..., -4.8828e-02,\n",
      "          3.9551e-02,  6.6757e-05],\n",
      "        ...,\n",
      "        [ 6.0425e-03,  4.5654e-02,  2.6123e-02,  ..., -1.3672e-02,\n",
      "         -2.5879e-02,  2.5146e-02],\n",
      "        [-2.5269e-02, -1.3855e-02,  8.9645e-04,  ..., -2.3682e-02,\n",
      "         -1.8677e-02,  8.7280e-03],\n",
      "        [ 1.0315e-02, -2.0996e-02, -2.6978e-02,  ..., -3.0762e-02,\n",
      "          3.3691e-02,  2.2705e-02]], requires_grad=True)\n",
      "Layer: model.layers.61.self_attn.kv_a_proj_with_mqa.weight | Shape Type: torch.Size([288, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0193,  0.0334, -0.0087,  ..., -0.0310, -0.0601, -0.1299],\n",
      "        [-0.0277,  0.0134,  0.0168,  ..., -0.0111, -0.0222, -0.0625],\n",
      "        [-0.0006,  0.0005, -0.0530,  ...,  0.0410,  0.0110,  0.0894],\n",
      "        ...,\n",
      "        [ 0.0248, -0.0061, -0.0266,  ...,  0.0021, -0.0036, -0.0266],\n",
      "        [-0.0562, -0.0027,  0.0371,  ...,  0.0461,  0.0115, -0.0093],\n",
      "        [ 0.0082, -0.0039, -0.0344,  ...,  0.0145,  0.0129,  0.0181]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.61.self_attn.kv_a_layernorm.weight | Shape Type: torch.Size([256])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.61.self_attn.kv_b_proj.weight | Shape Type: torch.Size([5120, 256])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0055, -0.0605, -0.0255,  ...,  0.0050, -0.0232,  0.0173],\n",
      "        [ 0.0474,  0.0261,  0.0310,  ...,  0.0238, -0.0225,  0.0041],\n",
      "        [-0.0496, -0.0564,  0.0625,  ...,  0.0101,  0.0099,  0.0342],\n",
      "        ...,\n",
      "        [ 0.0386,  0.0723, -0.0161,  ..., -0.0148, -0.0491,  0.2500],\n",
      "        [ 0.1240,  0.0254,  0.0537,  ...,  0.0986,  0.0359,  0.0223],\n",
      "        [-0.0684, -0.0371,  0.0664,  ...,  0.0020,  0.0082, -0.0281]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.61.self_attn.o_proj.weight | Shape Type: torch.Size([2560, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0347,  0.0498,  0.0122,  ...,  0.0664,  0.0018,  0.0276],\n",
      "        [-0.0327,  0.0104, -0.0082,  ...,  0.0060,  0.0047,  0.0320],\n",
      "        [ 0.0332,  0.0405, -0.0104,  ..., -0.0039, -0.0618, -0.0118],\n",
      "        ...,\n",
      "        [-0.0236, -0.0226,  0.0623,  ..., -0.0425,  0.0039,  0.0232],\n",
      "        [ 0.0320,  0.0457,  0.0305,  ..., -0.0081, -0.0752,  0.0361],\n",
      "        [-0.0125, -0.0405, -0.0374,  ..., -0.0094, -0.0713,  0.0237]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.61.mlp.gate_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[ 0.0327, -0.0469,  0.0015,  ...,  0.0684, -0.0413,  0.0635],\n",
      "        [ 0.0374,  0.0179,  0.0164,  ..., -0.0197, -0.0220, -0.0275],\n",
      "        [-0.0557,  0.0212, -0.0266,  ..., -0.0077,  0.0117,  0.0051],\n",
      "        ...,\n",
      "        [-0.0457,  0.0322,  0.1582,  ..., -0.0376,  0.0112,  0.0231],\n",
      "        [ 0.0031,  0.0095, -0.0145,  ...,  0.0181, -0.0088,  0.0101],\n",
      "        [ 0.0320, -0.0300, -0.0125,  ...,  0.0449,  0.0215,  0.0337]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.61.mlp.up_proj.weight | Shape Type: torch.Size([6400, 2560])| Data Type: Parameter containing:\n",
      "tensor([[-0.0281,  0.0129, -0.0359,  ..., -0.0479,  0.0089, -0.0091],\n",
      "        [ 0.0076,  0.0269,  0.0142,  ..., -0.0288,  0.0008, -0.0046],\n",
      "        [ 0.0415,  0.0344,  0.0913,  ..., -0.0042, -0.0391, -0.0820],\n",
      "        ...,\n",
      "        [ 0.0388, -0.0034, -0.0620,  ...,  0.0723,  0.0251, -0.0178],\n",
      "        [ 0.0830, -0.0723, -0.0386,  ..., -0.0918,  0.0068, -0.0481],\n",
      "        [ 0.0231,  0.0344, -0.0055,  ...,  0.0041, -0.0771,  0.0334]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.61.mlp.down_proj.weight | Shape Type: torch.Size([2560, 6400])| Data Type: Parameter containing:\n",
      "tensor([[-0.0322, -0.0342,  0.0054,  ..., -0.0239,  0.0062,  0.0141],\n",
      "        [-0.0483,  0.0320, -0.0957,  ...,  0.0004, -0.0028, -0.0439],\n",
      "        [-0.0371,  0.0007, -0.0242,  ...,  0.0352, -0.0021,  0.0005],\n",
      "        ...,\n",
      "        [ 0.0403, -0.0498, -0.0354,  ..., -0.0240, -0.0037,  0.0212],\n",
      "        [-0.0322,  0.0596, -0.0008,  ..., -0.0280, -0.0093,  0.0049],\n",
      "        [ 0.0118,  0.0211,  0.0083,  ...,  0.0012, -0.0061,  0.0334]],\n",
      "       requires_grad=True)\n",
      "Layer: model.layers.61.input_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.layers.61.post_attention_layernorm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Layer: model.norm.weight | Shape Type: torch.Size([2560])| Data Type: Parameter containing:\n",
      "tensor([8.1250, 7.7812, 7.9375,  ..., 7.8438, 7.8125, 7.8750],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 加载预训练模型和分词器\n",
    "model_path = \"/home/ztf/cpm\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "model.eval()\n",
    "\n",
    "#  输出模型的元信息\n",
    "print(model.config)\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name} | Shape Type: {param.shape}| Data Type: {param}\")\n",
    "        # if name==\"\"\n",
    "# if name == \"transformer.ln_f.weight\":\n",
    "#     print(f\"Layer: {name} | Shape Type: {param.shape}| Data Type: {param}\")\n",
    "# if name == \"transformer.ln_f.bias\":\n",
    "#     print(f\"Layer: {name} | Shape Type: {param.shape} | Data Type: {param}\")\n",
    "#             df = pd.DataFrame(param.numpy())\n",
    "            # df.to_csv('output.csv', index=False)\n",
    "        # print(f\"Layer: {name} | Shape: {param.shape}\")\n",
    "    # for name, module in model.named_modules():\n",
    "    #      print(f\"Name: {name}, Module: {module}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出每层打印信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: <class 'torch.nn.modules.sparse.Embedding'>\n",
      "Input: shape=torch.Size([1, 6])\n",
      "First 5 elements: [1, 11152, 6138, 1348, 1817]\n",
      "Last 5 elements: [11152, 6138, 1348, 1817, 59342]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.00185394287109375, 0.046875, -0.0030517578125, -0.013671875, -0.00518798828125]\n",
      "Last 5 elements: [-0.007110595703125, -0.0791015625, 0.083984375, -0.0281982421875, -0.05908203125]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.022247314453125, 0.5625, -0.03662109375, -0.1640625, -0.062255859375]\n",
      "Last 5 elements: [-0.0853271484375, -0.94921875, 1.0078125, -0.33837890625, -0.708984375]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.05698112025856972, 1.440707802772522, -0.09379608184099197, -0.4202064275741577, -0.15945333242416382]\n",
      "Last 5 elements: [-0.16926905512809753, -1.88302743434906, 1.9992636442184448, -0.6712644100189209, -1.4064587354660034]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.05698112025856972, 1.440707802772522, -0.09379608184099197, -0.4202064275741577, -0.15945333242416382]\n",
      "Last 5 elements: [-0.16926905512809753, -1.88302743434906, 1.9992636442184448, -0.6712644100189209, -1.4064587354660034]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-10.378754615783691, 2.8479819297790527, 5.096789836883545, 0.7801259756088257, -0.7688761949539185]\n",
      "Last 5 elements: [-1.151350498199463, -4.824507713317871, -4.375471591949463, 0.20381003618240356, -3.304752826690674]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-10.378754615783691, 2.8479819297790527, 5.096789836883545, 0.7801259756088257, -0.7688761949539185]\n",
      "Last 5 elements: [-1.151350498199463, -4.824507713317871, -4.375471591949463, 0.20381003618240356, -3.304752826690674]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-2.474034070968628, 0.6788872480392456, 1.2149465084075928, 0.18596240878105164, -0.18328073620796204]\n",
      "Last 5 elements: [-0.3167286217212677, -1.3271889686584473, -1.2036621570587158, 0.05606674402952194, -0.9091148376464844]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-2.474034070968628, 0.6788872480392456, 1.2149465084075928, 0.18596240878105164, -0.18328073620796204]\n",
      "Last 5 elements: [-0.3167286217212677, -1.3271889686584473, -1.2036621570587158, 0.05606674402952194, -0.9091148376464844]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [8.485595703125, -8.546122550964355, 8.513572692871094, -8.488927841186523, -8.561325073242188]\n",
      "Last 5 elements: [2.354822874069214, -3.474429130554199, 7.7113823890686035, 10.57819652557373, -7.972334384918213]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.05698112025856972, 1.440707802772522, -0.09379608184099197, -0.4202064275741577, -0.15945333242416382]\n",
      "Last 5 elements: [-0.16926905512809753, -1.88302743434906, 1.9992636442184448, -0.6712644100189209, -1.4064587354660034]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.6378437876701355, -1.5528998374938965, -0.44171130657196045, -0.5571991801261902, 2.7875072956085205]\n",
      "Last 5 elements: [-8.73303508758545, -17.87884521484375, 9.13306713104248, 16.286651611328125, 2.185399055480957]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.6378437876701355, -1.5528998374938965, -0.44171130657196045, -0.5571991801261902, 2.7875072956085205]\n",
      "Last 5 elements: [0.09792053699493408, -0.7448781728744507, -0.5007745623588562, 0.8530490398406982, 0.4397927522659302]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.07744742929935455, -0.18855415284633636, -0.053632888942956924, -0.06765550374984741, 0.3384610414505005]\n",
      "Last 5 elements: [0.020386194810271263, -0.15507709980010986, -0.10425686836242676, 0.177597314119339, 0.09156098961830139]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.07744742929935455, -0.18855415284633636, -0.053632888942956924, -0.06765550374984741, 0.3384610414505005]\n",
      "Last 5 elements: [0.020386194810271263, -0.15507709980010986, -0.10425686836242676, 0.177597314119339, 0.09156098961830139]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.6025527715682983, -0.6085225939750671, 0.5833086967468262, -0.5910924077033997, -0.5686672329902649]\n",
      "Last 5 elements: [0.026675742119550705, -0.005926039069890976, 0.03956938534975052, 0.5613017678260803, 0.2613714337348938]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.03098365105688572, -0.06009326130151749, 0.7905315160751343, 0.5664127469062805, -1.0943727493286133]\n",
      "Last 5 elements: [0.026675742119550705, -0.005926039069890976, 0.03956938534975052, 0.5613017678260803, 0.2613714337348938]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.03098365105688572, -0.06009326130151749, 0.7905315160751343, 0.5664127469062805, -1.0943727493286133]\n",
      "Last 5 elements: [0.024294307455420494, -0.0069979955442249775, 0.03926592320203781, 0.5586246252059937, 0.26388856768608093]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.32745450735092163, 1.2713990211486816, -0.2770426273345947, -0.12357491254806519, 0.7569798231124878]\n",
      "Last 5 elements: [0.5065720677375793, 0.6584499478340149, -1.8811671733856201, -0.0505535863339901, 1.3286755084991455]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.0804687887430191, 0.7885549664497375, -0.08587932586669922, -0.18603414297103882, 0.07233528792858124]\n",
      "Last 5 elements: [0.004741452634334564, -0.8321462273597717, 0.6733406782150269, -0.3473673462867737, -0.4727456271648407]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.10474307835102081, 1.0264312028884888, -0.11178576201200485, -0.2421533763408661, 0.09415601193904877]\n",
      "Last 5 elements: [0.0058853900991380215, -1.0329123735427856, 0.8357928991317749, -0.43117424845695496, -0.5868016481399536]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.10474307835102081, 1.0264312028884888, -0.11178576201200485, -0.2421533763408661, 0.09415601193904877]\n",
      "Last 5 elements: [0.0058853900991380215, -1.0329123735427856, 0.8357928991317749, -0.43117424845695496, -0.5868016481399536]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.7078678607940674, -1.7395057678222656, -3.18424654006958, -2.2381412982940674, -2.475472927093506]\n",
      "Last 5 elements: [-2.5498714447021484, -3.9506564140319824, -3.595895290374756, -4.227041721343994, -3.524977684020996]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.7078678607940674, -1.7395057678222656, -3.18424654006958, -2.2381412982940674, -2.475472927093506]\n",
      "Last 5 elements: [-2.5498714447021484, -3.9506564140319824, -3.595895290374756, -4.227041721343994, -3.524977684020996]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.23364605009555817, -0.2598399221897125, -0.12661480903625488, -0.215706005692482, -0.19208583235740662]\n",
      "Last 5 elements: [-0.18470023572444916, -0.07458365708589554, -0.09602287411689758, -0.060808274894952774, -0.10084903240203857]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.10474307835102081, 1.0264312028884888, -0.11178576201200485, -0.2421533763408661, 0.09415601193904877]\n",
      "Last 5 elements: [0.0058853900991380215, -1.0329123735427856, 0.8357928991317749, -0.43117424845695496, -0.5868016481399536]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.6089892387390137, 0.05952085554599762, 1.059490442276001, 0.6504959464073181, 0.37681448459625244]\n",
      "Last 5 elements: [0.4286356270313263, -0.017711132764816284, 0.14700829982757568, -0.9070649743080139, -1.3754340410232544]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.14228792488574982, -0.015465894713997841, -0.13414718210697174, -0.14031587541103363, -0.07238072156906128]\n",
      "Last 5 elements: [-0.07916910201311111, 0.0013209610478952527, -0.01411615964025259, 0.05515705794095993, 0.13871119916439056]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.995380163192749, 2.1374704837799072, -0.9504243731498718, 0.6591005325317383, -0.2895759344100952]\n",
      "Last 5 elements: [-0.16555112600326538, 2.3620994091033936, -1.9768091440200806, -0.26808440685272217, 2.118952989578247]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.10474307835102081, 1.0264312028884888, -0.11178576201200485, -0.2421533763408661, 0.09415601193904877]\n",
      "Last 5 elements: [0.0058853900991380215, -1.0329123735427856, 0.8357928991317749, -0.43117424845695496, -0.5868016481399536]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.995380163192749, 2.1374704837799072, -0.9504243731498718, 0.6591005325317383, -0.2895759344100952]\n",
      "Last 5 elements: [-0.16555112600326538, 2.3620994091033936, -1.9768091440200806, -0.26808440685272217, 2.118952989578247]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[ 0.0805,  0.7886, -0.0859,  ...,  0.1033, -0.2275, -0.3791],\n",
      "         [ 0.3782,  0.2407, -0.3621,  ...,  0.4442, -0.3347,  0.2835],\n",
      "         [-0.2011,  0.6895, -0.9275,  ...,  0.1209, -0.4362,  0.8949],\n",
      "         [-0.4984, -0.0790, -0.3431,  ...,  0.2121,  0.1387, -0.9944],\n",
      "         [-0.1932,  0.4798,  0.2697,  ...,  0.0166,  0.1267,  0.1625],\n",
      "         [-0.6075,  0.0244, -0.1731,  ...,  0.6733, -0.3474, -0.4727]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.022247314453125, 0.5625, -0.03662109375, -0.1640625, -0.062255859375]\n",
      "Last 5 elements: [-0.0853271484375, -0.94921875, 1.0078125, -0.33837890625, -0.708984375]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2743101716041565, 1.1685975790023804, -0.2548649311065674, -0.0688459500670433, 0.020848635584115982]\n",
      "Last 5 elements: [-0.0246935673058033, -0.4121645390987396, 0.32186365127563477, -0.3950327932834625, -0.09599539637565613]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2743101716041565, 1.1685975790023804, -0.2548649311065674, -0.0688459500670433, 0.020848635584115982]\n",
      "Last 5 elements: [-0.0246935673058033, -0.4121645390987396, 0.32186365127563477, -0.3950327932834625, -0.09599539637565613]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.28704628348350525, 1.2228550910949707, -0.2666982114315033, -0.07204244285821915, 0.02181662991642952]\n",
      "Last 5 elements: [-0.03311295062303543, -0.5526939034461975, 0.4316045343875885, -0.5297210216522217, -0.12872546911239624]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.28704628348350525, 1.2228550910949707, -0.2666982114315033, -0.07204244285821915, 0.02181662991642952]\n",
      "Last 5 elements: [-0.03311295062303543, -0.5526939034461975, 0.4316045343875885, -0.5297210216522217, -0.12872546911239624]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.073866844177246, 0.6052678227424622, -1.5019571781158447, -1.8850256204605103, 2.4774086475372314]\n",
      "Last 5 elements: [-0.3231002688407898, 0.6405969858169556, -0.2748364806175232, 0.9465550780296326, 4.046363353729248]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.073866844177246, 0.6052678227424622, -1.5019571781158447, -1.8850256204605103, 2.4774086475372314]\n",
      "Last 5 elements: [-0.3231002688407898, 0.6405969858169556, -0.2748364806175232, 0.9465550780296326, 4.046363353729248]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.9720613360404968, 0.28370070457458496, -0.7039963006973267, -0.883547842502594, 1.161209225654602]\n",
      "Last 5 elements: [-0.15129582583904266, 0.2999677062034607, -0.12869569659233093, 0.44323650002479553, 1.894761323928833]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.9720613360404968, 0.28370070457458496, -0.7039963006973267, -0.883547842502594, 1.161209225654602]\n",
      "Last 5 elements: [-0.15129582583904266, 0.2999677062034607, -0.12869569659233093, 0.44323650002479553, 1.894761323928833]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.494520664215088, -0.13388776779174805, -0.5403057336807251, -0.014084219932556152, 0.5313736200332642]\n",
      "Last 5 elements: [0.2551393508911133, 0.3452717661857605, -1.1007617712020874, 0.8155341148376465, 1.0432683229446411]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.28704628348350525, 1.2228550910949707, -0.2666982114315033, -0.07204244285821915, 0.02181662991642952]\n",
      "Last 5 elements: [-0.03311295062303543, -0.5526939034461975, 0.4316045343875885, -0.5297210216522217, -0.12872546911239624]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [1.1195276975631714, -0.2528151273727417, -0.13109412789344788, 0.8699626326560974, 0.9920936822891235]\n",
      "Last 5 elements: [0.7858289480209351, -9.817140579223633, 0.35470759868621826, -0.4017801284790039, -9.022942543029785]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [1.1195276975631714, -0.2528151273727417, -0.13109412789344788, 0.8699626326560974, 0.9920936822891235]\n",
      "Last 5 elements: [-0.2773692011833191, -2.440192461013794, -0.12661314010620117, -0.5619854927062988, 1.9022191762924194]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.32779181003570557, -0.07402294129133224, -0.03838367015123367, 0.2547204792499542, 0.2904798090457916]\n",
      "Last 5 elements: [-0.13756360113620758, -1.2102341651916504, -0.06279485672712326, -0.27872148156166077, 0.9434217214584351]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.32779181003570557, -0.07402294129133224, -0.03838367015123367, 0.2547204792499542, 0.2904798090457916]\n",
      "Last 5 elements: [-0.13756360113620758, -1.2102341651916504, -0.06279485672712326, -0.27872148156166077, 0.9434217214584351]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.010882481932640076, -0.28928467631340027, 0.16586153209209442, -0.6915594339370728, 0.12173470109701157]\n",
      "Last 5 elements: [0.10295242071151733, 0.11018804460763931, 0.20173776149749756, -0.015108957886695862, 0.04839730262756348]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [1.1922045946121216, -0.4047413170337677, -0.5547763109207153, -0.6528627276420593, -0.2653423249721527]\n",
      "Last 5 elements: [0.10295242071151733, 0.11018804460763931, 0.20173776149749756, -0.015108957886695862, 0.04839730262756348]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [1.1922045946121216, -0.4047413170337677, -0.5547763109207153, -0.6528627276420593, -0.2653423249721527]\n",
      "Last 5 elements: [-0.10705073177814484, 0.016958989202976227, -0.4483003616333008, 0.033471740782260895, 0.09768702834844589]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.4583776593208313, -1.5132205486297607, 1.1054954528808594, -0.026498466730117798, -1.2569866180419922]\n",
      "Last 5 elements: [-0.3280777931213379, 0.27988767623901367, -0.35944730043411255, 1.3344762325286865, 0.9155305027961731]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.1928105354309082, 0.8995466828346252, -0.058307647705078125, -0.07355738431215286, -0.20264381170272827]\n",
      "Last 5 elements: [-0.08302585780620575, -0.36240047216415405, 0.25795385241508484, -0.15776267647743225, 0.06678609549999237]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.20931625366210938, 0.9765531420707703, -0.06329912692308426, -0.0798543244600296, -0.2199913114309311]\n",
      "Last 5 elements: [-0.11604474484920502, -0.5065249800682068, 0.3605405390262604, -0.22050394117832184, 0.09334652125835419]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.20931625366210938, 0.9765531420707703, -0.06329912692308426, -0.0798543244600296, -0.2199913114309311]\n",
      "Last 5 elements: [-0.11604474484920502, -0.5065249800682068, 0.3605405390262604, -0.22050394117832184, 0.09334652125835419]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.9748775362968445, -1.2501308917999268, -0.5397446155548096, -1.4874885082244873, -1.194097638130188]\n",
      "Last 5 elements: [-1.8755130767822266, -2.311753749847412, -1.919700264930725, -2.0979936122894287, -1.9174220561981201]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.9748775362968445, -1.2501308917999268, -0.5397446155548096, -1.4874885082244873, -1.194097638130188]\n",
      "Last 5 elements: [-1.8755130767822266, -2.311753749847412, -1.919700264930725, -2.0979936122894287, -1.9174220561981201]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2670280933380127, -0.2783759832382202, -0.19875934720039368, -0.27414262294769287, -0.2776598036289215]\n",
      "Last 5 elements: [-0.24926525354385376, -0.20841428637504578, -0.24552005529403687, -0.22929388284683228, -0.24571631848812103]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.20931625366210938, 0.9765531420707703, -0.06329912692308426, -0.0798543244600296, -0.2199913114309311]\n",
      "Last 5 elements: [-0.11604474484920502, -0.5065249800682068, 0.3605405390262604, -0.22050394117832184, 0.09334652125835419]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.8717294931411743, -1.1622387170791626, -0.36538153886795044, 0.014838874340057373, 0.9343194961547852]\n",
      "Last 5 elements: [0.6659412980079651, 0.8620122075080872, 0.764317512512207, -0.29801279306411743, -0.2405472695827484]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.23277626931667328, 0.3235393464565277, 0.07262299954891205, -0.004067968111485243, -0.2594229578971863]\n",
      "Last 5 elements: [-0.1659960299730301, -0.17965565621852875, -0.1876552850008011, 0.06833250820636749, 0.05910639092326164]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.6062281131744385, 0.759858250617981, -0.007425397634506226, -0.6423068642616272, 1.1064140796661377]\n",
      "Last 5 elements: [0.363499253988266, 0.5635486245155334, -0.5314365029335022, 0.20283116400241852, 0.7155944108963013]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.20931625366210938, 0.9765531420707703, -0.06329912692308426, -0.0798543244600296, -0.2199913114309311]\n",
      "Last 5 elements: [-0.11604474484920502, -0.5065249800682068, 0.3605405390262604, -0.22050394117832184, 0.09334652125835419]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.6062281131744385, 0.759858250617981, -0.007425397634506226, -0.6423068642616272, 1.1064140796661377]\n",
      "Last 5 elements: [0.363499253988266, 0.5635486245155334, -0.5314365029335022, 0.20283116400241852, 0.7155944108963013]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1928,  0.8995, -0.0583,  ...,  0.1881, -0.0087, -0.0621],\n",
      "         [ 0.0123,  0.2049,  0.1131,  ...,  0.5825, -0.2489, -0.0884],\n",
      "         [-0.3494,  0.6450, -0.4556,  ...,  0.1642, -0.0398,  0.8689],\n",
      "         [-0.0308,  0.1269, -0.2109,  ..., -0.0366,  0.0957, -0.3008],\n",
      "         [-0.1311,  0.1521,  0.2437,  ...,  0.0489, -0.0813, -0.2053],\n",
      "         [-0.0043,  0.1532,  0.0157,  ...,  0.2580, -0.1578,  0.0668]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2743101716041565, 1.1685975790023804, -0.2548649311065674, -0.0688459500670433, 0.020848635584115982]\n",
      "Last 5 elements: [-0.0246935673058033, -0.4121645390987396, 0.32186365127563477, -0.3950327932834625, -0.09599539637565613]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4783981740474701, 1.0346496105194092, -0.05962788313627243, -0.187759667634964, -0.0059231966733932495]\n",
      "Last 5 elements: [-0.018395625054836273, -0.2622014284133911, 0.16346433758735657, -0.121699258685112, 0.1940189152956009]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4783981740474701, 1.0346496105194092, -0.05962788313627243, -0.187759667634964, -0.0059231966733932495]\n",
      "Last 5 elements: [-0.018395625054836273, -0.2622014284133911, 0.16346433758735657, -0.121699258685112, 0.1940189152956009]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.48283272981643677, 1.0442403554916382, -0.06018060818314552, -0.1895001232624054, -0.005978102330118418]\n",
      "Last 5 elements: [-0.02589588798582554, -0.3691061735153198, 0.2301120162010193, -0.17131847143173218, 0.2731243073940277]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.48283272981643677, 1.0442403554916382, -0.06018060818314552, -0.1895001232624054, -0.005978102330118418]\n",
      "Last 5 elements: [-0.02589588798582554, -0.3691061735153198, 0.2301120162010193, -0.17131847143173218, 0.2731243073940277]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.977034866809845, 0.18419434130191803, -0.6943028569221497, 0.325283408164978, -0.8761425018310547]\n",
      "Last 5 elements: [-0.2527819275856018, -0.8063911199569702, -0.7478237152099609, -0.11991211771965027, 0.1704140603542328]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.977034866809845, 0.18419434130191803, -0.6943028569221497, 0.325283408164978, -0.8761425018310547]\n",
      "Last 5 elements: [-0.2527819275856018, -0.8063911199569702, -0.7478237152099609, -0.11991211771965027, 0.1704140603542328]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.6443372368812561, 0.12147291749715805, -0.45788049697875977, 0.21451866626739502, -0.5778005123138428]\n",
      "Last 5 elements: [-0.1582719385623932, -0.504897952079773, -0.46822771430015564, -0.07507942616939545, 0.10669972747564316]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.6443372368812561, 0.12147291749715805, -0.45788049697875977, 0.21451866626739502, -0.5778005123138428]\n",
      "Last 5 elements: [-0.1582719385623932, -0.504897952079773, -0.46822771430015564, -0.07507942616939545, 0.10669972747564316]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.1215095520019531, 0.12133878469467163, 0.2751467227935791, 0.8340514898300171, 1.781461477279663]\n",
      "Last 5 elements: [0.8239070177078247, -0.70821213722229, 1.3585354089736938, -3.3361902236938477, -0.37068307399749756]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.48283272981643677, 1.0442403554916382, -0.06018060818314552, -0.1895001232624054, -0.005978102330118418]\n",
      "Last 5 elements: [-0.02589588798582554, -0.3691061735153198, 0.2301120162010193, -0.17131847143173218, 0.2731243073940277]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.658994197845459, 1.1369974613189697, 0.44981062412261963, 0.06253385543823242, 1.0485897064208984]\n",
      "Last 5 elements: [1.391528844833374, 0.943587064743042, -15.734437942504883, -12.082071304321289, -7.460181713104248]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.658994197845459, 1.1369974613189697, 0.44981062412261963, 0.06253385543823242, 1.0485897064208984]\n",
      "Last 5 elements: [1.1944835186004639, -0.10185492038726807, 0.1888638734817505, 0.023178108036518097, -0.02041124552488327]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.22359511256217957, 0.3857804238796234, 0.1526196300983429, 0.021217582747340202, 0.3557839095592499]\n",
      "Last 5 elements: [0.34546634554862976, -0.029458295553922653, 0.054622866213321686, 0.006703530438244343, -0.005903303623199463]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.22359511256217957, 0.3857804238796234, 0.1526196300983429, 0.021217582747340202, 0.3557839095592499]\n",
      "Last 5 elements: [0.34546634554862976, -0.029458295553922653, 0.054622866213321686, 0.006703530438244343, -0.005903303623199463]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.2540869414806366, -0.23384560644626617, 0.18077798187732697, 0.17123758792877197, 0.24269720911979675]\n",
      "Last 5 elements: [0.024984749034047127, -0.010130403563380241, -0.14520779252052307, 0.05190160125494003, 0.04458107799291611]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.7088724374771118, 0.47553807497024536, 0.03012133575975895, 0.07556562125682831, -0.7772915959358215]\n",
      "Last 5 elements: [0.024984749034047127, -0.010130403563380241, -0.14520779252052307, 0.05190160125494003, 0.04458107799291611]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.7088724374771118, 0.47553807497024536, 0.03012133575975895, 0.07556562125682831, -0.7772915959358215]\n",
      "Last 5 elements: [0.1501409113407135, -0.4555739164352417, 0.43085578083992004, -0.03077949956059456, -0.0022180022206157446]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.25516149401664734, -1.266270637512207, 0.4791991710662842, -0.04354792833328247, -0.6270161867141724]\n",
      "Last 5 elements: [1.2439138889312744, -0.21684634685516357, -0.3890652656555176, -0.4138415455818176, -0.8109232187271118]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4330304265022278, 0.8095064759254456, 0.025573812425136566, -0.19550248980522156, -0.11740678548812866]\n",
      "Last 5 elements: [0.20277249813079834, -0.3007567524909973, 0.09428846091032028, -0.19528035819530487, 0.049836620688438416]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.43137577176094055, 0.8064132332801819, 0.025476090610027313, -0.1947554498910904, -0.11695815622806549]\n",
      "Last 5 elements: [0.283372700214386, -0.4203047752380371, 0.13176725804805756, -0.2729024887084961, 0.06964621692895889]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.43137577176094055, 0.8064132332801819, 0.025476090610027313, -0.1947554498910904, -0.11695815622806549]\n",
      "Last 5 elements: [0.283372700214386, -0.4203047752380371, 0.13176725804805756, -0.2729024887084961, 0.06964621692895889]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.979464590549469, -2.956906795501709, -1.8513253927230835, -2.6218910217285156, 0.3714558482170105]\n",
      "Last 5 elements: [-3.258491039276123, -1.108471155166626, -2.0539231300354004, -1.3384442329406738, -1.2675026655197144]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.979464590549469, -2.956906795501709, -1.8513253927230835, -2.6218910217285156, 0.3714558482170105]\n",
      "Last 5 elements: [-3.258491039276123, -1.108471155166626, -2.0539231300354004, -1.3384442329406738, -1.2675026655197144]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2673918902873993, -0.14610399305820465, -0.2512570023536682, -0.17761416733264923, 0.21983155608177185]\n",
      "Last 5 elements: [-0.12063901126384735, -0.275073766708374, -0.23344185948371887, -0.2780832350254059, -0.2784513831138611]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.43137577176094055, 0.8064132332801819, 0.025476090610027313, -0.1947554498910904, -0.11695815622806549]\n",
      "Last 5 elements: [0.283372700214386, -0.4203047752380371, 0.13176725804805756, -0.2729024887084961, 0.06964621692895889]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.39063510298728943, 0.8898727893829346, -0.37185317277908325, -0.7755173444747925, 0.6216660737991333]\n",
      "Last 5 elements: [-0.16441451013088226, 0.3141624927520752, -0.19534125924110413, 0.46188634634017944, 0.2973688542842865]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.10445266216993332, -0.13001397252082825, 0.09343071281909943, 0.13774286210536957, 0.1366618275642395]\n",
      "Last 5 elements: [0.01983480341732502, -0.08641786128282547, 0.045600827783346176, -0.12844285368919373, -0.08280276507139206]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.3080201745033264, 0.7503070831298828, -0.8673751354217529, -0.4434985816478729, -0.69720458984375]\n",
      "Last 5 elements: [0.3168870508670807, 0.30247926712036133, 0.1541503369808197, 0.4641314744949341, 0.6996269226074219]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.43137577176094055, 0.8064132332801819, 0.025476090610027313, -0.1947554498910904, -0.11695815622806549]\n",
      "Last 5 elements: [0.283372700214386, -0.4203047752380371, 0.13176725804805756, -0.2729024887084961, 0.06964621692895889]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.3080201745033264, 0.7503070831298828, -0.8673751354217529, -0.4434985816478729, -0.69720458984375]\n",
      "Last 5 elements: [0.3168870508670807, 0.30247926712036133, 0.1541503369808197, 0.4641314744949341, 0.6996269226074219]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.4330,  0.8095,  0.0256,  ..., -0.2506,  0.0244,  0.1152],\n",
      "         [-0.1987,  0.0322,  0.6745,  ...,  0.7176, -0.1784,  0.0237],\n",
      "         [-0.2553,  0.6115, -0.1450,  ...,  0.1666, -0.3448,  0.6467],\n",
      "         [ 0.0949,  0.1532, -0.1908,  ..., -0.0635, -0.1019, -0.0074],\n",
      "         [-0.1926,  0.3435,  0.1297,  ..., -0.0092, -0.4158,  0.1835],\n",
      "         [-0.0943,  0.0029, -0.0153,  ...,  0.0943, -0.1953,  0.0498]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4783981740474701, 1.0346496105194092, -0.05962788313627243, -0.187759667634964, -0.0059231966733932495]\n",
      "Last 5 elements: [-0.018395625054836273, -0.2622014284133911, 0.16346433758735657, -0.121699258685112, 0.1940189152956009]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.48779645562171936, 0.9429112076759338, -0.1286456286907196, -0.2743566036224365, -0.24136988818645477]\n",
      "Last 5 elements: [0.259115070104599, -0.2469758838415146, 0.12169642001390457, -0.11275769770145416, 0.1742304116487503]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.48779645562171936, 0.9429112076759338, -0.1286456286907196, -0.2743566036224365, -0.24136988818645477]\n",
      "Last 5 elements: [0.259115070104599, -0.2469758838415146, 0.12169642001390457, -0.11275769770145416, 0.1742304116487503]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.444936603307724, 0.8600630760192871, -0.1173422783613205, -0.2502504885196686, -0.22016210854053497]\n",
      "Last 5 elements: [0.36277514696121216, -0.3457796275615692, 0.1703815907239914, -0.15786689519882202, 0.24393202364444733]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.444936603307724, 0.8600630760192871, -0.1173422783613205, -0.2502504885196686, -0.22016210854053497]\n",
      "Last 5 elements: [0.36277514696121216, -0.3457796275615692, 0.1703815907239914, -0.15786689519882202, 0.24393202364444733]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.5385594367980957, 0.41161951422691345, -0.4274471402168274, -0.12921035289764404, -0.47150784730911255]\n",
      "Last 5 elements: [-1.4785690307617188, -0.5333948135375977, 0.33028680086135864, -0.04466724395751953, 0.28018707036972046]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.5385594367980957, 0.41161951422691345, -0.4274471402168274, -0.12921035289764404, -0.47150784730911255]\n",
      "Last 5 elements: [-1.4785690307617188, -0.5333948135375977, 0.33028680086135864, -0.04466724395751953, 0.28018707036972046]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.5174372792243958, 0.3954758942127228, -0.4106827676296234, -0.12414275854825974, -0.45301544666290283]\n",
      "Last 5 elements: [-1.4509356021881104, -0.5234260559082031, 0.32411399483680725, -0.0438324473798275, 0.2749505639076233]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.5174372792243958, 0.3954758942127228, -0.4106827676296234, -0.12414275854825974, -0.45301544666290283]\n",
      "Last 5 elements: [-1.4509356021881104, -0.5234260559082031, 0.32411399483680725, -0.0438324473798275, 0.2749505639076233]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.429429531097412, -1.1486248970031738, -0.12228178232908249, 0.7223857641220093, -0.5217280983924866]\n",
      "Last 5 elements: [2.1426455974578857, 0.7125207781791687, -2.0552947521209717, 2.066739559173584, -0.7975616455078125]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.444936603307724, 0.8600630760192871, -0.1173422783613205, -0.2502504885196686, -0.22016210854053497]\n",
      "Last 5 elements: [0.36277514696121216, -0.3457796275615692, 0.1703815907239914, -0.15786689519882202, 0.24393202364444733]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.34825679659843445, 0.7603957653045654, 0.3118106722831726, -0.816609263420105, -0.01684756577014923]\n",
      "Last 5 elements: [0.7066338062286377, 14.383027076721191, 1.9015110731124878, -0.5426571369171143, -18.622310638427734]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.34825679659843445, 0.7603957653045654, 0.3118106722831726, -0.816609263420105, -0.01684756577014923]\n",
      "Last 5 elements: [0.537185549736023, 0.8142603635787964, -0.5932909250259399, -0.46636760234832764, -0.12786288559436798]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.09178832173347473, 0.2004137635231018, 0.0821823999285698, -0.21522967517375946, -0.004440429620444775]\n",
      "Last 5 elements: [0.17834466695785522, 0.27033302187919617, -0.19697155058383942, -0.15483322739601135, -0.042450256645679474]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.09178832173347473, 0.2004137635231018, 0.0821823999285698, -0.21522967517375946, -0.004440429620444775]\n",
      "Last 5 elements: [0.17834466695785522, 0.27033302187919617, -0.19697155058383942, -0.15483322739601135, -0.042450256645679474]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.10564988106489182, -0.09758998453617096, -0.6160415410995483, 0.008954726159572601, -0.1851934790611267]\n",
      "Last 5 elements: [0.12534545361995697, 0.08064797520637512, -0.06815356016159058, -0.04996896907687187, 0.13807004690170288]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.15257972478866577, -0.05369935929775238, -0.0315803587436676, -0.03031883016228676, 0.19862431287765503]\n",
      "Last 5 elements: [0.12534545361995697, 0.08064797520637512, -0.06815356016159058, -0.04996896907687187, 0.13807004690170288]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.15257972478866577, -0.05369935929775238, -0.0315803587436676, -0.03031883016228676, 0.19862431287765503]\n",
      "Last 5 elements: [0.08857343345880508, 0.0819963812828064, -0.06415735930204391, -0.03686529025435448, 0.08316441625356674]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.18225452303886414, -0.08057820051908493, 0.29154345393180847, 0.2364150732755661, 0.8999243974685669]\n",
      "Last 5 elements: [0.8774499893188477, 0.07276034355163574, 0.2302638590335846, -0.055665016174316406, 0.05044633150100708]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4553915560245514, 0.9285843968391418, -0.07680915296077728, -0.23232196271419525, -0.08136317133903503]\n",
      "Last 5 elements: [0.41512584686279297, -0.2340390831232071, 0.1626373827457428, -0.12265494465827942, 0.18319977819919586]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.4180619418621063, 0.8524659872055054, -0.07051291316747665, -0.2132779359817505, -0.07469362765550613]\n",
      "Last 5 elements: [0.5840219259262085, -0.32925906777381897, 0.2288072258234024, -0.1725577414035797, 0.25773555040359497]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4180619418621063, 0.8524659872055054, -0.07051291316747665, -0.2132779359817505, -0.07469362765550613]\n",
      "Last 5 elements: [0.5840219259262085, -0.32925906777381897, 0.2288072258234024, -0.1725577414035797, 0.25773555040359497]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.18354469537734985, -1.0848777294158936, -0.6666442155838013, -1.2184100151062012, -1.659314513206482]\n",
      "Last 5 elements: [-2.2584214210510254, -1.2963926792144775, -1.5412659645080566, -1.8872767686843872, -1.6718080043792725]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.18354469537734985, -1.0848777294158936, -0.6666442155838013, -1.2184100151062012, -1.659314513206482]\n",
      "Last 5 elements: [-2.2584214210510254, -1.2963926792144775, -1.5412659645080566, -1.8872767686843872, -1.6718080043792725]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.08337374776601791, -0.2740228474140167, -0.22615814208984375, -0.2780611217021942, -0.2652481198310852]\n",
      "Last 5 elements: [-0.21370431780815125, -0.2784298360347748, -0.2718042731285095, -0.24828122556209564, -0.2644520401954651]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4180619418621063, 0.8524659872055054, -0.07051291316747665, -0.2132779359817505, -0.07469362765550613]\n",
      "Last 5 elements: [0.5840219259262085, -0.32925906777381897, 0.2288072258234024, -0.1725577414035797, 0.25773555040359497]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.24884413182735443, 0.23419272899627686, 0.3228917121887207, -0.6176690459251404, 0.1095072478055954]\n",
      "Last 5 elements: [0.5146774649620056, 1.8675163984298706, 0.4889252185821533, 0.04338297247886658, -0.05707991123199463]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.020747067406773567, -0.06417416036128998, -0.07302459329366684, 0.17174974083900452, -0.029046591371297836]\n",
      "Last 5 elements: [-0.10998879373073578, -0.5199722647666931, -0.1328919678926468, -0.01077117770910263, 0.015094898641109467]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.0349056720733643, 0.5472320318222046, 0.45838993787765503, 0.8099073171615601, 0.5706912279129028]\n",
      "Last 5 elements: [-0.006655961275100708, -0.23567518591880798, -0.0751776248216629, 0.10231673717498779, 0.4463091790676117]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4180619418621063, 0.8524659872055054, -0.07051291316747665, -0.2132779359817505, -0.07469362765550613]\n",
      "Last 5 elements: [0.5840219259262085, -0.32925906777381897, 0.2288072258234024, -0.1725577414035797, 0.25773555040359497]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.0349056720733643, 0.5472320318222046, 0.45838993787765503, 0.8099073171615601, 0.5706912279129028]\n",
      "Last 5 elements: [-0.006655961275100708, -0.23567518591880798, -0.0751776248216629, 0.10231673717498779, 0.4463091790676117]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.4554,  0.9286, -0.0768,  ..., -0.2398,  0.0836, -0.1862],\n",
      "         [ 0.3778,  0.0457,  0.5396,  ...,  0.6415,  0.1219, -0.1622],\n",
      "         [-0.1022,  0.7070, -0.3631,  ...,  0.2448, -0.5029,  0.7224],\n",
      "         [ 0.2731,  0.0796, -0.3197,  ..., -0.2514,  0.0944,  0.1036],\n",
      "         [ 0.4034,  0.2494, -0.1961,  ..., -0.1398, -0.2845,  0.2543],\n",
      "         [ 0.0670, -0.2119,  0.0725,  ...,  0.1626, -0.1227,  0.1832]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.48779645562171936, 0.9429112076759338, -0.1286456286907196, -0.2743566036224365, -0.24136988818645477]\n",
      "Last 5 elements: [0.259115070104599, -0.2469758838415146, 0.12169642001390457, -0.11275769770145416, 0.1742304116487503]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6393979787826538, 1.025882363319397, 0.00469265878200531, -0.0883202999830246, 0.02010583132505417]\n",
      "Last 5 elements: [0.4139424264431, -0.2759421765804291, 0.14927078783512115, -0.10446301102638245, 0.2625536322593689]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6393979787826538, 1.025882363319397, 0.00469265878200531, -0.0883202999830246, 0.02010583132505417]\n",
      "Last 5 elements: [0.4139424264431, -0.2759421765804291, 0.14927078783512115, -0.10446301102638245, 0.2625536322593689]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.5272050499916077, 0.8458743691444397, 0.0038692543748766184, -0.07282304763793945, 0.016577931120991707]\n",
      "Last 5 elements: [0.5837197303771973, -0.38911908864974976, 0.2104937881231308, -0.14730821549892426, 0.3702392578125]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5272050499916077, 0.8458743691444397, 0.0038692543748766184, -0.07282304763793945, 0.016577931120991707]\n",
      "Last 5 elements: [0.5837197303771973, -0.38911908864974976, 0.2104937881231308, -0.14730821549892426, 0.3702392578125]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.3144649267196655, -0.5453058481216431, 0.07125967741012573, 0.6432327628135681, -0.6278424263000488]\n",
      "Last 5 elements: [1.4053035974502563, 1.4295427799224854, -0.205990269780159, -3.0303757190704346, -0.05625554919242859]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.3144649267196655, -0.5453058481216431, 0.07125967741012573, 0.6432327628135681, -0.6278424263000488]\n",
      "Last 5 elements: [1.4053035974502563, 1.4295427799224854, -0.205990269780159, -3.0303757190704346, -0.05625554919242859]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.9541091322898865, -0.3958122134208679, 0.05172409489750862, 0.4668928384780884, -0.4557217061519623]\n",
      "Last 5 elements: [0.9147487282752991, 0.930526614189148, -0.13408443331718445, -1.9725505113601685, -0.036618202924728394]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.9541091322898865, -0.3958122134208679, 0.05172409489750862, 0.4668928384780884, -0.4557217061519623]\n",
      "Last 5 elements: [0.9147487282752991, 0.930526614189148, -0.13408443331718445, -1.9725505113601685, -0.036618202924728394]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.3899564743041992, -1.9910438060760498, -0.182245671749115, -0.6565627455711365, 0.6934915781021118]\n",
      "Last 5 elements: [-0.7182932496070862, -0.08948312699794769, -1.0407017469406128, 0.017957210540771484, 0.32745224237442017]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5272050499916077, 0.8458743691444397, 0.0038692543748766184, -0.07282304763793945, 0.016577931120991707]\n",
      "Last 5 elements: [0.5837197303771973, -0.38911908864974976, 0.2104937881231308, -0.14730821549892426, 0.3702392578125]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-1.881555438041687, -1.4160500764846802, 0.4026830494403839, -0.9231206178665161, -0.4911862015724182]\n",
      "Last 5 elements: [-0.30548596382141113, -0.9559162259101868, -3.5567848682403564, 16.007862091064453, 19.451168060302734]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-1.881555438041687, -1.4160500764846802, 0.4026830494403839, -0.9231206178665161, -0.4911862015724182]\n",
      "Last 5 elements: [0.4760854244232178, 2.223362922668457, -0.9139549732208252, -0.14857029914855957, -0.9472429752349854]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.7465717792510986, -0.5618665218353271, 0.15977834165096283, -0.36627984046936035, -0.19489499926567078]\n",
      "Last 5 elements: [0.334785133600235, 1.5634775161743164, -0.642696738243103, -0.10447521507740021, -0.6661049723625183]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.7465717792510986, -0.5618665218353271, 0.15977834165096283, -0.36627984046936035, -0.19489499926567078]\n",
      "Last 5 elements: [0.334785133600235, 1.5634775161743164, -0.642696738243103, -0.10447521507740021, -0.6661049723625183]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.04711949825286865, -0.6524760127067566, 0.20215487480163574, -0.2669357657432556, -0.12249162793159485]\n",
      "Last 5 elements: [0.2965650260448456, 0.2769377827644348, -0.04405266046524048, -0.2547242343425751, -0.0015048384666442871]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.1552104949951172, 0.020213328301906586, 0.14364664256572723, 0.14334042370319366, 0.06587408483028412]\n",
      "Last 5 elements: [0.2965650260448456, 0.2769377827644348, -0.04405266046524048, -0.2547242343425751, -0.0015048384666442871]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.1552104949951172, 0.020213328301906586, 0.14364664256572723, 0.14334042370319366, 0.06587408483028412]\n",
      "Last 5 elements: [0.03013831004500389, 0.10404183715581894, -0.007684134878218174, 0.026029355823993683, -0.11753659695386887]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.18607500195503235, -1.162161111831665, 0.12929025292396545, 0.19140419363975525, 0.4531550407409668]\n",
      "Last 5 elements: [0.04856529086828232, -0.15246005356311798, -0.028841301798820496, 0.09192800521850586, 0.2590402662754059]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6724821329116821, 0.8192499279975891, 0.02768048830330372, -0.054288599640131, 0.10067687928676605]\n",
      "Last 5 elements: [0.4225773513317108, -0.30304959416389465, 0.14414280652999878, -0.08811819553375244, 0.30861103534698486]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.5617621541023254, 0.6843655705451965, 0.02312307059764862, -0.0453503243625164, 0.08410106599330902]\n",
      "Last 5 elements: [0.6109178066253662, -0.4381171464920044, 0.20838646590709686, -0.1273919939994812, 0.446157306432724]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5617621541023254, 0.6843655705451965, 0.02312307059764862, -0.0453503243625164, 0.08410106599330902]\n",
      "Last 5 elements: [0.6109178066253662, -0.4381171464920044, 0.20838646590709686, -0.1273919939994812, 0.446157306432724]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.9471954107284546, -1.9597138166427612, -1.6855796575546265, -1.3685799837112427, -1.5488964319229126]\n",
      "Last 5 elements: [-0.3042837381362915, -1.0799974203109741, -2.315419912338257, 1.2374080419540405, -1.182268500328064]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.9471954107284546, -1.9597138166427612, -1.6855796575546265, -1.3685799837112427, -1.5488964319229126]\n",
      "Last 5 elements: [-0.3042837381362915, -1.0799974203109741, -2.315419912338257, 1.2374080419540405, -1.182268500328064]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2646929919719696, -0.24202077090740204, -0.2635539472103119, -0.27761557698249817, -0.27143746614456177]\n",
      "Last 5 elements: [-0.12917166948318481, -0.27378636598587036, -0.20804955065250397, 0.9591304659843445, -0.27741289138793945]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5617621541023254, 0.6843655705451965, 0.02312307059764862, -0.0453503243625164, 0.08410106599330902]\n",
      "Last 5 elements: [0.6109178066253662, -0.4381171464920044, 0.20838646590709686, -0.1273919939994812, 0.446157306432724]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.5116400718688965, 0.22994545102119446, -1.0357338190078735, -0.13367959856987, 0.6931372284889221]\n",
      "Last 5 elements: [-0.6714230179786682, -0.006926417350769043, -0.10269361734390259, -0.05513767898082733, 0.31116050481796265]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.1354275345802307, -0.055651575326919556, 0.2729717493057251, 0.037111539393663406, -0.18814341723918915]\n",
      "Last 5 elements: [0.08672883361577988, 0.0018963586771860719, 0.021365361288189888, -0.05288422852754593, -0.0863199383020401]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.24148303270339966, 0.4581400156021118, 0.16631296277046204, -0.47507691383361816, -0.3992425799369812]\n",
      "Last 5 elements: [-0.9865405559539795, 0.5156285762786865, -0.2917070984840393, -0.041394829750061035, 0.5543917417526245]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5617621541023254, 0.6843655705451965, 0.02312307059764862, -0.0453503243625164, 0.08410106599330902]\n",
      "Last 5 elements: [0.6109178066253662, -0.4381171464920044, 0.20838646590709686, -0.1273919939994812, 0.446157306432724]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.24148303270339966, 0.4581400156021118, 0.16631296277046204, -0.47507691383361816, -0.3992425799369812]\n",
      "Last 5 elements: [-0.9865405559539795, 0.5156285762786865, -0.2917070984840393, -0.041394829750061035, 0.5543917417526245]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6725,  0.8192,  0.0277,  ..., -0.1178,  0.0478, -0.2669],\n",
      "         [ 0.4556, -0.1330,  0.4640,  ...,  0.6396,  0.0419, -0.2987],\n",
      "         [-0.0896,  0.4181, -0.2383,  ...,  0.3901, -0.4887,  0.7050],\n",
      "         [ 0.1564, -0.0475, -0.3641,  ..., -0.3051,  0.1238,  0.1879],\n",
      "         [ 0.4778, -0.0699, -0.1355,  ..., -0.3167, -0.3491,  0.3928],\n",
      "         [ 0.0277, -0.2178, -0.0825,  ...,  0.1441, -0.0881,  0.3086]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6393979787826538, 1.025882363319397, 0.00469265878200531, -0.0883202999830246, 0.02010583132505417]\n",
      "Last 5 elements: [0.4139424264431, -0.2759421765804291, 0.14927078783512115, -0.10446301102638245, 0.2625536322593689]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7154178619384766, 0.9007073044776917, 0.057250961661338806, -0.1387573629617691, 0.029691480100154877]\n",
      "Last 5 elements: [0.24717026948928833, -0.21137073636054993, 0.09227722883224487, -0.09547820687294006, 0.407181978225708]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7154178619384766, 0.9007073044776917, 0.057250961661338806, -0.1387573629617691, 0.029691480100154877]\n",
      "Last 5 elements: [0.24717026948928833, -0.21137073636054993, 0.09227722883224487, -0.09547820687294006, 0.407181978225708]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.5592455267906189, 0.7040871381759644, 0.04475334659218788, -0.10846728831529617, 0.02320997044444084]\n",
      "Last 5 elements: [0.3609234690666199, -0.3086481988430023, 0.13474524021148682, -0.13941937685012817, 0.5945760607719421]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5592455267906189, 0.7040871381759644, 0.04475334659218788, -0.10846728831529617, 0.02320997044444084]\n",
      "Last 5 elements: [0.3609234690666199, -0.3086481988430023, 0.13474524021148682, -0.13941937685012817, 0.5945760607719421]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.18618923425674438, 0.7741370797157288, -0.48564326763153076, -2.0108284950256348, -1.4162518978118896]\n",
      "Last 5 elements: [2.0438718795776367, -0.32347995042800903, -0.35756272077560425, -0.7236945629119873, -0.7792603373527527]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.18618923425674438, 0.7741370797157288, -0.48564326763153076, -2.0108284950256348, -1.4162518978118896]\n",
      "Last 5 elements: [2.0438718795776367, -0.32347995042800903, -0.35756272077560425, -0.7236945629119873, -0.7792603373527527]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.1537076234817505, 0.6390851736068726, -0.40092045068740845, -1.6600297689437866, -1.169179916381836]\n",
      "Last 5 elements: [1.8663302659988403, -0.29538077116012573, -0.3265029191970825, -0.6608306169509888, -0.7115696668624878]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.1537076234817505, 0.6390851736068726, -0.40092045068740845, -1.6600297689437866, -1.169179916381836]\n",
      "Last 5 elements: [1.8663302659988403, -0.29538077116012573, -0.3265029191970825, -0.6608306169509888, -0.7115696668624878]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.5466673374176025, -0.4216488003730774, 0.4648776650428772, -0.9777348041534424, -1.0370620489120483]\n",
      "Last 5 elements: [0.823261022567749, 1.4309353828430176, -1.014448642730713, 2.620934247970581, -3.1232972145080566]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5592455267906189, 0.7040871381759644, 0.04475334659218788, -0.10846728831529617, 0.02320997044444084]\n",
      "Last 5 elements: [0.3609234690666199, -0.3086481988430023, 0.13474524021148682, -0.13941937685012817, 0.5945760607719421]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.34410855174064636, 0.6714551448822021, -0.9093847274780273, 1.0202850103378296, 0.051418617367744446]\n",
      "Last 5 elements: [1.0950429439544678, 2.1998984813690186, 23.842329025268555, -25.16656494140625, -5.878223419189453]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.34410855174064636, 0.6714551448822021, -0.9093847274780273, 1.0202850103378296, 0.051418617367744446]\n",
      "Last 5 elements: [-0.5775200128555298, 0.41417089104652405, -1.1422204971313477, 0.5680729746818542, -0.649284303188324]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.12567560374736786, 0.24522939324378967, -0.3321262300014496, 0.372629314661026, 0.018779149278998375]\n",
      "Last 5 elements: [-0.1569829136133194, 0.11258094757795334, -0.3104811906814575, 0.15441499650478363, -0.17649005353450775]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.12567560374736786, 0.24522939324378967, -0.3321262300014496, 0.372629314661026, 0.018779149278998375]\n",
      "Last 5 elements: [-0.1569829136133194, 0.11258094757795334, -0.3104811906814575, 0.15441499650478363, -0.17649005353450775]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.29988089203834534, -0.08276625722646713, -0.12976208329200745, 0.2179829478263855, 0.271791011095047]\n",
      "Last 5 elements: [0.09202924370765686, -0.11037199944257736, -0.019307315349578857, 0.06405402719974518, 0.07323110103607178]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.021239638328552246, 0.3955830931663513, 0.2469944804906845, 0.0528801828622818, 0.10384980589151382]\n",
      "Last 5 elements: [0.09202924370765686, -0.11037199944257736, -0.019307315349578857, 0.06405402719974518, 0.07323110103607178]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021239638328552246, 0.3955830931663513, 0.2469944804906845, 0.0528801828622818, 0.10384980589151382]\n",
      "Last 5 elements: [0.12858185172080994, 0.5770989060401917, 0.5461597442626953, 0.2966224253177643, 0.256591796875]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.23515856266021729, 0.07679852843284607, 0.0612872838973999, 0.26746293902397156, -0.19160687923431396]\n",
      "Last 5 elements: [0.5287513732910156, -0.9720489382743835, -0.507605254650116, -0.2962122857570648, -0.01983720064163208]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6736066341400146, 0.9143620729446411, 0.06814785301685333, -0.09120240807533264, -0.004376258701086044]\n",
      "Last 5 elements: [0.3411823511123657, -0.3842012286186218, 0.002024926245212555, -0.14814481139183044, 0.40365493297576904]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.5267094969749451, 0.7149620652198792, 0.05328647419810295, -0.07131339609622955, -0.003421903820708394]\n",
      "Last 5 elements: [0.5035121440887451, -0.5669987797737122, 0.0029883577954024076, -0.21863003075122833, 0.5957083106040955]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5267094969749451, 0.7149620652198792, 0.05328647419810295, -0.07131339609622955, -0.003421903820708394]\n",
      "Last 5 elements: [0.5035121440887451, -0.5669987797737122, 0.0029883577954024076, -0.21863003075122833, 0.5957083106040955]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.0530807971954346, -0.904376208782196, -1.6638720035552979, -0.8819169998168945, -1.175485610961914]\n",
      "Last 5 elements: [-0.6826220750808716, -2.0781030654907227, -0.89708411693573, -0.28962498903274536, -1.2943158149719238]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.0530807971954346, -0.904376208782196, -1.6638720035552979, -0.8819169998168945, -1.175485610961914]\n",
      "Last 5 elements: [-0.6826220750808716, -2.0781030654907227, -0.89708411693573, -0.28962498903274536, -1.2943158149719238]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.27236244082450867, -0.260597825050354, -0.26495981216430664, -0.2582082450389862, -0.2772557735443115]\n",
      "Last 5 elements: [-0.22914007306098938, -0.23117518424987793, -0.2598404884338379, -0.12398719787597656, -0.27843737602233887]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5267094969749451, 0.7149620652198792, 0.05328647419810295, -0.07131339609622955, -0.003421903820708394]\n",
      "Last 5 elements: [0.5035121440887451, -0.5669987797737122, 0.0029883577954024076, -0.21863003075122833, 0.5957083106040955]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.3230501413345337, -0.0877029299736023, -0.18500180542469025, 1.0574955940246582, -0.14850538969039917]\n",
      "Last 5 elements: [0.2751786708831787, 0.8126206398010254, 0.28507861495018005, 0.035560242831707, -0.07109450548887253]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.08798672258853912, 0.02285519242286682, 0.04901804402470589, -0.2730540931224823, 0.04117397591471672]\n",
      "Last 5 elements: [-0.06305445730686188, -0.1878577321767807, -0.07407496869564056, -0.004409014713019133, 0.019795367494225502]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.348949134349823, -0.37028342485427856, -1.0656441450119019, -0.647800087928772, 0.40914976596832275]\n",
      "Last 5 elements: [-0.4612264335155487, -0.5074818730354309, -0.15189501643180847, 2.1567633152008057, -3.205531358718872]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5267094969749451, 0.7149620652198792, 0.05328647419810295, -0.07131339609622955, -0.003421903820708394]\n",
      "Last 5 elements: [0.5035121440887451, -0.5669987797737122, 0.0029883577954024076, -0.21863003075122833, 0.5957083106040955]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.348949134349823, -0.37028342485427856, -1.0656441450119019, -0.647800087928772, 0.40914976596832275]\n",
      "Last 5 elements: [-0.4612264335155487, -0.5074818730354309, -0.15189501643180847, 2.1567633152008057, -3.205531358718872]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6736,  0.9144,  0.0681,  ..., -0.0149,  0.1803, -0.3293],\n",
      "         [ 1.2107,  0.2025,  0.6493,  ...,  0.8374, -0.4336, -0.3246],\n",
      "         [-0.5289,  0.9981, -0.5780,  ...,  0.0419, -0.6080,  0.2191],\n",
      "         [ 0.0371,  0.2780, -0.1586,  ..., -0.3295, -0.1168,  0.3672],\n",
      "         [ 0.3263,  0.3230,  0.2294,  ..., -0.3382, -0.4930,  0.4986],\n",
      "         [ 0.0299, -0.0660,  0.0934,  ...,  0.0020, -0.1481,  0.4037]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7154178619384766, 0.9007073044776917, 0.057250961661338806, -0.1387573629617691, 0.029691480100154877]\n",
      "Last 5 elements: [0.24717026948928833, -0.21137073636054993, 0.09227722883224487, -0.09547820687294006, 0.407181978225708]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6115634441375732, 0.8485256433486938, -0.12132386863231659, -0.20638138055801392, 0.06837064027786255]\n",
      "Last 5 elements: [0.25917619466781616, -0.4744316041469574, -0.024982035160064697, 0.2353280782699585, -0.1662890911102295]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6115634441375732, 0.8485256433486938, -0.12132386863231659, -0.20638138055801392, 0.06837064027786255]\n",
      "Last 5 elements: [0.25917619466781616, -0.4744316041469574, -0.024982035160064697, 0.2353280782699585, -0.1662890911102295]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.28187108039855957, 0.3910875618457794, -0.05591847002506256, -0.09512168169021606, 0.031512197107076645]\n",
      "Last 5 elements: [0.37621021270751953, -0.6886667013168335, -0.036262962967157364, 0.3415932059288025, -0.24137885868549347]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.28187108039855957, 0.3910875618457794, -0.05591847002506256, -0.09512168169021606, 0.031512197107076645]\n",
      "Last 5 elements: [0.37621021270751953, -0.6886667013168335, -0.036262962967157364, 0.3415932059288025, -0.24137885868549347]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.49664121866226196, -0.6356462240219116, -0.6389593482017517, -1.2406954765319824, 0.589365541934967]\n",
      "Last 5 elements: [-0.39644768834114075, -0.0014813542366027832, -0.17705920338630676, 0.3041580319404602, -0.27241361141204834]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.49664121866226196, -0.6356462240219116, -0.6389593482017517, -1.2406954765319824, 0.589365541934967]\n",
      "Last 5 elements: [-0.39644768834114075, -0.0014813542366027832, -0.17705920338630676, 0.3041580319404602, -0.27241361141204834]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.35236096382141113, -0.45098334550857544, -0.4533339738845825, -0.8802585005760193, 0.4181477725505829]\n",
      "Last 5 elements: [-0.38108691573143005, -0.001423957641236484, -0.17019887268543243, 0.2923731207847595, -0.26185867190361023]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.35236096382141113, -0.45098334550857544, -0.4533339738845825, -0.8802585005760193, 0.4181477725505829]\n",
      "Last 5 elements: [-0.38108691573143005, -0.001423957641236484, -0.17019887268543243, 0.2923731207847595, -0.26185867190361023]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.4839353859424591, -0.29747796058654785, -0.14014269411563873, 0.8869118690490723, 0.5789194107055664]\n",
      "Last 5 elements: [1.2757761478424072, -1.8544764518737793, 2.3029472827911377, 2.226041316986084, -2.2206759452819824]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.28187108039855957, 0.3910875618457794, -0.05591847002506256, -0.09512168169021606, 0.031512197107076645]\n",
      "Last 5 elements: [0.37621021270751953, -0.6886667013168335, -0.036262962967157364, 0.3415932059288025, -0.24137885868549347]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.4803999662399292, -0.027890540659427643, -0.1445634663105011, 0.32106828689575195, -0.39521509408950806]\n",
      "Last 5 elements: [0.3428046405315399, -3.3426101207733154, -0.2000107765197754, -5.343489170074463, 2.7283010482788086]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.4803999662399292, -0.027890540659427643, -0.1445634663105011, 0.32106828689575195, -0.39521509408950806]\n",
      "Last 5 elements: [1.9441099166870117, 1.4472506046295166, 0.8454249501228333, -1.6673303842544556, -0.02346189320087433]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.03866375982761383, -0.002244698815047741, -0.011634820140898228, 0.025840358808636665, -0.03180787339806557]\n",
      "Last 5 elements: [1.9389349222183228, 1.4433982372283936, 0.8431745171546936, -1.6628921031951904, -0.023399440571665764]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.03866375982761383, -0.002244698815047741, -0.011634820140898228, 0.025840358808636665, -0.03180787339806557]\n",
      "Last 5 elements: [1.9389349222183228, 1.4433982372283936, 0.8431745171546936, -1.6628921031951904, -0.023399440571665764]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.030433423817157745, 0.025594014674425125, -0.02994488924741745, 0.03591389209032059, -0.01300047431141138]\n",
      "Last 5 elements: [-0.49587923288345337, 1.5458552837371826, 0.2963750660419464, -1.3801538944244385, -0.40657559037208557]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.005415075924247503, 0.06245986372232437, 0.005113982129842043, -0.03697314113378525, 0.08105377107858658]\n",
      "Last 5 elements: [-0.49587923288345337, 1.5458552837371826, 0.2963750660419464, -1.3801538944244385, -0.40657559037208557]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005415075924247503, 0.06245986372232437, 0.005113982129842043, -0.03697314113378525, 0.08105377107858658]\n",
      "Last 5 elements: [0.04056050628423691, 0.03572982922196388, 0.02199452370405197, 0.004806043114513159, -0.00535481097176671]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.004027597606182098, -0.030246494337916374, -0.07787802815437317, -0.12223570048809052, 0.23595044016838074]\n",
      "Last 5 elements: [-0.23362651467323303, -0.7072631120681763, -0.21762984991073608, 0.17719408869743347, 0.31172415614128113]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6108473539352417, 0.8431478142738342, -0.1351705938577652, -0.22811490297317505, 0.11032266914844513]\n",
      "Last 5 elements: [0.21763736009597778, -0.6001831293106079, -0.06367666274309158, 0.26683321595191956, -0.11086447536945343]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.284335196018219, 0.39246565103530884, -0.0629187598824501, -0.10618217289447784, 0.05135263130068779]\n",
      "Last 5 elements: [0.32301169633865356, -0.8907761573791504, -0.09450723975896835, 0.3960268795490265, -0.16454215347766876]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.284335196018219, 0.39246565103530884, -0.0629187598824501, -0.10618217289447784, 0.05135263130068779]\n",
      "Last 5 elements: [0.32301169633865356, -0.8907761573791504, -0.09450723975896835, 0.3960268795490265, -0.16454215347766876]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.20615249872207642, -0.5737330317497253, -1.2658017873764038, -2.7586312294006348, -1.899551272392273]\n",
      "Last 5 elements: [-3.249993324279785, 1.340722918510437, -0.5811722874641418, -1.7015478610992432, -0.2879568338394165]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.20615249872207642, -0.5737330317497253, -1.2658017873764038, -2.7586312294006348, -1.899551272392273]\n",
      "Last 5 elements: [-3.249993324279785, 1.340722918510437, -0.5811722874641418, -1.7015478610992432, -0.2879568338394165]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.09248901158571243, -0.20675955712795258, -0.2784469723701477, -0.16441726684570312, -0.2472442090511322]\n",
      "Last 5 elements: [-0.12131290882825851, 1.062668800354004, -0.20844493806362152, -0.2624862492084503, -0.12339069694280624]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.284335196018219, 0.39246565103530884, -0.0629187598824501, -0.10618217289447784, 0.05135263130068779]\n",
      "Last 5 elements: [0.32301169633865356, -0.8907761573791504, -0.09450723975896835, 0.3960268795490265, -0.16454215347766876]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.2709009647369385, -0.5112426280975342, 0.8202044367790222, -0.44178786873817444, 0.022139914333820343]\n",
      "Last 5 elements: [0.9113247394561768, 0.011251449584960938, -0.024894922971725464, -0.6992586851119995, 0.4059600830078125]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.025055361911654472, 0.10570430010557175, -0.22838343679904938, 0.07263755053281784, -0.0054739657789468765]\n",
      "Last 5 elements: [-0.11055545508861542, 0.011956564150750637, 0.005189220886677504, 0.183545783162117, -0.0500916987657547]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.4011283814907074, -0.7367700934410095, -0.5152831673622131, -0.2588721215724945, -0.24912029504776]\n",
      "Last 5 elements: [-1.0717829465866089, 0.6688274145126343, -0.15512824058532715, -0.07292073965072632, -0.3881857991218567]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.284335196018219, 0.39246565103530884, -0.0629187598824501, -0.10618217289447784, 0.05135263130068779]\n",
      "Last 5 elements: [0.32301169633865356, -0.8907761573791504, -0.09450723975896835, 0.3960268795490265, -0.16454215347766876]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.4011283814907074, -0.7367700934410095, -0.5152831673622131, -0.2588721215724945, -0.24912029504776]\n",
      "Last 5 elements: [-1.0717829465866089, 0.6688274145126343, -0.15512824058532715, -0.07292073965072632, -0.3881857991218567]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6108,  0.8431, -0.1352,  ...,  0.4775, -0.1781, -0.3634],\n",
      "         [ 1.4811,  0.0396,  0.6386,  ...,  0.6797, -0.1444,  0.1065],\n",
      "         [-0.0693,  0.7205, -0.1963,  ..., -0.1472,  0.2439, -0.8405],\n",
      "         [ 0.1542,  0.4826, -0.0828,  ..., -0.5045,  0.4407, -0.1241],\n",
      "         [ 1.0105,  1.0926,  0.4397,  ..., -0.5435, -0.3236, -0.0393],\n",
      "         [ 0.3245,  0.1260,  0.2553,  ..., -0.0637,  0.2668, -0.1109]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6115634441375732, 0.8485256433486938, -0.12132386863231659, -0.20638138055801392, 0.06837064027786255]\n",
      "Last 5 elements: [0.25917619466781616, -0.4744316041469574, -0.024982035160064697, 0.2353280782699585, -0.1662890911102295]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.539526641368866, 0.712149977684021, -0.22678804397583008, -0.27414241433143616, 0.06602903455495834]\n",
      "Last 5 elements: [0.027074158191680908, -0.48126548528671265, -0.09125849604606628, 0.25386789441108704, -0.17988398671150208]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.539526641368866, 0.712149977684021, -0.22678804397583008, -0.27414241433143616, 0.06602903455495834]\n",
      "Last 5 elements: [0.027074158191680908, -0.48126548528671265, -0.09125849604606628, 0.25386789441108704, -0.17988398671150208]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2207273542881012, 0.2913497984409332, -0.0927819311618805, -0.11215522140264511, 0.02701333537697792]\n",
      "Last 5 elements: [0.03948742523789406, -0.7019215226173401, -0.1330997198820114, 0.37026411294937134, -0.26235923171043396]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2207273542881012, 0.2913497984409332, -0.0927819311618805, -0.11215522140264511, 0.02701333537697792]\n",
      "Last 5 elements: [0.03948742523789406, -0.7019215226173401, -0.1330997198820114, 0.37026411294937134, -0.26235923171043396]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.6272692680358887, 0.13807642459869385, -0.19401568174362183, -0.007872343063354492, 0.2820684313774109]\n",
      "Last 5 elements: [0.4806552529335022, 0.7309398055076599, -1.0253797769546509, 0.623407781124115, 1.0483638048171997]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.6272692680358887, 0.13807642459869385, -0.19401568174362183, -0.007872343063354492, 0.2820684313774109]\n",
      "Last 5 elements: [0.4806552529335022, 0.7309398055076599, -1.0253797769546509, 0.623407781124115, 1.0483638048171997]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.37933409214019775, 0.08350017666816711, -0.11732881516218185, -0.004760711453855038, 0.170577734708786]\n",
      "Last 5 elements: [0.3602809011936188, 0.5478847026824951, -0.7685856819152832, 0.467282772064209, 0.7858136296272278]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.37933409214019775, 0.08350017666816711, -0.11732881516218185, -0.004760711453855038, 0.170577734708786]\n",
      "Last 5 elements: [0.3602809011936188, 0.5478847026824951, -0.7685856819152832, 0.467282772064209, 0.7858136296272278]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.3539204001426697, -0.16918352246284485, -0.3642716109752655, -0.0240151509642601, 0.06387785822153091]\n",
      "Last 5 elements: [1.9368259906768799, -0.8546289205551147, -0.4338666796684265, -2.5710291862487793, -2.1721043586730957]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2207273542881012, 0.2913497984409332, -0.0927819311618805, -0.11215522140264511, 0.02701333537697792]\n",
      "Last 5 elements: [0.03948742523789406, -0.7019215226173401, -0.1330997198820114, 0.37026411294937134, -0.26235923171043396]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.17528578639030457, 0.06282036751508713, 0.0011536702513694763, -0.18072184920310974, -0.2144555002450943]\n",
      "Last 5 elements: [0.18582147359848022, 7.04116153717041, 7.5545125007629395, -12.420186042785645, 32.918033599853516]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.17528578639030457, 0.06282036751508713, 0.0011536702513694763, -0.18072184920310974, -0.2144555002450943]\n",
      "Last 5 elements: [-0.35530316829681396, 0.48348838090896606, 0.3521299958229065, 0.3711214065551758, -0.9972385168075562]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.01517475862056017, 0.005438455380499363, 9.987499652197585e-05, -0.01564536616206169, -0.018565740436315536]\n",
      "Last 5 elements: [-0.5069652199745178, 0.6898666024208069, 0.5024375319480896, 0.5295354723930359, -1.4229122400283813]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.01517475862056017, 0.005438455380499363, 9.987499652197585e-05, -0.01564536616206169, -0.018565740436315536]\n",
      "Last 5 elements: [-0.5069652199745178, 0.6898666024208069, 0.5024375319480896, 0.5295354723930359, -1.4229122400283813]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.0409197099506855, 0.01144598238170147, -0.003276389092206955, -0.05358045548200607, 0.02216961979866028]\n",
      "Last 5 elements: [-0.849539041519165, -0.6894707679748535, -0.07901811599731445, 0.4054558277130127, 0.5497414469718933]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.02434205636382103, -0.02782806009054184, -0.0034704990684986115, 0.07751426100730896, -0.09195458143949509]\n",
      "Last 5 elements: [-0.849539041519165, -0.6894707679748535, -0.07901811599731445, 0.4054558277130127, 0.5497414469718933]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.02434205636382103, -0.02782806009054184, -0.0034704990684986115, 0.07751426100730896, -0.09195458143949509]\n",
      "Last 5 elements: [-0.07447905093431473, -0.0638292133808136, 0.007587154395878315, -0.024669736623764038, 0.04143264517188072]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.09353069961071014, 0.4191793203353882, 0.01135561615228653, 0.048006415367126465, -0.04947324097156525]\n",
      "Last 5 elements: [0.6905476450920105, 0.16795195639133453, 0.13545912504196167, -0.5793349742889404, -0.39202386140823364]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5228968858718872, 0.7866801023483276, -0.2247690111398697, -0.2656068801879883, 0.05723268538713455]\n",
      "Last 5 elements: [0.1498536467552185, -0.45140358805656433, -0.06717383861541748, 0.15086203813552856, -0.24958589673042297]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2137833833694458, 0.3216296136379242, -0.09189551323652267, -0.10859183967113495, 0.02339925244450569]\n",
      "Last 5 elements: [0.2225065678358078, -0.670255720615387, -0.09974145144224167, 0.2240038514137268, -0.37059158086776733]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2137833833694458, 0.3216296136379242, -0.09189551323652267, -0.10859183967113495, 0.02339925244450569]\n",
      "Last 5 elements: [0.2225065678358078, -0.670255720615387, -0.09974145144224167, 0.2240038514137268, -0.37059158086776733]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.564788818359375, -1.8196802139282227, -1.6615147590637207, -2.7953476905822754, -0.9902257919311523]\n",
      "Last 5 elements: [-1.3688658475875854, -0.6537774205207825, -1.0456969738006592, -1.0504099130630493, -0.8987544775009155]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.564788818359375, -1.8196802139282227, -1.6615147590637207, -2.7953476905822754, -0.9902257919311523]\n",
      "Last 5 elements: [-1.3688658475875854, -0.6537774205207825, -1.0456969738006592, -1.0504099130630493, -0.8987544775009155]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.18322651088237762, -0.2537948787212372, -0.26510924100875854, -0.16094520688056946, -0.2682199776172638]\n",
      "Last 5 elements: [-0.27761030197143555, -0.22368262708187103, -0.2719358503818512, -0.27220994234085083, -0.2600155174732208]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2137833833694458, 0.3216296136379242, -0.09189551323652267, -0.10859183967113495, 0.02339925244450569]\n",
      "Last 5 elements: [0.2225065678358078, -0.670255720615387, -0.09974145144224167, 0.2240038514137268, -0.37059158086776733]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.07824370265007019, -0.4990103542804718, 0.2892381250858307, 0.31725969910621643, -0.26964622735977173]\n",
      "Last 5 elements: [-0.5570529699325562, 0.7194832563400269, 0.6440373063087463, 0.12943662703037262, 0.4569101333618164]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.01433632057160139, 0.1266462653875351, -0.07667969912290573, -0.05106142908334732, 0.07232450693845749]\n",
      "Last 5 elements: [0.15464363992214203, -0.1609359085559845, -0.17513683438301086, -0.035233937203884125, -0.1188037246465683]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2349289208650589, -0.3117493987083435, 0.6149442195892334, 0.6446205377578735, 0.3194391131401062]\n",
      "Last 5 elements: [-0.9832570552825928, 1.2076104879379272, 0.14120765030384064, -0.07616861164569855, 2.04331374168396]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2137833833694458, 0.3216296136379242, -0.09189551323652267, -0.10859183967113495, 0.02339925244450569]\n",
      "Last 5 elements: [0.2225065678358078, -0.670255720615387, -0.09974145144224167, 0.2240038514137268, -0.37059158086776733]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2349289208650589, -0.3117493987083435, 0.6149442195892334, 0.6446205377578735, 0.3194391131401062]\n",
      "Last 5 elements: [-0.9832570552825928, 1.2076104879379272, 0.14120765030384064, -0.07616861164569855, 2.04331374168396]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.5229,  0.7867, -0.2248,  ...,  0.3950, -0.4130, -0.4901],\n",
      "         [ 1.4615, -0.0421,  0.8680,  ...,  0.4081, -0.0669,  0.2595],\n",
      "         [-0.2232, -0.0154, -0.8866,  ..., -0.2271, -0.3600, -0.8407],\n",
      "         [ 0.0510,  0.2423, -0.4973,  ..., -0.3698,  0.3515, -0.4881],\n",
      "         [ 0.4487,  0.8521, -0.6980,  ..., -0.8828, -0.2941, -0.2860],\n",
      "         [ 0.2264, -0.0576,  0.1272,  ..., -0.0672,  0.1509, -0.2496]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.539526641368866, 0.712149977684021, -0.22678804397583008, -0.27414241433143616, 0.06602903455495834]\n",
      "Last 5 elements: [0.027074158191680908, -0.48126548528671265, -0.09125849604606628, 0.25386789441108704, -0.17988398671150208]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.564667284488678, 0.7312510013580322, -0.11543182283639908, -0.1509932279586792, 0.11402902007102966]\n",
      "Last 5 elements: [-0.024969637393951416, -0.2366902232170105, -0.04206709563732147, 0.13731925189495087, 0.11371564865112305]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.564667284488678, 0.7312510013580322, -0.11543182283639908, -0.1509932279586792, 0.11402902007102966]\n",
      "Last 5 elements: [-0.024969637393951416, -0.2366902232170105, -0.04206709563732147, 0.13731925189495087, 0.11371564865112305]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.22790145874023438, 0.29513514041900635, -0.04658864066004753, -0.06094133108854294, 0.04602246358990669]\n",
      "Last 5 elements: [-0.035836249589920044, -0.33969616889953613, -0.06037440523505211, 0.1970796436071396, 0.1632039099931717]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22790145874023438, 0.29513514041900635, -0.04658864066004753, -0.06094133108854294, 0.04602246358990669]\n",
      "Last 5 elements: [-0.035836249589920044, -0.33969616889953613, -0.06037440523505211, 0.1970796436071396, 0.1632039099931717]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.44195544719696045, -0.3936370611190796, -0.8457129597663879, 0.4818977117538452, -0.8726322650909424]\n",
      "Last 5 elements: [0.648222804069519, 0.2915458083152771, -1.3126943111419678, 0.17809055745601654, -0.505698025226593]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.44195544719696045, -0.3936370611190796, -0.8457129597663879, 0.4818977117538452, -0.8726322650909424]\n",
      "Last 5 elements: [0.648222804069519, 0.2915458083152771, -1.3126943111419678, 0.17809055745601654, -0.505698025226593]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.503900408744812, -0.4488096535205841, -0.9642489552497864, 0.5494409799575806, -0.9949412941932678]\n",
      "Last 5 elements: [0.5459973812103271, 0.24556873738765717, -1.10568106174469, 0.1500054895877838, -0.42594894766807556]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.503900408744812, -0.4488096535205841, -0.9642489552497864, 0.5494409799575806, -0.9949412941932678]\n",
      "Last 5 elements: [0.5459973812103271, 0.24556873738765717, -1.10568106174469, 0.1500054895877838, -0.42594894766807556]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.0996849536895752, 0.8079324960708618, -1.0833193063735962, 0.26141035556793213, 0.8594847917556763]\n",
      "Last 5 elements: [0.45417144894599915, -0.17547783255577087, 0.8102666735649109, 1.8639717102050781, -1.3916940689086914]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22790145874023438, 0.29513514041900635, -0.04658864066004753, -0.06094133108854294, 0.04602246358990669]\n",
      "Last 5 elements: [-0.035836249589920044, -0.33969616889953613, -0.06037440523505211, 0.1970796436071396, 0.1632039099931717]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.03148326277732849, 0.3231655955314636, 0.13227201998233795, -0.28280314803123474, -0.18276211619377136]\n",
      "Last 5 elements: [0.48690277338027954, -8.179543495178223, 2.0490190982818604, 1.8487520217895508, -7.130880355834961]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.03148326277732849, 0.3231655955314636, 0.13227201998233795, -0.28280314803123474, -0.18276211619377136]\n",
      "Last 5 elements: [-0.9906376600265503, -0.22855573892593384, -1.136659860610962, -0.7972129583358765, 0.06277525424957275]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.0024476952385157347, 0.02512480691075325, 0.010283609852194786, -0.021986791864037514, -0.014209008775651455]\n",
      "Last 5 elements: [-1.129817008972168, -0.2606666088104248, -1.2963545322418213, -0.9092171788215637, 0.07159484177827835]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.0024476952385157347, 0.02512480691075325, 0.010283609852194786, -0.021986791864037514, -0.014209008775651455]\n",
      "Last 5 elements: [-1.129817008972168, -0.2606666088104248, -1.2963545322418213, -0.9092171788215637, 0.07159484177827835]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.21072110533714294, -0.04792964085936546, -0.19899767637252808, 0.06073736771941185, -0.009674559347331524]\n",
      "Last 5 elements: [-0.08411293476819992, -1.1565138101577759, 0.16094565391540527, 0.40736842155456543, 0.515820324420929]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.13243363797664642, -0.03915555775165558, 0.09052781760692596, -0.11137478053569794, 0.01994188129901886]\n",
      "Last 5 elements: [-0.08411293476819992, -1.1565138101577759, 0.16094565391540527, 0.40736842155456543, 0.515820324420929]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.13243363797664642, -0.03915555775165558, 0.09052781760692596, -0.11137478053569794, 0.01994188129901886]\n",
      "Last 5 elements: [-0.16857875883579254, -0.45835432410240173, -0.01142164971679449, 0.2554987967014313, 0.3051793873310089]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.09272176772356033, 0.09427003562450409, -0.12205952405929565, -0.06205054745078087, 0.18633151054382324]\n",
      "Last 5 elements: [0.44135379791259766, -0.30314695835113525, -0.4352226257324219, -0.34491434693336487, -0.3522343933582306]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5481813549995422, 0.7480122447013855, -0.13713403046131134, -0.1620258241891861, 0.14715880155563354]\n",
      "Last 5 elements: [0.05350314825773239, -0.2905898094177246, -0.11944975703954697, 0.07599341869354248, 0.05108831077814102]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.22453473508358002, 0.306385338306427, -0.056170012801885605, -0.06636567413806915, 0.060276150703430176]\n",
      "Last 5 elements: [0.0783839076757431, -0.4257238209247589, -0.17499789595603943, 0.11133290827274323, 0.07484608888626099]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22453473508358002, 0.306385338306427, -0.056170012801885605, -0.06636567413806915, 0.060276150703430176]\n",
      "Last 5 elements: [0.0783839076757431, -0.4257238209247589, -0.17499789595603943, 0.11133290827274323, 0.07484608888626099]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.8029637336730957, 0.0361303985118866, -1.2718713283538818, -0.6190134286880493, -0.17984303832054138]\n",
      "Last 5 elements: [-1.9148330688476562, -3.281827449798584, 0.12138829380273819, 0.4513617157936096, -0.3950801491737366]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.8029637336730957, 0.0361303985118866, -1.2718713283538818, -0.6190134286880493, -0.17984303832054138]\n",
      "Last 5 elements: [-1.9148330688476562, -3.281827449798584, 0.12138829380273819, 0.4513617157936096, -0.3950801491737366]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.16022928059101105, 0.01839151605963707, -0.2784598171710968, -0.2166583240032196, -0.0818573608994484]\n",
      "Last 5 elements: [-0.2459389716386795, -0.11880183964967728, 0.06437341123819351, 0.2757652699947357, -0.15901775658130646]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22453473508358002, 0.306385338306427, -0.056170012801885605, -0.06636567413806915, 0.060276150703430176]\n",
      "Last 5 elements: [0.0783839076757431, -0.4257238209247589, -0.17499789595603943, 0.11133290827274323, 0.07484608888626099]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.08774077892303467, -0.24913270771503448, -0.22390764951705933, 0.06056812405586243, 0.06209959089756012]\n",
      "Last 5 elements: [-1.1462782621383667, 0.01090860366821289, 0.9603756070137024, 0.9329144358634949, 0.8115135431289673]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.014058642089366913, -0.004581928253173828, 0.06234928220510483, -0.013122588396072388, -0.005083308555185795]\n",
      "Last 5 elements: [0.28191450238227844, -0.0012959621381014585, 0.06182265281677246, 0.2572653889656067, -0.12904506921768188]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.010626770555973053, -0.24670952558517456, 0.5784288644790649, 0.5217065811157227, -0.4111449718475342]\n",
      "Last 5 elements: [0.004722416400909424, 0.47825711965560913, 0.5912737846374512, -1.0211118459701538, 0.36590999364852905]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22453473508358002, 0.306385338306427, -0.056170012801885605, -0.06636567413806915, 0.060276150703430176]\n",
      "Last 5 elements: [0.0783839076757431, -0.4257238209247589, -0.17499789595603943, 0.11133290827274323, 0.07484608888626099]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.010626770555973053, -0.24670952558517456, 0.5784288644790649, 0.5217065811157227, -0.4111449718475342]\n",
      "Last 5 elements: [0.004722416400909424, 0.47825711965560913, 0.5912737846374512, -1.0211118459701538, 0.36590999364852905]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.5482,  0.7480, -0.1371,  ...,  0.2644, -0.4358, -0.4873],\n",
      "         [ 1.3767,  0.2300,  1.0337,  ...,  0.2470,  0.0714,  0.3231],\n",
      "         [-0.1348,  0.1694, -1.1707,  ...,  0.0097, -0.0257, -0.4654],\n",
      "         [ 0.2483,  0.1678, -0.5005,  ..., -0.2681,  0.4980, -0.1999],\n",
      "         [ 0.5498,  0.8987, -0.5013,  ..., -0.1099,  0.3170,  0.3233],\n",
      "         [ 0.3282, -0.0403,  0.3194,  ..., -0.1194,  0.0760,  0.0511]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.564667284488678, 0.7312510013580322, -0.11543182283639908, -0.1509932279586792, 0.11402902007102966]\n",
      "Last 5 elements: [-0.024969637393951416, -0.2366902232170105, -0.04206709563732147, 0.13731925189495087, 0.11371564865112305]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5462918877601624, 0.704147219657898, -0.03428927809000015, -0.06926630437374115, 0.07405715435743332]\n",
      "Last 5 elements: [0.05434279516339302, -0.20555561780929565, -0.01432117074728012, -0.10556045174598694, 0.11614717543125153]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5462918877601624, 0.704147219657898, -0.03428927809000015, -0.06926630437374115, 0.07405715435743332]\n",
      "Last 5 elements: [0.05434279516339302, -0.20555561780929565, -0.01432117074728012, -0.10556045174598694, 0.11614717543125153]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.21745780110359192, 0.28029394149780273, -0.013649243861436844, -0.027572253718972206, 0.029479308053851128]\n",
      "Last 5 elements: [0.07701438665390015, -0.291312575340271, -0.02029590494930744, -0.1495998352766037, 0.1646033078432083]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.21745780110359192, 0.28029394149780273, -0.013649243861436844, -0.027572253718972206, 0.029479308053851128]\n",
      "Last 5 elements: [0.07701438665390015, -0.291312575340271, -0.02029590494930744, -0.1495998352766037, 0.1646033078432083]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.08878877758979797, -0.23561561107635498, 1.4441453218460083, 0.4714559316635132, -1.039656639099121]\n",
      "Last 5 elements: [0.4950031042098999, 0.16773667931556702, -0.20263469219207764, 0.8515352606773376, 0.23442529141902924]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.08878877758979797, -0.23561561107635498, 1.4441453218460083, 0.4714559316635132, -1.039656639099121]\n",
      "Last 5 elements: [0.4950031042098999, 0.16773667931556702, -0.20263469219207764, 0.8515352606773376, 0.23442529141902924]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.10656177997589111, -0.28277918696403503, 1.7332223653793335, 0.5658280849456787, -1.2477664947509766]\n",
      "Last 5 elements: [0.44599515199661255, 0.1511298567056656, -0.18257278203964233, 0.7672287225723267, 0.21121592819690704]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.10656177997589111, -0.28277918696403503, 1.7332223653793335, 0.5658280849456787, -1.2477664947509766]\n",
      "Last 5 elements: [0.44599515199661255, 0.1511298567056656, -0.18257278203964233, 0.7672287225723267, 0.21121592819690704]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.39459428191185, 1.506284236907959, -1.0086925029754639, -0.7265484929084778, -0.532785952091217]\n",
      "Last 5 elements: [0.44454801082611084, 1.5651819705963135, -0.019030392169952393, 2.825265884399414, -0.10608600825071335]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.21745780110359192, 0.28029394149780273, -0.013649243861436844, -0.027572253718972206, 0.029479308053851128]\n",
      "Last 5 elements: [0.07701438665390015, -0.291312575340271, -0.02029590494930744, -0.1495998352766037, 0.1646033078432083]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.07362060993909836, 0.1023855060338974, 0.17054007947444916, -0.10497500747442245, -0.19371601939201355]\n",
      "Last 5 elements: [0.45474058389663696, 1.6894536018371582, 11.539928436279297, -2.4416491985321045, 0.4080733358860016]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.07362060993909836, 0.1023855060338974, 0.17054007947444916, -0.10497500747442245, -0.19371601939201355]\n",
      "Last 5 elements: [0.6251023411750793, 0.8525586128234863, -1.2998313903808594, 0.3062691390514374, -0.9075238108634949]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.006318353582173586, 0.008787048049271107, 0.014636289328336716, -0.009009286761283875, -0.01662532240152359]\n",
      "Last 5 elements: [0.7067945003509521, 0.9639761447906494, -1.4697011709213257, 0.34629425406455994, -1.0261244773864746]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.006318353582173586, 0.008787048049271107, 0.014636289328336716, -0.009009286761283875, -0.01662532240152359]\n",
      "Last 5 elements: [0.7067945003509521, 0.9639761447906494, -1.4697011709213257, 0.34629425406455994, -1.0261244773864746]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.21450762450695038, -0.23260287940502167, 0.23760749399662018, 0.09190189838409424, -0.018562076613307]\n",
      "Last 5 elements: [0.4413199722766876, 0.3061084747314453, 0.12580493092536926, -0.3855586051940918, -0.373079389333725]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.08412527292966843, 0.19584979116916656, -0.15189103782176971, -0.3001163899898529, 0.1903519183397293]\n",
      "Last 5 elements: [0.4413199722766876, 0.3061084747314453, 0.12580493092536926, -0.3855586051940918, -0.373079389333725]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.08412527292966843, 0.19584979116916656, -0.15189103782176971, -0.3001163899898529, 0.1903519183397293]\n",
      "Last 5 elements: [0.02270817756652832, 0.08995237201452255, 0.19181466102600098, -0.05827569589018822, -0.12037372589111328]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.017728224396705627, 0.09506139904260635, -0.0027294158935546875, 0.04089480638504028, 0.016344450414180756]\n",
      "Last 5 elements: [-0.1302560418844223, -0.0070604607462882996, 0.24173052608966827, -0.6204124689102173, 0.6279101371765137]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5494439601898193, 0.7210491299629211, -0.03477456793189049, -0.06199520081281662, 0.07696320116519928]\n",
      "Last 5 elements: [0.03118324838578701, -0.20681096613407135, 0.028658561408519745, -0.21586990356445312, 0.22778970003128052]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.22100722789764404, 0.29003334045410156, -0.013987652026116848, -0.024936825037002563, 0.030957521870732307]\n",
      "Last 5 elements: [0.043516624718904495, -0.2886073589324951, 0.03999339044094086, -0.3012492060661316, 0.3178834319114685]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22100722789764404, 0.29003334045410156, -0.013987652026116848, -0.024936825037002563, 0.030957521870732307]\n",
      "Last 5 elements: [0.043516624718904495, -0.2886073589324951, 0.03999339044094086, -0.3012492060661316, 0.3178834319114685]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-3.0376040935516357, -3.2332026958465576, -2.0935895442962646, -3.677624225616455, -2.4550211429595947]\n",
      "Last 5 elements: [-2.369384527206421, -2.063847303390503, -1.7128016948699951, -1.2646846771240234, -0.21927908062934875]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-3.0376040935516357, -3.2332026958465576, -2.0935895442962646, -3.677624225616455, -2.4550211429595947]\n",
      "Last 5 elements: [-2.369384527206421, -2.063847303390503, -1.7128016948699951, -1.2646846771240234, -0.21927908062934875]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.13898760080337524, -0.12265215069055557, -0.22971166670322418, -0.09068839251995087, -0.194123774766922]\n",
      "Last 5 elements: [-0.20267069339752197, -0.2325143963098526, -0.2617172598838806, -0.27844372391700745, -0.0976666510105133]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22100722789764404, 0.29003334045410156, -0.013987652026116848, -0.024936825037002563, 0.030957521870732307]\n",
      "Last 5 elements: [0.043516624718904495, -0.2886073589324951, 0.03999339044094086, -0.3012492060661316, 0.3178834319114685]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.4379534125328064, 0.26099568605422974, 0.7430156469345093, 0.186923086643219, 0.19493868947029114]\n",
      "Last 5 elements: [0.08747968077659607, 0.2676185369491577, 0.2289760708808899, -0.7272460460662842, 0.5664393901824951]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.06087009236216545, -0.03201168403029442, -0.17067936062812805, -0.016951754689216614, -0.03784223273396492]\n",
      "Last 5 elements: [-0.017729567363858223, -0.062225162982940674, -0.059926990419626236, 0.20249709486961365, -0.05532223731279373]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2104148417711258, -0.2822517454624176, 0.2614898979663849, -0.28653186559677124, -0.26170408725738525]\n",
      "Last 5 elements: [0.5308735370635986, -0.19470639526844025, -0.02735719084739685, 0.670646071434021, -0.8705173134803772]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.22100722789764404, 0.29003334045410156, -0.013987652026116848, -0.024936825037002563, 0.030957521870732307]\n",
      "Last 5 elements: [0.043516624718904495, -0.2886073589324951, 0.03999339044094086, -0.3012492060661316, 0.3178834319114685]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2104148417711258, -0.2822517454624176, 0.2614898979663849, -0.28653186559677124, -0.26170408725738525]\n",
      "Last 5 elements: [0.5308735370635986, -0.19470639526844025, -0.02735719084739685, 0.670646071434021, -0.8705173134803772]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-5.4944e-01,  7.2105e-01, -3.4775e-02,  ...,  1.6813e-01,\n",
      "          -4.7640e-01, -4.5719e-01],\n",
      "         [ 1.2375e+00,  5.6042e-01,  9.0055e-01,  ...,  1.5143e-02,\n",
      "          -3.6915e-02,  1.8743e-01],\n",
      "         [ 5.9996e-01, -2.2485e-01, -9.7866e-01,  ..., -3.4749e-02,\n",
      "          -9.1358e-02, -9.0454e-04],\n",
      "         [ 3.5379e-01, -4.9598e-02, -3.4704e-01,  ..., -2.2117e-01,\n",
      "           2.6820e-01, -1.3859e-02],\n",
      "         [ 8.9464e-01,  4.6988e-01, -3.8737e-01,  ..., -5.9561e-02,\n",
      "           1.5320e-01,  8.3711e-01],\n",
      "         [ 4.5905e-01, -1.4777e-01,  3.9361e-01,  ...,  2.8659e-02,\n",
      "          -2.1587e-01,  2.2779e-01]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5462918877601624, 0.704147219657898, -0.03428927809000015, -0.06926630437374115, 0.07405715435743332]\n",
      "Last 5 elements: [0.05434279516339302, -0.20555561780929565, -0.01432117074728012, -0.10556045174598694, 0.11614717543125153]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5868557691574097, 0.6708647012710571, 0.011718381196260452, -0.11294061690568924, 0.030432168394327164]\n",
      "Last 5 elements: [0.12557265162467957, -0.24142980575561523, 0.023794448003172874, -0.09662891179323196, 0.07301156222820282]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5868557691574097, 0.6708647012710571, 0.011718381196260452, -0.11294061690568924, 0.030432168394327164]\n",
      "Last 5 elements: [0.12557265162467957, -0.24142980575561523, 0.023794448003172874, -0.09662891179323196, 0.07301156222820282]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.23431463539600372, 0.26785698533058167, 0.004678812809288502, -0.04509394243359566, 0.012150689959526062]\n",
      "Last 5 elements: [0.17418688535690308, -0.3348970115184784, 0.03300623595714569, -0.13403785228729248, 0.10127727687358856]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.23431463539600372, 0.26785698533058167, 0.004678812809288502, -0.04509394243359566, 0.012150689959526062]\n",
      "Last 5 elements: [0.17418688535690308, -0.3348970115184784, 0.03300623595714569, -0.13403785228729248, 0.10127727687358856]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.0409199595451355, -0.08927381038665771, -0.2891252040863037, 1.191823124885559, 0.06550085544586182]\n",
      "Last 5 elements: [-1.520674228668213, 0.8731348514556885, -0.5077365040779114, -1.006786584854126, 0.4152625799179077]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.0409199595451355, -0.08927381038665771, -0.2891252040863037, 1.191823124885559, 0.06550085544586182]\n",
      "Last 5 elements: [-1.520674228668213, 0.8731348514556885, -0.5077365040779114, -1.006786584854126, 0.4152625799179077]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.04892873018980026, -0.10674629360437393, -0.34571218490600586, 1.4250842332839966, 0.07832054793834686]\n",
      "Last 5 elements: [-1.3255650997161865, 0.761107861995697, -0.44259169697761536, -0.8776114583015442, 0.3619825839996338]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.04892873018980026, -0.10674629360437393, -0.34571218490600586, 1.4250842332839966, 0.07832054793834686]\n",
      "Last 5 elements: [-1.3255650997161865, 0.761107861995697, -0.44259169697761536, -0.8776114583015442, 0.3619825839996338]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.4484171867370605, 1.0827107429504395, 0.2544407248497009, -0.7277575731277466, 1.2911282777786255]\n",
      "Last 5 elements: [0.3930166959762573, -3.647508144378662, 0.875737190246582, -1.283163070678711, 3.7419180870056152]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.23431463539600372, 0.26785698533058167, 0.004678812809288502, -0.04509394243359566, 0.012150689959526062]\n",
      "Last 5 elements: [0.17418688535690308, -0.3348970115184784, 0.03300623595714569, -0.13403785228729248, 0.10127727687358856]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.8930181264877319, -0.1596759408712387, -0.005029208958148956, 0.06630277633666992, 0.35546213388442993]\n",
      "Last 5 elements: [2.3932993412017822, -8.791945457458496, -5.291860580444336, 1.815076470375061, 0.8100728988647461]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.8930181264877319, -0.1596759408712387, -0.005029208958148956, 0.06630277633666992, 0.35546213388442993]\n",
      "Last 5 elements: [-0.1283714771270752, -0.5104958415031433, -0.7825491428375244, -0.9643626809120178, -1.2641983032226562]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.06566876173019409, -0.01174189057201147, -0.00036982668098062277, 0.004875624552369118, 0.02613917738199234]\n",
      "Last 5 elements: [-0.1384304165840149, -0.55049729347229, -0.8438681960105896, -1.0399283170700073, -1.3632584810256958]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.06566876173019409, -0.01174189057201147, -0.00036982668098062277, 0.004875624552369118, 0.02613917738199234]\n",
      "Last 5 elements: [-0.1384304165840149, -0.55049729347229, -0.8438681960105896, -1.0399283170700073, -1.3632584810256958]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.14885902404785156, -0.5071532130241394, 0.08785168826580048, 0.1069813147187233, 0.12268548458814621]\n",
      "Last 5 elements: [-0.1192803829908371, 0.9785023927688599, 0.21269315481185913, 1.167021632194519, 0.02354239672422409]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.015577060170471668, -0.012779487296938896, 0.006868468597531319, 0.0036353496834635735, 0.023021455854177475]\n",
      "Last 5 elements: [-0.1192803829908371, 0.9785023927688599, 0.21269315481185913, 1.167021632194519, 0.02354239672422409]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.015577060170471668, -0.012779487296938896, 0.006868468597531319, 0.0036353496834635735, 0.023021455854177475]\n",
      "Last 5 elements: [0.027936358004808426, 0.4685901999473572, 0.12058058381080627, 0.7923274636268616, -0.026775145903229713]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.10427769273519516, 0.20033375918865204, 0.18247061967849731, -0.03236645460128784, -0.02503202296793461]\n",
      "Last 5 elements: [0.09215787053108215, -0.541131854057312, -0.3132249116897583, -0.9204474687576294, -0.35288187861442566]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6053963899612427, 0.7064840793609619, 0.04416168853640556, -0.11869537830352783, 0.025981470942497253]\n",
      "Last 5 elements: [0.1419583410024643, -0.3376431465148926, -0.03189699351787567, -0.2602846324443817, 0.010269097983837128]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.242975115776062, 0.2835465371608734, 0.017724240198731422, -0.04763824865221977, 0.010427632369101048]\n",
      "Last 5 elements: [0.19751916825771332, -0.4697927236557007, -0.04438110440969467, -0.3621569871902466, 0.014288302510976791]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.242975115776062, 0.2835465371608734, 0.017724240198731422, -0.04763824865221977, 0.010427632369101048]\n",
      "Last 5 elements: [0.19751916825771332, -0.4697927236557007, -0.04438110440969467, -0.3621569871902466, 0.014288302510976791]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-3.5378174781799316, -3.1780476570129395, -1.1637468338012695, -2.110321044921875, -0.7855398654937744]\n",
      "Last 5 elements: [-0.5814455151557922, -1.1729872226715088, -2.264112710952759, 0.25057822465896606, -2.137566328048706]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-3.5378174781799316, -3.1780476570129395, -1.1637468338012695, -2.110321044921875, -0.7855398654937744]\n",
      "Last 5 elements: [-0.5814455151557922, -1.1729872226715088, -2.264112710952759, 0.25057822465896606, -2.137566328048706]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.09996156394481659, -0.1271226555109024, -0.2769567668437958, -0.22812087833881378, -0.2459738552570343]\n",
      "Last 5 elements: [-0.20850640535354614, -0.277195006608963, -0.21314145624637604, 0.14090484380722046, -0.22551074624061584]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.242975115776062, 0.2835465371608734, 0.017724240198731422, -0.04763824865221977, 0.010427632369101048]\n",
      "Last 5 elements: [0.19751916825771332, -0.4697927236557007, -0.04438110440969467, -0.3621569871902466, 0.014288302510976791]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.5826334953308105, -0.15976837277412415, 0.27528810501098633, -0.4596404433250427, 0.5916657447814941]\n",
      "Last 5 elements: [1.160874843597412, -0.3158918023109436, 0.8004879951477051, -0.6919119358062744, 0.19839562475681305]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.05824095383286476, 0.020310180261731148, -0.07624290138483047, 0.10485358536243439, -0.14553430676460266]\n",
      "Last 5 elements: [-0.24204984307289124, 0.08756363391876221, -0.17061717808246613, -0.0974937453866005, -0.04474034532904625]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.04673320800065994, -0.40349292755126953, 0.293366938829422, -0.28501802682876587, -0.5680062174797058]\n",
      "Last 5 elements: [-0.9570692181587219, 0.7837682962417603, 0.9992658495903015, 1.0383143424987793, 0.10946572571992874]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.242975115776062, 0.2835465371608734, 0.017724240198731422, -0.04763824865221977, 0.010427632369101048]\n",
      "Last 5 elements: [0.19751916825771332, -0.4697927236557007, -0.04438110440969467, -0.3621569871902466, 0.014288302510976791]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.04673320800065994, -0.40349292755126953, 0.293366938829422, -0.28501802682876587, -0.5680062174797058]\n",
      "Last 5 elements: [-0.9570692181587219, 0.7837682962417603, 0.9992658495903015, 1.0383143424987793, 0.10946572571992874]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6054,  0.7065,  0.0442,  ...,  0.1868, -0.5529, -0.4245],\n",
      "         [ 1.1923,  0.4349,  0.7803,  ..., -0.0136,  0.0306,  0.0607],\n",
      "         [ 0.5462, -0.3866, -1.2775,  ...,  0.0912, -0.3916, -0.0517],\n",
      "         [ 0.2461, -0.1411, -0.2711,  ..., -0.1455,  0.0196, -0.1987],\n",
      "         [ 0.8775,  0.2497, -0.4442,  ..., -0.0649,  0.0300,  0.3952],\n",
      "         [ 0.3892, -0.1071,  0.3907,  ..., -0.0319, -0.2603,  0.0103]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5868557691574097, 0.6708647012710571, 0.011718381196260452, -0.11294061690568924, 0.030432168394327164]\n",
      "Last 5 elements: [0.12557265162467957, -0.24142980575561523, 0.023794448003172874, -0.09662891179323196, 0.07301156222820282]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5970872044563293, 0.6347429752349854, 0.09632238745689392, -0.16937163472175598, -0.07501013576984406]\n",
      "Last 5 elements: [-0.02820873260498047, -0.19828900694847107, 0.14577265083789825, -0.07567214965820312, 0.029732123017311096]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5970872044563293, 0.6347429752349854, 0.09632238745689392, -0.16937163472175598, -0.07501013576984406]\n",
      "Last 5 elements: [-0.02820873260498047, -0.19828900694847107, 0.14577265083789825, -0.07567214965820312, 0.029732123017311096]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.24000748991966248, 0.25514376163482666, 0.038718122988939285, -0.06808128207921982, -0.03015136532485485]\n",
      "Last 5 elements: [-0.038926176726818085, -0.2736256718635559, 0.20115657150745392, -0.10442253947257996, 0.041028354316949844]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24000748991966248, 0.25514376163482666, 0.038718122988939285, -0.06808128207921982, -0.03015136532485485]\n",
      "Last 5 elements: [-0.038926176726818085, -0.2736256718635559, 0.20115657150745392, -0.10442253947257996, 0.041028354316949844]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.28382349014282227, -0.3513803482055664, -0.7337693572044373, -0.25873953104019165, 0.010253429412841797]\n",
      "Last 5 elements: [0.10631948709487915, -0.19255587458610535, 0.3197804391384125, 0.6299062967300415, 1.4460840225219727]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.28382349014282227, -0.3513803482055664, -0.7337693572044373, -0.25873953104019165, 0.010253429412841797]\n",
      "Last 5 elements: [0.10631948709487915, -0.19255587458610535, 0.3197804391384125, 0.6299062967300415, 1.4460840225219727]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.383903831243515, -0.4752822518348694, -0.99250727891922, -0.3499749004840851, 0.013868940062820911]\n",
      "Last 5 elements: [0.09553484618663788, -0.1730237454175949, 0.2873431146144867, 0.5660110116004944, 1.2993987798690796]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.383903831243515, -0.4752822518348694, -0.99250727891922, -0.3499749004840851, 0.013868940062820911]\n",
      "Last 5 elements: [0.09553484618663788, -0.1730237454175949, 0.2873431146144867, 0.5660110116004944, 1.2993987798690796]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.9748303294181824, 0.3586757183074951, -0.9976047277450562, 0.843130886554718, 0.2146053910255432]\n",
      "Last 5 elements: [0.880029559135437, -0.7333807349205017, -8.010451316833496, 0.25002971291542053, 2.2940526008605957]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24000748991966248, 0.25514376163482666, 0.038718122988939285, -0.06808128207921982, -0.03015136532485485]\n",
      "Last 5 elements: [-0.038926176726818085, -0.2736256718635559, 0.20115657150745392, -0.10442253947257996, 0.041028354316949844]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.029020100831985474, 0.06631171703338623, 0.15743772685527802, 0.028918400406837463, 0.33306455612182617]\n",
      "Last 5 elements: [2.0328879356384277, -0.7032240629196167, -3.6688055992126465, -0.9725043773651123, 3.4484944343566895]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.029020100831985474, 0.06631171703338623, 0.15743772685527802, 0.028918400406837463, 0.33306455612182617]\n",
      "Last 5 elements: [-0.28906095027923584, -0.5720688104629517, -0.4297003149986267, -0.635445237159729, -0.09890025854110718]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.00264659128151834, 0.006047532893717289, 0.014358093030750751, 0.002637316472828388, 0.030375007539987564]\n",
      "Last 5 elements: [-0.31590014696121216, -0.6251851916313171, -0.46959781646728516, -0.6944460868835449, -0.10808310657739639]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.00264659128151834, 0.006047532893717289, 0.014358093030750751, 0.002637316472828388, 0.030375007539987564]\n",
      "Last 5 elements: [-0.31590014696121216, -0.6251851916313171, -0.46959781646728516, -0.6944460868835449, -0.10808310657739639]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.02146272361278534, 0.10452616214752197, -0.17342078685760498, -0.09386385977268219, -0.06250296533107758]\n",
      "Last 5 elements: [-0.01797400414943695, 0.1612108051776886, -0.457491934299469, -0.3159359395503998, -0.024323031306266785]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.021793795749545097, -0.021920310333371162, 0.022166971117258072, -0.01369958184659481, 0.004946231376379728]\n",
      "Last 5 elements: [-0.01797400414943695, 0.1612108051776886, -0.457491934299469, -0.3159359395503998, -0.024323031306266785]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021793795749545097, -0.021920310333371162, 0.022166971117258072, -0.01369958184659481, 0.004946231376379728]\n",
      "Last 5 elements: [0.003134547732770443, -0.008760440163314342, -0.021956872195005417, -0.013416358269751072, 0.01114002987742424]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.04584047943353653, 0.21260523796081543, -0.05790579691529274, 0.03298339620232582, -0.1507883369922638]\n",
      "Last 5 elements: [-0.35716554522514343, 0.4231981337070465, 0.05369139462709427, 0.18660509586334229, 0.1542113721370697]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6052376627922058, 0.6725442409515381, 0.08602672815322876, -0.16350717842578888, -0.10182032734155655]\n",
      "Last 5 elements: [-0.0917128324508667, -0.12304430454969406, 0.1553189903497696, -0.042493730783462524, 0.05715093016624451]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.24490706622600555, 0.2721424102783203, 0.0348103791475296, -0.06616254150867462, -0.04120119661092758]\n",
      "Last 5 elements: [-0.12715797126293182, -0.17059841752052307, 0.21534661948680878, -0.058916691690683365, 0.07923860102891922]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24490706622600555, 0.2721424102783203, 0.0348103791475296, -0.06616254150867462, -0.04120119661092758]\n",
      "Last 5 elements: [-0.12715797126293182, -0.17059841752052307, 0.21534661948680878, -0.058916691690683365, 0.07923860102891922]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.5315909385681152, 0.08876842260360718, -5.436923503875732, -3.176558017730713, -3.6494174003601074]\n",
      "Last 5 elements: [0.2457256317138672, -0.39524585008621216, 0.12227416038513184, -0.7684226036071777, -0.05382893979549408]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.5315909385681152, 0.08876842260360718, -5.436923503875732, -3.176558017730713, -3.6494174003601074]\n",
      "Last 5 elements: [0.2457256317138672, -0.39524585008621216, 0.12227416038513184, -0.7684226036071777, -0.05382893979549408]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.1865098923444748, 0.04635287821292877, -0.02356356754899025, -0.12724490463733673, -0.09250211715698242]\n",
      "Last 5 elements: [0.13788259029388428, -0.15906870365142822, 0.06487017124891281, -0.24345198273658752, -0.0261902566999197]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24490706622600555, 0.2721424102783203, 0.0348103791475296, -0.06616254150867462, -0.04120119661092758]\n",
      "Last 5 elements: [-0.12715797126293182, -0.17059841752052307, 0.21534661948680878, -0.058916691690683365, 0.07923860102891922]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.3049994111061096, 0.030876368284225464, 0.5083131790161133, -0.7779313921928406, -0.715547502040863]\n",
      "Last 5 elements: [0.6275543570518494, 0.6276930570602417, 0.10950329899787903, -0.3777684271335602, 0.01665341854095459]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.056885406374931335, 0.0014312085695564747, -0.011977671645581722, 0.09898780286312103, 0.06618966162204742]\n",
      "Last 5 elements: [0.08652882277965546, -0.09984631836414337, 0.007103497628122568, 0.09196846932172775, -0.0004361573082860559]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.0730907917022705, -1.109541416168213, -1.082573413848877, -0.1033008024096489, 0.5276140570640564]\n",
      "Last 5 elements: [0.33486777544021606, -0.8382807374000549, 0.48020413517951965, -0.8503749966621399, 0.39182963967323303]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24490706622600555, 0.2721424102783203, 0.0348103791475296, -0.06616254150867462, -0.04120119661092758]\n",
      "Last 5 elements: [-0.12715797126293182, -0.17059841752052307, 0.21534661948680878, -0.058916691690683365, 0.07923860102891922]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.0730907917022705, -1.109541416168213, -1.082573413848877, -0.1033008024096489, 0.5276140570640564]\n",
      "Last 5 elements: [0.33486777544021606, -0.8382807374000549, 0.48020413517951965, -0.8503749966621399, 0.39182963967323303]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6052,  0.6725,  0.0860,  ...,  0.3002, -0.5107, -0.4763],\n",
      "         [ 1.1021,  0.3888,  1.0007,  ...,  0.2458,  0.1466, -0.1055],\n",
      "         [ 0.8316, -0.4288, -1.2033,  ...,  0.2150, -0.3609, -0.1531],\n",
      "         [ 0.1907, -0.3223, -0.1296,  ...,  0.0292,  0.0816, -0.2320],\n",
      "         [ 0.9970,  0.1531, -0.4491,  ..., -0.0817,  0.2869,  0.3523],\n",
      "         [ 0.4831, -0.0841,  0.4729,  ...,  0.1553, -0.0425,  0.0572]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5970872044563293, 0.6347429752349854, 0.09632238745689392, -0.16937163472175598, -0.07501013576984406]\n",
      "Last 5 elements: [-0.02820873260498047, -0.19828900694847107, 0.14577265083789825, -0.07567214965820312, 0.029732123017311096]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7960333824157715, 0.47526758909225464, -0.1064550131559372, -0.181874081492424, -0.00801045447587967]\n",
      "Last 5 elements: [-0.0321732833981514, -0.27209076285362244, 0.2406993806362152, -0.19369055330753326, 0.12681829929351807]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7960333824157715, 0.47526758909225464, -0.1064550131559372, -0.181874081492424, -0.00801045447587967]\n",
      "Last 5 elements: [-0.0321732833981514, -0.27209076285362244, 0.2406993806362152, -0.19369055330753326, 0.12681829929351807]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.32385656237602234, 0.19335687160491943, -0.04330993443727493, -0.0739932730793953, -0.0032589565962553024]\n",
      "Last 5 elements: [-0.044037941843271255, -0.3724306523799896, 0.3294629454612732, -0.2651185095310211, 0.17358553409576416]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.32385656237602234, 0.19335687160491943, -0.04330993443727493, -0.0739932730793953, -0.0032589565962553024]\n",
      "Last 5 elements: [-0.044037941843271255, -0.3724306523799896, 0.3294629454612732, -0.2651185095310211, 0.17358553409576416]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.4416412115097046, 0.0979568362236023, 0.5064610242843628, 0.23283171653747559, -0.048357367515563965]\n",
      "Last 5 elements: [0.5175989866256714, -0.5613902807235718, -0.011701568961143494, -1.1604678630828857, 0.0373469740152359]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.4416412115097046, 0.0979568362236023, 0.5064610242843628, 0.23283171653747559, -0.048357367515563965]\n",
      "Last 5 elements: [0.5175989866256714, -0.5613902807235718, -0.011701568961143494, -1.1604678630828857, 0.0373469740152359]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.5234342813491821, 0.11609868705272675, 0.6002588868141174, 0.2759527266025543, -0.05731327086687088]\n",
      "Last 5 elements: [0.37219178676605225, -0.4036809504032135, -0.00841428991407156, -0.8344618678092957, 0.02685522474348545]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.5234342813491821, 0.11609868705272675, 0.6002588868141174, 0.2759527266025543, -0.05731327086687088]\n",
      "Last 5 elements: [0.37219178676605225, -0.4036809504032135, -0.00841428991407156, -0.8344618678092957, 0.02685522474348545]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.1778963804244995, -1.0279408693313599, -0.9310626983642578, 2.5934200286865234, 0.5808916091918945]\n",
      "Last 5 elements: [-0.06494522094726562, -0.15625187754631042, 6.477793216705322, 1.3226772546768188, -1.263352870941162]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.32385656237602234, 0.19335687160491943, -0.04330993443727493, -0.0739932730793953, -0.0032589565962553024]\n",
      "Last 5 elements: [-0.044037941843271255, -0.3724306523799896, 0.3294629454612732, -0.2651185095310211, 0.17358553409576416]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.01751762628555298, 0.05452531576156616, -0.08764442056417465, -0.3738830089569092, 0.17171470820903778]\n",
      "Last 5 elements: [4.382693767547607, 0.567653477191925, 3.4405550956726074, -9.956488609313965, 8.561820030212402]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.01751762628555298, 0.05452531576156616, -0.08764442056417465, -0.3738830089569092, 0.17171470820903778]\n",
      "Last 5 elements: [0.345431923866272, 0.33064329624176025, -0.149849995970726, -0.2088605761528015, 0.413399338722229]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.002258539432659745, 0.00702992407605052, -0.01129995472729206, -0.048204563558101654, 0.02213909849524498]\n",
      "Last 5 elements: [0.31620556116104126, 0.30266818404197693, -0.13717146217823029, -0.19118927419185638, 0.3784223794937134]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.002258539432659745, 0.00702992407605052, -0.01129995472729206, -0.048204563558101654, 0.02213909849524498]\n",
      "Last 5 elements: [0.31620556116104126, 0.30266818404197693, -0.13717146217823029, -0.19118927419185638, 0.3784223794937134]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.02016254886984825, 0.18800893425941467, 0.11681552231311798, 1.0428768396377563, -0.12086840718984604]\n",
      "Last 5 elements: [0.8005234003067017, 0.2827710509300232, 0.2265264391899109, -0.07345129549503326, -0.05279584228992462]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.0059353201650083065, -0.02271248772740364, -0.013703316450119019, 0.004357704892754555, 0.034190718084573746]\n",
      "Last 5 elements: [0.8005234003067017, 0.2827710509300232, 0.2265264391899109, -0.07345129549503326, -0.05279584228992462]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.0059353201650083065, -0.02271248772740364, -0.013703316450119019, 0.004357704892754555, 0.034190718084573746]\n",
      "Last 5 elements: [-0.04364708065986633, -0.0009812142234295607, 0.03027424030005932, -0.008978676982223988, -0.008093937300145626]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.03197247162461281, 0.012934401631355286, 0.043533436954021454, -0.16021889448165894, -0.12858141958713531]\n",
      "Last 5 elements: [-0.14472457766532898, 0.4079638719558716, 0.11327946931123734, -0.21461157500743866, -0.17506833374500275]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7903486490249634, 0.47756731510162354, -0.09871476143598557, -0.2103610336780548, -0.030872253701090813]\n",
      "Last 5 elements: [-0.05790533870458603, -0.1995547115802765, 0.2608404755592346, -0.23184853792190552, 0.09569111466407776]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.32339149713516235, 0.19540897011756897, -0.04039168730378151, -0.08607463538646698, -0.012632177211344242]\n",
      "Last 5 elements: [-0.08002234250307083, -0.27577486634254456, 0.3604687750339508, -0.3204033374786377, 0.1322404444217682]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.32339149713516235, 0.19540897011756897, -0.04039168730378151, -0.08607463538646698, -0.012632177211344242]\n",
      "Last 5 elements: [-0.08002234250307083, -0.27577486634254456, 0.3604687750339508, -0.3204033374786377, 0.1322404444217682]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.6551939845085144, -0.2881513833999634, -0.7170595526695251, -3.3414454460144043, 14.134657859802246]\n",
      "Last 5 elements: [-5.114402770996094, -1.801940679550171, -3.655289649963379, -1.9228821992874146, -0.6121110916137695]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.6551939845085144, -0.2881513833999634, -0.7170595526695251, -3.3414454460144043, 14.134657859802246]\n",
      "Last 5 elements: [-5.114402770996094, -1.801940679550171, -3.655289649963379, -1.9228821992874146, -0.6121110916137695]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.43123558163642883, -0.12346033751964569, -0.23522479832172394, -0.11419862508773804, 14.134647369384766]\n",
      "Last 5 elements: [-0.030551739037036896, -0.25518181920051575, -0.0921221598982811, -0.24524536728858948, -0.215204656124115]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.32339149713516235, 0.19540897011756897, -0.04039168730378151, -0.08607463538646698, -0.012632177211344242]\n",
      "Last 5 elements: [-0.08002234250307083, -0.27577486634254456, 0.3604687750339508, -0.3204033374786377, 0.1322404444217682]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.4278407692909241, -0.20027239620685577, 0.35161516070365906, -1.4152820110321045, -13.057998657226562]\n",
      "Last 5 elements: [-0.09613564610481262, 0.7222594618797302, 0.36564141511917114, -0.11004408448934555, 0.9543037414550781]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.18450015783309937, 0.024725697934627533, -0.08270860463380814, 0.1616232544183731, -184.57020568847656]\n",
      "Last 5 elements: [0.00293711107224226, -0.18430748581886292, -0.03368367627263069, 0.026987802237272263, -0.20537060499191284]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.1070619821548462, -12.6884765625, -4.288998603820801, 1.0359842777252197, 3.448176383972168]\n",
      "Last 5 elements: [1.1372349262237549, -0.7085874080657959, -1.208228349685669, 0.3502950668334961, 1.0203286409378052]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.32339149713516235, 0.19540897011756897, -0.04039168730378151, -0.08607463538646698, -0.012632177211344242]\n",
      "Last 5 elements: [-0.08002234250307083, -0.27577486634254456, 0.3604687750339508, -0.3204033374786377, 0.1322404444217682]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.1070619821548462, -12.6884765625, -4.288998603820801, 1.0359842777252197, 3.448176383972168]\n",
      "Last 5 elements: [1.1372349262237549, -0.7085874080657959, -1.208228349685669, 0.3502950668334961, 1.0203286409378052]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.7903,  0.4776, -0.0987,  ...,  0.3165, -0.6962, -0.4596],\n",
      "         [ 1.1895,  0.5511,  1.2216,  ...,  0.3907,  0.2801, -0.2530],\n",
      "         [ 0.6610, -0.5150, -1.1579,  ...,  0.7015, -0.4749, -0.0217],\n",
      "         [ 0.2216, -0.5292, -0.1042,  ...,  0.2520, -0.0558, -0.3079],\n",
      "         [ 1.0808, -0.0745, -0.6520,  ...,  0.0764,  0.1301,  0.2538],\n",
      "         [ 0.3716, -0.1119,  0.4800,  ...,  0.2608, -0.2318,  0.0957]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7960333824157715, 0.47526758909225464, -0.1064550131559372, -0.181874081492424, -0.00801045447587967]\n",
      "Last 5 elements: [-0.0321732833981514, -0.27209076285362244, 0.2406993806362152, -0.19369055330753326, 0.12681829929351807]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.987184464931488, -1.778446078300476, -0.8612995147705078, -0.026162847876548767, 0.5822141766548157]\n",
      "Last 5 elements: [0.14429524540901184, -0.3255416750907898, 0.04601725935935974, -0.16956600546836853, 0.27710574865341187]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.987184464931488, -1.778446078300476, -0.8612995147705078, -0.026162847876548767, 0.5822141766548157]\n",
      "Last 5 elements: [0.14429524540901184, -0.3255416750907898, 0.04601725935935974, -0.16956600546836853, 0.27710574865341187]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.26015087962150574, -0.4686705768108368, -0.2269766628742218, -0.006894646678119898, 0.1534298211336136]\n",
      "Last 5 elements: [0.20035533607006073, -0.45201775431632996, 0.06389540433883667, -0.23544403910636902, 0.38476401567459106]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.26015087962150574, -0.4686705768108368, -0.2269766628742218, -0.006894646678119898, 0.1534298211336136]\n",
      "Last 5 elements: [0.20035533607006073, -0.45201775431632996, 0.06389540433883667, -0.23544403910636902, 0.38476401567459106]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.4422318935394287, 0.2605414390563965, 0.4189344048500061, -1.494523525238037, 2.6957249641418457]\n",
      "Last 5 elements: [-0.42395108938217163, 0.3348625600337982, 1.570533037185669, -1.5477933883666992, 0.8819659948348999]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.4422318935394287, 0.2605414390563965, 0.4189344048500061, -1.494523525238037, 2.6957249641418457]\n",
      "Last 5 elements: [-0.42395108938217163, 0.3348625600337982, 1.570533037185669, -1.5477933883666992, 0.8819659948348999]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.1588349342346191, 0.1236264705657959, 0.19878366589546204, -0.7091488838195801, 1.2791168689727783]\n",
      "Last 5 elements: [-0.3161084055900574, 0.24968180060386658, 1.1710282564163208, -1.1540729999542236, 0.6576156616210938]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.1588349342346191, 0.1236264705657959, 0.19878366589546204, -0.7091488838195801, 1.2791168689727783]\n",
      "Last 5 elements: [-0.3161084055900574, 0.24968180060386658, 1.1710282564163208, -1.1540729999542236, 0.6576156616210938]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.21214167773723602, 0.5416626930236816, 0.30277931690216064, 0.2103484719991684, 1.2642834186553955]\n",
      "Last 5 elements: [-0.9250104427337646, 0.5970824956893921, -1.1045598983764648, -0.23275047540664673, -2.4401330947875977]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.26015087962150574, -0.4686705768108368, -0.2269766628742218, -0.006894646678119898, 0.1534298211336136]\n",
      "Last 5 elements: [0.20035533607006073, -0.45201775431632996, 0.06389540433883667, -0.23544403910636902, 0.38476401567459106]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.8303552269935608, -0.3280525207519531, 0.20255109667778015, -0.037398964166641235, -0.3937505781650543]\n",
      "Last 5 elements: [-1.2546131610870361, 0.42861032485961914, 14.275165557861328, -0.37413015961647034, 4.695975303649902]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.8303552269935608, -0.3280525207519531, 0.20255109667778015, -0.037398964166641235, -0.3937505781650543]\n",
      "Last 5 elements: [0.5619426965713501, 2.3642852306365967, 0.026354163885116577, -1.3537101745605469, 0.4157549738883972]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.08817245811223984, -0.03483472391963005, 0.021508177742362022, -0.003971262369304895, -0.04181096702814102]\n",
      "Last 5 elements: [0.5640722513198853, 2.3732450008392334, 0.026454037055373192, -1.3588402271270752, 0.4173305332660675]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.08817245811223984, -0.03483472391963005, 0.021508177742362022, -0.003971262369304895, -0.04181096702814102]\n",
      "Last 5 elements: [0.5640722513198853, 2.3732450008392334, 0.026454037055373192, -1.3588402271270752, 0.4173305332660675]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.2702237665653229, -0.12721341848373413, 0.03375532478094101, 0.1669626235961914, -0.0987677201628685]\n",
      "Last 5 elements: [0.1327979564666748, 1.1497609615325928, 0.5180970430374146, 0.5130544304847717, -0.00927916169166565]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.05422560125589371, -0.032951753586530685, 0.0011078459210693836, -0.07029388844966888, -0.04247848689556122]\n",
      "Last 5 elements: [0.1327979564666748, 1.1497609615325928, 0.5180970430374146, 0.5130544304847717, -0.00927916169166565]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.05422560125589371, -0.032951753586530685, 0.0011078459210693836, -0.07029388844966888, -0.04247848689556122]\n",
      "Last 5 elements: [-0.08685826510190964, 0.0800226703286171, 0.06765925139188766, 0.1071886420249939, 0.00954496767371893]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.26859551668167114, 0.07690247148275375, 0.021588757634162903, -0.1150914654135704, 0.10596553981304169]\n",
      "Last 5 elements: [-0.2709420323371887, 0.6378271579742432, -0.31863486766815186, 0.36147409677505493, 0.8811182975769043]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.9394281506538391, -1.7647727727890015, -0.8574610352516174, -0.04662612825632095, 0.601054847240448]\n",
      "Last 5 elements: [0.09612169861793518, -0.2121358960866928, -0.01063607633113861, -0.10529584437608719, 0.43376874923706055]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.24825268983840942, -0.4663577377796173, -0.22659210860729218, -0.012321391142904758, 0.15883436799049377]\n",
      "Last 5 elements: [0.13595737516880035, -0.3000513017177582, -0.015043982304632664, -0.1489335596561432, 0.6135354042053223]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24825268983840942, -0.4663577377796173, -0.22659210860729218, -0.012321391142904758, 0.15883436799049377]\n",
      "Last 5 elements: [0.13595737516880035, -0.3000513017177582, -0.015043982304632664, -0.1489335596561432, 0.6135354042053223]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.4806761741638184, -2.974069356918335, -1.6925857067108154, 0.42854931950569153, -2.1464898586273193]\n",
      "Last 5 elements: [-1.3515183925628662, -2.357938051223755, -3.1865177154541016, -1.46367347240448, 0.0534290075302124]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.4806761741638184, -2.974069356918335, -1.6925857067108154, 0.42854931950569153, -2.1464898586273193]\n",
      "Last 5 elements: [-1.3515183925628662, -2.357938051223755, -3.1865177154541016, -1.46367347240448, 0.0534290075302124]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.19156776368618011, -0.14457300305366516, -0.2630889415740967, 0.25949826836586, -0.22465096414089203]\n",
      "Last 5 elements: [-0.2779022455215454, -0.20381280779838562, -0.12642908096313477, -0.27503320574760437, 0.027427999302744865]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24825268983840942, -0.4663577377796173, -0.22659210860729218, -0.012321391142904758, 0.15883436799049377]\n",
      "Last 5 elements: [0.13595737516880035, -0.3000513017177582, -0.015043982304632664, -0.1489335596561432, 0.6135354042053223]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.060086578130722046, 0.03758007287979126, -0.5761563181877136, 1.9906387329101562, -1.7277039289474487]\n",
      "Last 5 elements: [0.5963606834411621, 0.2642159163951874, -0.33111220598220825, -0.4976330101490021, 0.4536435604095459]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.011510651558637619, -0.005433063954114914, 0.151580348610878, 0.5165672898292542, 0.3881303668022156]\n",
      "Last 5 elements: [-0.16572996973991394, -0.05385058745741844, 0.041862212121486664, 0.13686560094356537, 0.01244253572076559]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-2.887604236602783, 0.9569195508956909, 3.25150465965271, -0.7385095357894897, 2.1464462280273438]\n",
      "Last 5 elements: [-0.49311941862106323, 0.46207374334335327, 0.4075664281845093, 0.7919384837150574, 0.1200457215309143]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.24825268983840942, -0.4663577377796173, -0.22659210860729218, -0.012321391142904758, 0.15883436799049377]\n",
      "Last 5 elements: [0.13595737516880035, -0.3000513017177582, -0.015043982304632664, -0.1489335596561432, 0.6135354042053223]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-2.887604236602783, 0.9569195508956909, 3.25150465965271, -0.7385095357894897, 2.1464462280273438]\n",
      "Last 5 elements: [-0.49311941862106323, 0.46207374334335327, 0.4075664281845093, 0.7919384837150574, 0.1200457215309143]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.9394, -1.7648, -0.8575,  ...,  0.2468, -0.9268, -1.3962],\n",
      "         [ 1.3000,  0.6608,  1.0687,  ...,  0.4522,  0.0741,  0.1810],\n",
      "         [ 0.3123, -0.7667, -0.7324,  ...,  0.6568, -0.4156, -0.0612],\n",
      "         [ 0.0466, -0.3195,  0.0278,  ...,  0.4501,  0.0217, -0.0245],\n",
      "         [ 0.5672,  0.2225, -0.4184,  ...,  0.1510,  0.4556,  0.3600],\n",
      "         [ 0.4282, -0.0834,  0.6068,  ..., -0.0106, -0.1053,  0.4338]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.987184464931488, -1.778446078300476, -0.8612995147705078, -0.026162847876548767, 0.5822141766548157]\n",
      "Last 5 elements: [0.14429524540901184, -0.3255416750907898, 0.04601725935935974, -0.16956600546836853, 0.27710574865341187]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.4528446197509766, -1.5946322679519653, -0.2793429493904114, -0.1779332458972931, 0.9826933741569519]\n",
      "Last 5 elements: [0.008444979786872864, -0.12997910380363464, 0.061829306185245514, 0.03551096469163895, 0.45511290431022644]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.4528446197509766, -1.5946322679519653, -0.2793429493904114, -0.1779332458972931, 0.9826933741569519]\n",
      "Last 5 elements: [0.008444979786872864, -0.12997910380363464, 0.061829306185245514, 0.03551096469163895, 0.45511290431022644]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.3758234679698944, -0.4125012457370758, -0.07226074486970901, -0.04602796956896782, 0.2542042136192322]\n",
      "Last 5 elements: [0.011512970551848412, -0.17719942331314087, 0.08429137617349625, 0.04841180145740509, 0.6204516291618347]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3758234679698944, -0.4125012457370758, -0.07226074486970901, -0.04602796956896782, 0.2542042136192322]\n",
      "Last 5 elements: [0.011512970551848412, -0.17719942331314087, 0.08429137617349625, 0.04841180145740509, 0.6204516291618347]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.3296683132648468, 0.6431335210800171, -0.8690479397773743, -3.9996299743652344, -0.24366232752799988]\n",
      "Last 5 elements: [0.5801570415496826, -0.2101731151342392, 0.0340782105922699, 0.40911799669265747, 0.574371337890625]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.3296683132648468, 0.6431335210800171, -0.8690479397773743, -3.9996299743652344, -0.24366232752799988]\n",
      "Last 5 elements: [0.5801570415496826, -0.2101731151342392, 0.0340782105922699, 0.40911799669265747, 0.574371337890625]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.25020521879196167, 0.4881129264831543, -0.6595730185508728, -3.0355610847473145, -0.18493007123470306]\n",
      "Last 5 elements: [0.5365184545516968, -0.19436419010162354, 0.03151489421725273, 0.37834471464157104, 0.5311679244041443]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.25020521879196167, 0.4881129264831543, -0.6595730185508728, -3.0355610847473145, -0.18493007123470306]\n",
      "Last 5 elements: [0.5365184545516968, -0.19436419010162354, 0.03151489421725273, 0.37834471464157104, 0.5311679244041443]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.04045914113521576, 0.03713977336883545, 1.3960168361663818, 1.871515154838562, -0.5945326685905457]\n",
      "Last 5 elements: [2.7133712768554688, 1.250744104385376, -3.83485746383667, -1.2008146047592163, -0.8171045780181885]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3758234679698944, -0.4125012457370758, -0.07226074486970901, -0.04602796956896782, 0.2542042136192322]\n",
      "Last 5 elements: [0.011512970551848412, -0.17719942331314087, 0.08429137617349625, 0.04841180145740509, 0.6204516291618347]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.024214185774326324, -0.001308433711528778, -0.16919952630996704, -0.12893006205558777, -0.17883285880088806]\n",
      "Last 5 elements: [2.7961230278015137, -5.592177391052246, 6.581206798553467, -5.87677001953125, 6.698712348937988]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.024214185774326324, -0.001308433711528778, -0.16919952630996704, -0.12893006205558777, -0.17883285880088806]\n",
      "Last 5 elements: [0.03877750039100647, 1.3848713636398315, -1.0917284488677979, -0.20263753831386566, -1.0247420072555542]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.0028185518458485603, -0.00015230280405376107, -0.019694969058036804, -0.015007569454610348, -0.020816298201680183]\n",
      "Last 5 elements: [0.033030908554792404, 1.179641842842102, -0.9299408793449402, -0.172607883810997, -0.8728814125061035]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.0028185518458485603, -0.00015230280405376107, -0.019694969058036804, -0.015007569454610348, -0.020816298201680183]\n",
      "Last 5 elements: [0.033030908554792404, 1.179641842842102, -0.9299408793449402, -0.172607883810997, -0.8728814125061035]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.08257715404033661, 0.07059557735919952, -0.8117137551307678, 0.19349437952041626, -0.09341699630022049]\n",
      "Last 5 elements: [0.2270270138978958, -0.2914811074733734, 0.6255983710289001, -0.2557224929332733, -0.2618321180343628]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.02112732082605362, 0.008473558351397514, 0.026848044246435165, 0.04365377873182297, 0.01132228784263134]\n",
      "Last 5 elements: [0.2270270138978958, -0.2914811074733734, 0.6255983710289001, -0.2557224929332733, -0.2618321180343628]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.02112732082605362, 0.008473558351397514, 0.026848044246435165, 0.04365377873182297, 0.01132228784263134]\n",
      "Last 5 elements: [-0.00733860582113266, 0.03355509415268898, -0.003236443502828479, -0.004261388909071684, -0.020008200779557228]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.2549592852592468, 0.06399048864841461, -0.03208690136671066, -0.04588879272341728, -0.056575119495391846]\n",
      "Last 5 elements: [-0.17498093843460083, 0.027469316497445107, -0.6182154417037964, -0.006060306914150715, -0.1817619502544403]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.4075127840042114, -1.5832546949386597, -0.2850480079650879, -0.1860922873020172, 0.9726343154907227]\n",
      "Last 5 elements: [-0.02266666293144226, -0.12509505450725555, -0.048089511692523956, 0.03443343937397003, 0.4227955937385559]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.36492031812667847, -0.4104842245578766, -0.07390327751636505, -0.04824741929769516, 0.2521710991859436]\n",
      "Last 5 elements: [-0.031117016449570656, -0.17173171043395996, -0.0660177543759346, 0.04727056249976158, 0.5804179310798645]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.36492031812667847, -0.4104842245578766, -0.07390327751636505, -0.04824741929769516, 0.2521710991859436]\n",
      "Last 5 elements: [-0.031117016449570656, -0.17173171043395996, -0.0660177543759346, 0.04727056249976158, 0.5804179310798645]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.09891378879547119, -3.1833302974700928, -1.848888874053955, -0.8876572847366333, -0.3809713125228882]\n",
      "Last 5 elements: [-3.866227388381958, -1.8334681987762451, 0.7115150690078735, -1.3317056894302368, -1.541390061378479]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.09891378879547119, -3.1833302974700928, -1.848888874053955, -0.8876572847366333, -0.3809713125228882]\n",
      "Last 5 elements: [-3.866227388381958, -1.8334681987762451, 0.7115150690078735, -1.3317056894302368, -1.541390061378479]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.04701290652155876, -0.12668977677822113, -0.2514551877975464, -0.258835107088089, -0.15463346242904663]\n",
      "Last 5 elements: [-0.07928794622421265, -0.2526988983154297, 0.47723865509033203, -0.2781631648540497, -0.27179840207099915]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.36492031812667847, -0.4104842245578766, -0.07390327751636505, -0.04824741929769516, 0.2521710991859436]\n",
      "Last 5 elements: [-0.031117016449570656, -0.17173171043395996, -0.0660177543759346, 0.04727056249976158, 0.5804179310798645]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [5.34359884262085, -0.7110482454299927, 0.544363796710968, 0.4153476655483246, -1.2383841276168823]\n",
      "Last 5 elements: [0.21297770738601685, -0.7666283845901489, 0.10482138395309448, -1.476607322692871, -0.1334889531135559]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.25121811032295227, 0.09008254110813141, -0.13688309490680695, -0.10750655829906464, 0.1914956271648407]\n",
      "Last 5 elements: [-0.01688656583428383, 0.19372615218162537, 0.050024814903736115, 0.4107377529144287, 0.03628208488225937]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [8.96076774597168, 6.943720817565918, -6.698631763458252, -22.179553985595703, 8.843609809875488]\n",
      "Last 5 elements: [0.10878616571426392, -0.2330794781446457, 0.5930560827255249, -0.7097598314285278, -0.7067564725875854]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.36492031812667847, -0.4104842245578766, -0.07390327751636505, -0.04824741929769516, 0.2521710991859436]\n",
      "Last 5 elements: [-0.031117016449570656, -0.17173171043395996, -0.0660177543759346, 0.04727056249976158, 0.5804179310798645]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [8.96076774597168, 6.943720817565918, -6.698631763458252, -22.179553985595703, 8.843609809875488]\n",
      "Last 5 elements: [0.10878616571426392, -0.2330794781446457, 0.5930560827255249, -0.7097598314285278, -0.7067564725875854]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-1.4075, -1.5833, -0.2850,  ...,  0.2188, -1.0764, -1.9162],\n",
      "         [ 1.0888,  0.6715,  1.1811,  ...,  0.1334, -0.0898,  0.1140],\n",
      "         [ 0.2507, -0.9215, -0.4737,  ...,  0.4201, -0.2074, -0.3608],\n",
      "         [ 0.3758, -0.3213, -0.2563,  ...,  0.3387,  0.1267, -0.2542],\n",
      "         [ 0.6075,  0.1539, -0.3485,  ...,  0.1205,  0.4643,  0.0755],\n",
      "         [ 0.4220,  0.0856,  0.4977,  ..., -0.0481,  0.0344,  0.4228]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.4528446197509766, -1.5946322679519653, -0.2793429493904114, -0.1779332458972931, 0.9826933741569519]\n",
      "Last 5 elements: [0.008444979786872864, -0.12997910380363464, 0.061829306185245514, 0.03551096469163895, 0.45511290431022644]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.1857132911682129, -0.348659873008728, -1.4760658740997314, -4.1296210289001465, 2.545029640197754]\n",
      "Last 5 elements: [-0.003324463963508606, -0.1665366291999817, 0.057355962693691254, -0.0917619913816452, 0.2971341609954834]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.1857132911682129, -0.348659873008728, -1.4760658740997314, -4.1296210289001465, 2.545029640197754]\n",
      "Last 5 elements: [-0.003324463963508606, -0.1665366291999817, 0.057355962693691254, -0.0917619913816452, 0.2971341609954834]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.007734066341072321, -0.014520008116960526, -0.06147105246782303, -0.1719788759946823, 0.10598825663328171]\n",
      "Last 5 elements: [-0.004512450657784939, -0.22604796290397644, 0.07785192877054214, -0.12455284595489502, 0.40331408381462097]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.007734066341072321, -0.014520008116960526, -0.06147105246782303, -0.1719788759946823, 0.10598825663328171]\n",
      "Last 5 elements: [-0.004512450657784939, -0.22604796290397644, 0.07785192877054214, -0.12455284595489502, 0.40331408381462097]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.14622056484222412, -0.4081551432609558, 0.8263349533081055, -0.24149920046329498, -1.8897744417190552]\n",
      "Last 5 elements: [0.37751761078834534, 0.8046330809593201, 0.5420603156089783, 1.4628102779388428, 0.8046510815620422]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.14622056484222412, -0.4081551432609558, 0.8263349533081055, -0.24149920046329498, -1.8897744417190552]\n",
      "Last 5 elements: [0.37751761078834534, 0.8046330809593201, 0.5420603156089783, 1.4628102779388428, 0.8046510815620422]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.08932147920131683, -0.24932895600795746, 0.5047816634178162, -0.1475241631269455, -1.1544029712677002]\n",
      "Last 5 elements: [0.2943114638328552, 0.6272892355918884, 0.42258840799331665, 1.1404019594192505, 0.6273032426834106]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.08932147920131683, -0.24932895600795746, 0.5047816634178162, -0.1475241631269455, -1.1544029712677002]\n",
      "Last 5 elements: [0.2943114638328552, 0.6272892355918884, 0.42258840799331665, 1.1404019594192505, 0.6273032426834106]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.3553454875946045, 0.21959692239761353, -0.7431075572967529, 0.8924083709716797, 1.0546865463256836]\n",
      "Last 5 elements: [0.9050222635269165, 0.3101574778556824, 0.6819940805435181, 0.9020206928253174, -2.2588725090026855]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.007734066341072321, -0.014520008116960526, -0.06147105246782303, -0.1719788759946823, 0.10598825663328171]\n",
      "Last 5 elements: [-0.004512450657784939, -0.22604796290397644, 0.07785192877054214, -0.12455284595489502, 0.40331408381462097]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.09712144732475281, -0.0851592868566513, -0.03524477779865265, -0.09022250771522522, 0.079599529504776]\n",
      "Last 5 elements: [1.9482978582382202, 1.1333283185958862, -17.456592559814453, 3.950286388397217, 0.2842960059642792]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.09712144732475281, -0.0851592868566513, -0.03524477779865265, -0.09022250771522522, 0.079599529504776]\n",
      "Last 5 elements: [0.0350530743598938, 1.3248413801193237, 0.8602637052536011, 0.06910964846611023, -0.08599884808063507]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.01190437562763691, -0.010438148863613605, -0.004320024978369474, -0.01105875801295042, 0.009756677784025669]\n",
      "Last 5 elements: [0.029369520023465157, 1.1100298166275024, 0.7207793593406677, 0.057904113084077835, -0.07205487787723541]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.01190437562763691, -0.010438148863613605, -0.004320024978369474, -0.01105875801295042, 0.009756677784025669]\n",
      "Last 5 elements: [0.029369520023465157, 1.1100298166275024, 0.7207793593406677, 0.057904113084077835, -0.07205487787723541]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.09397406876087189, 0.014332884922623634, 0.16338056325912476, -0.18643967807292938, 0.22923974692821503]\n",
      "Last 5 elements: [-0.1768852025270462, 1.0819709300994873, -0.9473929405212402, 0.5522076487541199, 1.6255054473876953]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.0019092403817921877, 0.03436768427491188, -0.006002180743962526, 0.037458665668964386, 0.01865614391863346]\n",
      "Last 5 elements: [-0.1768852025270462, 1.0819709300994873, -0.9473929405212402, 0.5522076487541199, 1.6255054473876953]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0019092403817921877, 0.03436768427491188, -0.006002180743962526, 0.037458665668964386, 0.01865614391863346]\n",
      "Last 5 elements: [-0.13215693831443787, 0.2207724153995514, -0.2639999985694885, 0.08322666585445404, 0.11488839983940125]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.05955144762992859, 0.28583288192749023, 0.023169681429862976, 0.1253247857093811, 0.1686137616634369]\n",
      "Last 5 elements: [-0.3862549960613251, -0.42873358726501465, -0.9303880929946899, -0.2812047600746155, 0.15351545810699463]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.19630154967308044, -0.2978387475013733, -1.471946358680725, -4.1073384284973145, 2.5750091075897217]\n",
      "Last 5 elements: [-0.07200067490339279, -0.24276554584503174, -0.10806720703840256, -0.14176024496555328, 0.3244292438030243]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.008176642470061779, -0.012406019493937492, -0.06131168454885483, -0.171084925532341, 0.10725808143615723]\n",
      "Last 5 elements: [-0.0985269770026207, -0.33220458030700684, -0.14788104593753815, -0.1939871907234192, 0.44395461678504944]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.008176642470061779, -0.012406019493937492, -0.06131168454885483, -0.171084925532341, 0.10725808143615723]\n",
      "Last 5 elements: [-0.0985269770026207, -0.33220458030700684, -0.14788104593753815, -0.1939871907234192, 0.44395461678504944]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.831034779548645, -1.9406278133392334, -1.589482069015503, -1.1550246477127075, -1.9136230945587158]\n",
      "Last 5 elements: [-1.69538414478302, -0.039459288120269775, -1.0421009063720703, -1.2660319805145264, 0.6192837357521057]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.831034779548645, -1.9406278133392334, -1.589482069015503, -1.1550246477127075, -1.9136230945587158]\n",
      "Last 5 elements: [-1.69538414478302, -0.039459288120269775, -1.0421009063720703, -1.2660319805145264, 0.6192837357521057]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2521578371524811, -0.24370191991329193, -0.26934850215911865, -0.2767121493816376, -0.246042862534523]\n",
      "Last 5 elements: [-0.2629016637802124, -0.019340435042977333, -0.2717224061489105, -0.27844762802124023, 0.40256887674331665]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.008176642470061779, -0.012406019493937492, -0.06131168454885483, -0.171084925532341, 0.10725808143615723]\n",
      "Last 5 elements: [-0.0985269770026207, -0.33220458030700684, -0.14788104593753815, -0.1939871907234192, 0.44395461678504944]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.04157552123069763, 0.04877564311027527, -0.5846372842788696, -0.41327887773513794, -1.3959988355636597]\n",
      "Last 5 elements: [-0.007566988468170166, -1.936302900314331, 0.39792749285697937, 0.9859256148338318, 0.3126510977745056]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.010483593679964542, -0.0118867177516222, 0.1574711799621582, 0.1143592894077301, 0.3434755504131317]\n",
      "Last 5 elements: [0.0019893739372491837, 0.0374489389359951, -0.10812581330537796, -0.2745286524295807, 0.12586359679698944]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.04923395812511444, 1.028936743736267, -1.0929460525512695, -0.2880184054374695, 0.1025138795375824]\n",
      "Last 5 elements: [-0.09360402822494507, 0.7082445621490479, 0.9136042594909668, 0.5090717673301697, 0.25562459230422974]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.008176642470061779, -0.012406019493937492, -0.06131168454885483, -0.171084925532341, 0.10725808143615723]\n",
      "Last 5 elements: [-0.0985269770026207, -0.33220458030700684, -0.14788104593753815, -0.1939871907234192, 0.44395461678504944]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.04923395812511444, 1.028936743736267, -1.0929460525512695, -0.2880184054374695, 0.1025138795375824]\n",
      "Last 5 elements: [-0.09360402822494507, 0.7082445621490479, 0.9136042594909668, 0.5090717673301697, 0.25562459230422974]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[ 0.1963, -0.2978, -1.4719,  ...,  1.7062, -1.2477, -0.2046],\n",
      "         [ 1.0913,  0.6456,  1.2393,  ..., -0.1500,  0.1423,  0.2036],\n",
      "         [ 0.5791, -0.4904, -0.7253,  ...,  0.8599, -0.2618, -0.0556],\n",
      "         [ 0.3856, -0.2738, -0.2244,  ...,  0.5265,  0.2459, -0.0485],\n",
      "         [ 0.6311,  0.4833, -0.6518,  ...,  0.0575,  0.3923,  0.0730],\n",
      "         [ 0.4323,  0.1874,  0.7188,  ..., -0.1081, -0.1418,  0.3244]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.1857132911682129, -0.348659873008728, -1.4760658740997314, -4.1296210289001465, 2.545029640197754]\n",
      "Last 5 elements: [-0.003324463963508606, -0.1665366291999817, 0.057355962693691254, -0.0917619913816452, 0.2971341609954834]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.2050553560256958, -0.11489361524581909, -1.6662724018096924, -4.158548355102539, 2.593236207962036]\n",
      "Last 5 elements: [-0.08864349126815796, -0.11683954298496246, 0.05437179654836655, -0.05124719440937042, 0.3698793351650238]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.2050553560256958, -0.11489361524581909, -1.6662724018096924, -4.158548355102539, 2.593236207962036]\n",
      "Last 5 elements: [-0.08864349126815796, -0.11683954298496246, 0.05437179654836655, -0.05124719440937042, 0.3698793351650238]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.00851242896169424, -0.004769559949636459, -0.06917168945074081, -0.17263314127922058, 0.10765258967876434]\n",
      "Last 5 elements: [-0.11959411948919296, -0.15763506293296814, 0.07335617393255234, -0.06914059072732925, 0.4990258514881134]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.00851242896169424, -0.004769559949636459, -0.06917168945074081, -0.17263314127922058, 0.10765258967876434]\n",
      "Last 5 elements: [-0.11959411948919296, -0.15763506293296814, 0.07335617393255234, -0.06914059072732925, 0.4990258514881134]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.7197691202163696, -1.2505884170532227, 1.6014676094055176, -0.6055566668510437, -1.7781809568405151]\n",
      "Last 5 elements: [-0.08918901532888412, 1.026574730873108, 0.3876902759075165, 0.1861269474029541, -0.28066712617874146]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.7197691202163696, -1.2505884170532227, 1.6014676094055176, -0.6055566668510437, -1.7781809568405151]\n",
      "Last 5 elements: [-0.08918901532888412, 1.026574730873108, 0.3876902759075165, 0.1861269474029541, -0.28066712617874146]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.36488649249076843, -0.6339849829673767, 0.8118630051612854, -0.30698657035827637, -0.9014477133750916]\n",
      "Last 5 elements: [-0.06331515312194824, 0.7287638783454895, 0.27522075176239014, 0.13213124871253967, -0.19924518465995789]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.36488649249076843, -0.6339849829673767, 0.8118630051612854, -0.30698657035827637, -0.9014477133750916]\n",
      "Last 5 elements: [-0.06331515312194824, 0.7287638783454895, 0.27522075176239014, 0.13213124871253967, -0.19924518465995789]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.2648065984249115, 0.5551658868789673, -0.0942179262638092, 0.007824510335922241, 0.3329280614852905]\n",
      "Last 5 elements: [-1.382948637008667, -0.6436432600021362, -1.5779685974121094, 0.2605259418487549, 0.07672366499900818]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.00851242896169424, -0.004769559949636459, -0.06917168945074081, -0.17263314127922058, 0.10765258967876434]\n",
      "Last 5 elements: [-0.11959411948919296, -0.15763506293296814, 0.07335617393255234, -0.06914059072732925, 0.4990258514881134]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.17445845901966095, 0.06001385301351547, 0.12277407199144363, 0.1390468329191208, -0.019321255385875702]\n",
      "Last 5 elements: [-4.430427551269531, -0.09027033299207687, -2.985651969909668, -13.057952880859375, -1.7389885187149048]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.17445845901966095, 0.06001385301351547, 0.12277407199144363, 0.1390468329191208, -0.019321255385875702]\n",
      "Last 5 elements: [-0.4107864499092102, -0.5240796804428101, 0.17328953742980957, 1.1545631885528564, -1.2399344444274902]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.021826017647981644, 0.007508167531341314, 0.015359926037490368, 0.01739576645195484, -0.002417229115962982]\n",
      "Last 5 elements: [-0.36274656653404236, -0.4627905786037445, 0.15302398800849915, 1.0195415019989014, -1.0949288606643677]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.021826017647981644, 0.007508167531341314, 0.015359926037490368, 0.01739576645195484, -0.002417229115962982]\n",
      "Last 5 elements: [-0.36274656653404236, -0.4627905786037445, 0.15302398800849915, 1.0195415019989014, -1.0949288606643677]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.11578519642353058, 0.036033451557159424, -0.024356301873922348, -0.13831594586372375, -0.07176230102777481]\n",
      "Last 5 elements: [-0.45979997515678406, 0.2259601503610611, 0.26422205567359924, 0.11650350689888, -0.5920771956443787]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.003779746824875474, 0.028875114396214485, -0.016018152236938477, -0.014529137872159481, 0.006400687620043755]\n",
      "Last 5 elements: [-0.45979997515678406, 0.2259601503610611, 0.26422205567359924, 0.11650350689888, -0.5920771956443787]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.003779746824875474, 0.028875114396214485, -0.016018152236938477, -0.014529137872159481, 0.006400687620043755]\n",
      "Last 5 elements: [-0.4503186047077179, 0.2223808318376541, 0.26383018493652344, 0.11561700701713562, -0.587531566619873]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.10189530998468399, 0.028538428246974945, 0.06289280205965042, -0.0266033336520195, 0.17363275587558746]\n",
      "Last 5 elements: [-0.24449285864830017, -0.3815206289291382, 0.3427548408508301, -0.6173397302627563, -0.03850071132183075]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.2231723666191101, -0.10981947928667068, -1.655090093612671, -4.163278579711914, 2.624108076095581]\n",
      "Last 5 elements: [-0.13211436569690704, -0.1846739798784256, 0.11531366407871246, -0.16101031005382538, 0.36303389072418213]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.009266716428101063, -0.004560000263154507, -0.06872379034757614, -0.17287051677703857, 0.10896002501249313]\n",
      "Last 5 elements: [-0.1771734058856964, -0.24765904247760773, 0.15464264154434204, -0.21592462062835693, 0.4868505597114563]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.009266716428101063, -0.004560000263154507, -0.06872379034757614, -0.17287051677703857, 0.10896002501249313]\n",
      "Last 5 elements: [-0.1771734058856964, -0.24765904247760773, 0.15464264154434204, -0.21592462062835693, 0.4868505597114563]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.3463304936885834, -1.014472484588623, 0.025723639875650406, -2.1769683361053467, 0.1524818241596222]\n",
      "Last 5 elements: [1.251412272453308, -0.8791427612304688, 0.5180012583732605, -1.026665210723877, -1.4989641904830933]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.3463304936885834, -1.014472484588623, 0.025723639875650406, -2.1769683361053467, 0.1524818241596222]\n",
      "Last 5 elements: [1.251412272453308, -0.8791427612304688, 0.5180012583732605, -1.026665210723877, -1.4989641904830933]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.1434752196073532, -0.26995670795440674, 0.013027237728238106, -0.2216978669166565, 0.08204235136508942]\n",
      "Last 5 elements: [0.9730284810066223, -0.25790131092071533, 0.32462117075920105, -0.2707635760307312, -0.27368098497390747]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.009266716428101063, -0.004560000263154507, -0.06872379034757614, -0.17287051677703857, 0.10896002501249313]\n",
      "Last 5 elements: [-0.1771734058856964, -0.24765904247760773, 0.15464264154434204, -0.21592462062835693, 0.4868505597114563]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.04141458123922348, 0.8021515607833862, -0.513508677482605, -0.02829813025891781, 0.47509217262268066]\n",
      "Last 5 elements: [-0.9843695759773254, 0.4968857765197754, 0.9968279600143433, 0.4535544514656067, -0.3050515353679657]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.0059419660829007626, -0.2165461927652359, -0.0066895997151732445, 0.006273635197430849, 0.03897767886519432]\n",
      "Last 5 elements: [-0.9578196406364441, -0.12814749777317047, 0.3235914707183838, -0.12280602753162384, 0.08348680287599564]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-2.3120102882385254, 0.3444522023200989, 2.9304604530334473, 9.884074211120605, -4.596773624420166]\n",
      "Last 5 elements: [0.6412985324859619, 0.5067315101623535, 0.27961474657058716, 0.7223331332206726, -0.32568737864494324]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.009266716428101063, -0.004560000263154507, -0.06872379034757614, -0.17287051677703857, 0.10896002501249313]\n",
      "Last 5 elements: [-0.1771734058856964, -0.24765904247760773, 0.15464264154434204, -0.21592462062835693, 0.4868505597114563]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-2.3120102882385254, 0.3444522023200989, 2.9304604530334473, 9.884074211120605, -4.596773624420166]\n",
      "Last 5 elements: [0.6412985324859619, 0.5067315101623535, 0.27961474657058716, 0.7223331332206726, -0.32568737864494324]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[ 0.2232, -0.1098, -1.6551,  ...,  1.4768, -1.2385,  0.0722],\n",
      "         [ 0.9967,  0.8846,  1.3159,  ..., -0.0520,  0.3142,  0.4056],\n",
      "         [ 0.2051, -0.3735, -1.1790,  ...,  0.8950, -0.5554,  0.0508],\n",
      "         [ 0.1242, -0.1569, -0.5465,  ...,  0.6846,  0.1674, -0.1528],\n",
      "         [ 0.1164,  0.5543, -0.7737,  ...,  0.3377,  0.1725,  0.1525],\n",
      "         [ 0.2094,  0.0318,  0.5665,  ...,  0.1153, -0.1610,  0.3630]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.2050553560256958, -0.11489361524581909, -1.6662724018096924, -4.158548355102539, 2.593236207962036]\n",
      "Last 5 elements: [-0.08864349126815796, -0.11683954298496246, 0.05437179654836655, -0.05124719440937042, 0.3698793351650238]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.18790346384048462, -0.04857581481337547, -1.1340537071228027, -2.405888557434082, 1.8068008422851562]\n",
      "Last 5 elements: [-0.018091373145580292, -0.09457702934741974, 0.16502921283245087, -0.03257934749126434, 0.3051266074180603]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.18790346384048462, -0.04857581481337547, -1.1340537071228027, -2.405888557434082, 1.8068008422851562]\n",
      "Last 5 elements: [-0.018091373145580292, -0.09457702934741974, 0.16502921283245087, -0.03257934749126434, 0.3051266074180603]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.005747100804001093, -0.0014857102651149035, -0.03468547761440277, -0.07358504086732864, 0.05526171252131462]\n",
      "Last 5 elements: [-0.024020688608288765, -0.12557396292686462, 0.21911633014678955, -0.04325699061155319, 0.405129611492157]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005747100804001093, -0.0014857102651149035, -0.03468547761440277, -0.07358504086732864, 0.05526171252131462]\n",
      "Last 5 elements: [-0.024020688608288765, -0.12557396292686462, 0.21911633014678955, -0.04325699061155319, 0.405129611492157]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-2.0572831630706787, 0.031180627644062042, -0.5255395174026489, -1.3025405406951904, 1.6704370975494385]\n",
      "Last 5 elements: [-0.1400391012430191, -0.21234089136123657, -0.8215153217315674, -1.0186941623687744, 0.47713038325309753]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-2.0572831630706787, 0.031180627644062042, -0.5255395174026489, -1.3025405406951904, 1.6704370975494385]\n",
      "Last 5 elements: [-0.1400391012430191, -0.21234089136123657, -0.8215153217315674, -1.0186941623687744, 0.47713038325309753]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.624298095703125, 0.02461821399629116, -0.41493213176727295, -1.0284019708633423, 1.3188694715499878]\n",
      "Last 5 elements: [-0.1272222250699997, -0.1929066926240921, -0.74632728099823, -0.925459623336792, 0.4334616959095001]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.624298095703125, 0.02461821399629116, -0.41493213176727295, -1.0284019708633423, 1.3188694715499878]\n",
      "Last 5 elements: [-0.1272222250699997, -0.1929066926240921, -0.74632728099823, -0.925459623336792, 0.4334616959095001]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.6803882122039795, -0.9671204090118408, -1.382924199104309, 0.5812436938285828, 1.0845890045166016]\n",
      "Last 5 elements: [-2.1638641357421875, 0.7667500972747803, 2.1543729305267334, 2.1203458309173584, -0.014057725667953491]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005747100804001093, -0.0014857102651149035, -0.03468547761440277, -0.07358504086732864, 0.05526171252131462]\n",
      "Last 5 elements: [-0.024020688608288765, -0.12557396292686462, 0.21911633014678955, -0.04325699061155319, 0.405129611492157]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.21997840702533722, -0.17178776860237122, 0.270613431930542, 0.5575907826423645, 0.053224578499794006]\n",
      "Last 5 elements: [-0.025213375687599182, 0.498481810092926, -0.7952460050582886, -8.701654434204102, -0.48415684700012207]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.21997840702533722, -0.17178776860237122, 0.270613431930542, 0.5575907826423645, 0.053224578499794006]\n",
      "Last 5 elements: [0.24508604407310486, -0.23605352640151978, -0.9795649647712708, -0.5123634338378906, -0.1301550418138504]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.03419160097837448, -0.026701252907514572, 0.04206188768148422, 0.08666723966598511, 0.008272782899439335]\n",
      "Last 5 elements: [0.19728755950927734, -0.19001662731170654, -0.7885230183601379, -0.4124385416507721, -0.10477124899625778]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.03419160097837448, -0.026701252907514572, 0.04206188768148422, 0.08666723966598511, 0.008272782899439335]\n",
      "Last 5 elements: [0.19728755950927734, -0.19001662731170654, -0.7885230183601379, -0.4124385416507721, -0.10477124899625778]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.09539593756198883, -0.03190561756491661, -0.07016272842884064, -0.008403168059885502, -0.0010416805744171143]\n",
      "Last 5 elements: [1.587692379951477, 0.8669365644454956, -0.879281759262085, 0.6458876132965088, -0.24127234518527985]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.023240728303790092, 0.05315043404698372, -0.013933338224887848, 0.047816745936870575, 0.05590388923883438]\n",
      "Last 5 elements: [1.587692379951477, 0.8669365644454956, -0.879281759262085, 0.6458876132965088, -0.24127234518527985]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.023240728303790092, 0.05315043404698372, -0.013933338224887848, 0.047816745936870575, 0.05590388923883438]\n",
      "Last 5 elements: [0.09939971566200256, -0.02000277489423752, 0.005884623154997826, -0.08202242851257324, -0.05191400274634361]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.3916158676147461, 0.32567915320396423, 0.058890700340270996, -0.038840167224407196, 0.0030323192477226257]\n",
      "Last 5 elements: [-0.48165464401245117, 0.3412340581417084, -0.32794415950775146, -0.17419180274009705, 0.2401922345161438]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.11827409267425537, 0.00932999700307846, -1.1235829591751099, -2.412794351577759, 1.8073400259017944]\n",
      "Last 5 elements: [-0.10372965782880783, -0.03390555456280708, 0.1067206859588623, -0.0635506808757782, 0.3478328287601471]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0036214422434568405, 0.000285675807390362, -0.034403059631586075, -0.07387751340866089, 0.055339064449071884]\n",
      "Last 5 elements: [-0.13862989842891693, -0.04531320556998253, 0.1426272690296173, -0.08493255078792572, 0.46486249566078186]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0036214422434568405, 0.000285675807390362, -0.034403059631586075, -0.07387751340866089, 0.055339064449071884]\n",
      "Last 5 elements: [-0.13862989842891693, -0.04531320556998253, 0.1426272690296173, -0.08493255078792572, 0.46486249566078186]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.686155080795288, -1.6052448749542236, -1.3691986799240112, -0.04652019217610359, -1.1579556465148926]\n",
      "Last 5 elements: [0.34211546182632446, -1.697131633758545, 0.9707725048065186, -0.6679471135139465, -1.1183968782424927]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.686155080795288, -1.6052448749542236, -1.3691986799240112, -0.04652019217610359, -1.1579556465148926]\n",
      "Last 5 elements: [0.34211546182632446, -1.697131633758545, 0.9707725048065186, -0.6679471135139465, -1.1183968782424927]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2635159492492676, -0.2684769630432129, -0.2776041328907013, -0.022719159722328186, -0.27679651975631714]\n",
      "Last 5 elements: [0.20003637671470642, -0.26278430223464966, 0.7040754556655884, -0.22640512883663177, -0.27547094225883484]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0036214422434568405, 0.000285675807390362, -0.034403059631586075, -0.07387751340866089, 0.055339064449071884]\n",
      "Last 5 elements: [-0.13862989842891693, -0.04531320556998253, 0.1426272690296173, -0.08493255078792572, 0.46486249566078186]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.42701256275177, 0.7894443273544312, 0.2560296058654785, -0.4007796049118042, -0.9295096397399902]\n",
      "Last 5 elements: [0.16179388761520386, 0.6763575077056885, 1.6581047773361206, -1.3657366037368774, 0.8659444451332092]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.37604057788848877, -0.21194761991500854, -0.07107487320899963, 0.009105375967919827, 0.2572850286960602]\n",
      "Last 5 elements: [0.03236466273665428, -0.17773613333702087, 1.1674308776855469, 0.30920976400375366, -0.23854252696037292]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.3375445008277893, 0.8769621849060059, -0.43295326828956604, 0.05574246495962143, 0.461059033870697]\n",
      "Last 5 elements: [-0.9886465668678284, -2.1007189750671387, 1.5214886665344238, 1.7530510425567627, 0.2767285108566284]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0036214422434568405, 0.000285675807390362, -0.034403059631586075, -0.07387751340866089, 0.055339064449071884]\n",
      "Last 5 elements: [-0.13862989842891693, -0.04531320556998253, 0.1426272690296173, -0.08493255078792572, 0.46486249566078186]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.3375445008277893, 0.8769621849060059, -0.43295326828956604, 0.05574246495962143, 0.461059033870697]\n",
      "Last 5 elements: [-0.9886465668678284, -2.1007189750671387, 1.5214886665344238, 1.7530510425567627, 0.2767285108566284]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1183,  0.0093, -1.1236,  ...,  1.6650, -0.6634, -1.1416],\n",
      "         [ 1.0221,  0.7922,  1.4752,  ..., -0.0342,  0.2931,  0.4915],\n",
      "         [ 0.2953, -0.1471, -0.9726,  ...,  1.0534, -0.6705,  0.1781],\n",
      "         [ 0.3060, -0.0172, -0.4789,  ...,  0.7017,  0.0455, -0.1282],\n",
      "         [ 0.0188,  0.5589, -0.7261,  ...,  0.4637,  0.1227,  0.0112],\n",
      "         [ 0.3071,  0.1187,  0.4968,  ...,  0.1067, -0.0636,  0.3478]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.18790346384048462, -0.04857581481337547, -1.1340537071228027, -2.405888557434082, 1.8068008422851562]\n",
      "Last 5 elements: [-0.018091373145580292, -0.09457702934741974, 0.16502921283245087, -0.03257934749126434, 0.3051266074180603]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.05825861915946007, 0.16525402665138245, -1.2005621194839478, -2.402883291244507, 1.889316439628601]\n",
      "Last 5 elements: [-0.2795111835002899, -0.4074137806892395, 0.3772416412830353, 0.2481420934200287, 0.3970352113246918]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.05825861915946007, 0.16525402665138245, -1.2005621194839478, -2.402883291244507, 1.889316439628601]\n",
      "Last 5 elements: [-0.2795111835002899, -0.4074137806892395, 0.3772416412830353, 0.2481420934200287, 0.3970352113246918]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0017847615526989102, 0.005062581971287727, -0.03677939996123314, -0.07361268997192383, 0.0578794926404953]\n",
      "Last 5 elements: [-0.37506723403930664, -0.5466956496238708, 0.5062086582183838, 0.33297404646873474, 0.5327690243721008]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0017847615526989102, 0.005062581971287727, -0.03677939996123314, -0.07361268997192383, 0.0578794926404953]\n",
      "Last 5 elements: [-0.37506723403930664, -0.5466956496238708, 0.5062086582183838, 0.33297404646873474, 0.5327690243721008]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.8390694856643677, 0.1763281524181366, 0.25928372144699097, -1.2476013898849487, 3.5491602420806885]\n",
      "Last 5 elements: [1.8315602540969849, 0.20446237921714783, 1.7133772373199463, -1.2309798002243042, 0.3483850061893463]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.8390694856643677, 0.1763281524181366, 0.25928372144699097, -1.2476013898849487, 3.5491602420806885]\n",
      "Last 5 elements: [1.8315602540969849, 0.20446237921714783, 1.7133772373199463, -1.2309798002243042, 0.3483850061893463]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.6534982919692993, 0.13733087480068207, 0.20193973183631897, -0.9716780185699463, 2.764216899871826]\n",
      "Last 5 elements: [1.3755959272384644, 0.1535617560148239, 1.2868343591690063, -0.9245291352272034, 0.2616550624370575]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.6534982919692993, 0.13733087480068207, 0.20193973183631897, -0.9716780185699463, 2.764216899871826]\n",
      "Last 5 elements: [1.3755959272384644, 0.1535617560148239, 1.2868343591690063, -0.9245291352272034, 0.2616550624370575]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.4539254903793335, -1.0992817878723145, -1.011348009109497, -0.6010727882385254, 0.04645264148712158]\n",
      "Last 5 elements: [-0.20084309577941895, 0.09772682189941406, 1.4429311752319336, -5.352748870849609, 0.7976696491241455]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0017847615526989102, 0.005062581971287727, -0.03677939996123314, -0.07361268997192383, 0.0578794926404953]\n",
      "Last 5 elements: [-0.37506723403930664, -0.5466956496238708, 0.5062086582183838, 0.33297404646873474, 0.5327690243721008]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.1631576269865036, -0.035642411559820175, 0.013989515602588654, -0.0963549092411995, 0.07603693008422852]\n",
      "Last 5 elements: [-0.8212369680404663, -7.598612308502197, 1.3133468627929688, 2.057710647583008, 0.40603750944137573]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.1631576269865036, -0.035642411559820175, 0.013989515602588654, -0.0963549092411995, 0.07603693008422852]\n",
      "Last 5 elements: [-2.195791482925415, -1.6005010604858398, -0.1799945831298828, 0.48943427205085754, -0.1845139116048813]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.020638031885027885, -0.004508457612246275, 0.0017695529386401176, -0.012188063934445381, 0.00961801502853632]\n",
      "Last 5 elements: [-2.0304179191589355, -1.4799610376358032, -0.166438490152359, 0.4525730609893799, -0.17061744630336761]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.020638031885027885, -0.004508457612246275, 0.0017695529386401176, -0.012188063934445381, 0.00961801502853632]\n",
      "Last 5 elements: [-2.0304179191589355, -1.4799610376358032, -0.166438490152359, 0.4525730609893799, -0.17061744630336761]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.1544409990310669, 0.02714577317237854, 0.04427861049771309, -0.002949096728116274, -0.20953455567359924]\n",
      "Last 5 elements: [0.40240639448165894, -0.041719838976860046, -0.9058917164802551, -0.32215458154678345, -0.288856565952301]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.002611511619761586, 0.014856619760394096, -0.019052181392908096, -0.012001140974462032, 0.015173835679888725]\n",
      "Last 5 elements: [0.40240639448165894, -0.041719838976860046, -0.9058917164802551, -0.32215458154678345, -0.288856565952301]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.002611511619761586, 0.014856619760394096, -0.019052181392908096, -0.012001140974462032, 0.015173835679888725]\n",
      "Last 5 elements: [0.2669107913970947, -0.10129920393228531, -0.13412031531333923, -0.289218932390213, 0.045768942683935165]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.1254788339138031, 0.17354042828083038, 0.13842442631721497, 0.023606237024068832, -0.08011476695537567]\n",
      "Last 5 elements: [-0.2004700005054474, 0.79729163646698, -0.16520866751670837, -0.7674518823623657, 0.15647631883621216]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.08056877553462982, 0.19610954821109772, -1.175950288772583, -2.398686170578003, 1.8750720024108887]\n",
      "Last 5 elements: [-0.3151547908782959, -0.26565518975257874, 0.34786751866340637, 0.1116890162229538, 0.4248567223548889]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.002468585502356291, 0.006008694879710674, -0.03603050857782364, -0.07349450141191483, 0.05745123699307442]\n",
      "Last 5 elements: [-0.4099752902984619, -0.3455827534198761, 0.45253026485443115, 0.14529284834861755, 0.5526831746101379]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002468585502356291, 0.006008694879710674, -0.03603050857782364, -0.07349450141191483, 0.05745123699307442]\n",
      "Last 5 elements: [-0.4099752902984619, -0.3455827534198761, 0.45253026485443115, 0.14529284834861755, 0.5526831746101379]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.0001959800720215, -0.8119257688522339, -1.0413141250610352, -1.3697843551635742, -0.2670653462409973]\n",
      "Last 5 elements: [-0.9323307871818542, -2.2513904571533203, -0.9090493321418762, 1.4060704708099365, 0.5808345675468445]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.0001959800720215, -0.8119257688522339, -1.0413141250610352, -1.3697843551635742, -0.2670653462409973]\n",
      "Last 5 elements: [-0.9323307871818542, -2.2513904571533203, -0.9090493321418762, 1.4060704708099365, 0.5808345675468445]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2689555883407593, -0.24965116381645203, -0.2716752290725708, -0.2775932252407074, -0.1158069372177124]\n",
      "Last 5 elements: [-0.26333877444267273, -0.21439899504184723, -0.26107388734817505, 1.1292790174484253, 0.3724656403064728]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002468585502356291, 0.006008694879710674, -0.03603050857782364, -0.07349450141191483, 0.05745123699307442]\n",
      "Last 5 elements: [-0.4099752902984619, -0.3455827534198761, 0.45253026485443115, 0.14529284834861755, 0.5526831746101379]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.7386651039123535, -0.12500417232513428, -0.005073852837085724, 1.0420736074447632, 0.4039275348186493]\n",
      "Last 5 elements: [-0.6905624270439148, 0.6126963496208191, 0.23688030242919922, 0.6737653017044067, 0.0336836576461792]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.19866810739040375, 0.031207436695694923, 0.0013784401817247272, -0.28927257657051086, -0.04677760973572731]\n",
      "Last 5 elements: [0.18185186386108398, -0.1313614845275879, -0.06184326112270355, 0.760869026184082, 0.012546004727482796]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.06664617359638214, -1.482662558555603, -0.43084684014320374, 0.073344387114048, -0.6298086643218994]\n",
      "Last 5 elements: [-1.7181552648544312, -0.17604291439056396, -1.024802327156067, 0.24436187744140625, -0.26900482177734375]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002468585502356291, 0.006008694879710674, -0.03603050857782364, -0.07349450141191483, 0.05745123699307442]\n",
      "Last 5 elements: [-0.4099752902984619, -0.3455827534198761, 0.45253026485443115, 0.14529284834861755, 0.5526831746101379]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.06664617359638214, -1.482662558555603, -0.43084684014320374, 0.073344387114048, -0.6298086643218994]\n",
      "Last 5 elements: [-1.7181552648544312, -0.17604291439056396, -1.024802327156067, 0.24436187744140625, -0.26900482177734375]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.0806,  0.1961, -1.1760,  ...,  1.3322, -0.6778, -1.1438],\n",
      "         [ 0.9149,  1.0826,  1.3235,  ...,  0.0533,  0.5088,  0.6733],\n",
      "         [ 0.5568,  0.0907, -1.1569,  ...,  1.1115, -0.3907,  0.1137],\n",
      "         [ 0.2940,  0.3379, -0.1454,  ...,  0.8186, -0.0198, -0.1367],\n",
      "         [ 0.1892,  0.7701, -0.6984,  ...,  0.4648,  0.4905, -0.1221],\n",
      "         [ 0.5443,  0.3632,  0.5900,  ...,  0.3479,  0.1117,  0.4249]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.05825861915946007, 0.16525402665138245, -1.2005621194839478, -2.402883291244507, 1.889316439628601]\n",
      "Last 5 elements: [-0.2795111835002899, -0.4074137806892395, 0.3772416412830353, 0.2481420934200287, 0.3970352113246918]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.09241847693920135, -0.06750811636447906, -1.2525548934936523, -2.385645627975464, 1.7630919218063354]\n",
      "Last 5 elements: [-0.620643138885498, -0.2969556450843811, 0.16565747559070587, 0.1551366001367569, 0.37702763080596924]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.09241847693920135, -0.06750811636447906, -1.2525548934936523, -2.385645627975464, 1.7630919218063354]\n",
      "Last 5 elements: [-0.620643138885498, -0.2969556450843811, 0.16565747559070587, 0.1551366001367569, 0.37702763080596924]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0028311344794929028, -0.0020680339075624943, -0.038370586931705475, -0.07308153063058853, 0.0540103055536747]\n",
      "Last 5 elements: [-0.827612578868866, -0.39598312973976135, 0.22090022265911102, 0.2068708837032318, 0.50275719165802]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0028311344794929028, -0.0020680339075624943, -0.038370586931705475, -0.07308153063058853, 0.0540103055536747]\n",
      "Last 5 elements: [-0.827612578868866, -0.39598312973976135, 0.22090022265911102, 0.2068708837032318, 0.50275719165802]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-2.5818417072296143, -2.0672495365142822, 0.25481531023979187, 0.30027976632118225, -1.400816559791565]\n",
      "Last 5 elements: [0.6267207264900208, -1.3999319076538086, 0.4772467613220215, 0.5549722909927368, 0.36635622382164]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-2.5818417072296143, -2.0672495365142822, 0.25481531023979187, 0.30027976632118225, -1.400816559791565]\n",
      "Last 5 elements: [0.6267207264900208, -1.3999319076538086, 0.4772467613220215, 0.5549722909927368, 0.36635622382164]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.271511435508728, -1.018083930015564, 0.12549203634262085, 0.14788247644901276, -0.6898773908615112]\n",
      "Last 5 elements: [0.4980529844760895, -1.1125215291976929, 0.37926650047302246, 0.441034734249115, 0.29114213585853577]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.271511435508728, -1.018083930015564, 0.12549203634262085, 0.14788247644901276, -0.6898773908615112]\n",
      "Last 5 elements: [0.4980529844760895, -1.1125215291976929, 0.37926650047302246, 0.441034734249115, 0.29114213585853577]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.1336802244186401, -0.04987382888793945, -1.2960999011993408, 0.5800267457962036, -0.37441861629486084]\n",
      "Last 5 elements: [-0.7937265634536743, -3.9045214653015137, 0.7930164933204651, 1.1426606178283691, 1.4434932470321655]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0028311344794929028, -0.0020680339075624943, -0.038370586931705475, -0.07308153063058853, 0.0540103055536747]\n",
      "Last 5 elements: [-0.827612578868866, -0.39598312973976135, 0.22090022265911102, 0.2068708837032318, 0.50275719165802]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.0645809918642044, -0.013193868100643158, -0.03969646245241165, -0.18310147523880005, -0.07704298198223114]\n",
      "Last 5 elements: [-0.5068109035491943, -1.4198262691497803, 2.4566493034362793, 1.1460134983062744, -10.386022567749023]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.0645809918642044, -0.013193868100643158, -0.03969646245241165, -0.18310147523880005, -0.07704298198223114]\n",
      "Last 5 elements: [0.9122467041015625, 1.1446533203125, -0.33248287439346313, -1.8850429058074951, 0.29022878408432007]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.007940595969557762, -0.0016222601989284158, -0.004880903288722038, -0.022513356059789658, -0.009472867473959923]\n",
      "Last 5 elements: [0.9629897475242615, 1.2083238363265991, -0.35097697377204895, -1.9898970127105713, 0.3063725531101227]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.007940595969557762, -0.0016222601989284158, -0.004880903288722038, -0.022513356059789658, -0.009472867473959923]\n",
      "Last 5 elements: [0.9629897475242615, 1.2083238363265991, -0.35097697377204895, -1.9898970127105713, 0.3063725531101227]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.23757708072662354, -0.07313230633735657, 0.40948161482810974, 0.26238733530044556, 0.013209174387156963]\n",
      "Last 5 elements: [0.6426931619644165, -0.4719144105911255, 0.83821702003479, 0.48702025413513184, -0.5162680149078369]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.026433978229761124, 0.007587052881717682, -0.011448272503912449, 0.027936086058616638, -0.039130374789237976]\n",
      "Last 5 elements: [0.6426931619644165, -0.4719144105911255, 0.83821702003479, 0.48702025413513184, -0.5162680149078369]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.026433978229761124, 0.007587052881717682, -0.011448272503912449, 0.027936086058616638, -0.039130374789237976]\n",
      "Last 5 elements: [0.36993318796157837, -0.3819540739059448, 0.6425686478614807, 0.3907518982887268, -0.28290024399757385]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.032642826437950134, -0.06895682215690613, 0.14612622559070587, 0.041347935795784, -0.023960132151842117]\n",
      "Last 5 elements: [-0.518555760383606, 0.6801868677139282, 0.2787243127822876, 0.5192620158195496, 0.3364764153957367]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.08661457896232605, -0.07976865023374557, -1.2265735864639282, -2.378293991088867, 1.7588318586349487]\n",
      "Last 5 elements: [-0.7128424644470215, -0.17601829767227173, 0.21521469950675964, 0.2474614828824997, 0.43685320019721985]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.00265332730486989, -0.0024436109233647585, -0.03757451847195625, -0.07285600155591965, 0.053879570215940475]\n",
      "Last 5 elements: [-0.9973149299621582, -0.24626152217388153, 0.301099956035614, 0.3462153971195221, 0.611187219619751]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00265332730486989, -0.0024436109233647585, -0.03757451847195625, -0.07285600155591965, 0.053879570215940475]\n",
      "Last 5 elements: [-0.9973149299621582, -0.24626152217388153, 0.301099956035614, 0.3462153971195221, 0.611187219619751]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.7586612105369568, -1.1835038661956787, 0.14091186225414276, -0.6822835206985474, -2.822476863861084]\n",
      "Last 5 elements: [-0.5852965712547302, -0.42057061195373535, -1.4655940532684326, -1.3313589096069336, -2.708770513534546]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.7586612105369568, -1.1835038661956787, 0.14091186225414276, -0.6822835206985474, -2.822476863861084]\n",
      "Last 5 elements: [-0.5852965712547302, -0.42057061195373535, -1.4655940532684326, -1.3313589096069336, -2.708770513534546]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2419651299715042, -0.27744024991989136, 0.07541177421808243, -0.22907795011997223, -0.15840187668800354]\n",
      "Last 5 elements: [-0.2093692272901535, -0.1667058765888214, -0.2749648094177246, -0.2781670093536377, -0.1691838651895523]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00265332730486989, -0.0024436109233647585, -0.03757451847195625, -0.07285600155591965, 0.053879570215940475]\n",
      "Last 5 elements: [-0.9973149299621582, -0.24626152217388153, 0.301099956035614, 0.3462153971195221, 0.611187219619751]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.3455405533313751, -0.20746314525604248, 0.008280031383037567, 0.11002030968666077, -0.6433901190757751]\n",
      "Last 5 elements: [0.7973864078521729, 0.4508669376373291, 0.44196581840515137, 0.36506158113479614, -1.985133171081543]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.08360876142978668, 0.05755862593650818, 0.0006244118558242917, -0.025203226134181023, 0.10191420465707779]\n",
      "Last 5 elements: [-0.16694816946983337, -0.07516216486692429, -0.12152504920959473, -0.10154809057712555, 0.3358525037765503]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.0317096710205078, -0.5259603261947632, -1.2846965789794922, 0.2573127746582031, -2.4241178035736084]\n",
      "Last 5 elements: [1.6310499906539917, -0.6309921741485596, -1.7175029516220093, -0.570906400680542, 0.4637902081012726]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00265332730486989, -0.0024436109233647585, -0.03757451847195625, -0.07285600155591965, 0.053879570215940475]\n",
      "Last 5 elements: [-0.9973149299621582, -0.24626152217388153, 0.301099956035614, 0.3462153971195221, 0.611187219619751]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.0317096710205078, -0.5259603261947632, -1.2846965789794922, 0.2573127746582031, -2.4241178035736084]\n",
      "Last 5 elements: [1.6310499906539917, -0.6309921741485596, -1.7175029516220093, -0.570906400680542, 0.4637902081012726]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.0866, -0.0798, -1.2266,  ...,  1.0121, -0.6910, -1.1243],\n",
      "         [ 0.8742,  1.0541,  1.2506,  ...,  0.1791,  0.9736,  0.4187],\n",
      "         [ 0.8101,  0.0092, -0.7880,  ...,  1.0791, -0.4576, -0.3096],\n",
      "         [ 0.2062,  0.4165, -0.1063,  ...,  0.6508,  0.2588, -0.2338],\n",
      "         [ 0.1253,  0.7517, -0.3054,  ...,  0.6428,  0.5292, -0.3186],\n",
      "         [ 0.1843,  0.4287,  0.4618,  ...,  0.2152,  0.2475,  0.4369]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.09241847693920135, -0.06750811636447906, -1.2525548934936523, -2.385645627975464, 1.7630919218063354]\n",
      "Last 5 elements: [-0.620643138885498, -0.2969556450843811, 0.16565747559070587, 0.1551366001367569, 0.37702763080596924]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2700527310371399, -0.17328450083732605, -1.4549928903579712, -2.3325438499450684, 1.327823281288147]\n",
      "Last 5 elements: [-0.42284148931503296, -0.28820881247520447, -0.09015762805938721, 0.1459542214870453, 0.5193151831626892]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2700527310371399, -0.17328450083732605, -1.4549928903579712, -2.3325438499450684, 1.327823281288147]\n",
      "Last 5 elements: [-0.42284148931503296, -0.28820881247520447, -0.09015762805938721, 0.1459542214870453, 0.5193151831626892]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.008267814293503761, -0.005305201280862093, -0.04454541578888893, -0.07141212373971939, 0.04065204784274101]\n",
      "Last 5 elements: [-0.5389662384986877, -0.367359459400177, -0.1149175688624382, 0.1860375553369522, 0.6619344353675842]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008267814293503761, -0.005305201280862093, -0.04454541578888893, -0.07141212373971939, 0.04065204784274101]\n",
      "Last 5 elements: [-0.5389662384986877, -0.367359459400177, -0.1149175688624382, 0.1860375553369522, 0.6619344353675842]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.3153959512710571, 5.414787292480469, -0.22354735434055328, -1.7407094240188599, -3.3161606788635254]\n",
      "Last 5 elements: [-0.7201462388038635, 3.049328327178955, -0.7405835390090942, -1.7528449296951294, -0.34170645475387573]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.3153959512710571, 5.414787292480469, -0.22354735434055328, -1.7407094240188599, -3.3161606788635254]\n",
      "Last 5 elements: [-0.7201462388038635, 3.049328327178955, -0.7405835390090942, -1.7528449296951294, -0.34170645475387573]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.617206871509552, 2.540713310241699, -0.10489234328269958, -0.8167714476585388, -1.556000828742981]\n",
      "Last 5 elements: [-0.6044641733169556, 2.5594937801361084, -0.6216185092926025, -1.4712733030319214, -0.2868157923221588]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.617206871509552, 2.540713310241699, -0.10489234328269958, -0.8167714476585388, -1.556000828742981]\n",
      "Last 5 elements: [-0.6044641733169556, 2.5594937801361084, -0.6216185092926025, -1.4712733030319214, -0.2868157923221588]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.18993449211120605, 1.9525556564331055, 0.5146634578704834, 0.8419315814971924, -1.1209763288497925]\n",
      "Last 5 elements: [-0.304036021232605, 0.09121300280094147, -0.9192387461662292, -3.692603349685669, 3.9320058822631836]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008267814293503761, -0.005305201280862093, -0.04454541578888893, -0.07141212373971939, 0.04065204784274101]\n",
      "Last 5 elements: [-0.5389662384986877, -0.367359459400177, -0.1149175688624382, 0.1860375553369522, 0.6619344353675842]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.08461839705705643, 0.07405165582895279, -0.09288956969976425, 0.19566944241523743, -0.22391477227210999]\n",
      "Last 5 elements: [1.2272639274597168, 5.583731651306152, -0.24309086799621582, 0.2575809955596924, 2.395782947540283]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.08461839705705643, 0.07405165582895279, -0.09288956969976425, 0.19566944241523743, -0.22391477227210999]\n",
      "Last 5 elements: [-0.9934201836585999, 2.379817008972168, -0.00981903076171875, -1.1668918132781982, -0.020290672779083252]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.011721353977918625, 0.01025764737278223, -0.012867078185081482, 0.02710416354238987, -0.03101671114563942]\n",
      "Last 5 elements: [-0.9379720687866211, 2.2469866275787354, -0.009270977228879929, -1.1017612218856812, -0.019158141687512398]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.011721353977918625, 0.01025764737278223, -0.012867078185081482, 0.02710416354238987, -0.03101671114563942]\n",
      "Last 5 elements: [-0.9379720687866211, 2.2469866275787354, -0.009270977228879929, -1.1017612218856812, -0.019158141687512398]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.05078662931919098, 0.1712564080953598, -0.07482324540615082, -0.18154042959213257, -0.10425898432731628]\n",
      "Last 5 elements: [-0.1049237996339798, 0.23766493797302246, 0.22373855113983154, 0.28739356994628906, -0.021070487797260284]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.009410083293914795, 0.013884295709431171, 0.03377429395914078, -0.018191322684288025, 0.0006893640384078026]\n",
      "Last 5 elements: [-0.1049237996339798, 0.23766493797302246, 0.22373855113983154, 0.28739356994628906, -0.021070487797260284]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.009410083293914795, 0.013884295709431171, 0.03377429395914078, -0.018191322684288025, 0.0006893640384078026]\n",
      "Last 5 elements: [0.07197679579257965, 0.22900132834911346, 0.11622805893421173, -0.026800217106938362, -0.09310467541217804]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.09713812172412872, -0.11931877583265305, -0.18984511494636536, -0.020099306479096413, 0.036742717027664185]\n",
      "Last 5 elements: [-0.010262161493301392, -0.029971100389957428, -0.5351647138595581, -0.13001060485839844, -0.29028162360191345]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.28732389211654663, -0.1944994032382965, -1.4887473583221436, -2.3361175060272217, 1.3343561887741089]\n",
      "Last 5 elements: [-0.4246661067008972, -0.2935376763343811, -0.1853100061416626, 0.12283831089735031, 0.46770304441452026]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.008798003196716309, -0.005955670494586229, -0.045586198568344116, -0.07153310626745224, 0.040858663618564606]\n",
      "Last 5 elements: [-0.5466766953468323, -0.37787383794784546, -0.2385513335466385, 0.1581309288740158, 0.6020785570144653]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008798003196716309, -0.005955670494586229, -0.045586198568344116, -0.07153310626745224, 0.040858663618564606]\n",
      "Last 5 elements: [-0.5466766953468323, -0.37787383794784546, -0.2385513335466385, 0.1581309288740158, 0.6020785570144653]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.1504879593849182, -2.650939464569092, -0.006113678216934204, -1.604649305343628, -0.005616862326860428]\n",
      "Last 5 elements: [-1.7394516468048096, -3.653557538986206, -1.2109047174453735, -1.8571722507476807, -0.9263197183609009]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.1504879593849182, -2.650939464569092, -0.006113678216934204, -1.604649305343628, -0.005616862326860428]\n",
      "Last 5 elements: [-1.7394516468048096, -3.653557538986206, -1.2109047174453735, -1.8571722507476807, -0.9263197183609009]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.08089497685432434, -0.17477943003177643, -0.0030474949162453413, -0.26851049065589905, -0.002800544025376439]\n",
      "Last 5 elements: [-0.2598437964916229, -0.09223410487174988, -0.27795231342315674, -0.25077950954437256, -0.26277095079421997]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008798003196716309, -0.005955670494586229, -0.045586198568344116, -0.07153310626745224, 0.040858663618564606]\n",
      "Last 5 elements: [-0.5466766953468323, -0.37787383794784546, -0.2385513335466385, 0.1581309288740158, 0.6020785570144653]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.36581099033355713, 0.06664616614580154, 0.7298625111579895, 0.27246055006980896, 0.019483819603919983]\n",
      "Last 5 elements: [-1.5221718549728394, 0.10585105419158936, -0.6719475388526917, 0.844957709312439, -0.37384337186813354]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.029592271894216537, -0.011648379266262054, -0.002224252326413989, -0.07315851747989655, -5.456529470393434e-05]\n",
      "Last 5 elements: [0.3955269157886505, -0.009763076901435852, 0.18676936626434326, -0.211898073554039, 0.09823517501354218]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.545200765132904, -0.2775985300540924, 0.6134865283966064, 0.6684247255325317, -0.519904613494873]\n",
      "Last 5 elements: [3.2079532146453857, 0.9035204648971558, -2.1785693168640137, 1.2079334259033203, -0.7188894748687744]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008798003196716309, -0.005955670494586229, -0.045586198568344116, -0.07153310626745224, 0.040858663618564606]\n",
      "Last 5 elements: [-0.5466766953468323, -0.37787383794784546, -0.2385513335466385, 0.1581309288740158, 0.6020785570144653]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.545200765132904, -0.2775985300540924, 0.6134865283966064, 0.6684247255325317, -0.519904613494873]\n",
      "Last 5 elements: [3.2079532146453857, 0.9035204648971558, -2.1785693168640137, 1.2079334259033203, -0.7188894748687744]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.2873, -0.1945, -1.4887,  ...,  0.9578, -0.8110, -0.9242],\n",
      "         [ 0.8908,  0.9295,  0.8368,  ...,  0.1492,  0.7741,  0.4128],\n",
      "         [ 0.3298, -0.0238, -0.7524,  ...,  0.8024, -0.3870, -0.2432],\n",
      "         [ 0.1708,  0.4628, -0.2751,  ...,  0.3991,  0.1573, -0.2035],\n",
      "         [ 0.1607,  0.8837, -0.3055,  ...,  0.4026,  0.1764, -0.0979],\n",
      "         [ 0.4388,  0.5656,  0.3173,  ..., -0.1853,  0.1228,  0.4677]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2700527310371399, -0.17328450083732605, -1.4549928903579712, -2.3325438499450684, 1.327823281288147]\n",
      "Last 5 elements: [-0.42284148931503296, -0.28820881247520447, -0.09015762805938721, 0.1459542214870453, 0.5193151831626892]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3842606842517853, -0.24385647475719452, -1.3796693086624146, -2.217271566390991, 1.2419170141220093]\n",
      "Last 5 elements: [0.14570856094360352, -0.13289158046245575, -0.5726600289344788, 0.33760908246040344, 0.33988437056541443]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3842606842517853, -0.24385647475719452, -1.3796693086624146, -2.217271566390991, 1.2419170141220093]\n",
      "Last 5 elements: [0.14570856094360352, -0.13289158046245575, -0.5726600289344788, 0.33760908246040344, 0.33988437056541443]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0117715522646904, -0.007470369338989258, -0.042265187948942184, -0.06792453676462173, 0.0380452424287796]\n",
      "Last 5 elements: [0.16688594222068787, -0.15220613777637482, -0.6558908224105835, 0.38667741417884827, 0.3892833888530731]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0117715522646904, -0.007470369338989258, -0.042265187948942184, -0.06792453676462173, 0.0380452424287796]\n",
      "Last 5 elements: [0.16688594222068787, -0.15220613777637482, -0.6558908224105835, 0.38667741417884827, 0.3892833888530731]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [4.16823148727417, -1.3455402851104736, 1.243218183517456, -0.25424259901046753, 1.0131827592849731]\n",
      "Last 5 elements: [-2.079714298248291, 1.8495380878448486, 0.08633148670196533, 0.7249636650085449, -0.56289142370224]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [4.16823148727417, -1.3455402851104736, 1.243218183517456, -0.25424259901046753, 1.0131827592849731]\n",
      "Last 5 elements: [-2.079714298248291, 1.8495380878448486, 0.08633148670196533, 0.7249636650085449, -0.56289142370224]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.6561450958251953, -0.8574260473251343, 0.792222797870636, -0.16201241314411163, 0.6456360220909119]\n",
      "Last 5 elements: [-1.6823692321777344, 1.496169924736023, 0.06983720511198044, 0.586453914642334, -0.4553467929363251]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.6561450958251953, -0.8574260473251343, 0.792222797870636, -0.16201241314411163, 0.6456360220909119]\n",
      "Last 5 elements: [-1.6823692321777344, 1.496169924736023, 0.06983720511198044, 0.586453914642334, -0.4553467929363251]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.1116788238286972, 0.4446762204170227, 0.4983270764350891, 0.9535282850265503, -0.9697943925857544]\n",
      "Last 5 elements: [2.599344253540039, -0.20684894919395447, 0.0819421261548996, -0.35460445284843445, 2.7637040615081787]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0117715522646904, -0.007470369338989258, -0.042265187948942184, -0.06792453676462173, 0.0380452424287796]\n",
      "Last 5 elements: [0.16688594222068787, -0.15220613777637482, -0.6558908224105835, 0.38667741417884827, 0.3892833888530731]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.09567932039499283, 0.040836043655872345, -0.07208716124296188, -0.009359966963529587, -0.10846778750419617]\n",
      "Last 5 elements: [0.5366337895393372, -1.6231921911239624, -12.967156410217285, 2.0477819442749023, 2.9053525924682617]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.09567932039499283, 0.040836043655872345, -0.07208716124296188, -0.009359966963529587, -0.10846778750419617]\n",
      "Last 5 elements: [-1.4129283428192139, 0.20149445533752441, 0.030313998460769653, -2.9476609230041504, -0.11547189950942993]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.013104598969221115, 0.005593057721853256, -0.009873328730463982, -0.0012819762341678143, -0.014856155030429363]\n",
      "Last 5 elements: [-1.0007781982421875, 0.14271867275238037, 0.021471425890922546, -2.0878303050994873, -0.08178883045911789]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.013104598969221115, 0.005593057721853256, -0.009873328730463982, -0.0012819762341678143, -0.014856155030429363]\n",
      "Last 5 elements: [-1.0007781982421875, 0.14271867275238037, 0.021471425890922546, -2.0878303050994873, -0.08178883045911789]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.07236547768115997, -0.035370808094739914, 0.08231285214424133, -0.042285144329071045, -0.09067720919847488]\n",
      "Last 5 elements: [0.25125518441200256, 1.3051923513412476, -1.0075170993804932, -0.5420488119125366, -1.0211796760559082]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.011715399101376534, 0.008661806583404541, 0.08011538535356522, -0.01581493578851223, -0.24613413214683533]\n",
      "Last 5 elements: [0.25125518441200256, 1.3051923513412476, -1.0075170993804932, -0.5420488119125366, -1.0211796760559082]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.011715399101376534, 0.008661806583404541, 0.08011538535356522, -0.01581493578851223, -0.24613413214683533]\n",
      "Last 5 elements: [0.039369989186525345, 0.4488617777824402, -0.46938154101371765, -0.0474393330514431, -0.38050377368927]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.10605604946613312, -0.00783681869506836, -0.13152281939983368, 0.1952528953552246, 0.07020216435194016]\n",
      "Last 5 elements: [-0.06173288822174072, -0.2538377046585083, 0.3583194613456726, -0.3729018270969391, -0.2765967845916748]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.40311747789382935, -0.24524986743927002, -1.403054118156433, -2.182555675506592, 1.2543989419937134]\n",
      "Last 5 elements: [0.1347324401140213, -0.17802396416664124, -0.5089507699012756, 0.2713070809841156, 0.2907054126262665]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.012350344099104404, -0.007513740565627813, -0.04298548772931099, -0.06686714291572571, 0.03843112662434578]\n",
      "Last 5 elements: [0.1540113240480423, -0.20349743962287903, -0.5817766189575195, 0.31012845039367676, 0.3323024809360504]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012350344099104404, -0.007513740565627813, -0.04298548772931099, -0.06686714291572571, 0.03843112662434578]\n",
      "Last 5 elements: [0.1540113240480423, -0.20349743962287903, -0.5817766189575195, 0.31012845039367676, 0.3323024809360504]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-3.5697946548461914, 0.49040091037750244, -1.3794372081756592, -4.461427688598633, -0.5145463943481445]\n",
      "Last 5 elements: [-1.4878220558166504, -0.9226851463317871, -2.6097888946533203, -2.1838698387145996, -2.479247570037842]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-3.5697946548461914, 0.49040091037750244, -1.3794372081756592, -4.461427688598633, -0.5145463943481445]\n",
      "Last 5 elements: [-1.4878220558166504, -0.9226851463317871, -2.6097888946533203, -2.1838698387145996, -2.479247570037842]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.09777767956256866, 0.30414706468582153, -0.27740398049354553, -0.05092310532927513, -0.19250640273094177]\n",
      "Last 5 elements: [-0.2741294801235199, -0.2624219059944153, -0.17879945039749146, -0.22102588415145874, -0.191709965467453]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012350344099104404, -0.007513740565627813, -0.04298548772931099, -0.06686714291572571, 0.03843112662434578]\n",
      "Last 5 elements: [0.1540113240480423, -0.20349743962287903, -0.5817766189575195, 0.31012845039367676, 0.3323024809360504]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [3.4535722732543945, -0.37856101989746094, -0.3782685697078705, 11.882452964782715, -0.056198544800281525]\n",
      "Last 5 elements: [0.37511324882507324, 0.5840588808059692, -0.832791805267334, -2.8505022525787354, 0.41117674112319946]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.3376822769641876, -0.1151382252573967, 0.10493320971727371, -0.605091392993927, 0.010818579234182835]\n",
      "Last 5 elements: [-0.10282959789037704, -0.15326984226703644, 0.14890271425247192, 0.6300348043441772, -0.07882668077945709]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.042510390281677246, 0.09274095296859741, -0.27588871121406555, 0.07508312165737152, -1.2293649911880493]\n",
      "Last 5 elements: [-1.093178391456604, -1.4048646688461304, -0.7908200025558472, 0.9274791479110718, 0.14281022548675537]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012350344099104404, -0.007513740565627813, -0.04298548772931099, -0.06686714291572571, 0.03843112662434578]\n",
      "Last 5 elements: [0.1540113240480423, -0.20349743962287903, -0.5817766189575195, 0.31012845039367676, 0.3323024809360504]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.042510390281677246, 0.09274095296859741, -0.27588871121406555, 0.07508312165737152, -1.2293649911880493]\n",
      "Last 5 elements: [-1.093178391456604, -1.4048646688461304, -0.7908200025558472, 0.9274791479110718, 0.14281022548675537]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.4031, -0.2452, -1.4031,  ...,  0.8778, -0.7284, -1.2171],\n",
      "         [ 1.0053,  0.9949,  0.7486,  ..., -0.3109,  0.5016,  0.4253],\n",
      "         [ 0.6642,  0.0341, -0.6514,  ...,  0.4270, -0.2934, -0.6167],\n",
      "         [ 0.5117,  0.2526, -0.2000,  ...,  0.0236,  0.0312, -0.2179],\n",
      "         [ 0.2902,  1.0018,  0.0497,  ...,  0.1912,  0.1417, -0.2849],\n",
      "         [ 0.8125,  0.8644,  0.2931,  ..., -0.5090,  0.2713,  0.2907]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3842606842517853, -0.24385647475719452, -1.3796693086624146, -2.217271566390991, 1.2419170141220093]\n",
      "Last 5 elements: [0.14570856094360352, -0.13289158046245575, -0.5726600289344788, 0.33760908246040344, 0.33988437056541443]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4106758236885071, -0.2287605106830597, -1.4521071910858154, -2.169205904006958, 1.0358176231384277]\n",
      "Last 5 elements: [-0.05963487923145294, -0.4278091490268707, -0.6495587229728699, 0.43621304631233215, 0.31609708070755005]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4106758236885071, -0.2287605106830597, -1.4521071910858154, -2.169205904006958, 1.0358176231384277]\n",
      "Last 5 elements: [-0.05963487923145294, -0.4278091490268707, -0.6495587229728699, 0.43621304631233215, 0.31609708070755005]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.012597736902534962, -0.007017371244728565, -0.044544294476509094, -0.06654174625873566, 0.03177435323596001]\n",
      "Last 5 elements: [-0.06552263349294662, -0.4700467884540558, -0.7136896848678589, 0.47928041219711304, 0.34730538725852966]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012597736902534962, -0.007017371244728565, -0.044544294476509094, -0.06654174625873566, 0.03177435323596001]\n",
      "Last 5 elements: [-0.06552263349294662, -0.4700467884540558, -0.7136896848678589, 0.47928041219711304, 0.34730538725852966]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.9172978401184082, -0.7048472166061401, 1.071943998336792, -0.2594485580921173, -3.1076748371124268]\n",
      "Last 5 elements: [0.5900701284408569, -1.532450795173645, 0.3085479736328125, -0.9661383032798767, -0.6961108446121216]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.9172978401184082, -0.7048472166061401, 1.071943998336792, -0.2594485580921173, -3.1076748371124268]\n",
      "Last 5 elements: [0.5900701284408569, -1.532450795173645, 0.3085479736328125, -0.9661383032798767, -0.6961108446121216]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.42495858669281006, -0.3265361189842224, 0.4966018795967102, -0.12019530683755875, -1.439699411392212]\n",
      "Last 5 elements: [0.48672035336494446, -1.2640446424484253, 0.25450631976127625, -0.7969208359718323, -0.574188232421875]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.42495858669281006, -0.3265361189842224, 0.4966018795967102, -0.12019530683755875, -1.439699411392212]\n",
      "Last 5 elements: [0.48672035336494446, -1.2640446424484253, 0.25450631976127625, -0.7969208359718323, -0.574188232421875]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.46486809849739075, -0.5206983089447021, 0.5991942286491394, 0.45991891622543335, -0.02089419960975647]\n",
      "Last 5 elements: [-1.5612084865570068, 1.8125278949737549, -2.748809814453125, -1.9486801624298096, -3.157219171524048]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012597736902534962, -0.007017371244728565, -0.044544294476509094, -0.06654174625873566, 0.03177435323596001]\n",
      "Last 5 elements: [-0.06552263349294662, -0.4700467884540558, -0.7136896848678589, 0.47928041219711304, 0.34730538725852966]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.40790513157844543, -0.045074719935655594, -0.13220512866973877, -0.03323906660079956, -0.029428012669086456]\n",
      "Last 5 elements: [-0.665734052658081, -0.8905093669891357, 14.053277015686035, -0.039403438568115234, 0.7193976044654846]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.40790513157844543, -0.045074719935655594, -0.13220512866973877, -0.03323906660079956, -0.029428012669086456]\n",
      "Last 5 elements: [0.8272150754928589, 0.7700542211532593, 1.7487329244613647, -0.07468616962432861, 2.7422876358032227]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.060341525822877884, -0.006667916662991047, -0.01955714449286461, -0.004917064681649208, -0.004353294614702463]\n",
      "Last 5 elements: [0.7250149846076965, 0.6749162077903748, 1.5326818227767944, -0.06545890122652054, 2.4034857749938965]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.060341525822877884, -0.006667916662991047, -0.01955714449286461, -0.004917064681649208, -0.004353294614702463]\n",
      "Last 5 elements: [0.7250149846076965, 0.6749162077903748, 1.5326818227767944, -0.06545890122652054, 2.4034857749938965]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.034306515008211136, -0.1022133082151413, 0.031940020620822906, -0.04008959233760834, 0.09564565122127533]\n",
      "Last 5 elements: [0.03438931703567505, 0.7585423588752747, -0.8632392883300781, -0.08455789089202881, 0.8713976740837097]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.06530894339084625, -0.02681896835565567, -0.018133923411369324, -0.0020448314025998116, 0.023073358461260796]\n",
      "Last 5 elements: [0.03438931703567505, 0.7585423588752747, -0.8632392883300781, -0.08455789089202881, 0.8713976740837097]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.06530894339084625, -0.02681896835565567, -0.018133923411369324, -0.0020448314025998116, 0.023073358461260796]\n",
      "Last 5 elements: [0.6053597927093506, -0.03942001983523369, -0.13710875809192657, 0.13675622642040253, 0.06819792091846466]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.09693058580160141, 0.11216159909963608, -0.0010076463222503662, -0.008854888379573822, 0.08808796107769012]\n",
      "Last 5 elements: [0.1311967968940735, 0.7130703330039978, -0.13270097970962524, -0.2647569179534912, 0.03940998762845993]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3934415578842163, -0.20881815254688263, -1.4522863626480103, -2.1707804203033447, 1.051479697227478]\n",
      "Last 5 elements: [-0.03630806505680084, -0.3010251224040985, -0.6731529831886292, 0.38913923501968384, 0.3231041729450226]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.012068482115864754, -0.006405317224562168, -0.044547636061906815, -0.06658682227134705, 0.03225323557853699]\n",
      "Last 5 elements: [-0.03993936628103256, -0.3311317265033722, -0.740477442741394, 0.4280584454536438, 0.35541898012161255]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012068482115864754, -0.006405317224562168, -0.044547636061906815, -0.06658682227134705, 0.03225323557853699]\n",
      "Last 5 elements: [-0.03993936628103256, -0.3311317265033722, -0.740477442741394, 0.4280584454536438, 0.35541898012161255]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.8567463755607605, -1.2098968029022217, -0.24007785320281982, -1.1339445114135742, -0.16137579083442688]\n",
      "Last 5 elements: [1.1761876344680786, -1.3413443565368652, -1.1143038272857666, -0.45375490188598633, -1.4643651247024536]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.8567463755607605, -1.2098968029022217, -0.24007785320281982, -1.1339445114135742, -0.16137579083442688]\n",
      "Last 5 elements: [1.1761876344680786, -1.3413443565368652, -1.1143038272857666, -0.45375490188598633, -1.4643651247024536]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2553271949291229, -0.2779366672039032, -0.10569839924573898, -0.27604052424430847, -0.07419145107269287]\n",
      "Last 5 elements: [0.8989151120185852, -0.27804601192474365, -0.27531036734580994, -0.17626942694187164, -0.2750086486339569]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012068482115864754, -0.006405317224562168, -0.044547636061906815, -0.06658682227134705, 0.03225323557853699]\n",
      "Last 5 elements: [-0.03993936628103256, -0.3311317265033722, -0.740477442741394, 0.4280584454536438, 0.35541898012161255]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.14036396145820618, -0.26729679107666016, 0.07621681690216064, 0.7327362298965454, 0.053334835916757584]\n",
      "Last 5 elements: [-0.5479391813278198, 0.6914936900138855, 0.9039578437805176, 0.14338421821594238, -0.41438889503479004]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.035838738083839417, 0.07429157942533493, -0.008055995218455791, -0.20226489007472992, -0.003956988919526339]\n",
      "Last 5 elements: [-0.4925508201122284, -0.1922670602798462, -0.24886897206306458, -0.025274254381656647, 0.11396052688360214]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.006347417831421, -0.37237346172332764, -0.44702744483947754, -0.14802208542823792, -0.10682187974452972]\n",
      "Last 5 elements: [-0.43201130628585815, 0.21386218070983887, -0.9726368188858032, 1.5554625988006592, -0.09115085005760193]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012068482115864754, -0.006405317224562168, -0.044547636061906815, -0.06658682227134705, 0.03225323557853699]\n",
      "Last 5 elements: [-0.03993936628103256, -0.3311317265033722, -0.740477442741394, 0.4280584454536438, 0.35541898012161255]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.006347417831421, -0.37237346172332764, -0.44702744483947754, -0.14802208542823792, -0.10682187974452972]\n",
      "Last 5 elements: [-0.43201130628585815, 0.21386218070983887, -0.9726368188858032, 1.5554625988006592, -0.09115085005760193]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3934, -0.2088, -1.4523,  ...,  0.4857, -0.6681, -1.1788],\n",
      "         [ 0.7849,  0.8080,  1.1827,  ..., -0.4857,  0.6082,  0.1824],\n",
      "         [ 0.8110, -0.2093, -0.8583,  ...,  0.5371, -0.0911, -0.4885],\n",
      "         [ 0.5853,  0.2480,  0.0020,  ..., -0.0498, -0.0182, -0.4359],\n",
      "         [ 0.0823,  1.0355,  0.0069,  ...,  0.1619,  0.3026, -0.4426],\n",
      "         [ 0.5580,  0.5667,  0.9109,  ..., -0.6732,  0.3891,  0.3231]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4106758236885071, -0.2287605106830597, -1.4521071910858154, -2.169205904006958, 1.0358176231384277]\n",
      "Last 5 elements: [-0.05963487923145294, -0.4278091490268707, -0.6495587229728699, 0.43621304631233215, 0.31609708070755005]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5723702907562256, -0.27502620220184326, -1.5317679643630981, -2.197098731994629, 1.0324867963790894]\n",
      "Last 5 elements: [-0.11311975121498108, -0.26300039887428284, -0.8460879921913147, 0.6657007932662964, 0.30689752101898193]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5723702907562256, -0.27502620220184326, -1.5317679643630981, -2.197098731994629, 1.0324867963790894]\n",
      "Last 5 elements: [-0.11311975121498108, -0.26300039887428284, -0.8460879921913147, 0.6657007932662964, 0.30689752101898193]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.01756366714835167, -0.008439411409199238, -0.047003597021102905, -0.06741983443498611, 0.031682729721069336]\n",
      "Last 5 elements: [-0.1176244467496872, -0.27347368001937866, -0.879781186580658, 0.6922105550765991, 0.3191188871860504]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01756366714835167, -0.008439411409199238, -0.047003597021102905, -0.06741983443498611, 0.031682729721069336]\n",
      "Last 5 elements: [-0.1176244467496872, -0.27347368001937866, -0.879781186580658, 0.6922105550765991, 0.3191188871860504]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.0487089157104492, -0.019606832414865494, 1.2060770988464355, 2.0929980278015137, -2.0811984539031982]\n",
      "Last 5 elements: [-1.2212196588516235, 1.887853741645813, 1.4031291007995605, -0.4369833767414093, 0.9707391858100891]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.0487089157104492, -0.019606832414865494, 1.2060770988464355, 2.0929980278015137, -2.0811984539031982]\n",
      "Last 5 elements: [-1.2212196588516235, 1.887853741645813, 1.4031291007995605, -0.4369833767414093, 0.9707391858100891]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.6991382241249084, -0.013071201741695404, 0.8040502071380615, 1.3953299522399902, -1.3874635696411133]\n",
      "Last 5 elements: [-1.0862160921096802, 1.6791549921035767, 1.2480157613754272, -0.3886756896972656, 0.8634257912635803]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.6991382241249084, -0.013071201741695404, 0.8040502071380615, 1.3953299522399902, -1.3874635696411133]\n",
      "Last 5 elements: [-1.0862160921096802, 1.6791549921035767, 1.2480157613754272, -0.3886756896972656, 0.8634257912635803]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.23104411363601685, -1.1691701412200928, -0.29356032609939575, -0.8239714503288269, 1.4186021089553833]\n",
      "Last 5 elements: [0.39433544874191284, -0.6094264388084412, -8.21255874633789, 0.947708249092102, 1.5001676082611084]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01756366714835167, -0.008439411409199238, -0.047003597021102905, -0.06741983443498611, 0.031682729721069336]\n",
      "Last 5 elements: [-0.1176244467496872, -0.27347368001937866, -0.879781186580658, 0.6922105550765991, 0.3191188871860504]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.07160280644893646, -0.20669257640838623, -0.0605749636888504, 0.0927286446094513, -0.047286003828048706]\n",
      "Last 5 elements: [1.8061165809631348, -0.5997213125228882, 2.313560962677002, -0.3151609003543854, 0.778419017791748]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.07160280644893646, -0.20669257640838623, -0.0605749636888504, 0.0927286446094513, -0.047286003828048706]\n",
      "Last 5 elements: [0.7351866960525513, -0.5037404894828796, -0.0575939416885376, -0.13605491816997528, 0.08019353449344635]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.010652082972228527, -0.0307488851249218, -0.009011511690914631, 0.013794895261526108, -0.00703456299379468]\n",
      "Last 5 elements: [0.6512202024459839, -0.4462077021598816, -0.05101607367396355, -0.12051592767238617, 0.07103453576564789]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.010652082972228527, -0.0307488851249218, -0.009011511690914631, 0.013794895261526108, -0.00703456299379468]\n",
      "Last 5 elements: [0.6512202024459839, -0.4462077021598816, -0.05101607367396355, -0.12051592767238617, 0.07103453576564789]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.06783036887645721, -0.010495733469724655, 0.17401374876499176, -0.021400004625320435, 0.012488104403018951]\n",
      "Last 5 elements: [0.1837269365787506, 1.205317497253418, 0.3815796971321106, 0.12155714631080627, 0.1929703950881958]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.003308534622192383, 0.463762104511261, -0.01940154656767845, -0.012103787623345852, 0.010222790762782097]\n",
      "Last 5 elements: [0.1837269365787506, 1.205317497253418, 0.3815796971321106, 0.12155714631080627, 0.1929703950881958]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.003308534622192383, 0.463762104511261, -0.01940154656767845, -0.012103787623345852, 0.010222790762782097]\n",
      "Last 5 elements: [-0.003637729212641716, 0.039495065808296204, -0.0022278842516243458, 0.06495586782693863, -0.002300392370671034]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.3812066316604614, 0.056949421763420105, 5.9351325035095215e-05, 0.03515378385782242, 0.06522103399038315]\n",
      "Last 5 elements: [-0.5409582257270813, 0.11839534342288971, 0.2963404357433319, -0.2601839303970337, -0.024524003267288208]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6401488780975342, -0.2649005949497223, -1.5317573547363281, -2.1908483505249023, 1.0440831184387207]\n",
      "Last 5 elements: [-0.20930221676826477, -0.2419496774673462, -0.7933986186981201, 0.6194400191307068, 0.30253714323043823]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.019645871594548225, -0.00812967587262392, -0.04700892046093941, -0.06723611801862717, 0.032042425125837326]\n",
      "Last 5 elements: [-0.22402149438858032, -0.2589648962020874, -0.8491947650909424, 0.6630024313926697, 0.32381322979927063]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019645871594548225, -0.00812967587262392, -0.04700892046093941, -0.06723611801862717, 0.032042425125837326]\n",
      "Last 5 elements: [-0.22402149438858032, -0.2589648962020874, -0.8491947650909424, 0.6630024313926697, 0.32381322979927063]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.670939028263092, -1.1867170333862305, 0.212753027677536, -1.3210150003433228, -0.437730073928833]\n",
      "Last 5 elements: [0.23665335774421692, -0.9302619099617004, -0.8851280808448792, -1.28561532497406, -0.631056547164917]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.670939028263092, -1.1867170333862305, 0.212753027677536, -1.3210150003433228, -0.437730073928833]\n",
      "Last 5 elements: [0.23665335774421692, -0.9302619099617004, -0.8851280808448792, -1.28561532497406, -0.631056547164917]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.22696968913078308, -0.27750974893569946, 0.11764997988939285, -0.2782711088657379, -0.17171362042427063]\n",
      "Last 5 elements: [0.13226290047168732, -0.26314467191696167, -0.25856029987335205, -0.27845898270606995, -0.21914765238761902]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019645871594548225, -0.00812967587262392, -0.04700892046093941, -0.06723611801862717, 0.032042425125837326]\n",
      "Last 5 elements: [-0.22402149438858032, -0.2589648962020874, -0.8491947650909424, 0.6630024313926697, 0.32381322979927063]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.16450121998786926, -0.36494237184524536, -0.28934043645858765, -0.016188647598028183, 0.2949483096599579]\n",
      "Last 5 elements: [-0.18648958206176758, -0.694495677947998, 1.1771745681762695, 0.0794721245765686, 0.44055113196372986]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.037336789071559906, 0.10127506405115128, -0.0340408980846405, 0.0045048329047858715, -0.05064664036035538]\n",
      "Last 5 elements: [-0.024665653705596924, 0.1827528327703476, -0.30437061190605164, -0.0221297275274992, -0.0965457484126091]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2940610647201538, 1.4591255187988281, -0.0608610063791275, 0.6243532299995422, -1.2441394329071045]\n",
      "Last 5 elements: [-0.06772434711456299, 0.2583165764808655, -0.3274996280670166, -1.7939027547836304, -1.0121599435806274]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019645871594548225, -0.00812967587262392, -0.04700892046093941, -0.06723611801862717, 0.032042425125837326]\n",
      "Last 5 elements: [-0.22402149438858032, -0.2589648962020874, -0.8491947650909424, 0.6630024313926697, 0.32381322979927063]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2940610647201538, 1.4591255187988281, -0.0608610063791275, 0.6243532299995422, -1.2441394329071045]\n",
      "Last 5 elements: [-0.06772434711456299, 0.2583165764808655, -0.3274996280670166, -1.7939027547836304, -1.0121599435806274]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6401, -0.2649, -1.5318,  ...,  0.2605, -0.7280, -1.0861],\n",
      "         [ 0.8971,  0.8386,  1.2043,  ..., -0.8703,  0.4879,  0.1595],\n",
      "         [ 0.9747, -0.1741, -0.4888,  ...,  0.7247, -0.2530, -0.2397],\n",
      "         [ 0.7828,  0.4835,  0.3610,  ...,  0.1313, -0.1209, -0.1862],\n",
      "         [ 0.4109,  1.1823,  0.0792,  ...,  0.2943,  0.2862, -0.2051],\n",
      "         [ 1.2298,  0.5252,  1.1956,  ..., -0.7934,  0.6194,  0.3025]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5723702907562256, -0.27502620220184326, -1.5317679643630981, -2.197098731994629, 1.0324867963790894]\n",
      "Last 5 elements: [-0.11311975121498108, -0.26300039887428284, -0.8460879921913147, 0.6657007932662964, 0.30689752101898193]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6924329996109009, -0.005467832088470459, -1.5425784587860107, -2.079838275909424, 0.822874903678894]\n",
      "Last 5 elements: [-0.22134362161159515, -0.1960209459066391, -0.8516281247138977, 0.3004837930202484, 0.12257492542266846]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6924329996109009, -0.005467832088470459, -1.5425784587860107, -2.079838275909424, 0.822874903678894]\n",
      "Last 5 elements: [-0.22134362161159515, -0.1960209459066391, -0.8516281247138977, 0.3004837930202484, 0.12257492542266846]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.021150192245841026, -0.00016701356798876077, -0.047117672860622406, -0.0635281428694725, 0.025134509429335594]\n",
      "Last 5 elements: [-0.22554819285869598, -0.19974449276924133, -0.8678053617477417, 0.30619168281555176, 0.12490331381559372]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021150192245841026, -0.00016701356798876077, -0.047117672860622406, -0.0635281428694725, 0.025134509429335594]\n",
      "Last 5 elements: [-0.22554819285869598, -0.19974449276924133, -0.8678053617477417, 0.30619168281555176, 0.12490331381559372]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-2.0026824474334717, 2.097022294998169, 0.1387343406677246, -2.460675001144409, -1.8955661058425903]\n",
      "Last 5 elements: [0.31990644335746765, -0.8361943364143372, -0.0890812873840332, 1.3337275981903076, 0.7415119409561157]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-2.0026824474334717, 2.097022294998169, 0.1387343406677246, -2.460675001144409, -1.8955661058425903]\n",
      "Last 5 elements: [0.31990644335746765, -0.8361943364143372, -0.0890812873840332, 1.3337275981903076, 0.7415119409561157]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.3980093002319336, 1.4638649225234985, 0.09684605896472931, -1.7177194356918335, -1.3232347965240479]\n",
      "Last 5 elements: [0.29495546221733093, -0.7709757089614868, -0.08213342726230621, 1.2297040224075317, 0.6836780309677124]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.3980093002319336, 1.4638649225234985, 0.09684605896472931, -1.7177194356918335, -1.3232347965240479]\n",
      "Last 5 elements: [0.29495546221733093, -0.7709757089614868, -0.08213342726230621, 1.2297040224075317, 0.6836780309677124]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.971821665763855, 1.1061577796936035, 0.870438814163208, -0.5158275961875916, 0.4803406000137329]\n",
      "Last 5 elements: [-0.9289454221725464, -1.1005486249923706, 1.433334469795227, -0.27345913648605347, -1.0269228219985962]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021150192245841026, -0.00016701356798876077, -0.047117672860622406, -0.0635281428694725, 0.025134509429335594]\n",
      "Last 5 elements: [-0.22554819285869598, -0.19974449276924133, -0.8678053617477417, 0.30619168281555176, 0.12490331381559372]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.013581998646259308, -0.05051295459270477, 0.061732418835163116, -0.13857688009738922, 0.016357630491256714]\n",
      "Last 5 elements: [-1.0223493576049805, -2.4823460578918457, -10.104660987854004, 0.5907036662101746, -1.895946979522705]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.013581998646259308, -0.05051295459270477, 0.061732418835163116, -0.13857688009738922, 0.016357630491256714]\n",
      "Last 5 elements: [-1.937700629234314, -0.15325725078582764, 0.4041941165924072, -1.5098397731781006, 0.32474881410598755]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.0024295442271977663, -0.009035743772983551, 0.01104267779737711, -0.024788593873381615, 0.00292604835703969]\n",
      "Last 5 elements: [-1.5700629949569702, -0.12417993694543839, 0.3275068402290344, -1.2233797311782837, 0.26313459873199463]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.0024295442271977663, -0.009035743772983551, 0.01104267779737711, -0.024788593873381615, 0.00292604835703969]\n",
      "Last 5 elements: [-1.5700629949569702, -0.12417993694543839, 0.3275068402290344, -1.2233797311782837, 0.26313459873199463]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.04526834189891815, -0.688517153263092, -0.6293111443519592, 0.22116002440452576, -0.15477406978607178]\n",
      "Last 5 elements: [0.7080549597740173, -0.5534874796867371, -0.14416196942329407, -0.7335853576660156, -0.8711377382278442]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.04426223039627075, 0.01384109165519476, 0.0009505972266197205, 0.042273376137018204, -0.010604812763631344]\n",
      "Last 5 elements: [0.7080549597740173, -0.5534874796867371, -0.14416196942329407, -0.7335853576660156, -0.8711377382278442]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.04426223039627075, 0.01384109165519476, 0.0009505972266197205, 0.042273376137018204, -0.010604812763631344]\n",
      "Last 5 elements: [0.11976613104343414, 0.10195887088775635, 0.1123710572719574, -0.06479864567518234, 0.017610903829336166]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.010721243917942047, 0.14984337985515594, -0.023233339190483093, -0.22999358177185059, -0.18801814317703247]\n",
      "Last 5 elements: [-0.03673344850540161, -0.005953654646873474, -0.30919843912124634, -0.21526974439620972, -0.0939452052116394]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6943392157554626, 0.021174347028136253, -1.5467092990875244, -2.1207311153411865, 0.7894452214241028]\n",
      "Last 5 elements: [-0.22787483036518097, -0.19707950949668884, -0.9066036939620972, 0.2622087895870209, 0.10587145388126373]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.021212199702858925, 0.0006468804785981774, -0.04725227504968643, -0.06478875130414963, 0.02411770634353161]\n",
      "Last 5 elements: [-0.2383846789598465, -0.2061690390110016, -0.9484172463417053, 0.2743021547794342, 0.11075436323881149]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021212199702858925, 0.0006468804785981774, -0.04725227504968643, -0.06478875130414963, 0.02411770634353161]\n",
      "Last 5 elements: [-0.2383846789598465, -0.2061690390110016, -0.9484172463417053, 0.2743021547794342, 0.11075436323881149]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.1180641651153564, -0.8793226480484009, -0.2016751766204834, -2.73353910446167, -0.41366949677467346]\n",
      "Last 5 elements: [-0.4126570224761963, 0.7382804751396179, 1.9289789199829102, -1.6351392269134521, 0.9387194514274597]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.1180641651153564, -0.8793226480484009, -0.2016751766204834, -2.73353910446167, -0.41366949677467346]\n",
      "Last 5 elements: [-0.4126570224761963, 0.7382804751396179, 1.9289789199829102, -1.6351392269134521, 0.9387194514274597]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.27545809745788574, -0.2579213082790375, -0.09070368856191635, -0.16680890321731567, -0.1646539270877838]\n",
      "Last 5 elements: [-0.16435106098651886, 0.49953511357307434, 1.684261679649353, -0.2667362689971924, 0.6747899651527405]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021212199702858925, 0.0006468804785981774, -0.04725227504968643, -0.06478875130414963, 0.02411770634353161]\n",
      "Last 5 elements: [-0.2383846789598465, -0.2061690390110016, -0.9484172463417053, 0.2743021547794342, 0.11075436323881149]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [1.5958513021469116, 0.3196430802345276, 0.7303414344787598, 0.801602840423584, 0.36997634172439575]\n",
      "Last 5 elements: [0.6655818819999695, 0.18429583311080933, 0.6226956248283386, 1.3366737365722656, -0.08121663331985474]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.4395901560783386, -0.0824427604675293, -0.06624466180801392, -0.133714497089386, -0.06091805920004845]\n",
      "Last 5 elements: [-0.10938908904790878, 0.09206224232912064, 1.0487823486328125, -0.35653936862945557, -0.05480416864156723]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.4800720810890198, -1.5989573001861572, -1.0412282943725586, -0.33551955223083496, -0.49689629673957825]\n",
      "Last 5 elements: [0.7419512271881104, 0.3640201687812805, -0.873494029045105, -2.8421778678894043, -0.13054391741752625]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021212199702858925, 0.0006468804785981774, -0.04725227504968643, -0.06478875130414963, 0.02411770634353161]\n",
      "Last 5 elements: [-0.2383846789598465, -0.2061690390110016, -0.9484172463417053, 0.2743021547794342, 0.11075436323881149]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.4800720810890198, -1.5989573001861572, -1.0412282943725586, -0.33551955223083496, -0.49689629673957825]\n",
      "Last 5 elements: [0.7419512271881104, 0.3640201687812805, -0.873494029045105, -2.8421778678894043, -0.13054391741752625]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6943,  0.0212, -1.5467,  ...,  0.2392, -0.9831, -1.0422],\n",
      "         [ 0.8184,  0.7114,  1.2264,  ..., -0.9789,  0.3424,  0.0571],\n",
      "         [ 0.7605,  0.1065, -0.6357,  ...,  0.4514,  0.0169, -0.2524],\n",
      "         [ 1.1938,  0.2576,  0.5440,  ...,  0.0693,  0.3706,  0.3554],\n",
      "         [ 0.1498,  1.1127,  0.0382,  ...,  0.2210,  0.4332, -0.2171],\n",
      "         [ 1.1328,  0.7219,  1.1004,  ..., -0.9066,  0.2622,  0.1059]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6924329996109009, -0.005467832088470459, -1.5425784587860107, -2.079838275909424, 0.822874903678894]\n",
      "Last 5 elements: [-0.22134362161159515, -0.1960209459066391, -0.8516281247138977, 0.3004837930202484, 0.12257492542266846]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7796961069107056, -0.26312056183815, -1.731839895248413, -2.180386543273926, 0.7010969519615173]\n",
      "Last 5 elements: [-0.09595577418804169, -0.132356658577919, -1.0619111061096191, -0.24313095211982727, 0.0826607197523117]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7796961069107056, -0.26312056183815, -1.731839895248413, -2.180386543273926, 0.7010969519615173]\n",
      "Last 5 elements: [-0.09595577418804169, -0.132356658577919, -1.0619111061096191, -0.24313095211982727, 0.0826607197523117]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.023705458268523216, -0.007999774999916553, -0.05265391990542412, -0.06629128754138947, 0.021315772086381912]\n",
      "Last 5 elements: [-0.09606865048408508, -0.13251236081123352, -1.0631603002548218, -0.24341696500778198, 0.08275795727968216]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.023705458268523216, -0.007999774999916553, -0.05265391990542412, -0.06629128754138947, 0.021315772086381912]\n",
      "Last 5 elements: [-0.09606865048408508, -0.13251236081123352, -1.0631603002548218, -0.24341696500778198, 0.08275795727968216]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.199229896068573, -1.3046143054962158, -0.9049828052520752, 0.7193812131881714, 0.5531095862388611]\n",
      "Last 5 elements: [-1.9099581241607666, 0.25883936882019043, -1.1645667552947998, -0.16114848852157593, -1.0597591400146484]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.199229896068573, -1.3046143054962158, -0.9049828052520752, 0.7193812131881714, 0.5531095862388611]\n",
      "Last 5 elements: [-1.9099581241607666, 0.25883936882019043, -1.1645667552947998, -0.16114848852157593, -1.0597591400146484]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.16735078394412994, -1.0958607196807861, -0.7601749897003174, 0.6042717695236206, 0.46460556983947754]\n",
      "Last 5 elements: [-1.7927333116531372, 0.24295294284820557, -1.0930907726287842, -0.15125790238380432, -0.9947157502174377]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.16735078394412994, -1.0958607196807861, -0.7601749897003174, 0.6042717695236206, 0.46460556983947754]\n",
      "Last 5 elements: [-1.7927333116531372, 0.24295294284820557, -1.0930907726287842, -0.15125790238380432, -0.9947157502174377]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.638925313949585, 1.322070598602295, -2.2462315559387207, -1.2242281436920166, -0.0012781023979187012]\n",
      "Last 5 elements: [-0.5176535248756409, 0.014849215745925903, 5.212035655975342, -1.861199975013733, 3.5296061038970947]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.023705458268523216, -0.007999774999916553, -0.05265391990542412, -0.06629128754138947, 0.021315772086381912]\n",
      "Last 5 elements: [-0.09606865048408508, -0.13251236081123352, -1.0631603002548218, -0.24341696500778198, 0.08275795727968216]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.16159318387508392, 0.01573954150080681, -0.12205237150192261, 0.14446961879730225, -0.07918359339237213]\n",
      "Last 5 elements: [-0.7440465092658997, -0.3265472650527954, -1.2998230457305908, -3.0815300941467285, -4.227832794189453]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.16159318387508392, 0.01573954150080681, -0.12205237150192261, 0.14446961879730225, -0.07918359339237213]\n",
      "Last 5 elements: [1.832021713256836, -0.09372593462467194, -0.14997602999210358, -0.1978096067905426, 0.05467277765274048]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.024550283327698708, 0.0023912531323730946, -0.01854298636317253, 0.021948760375380516, -0.012030083686113358]\n",
      "Last 5 elements: [1.7941092252731323, -0.09178633987903595, -0.1468723714351654, -0.19371607899665833, 0.053541362285614014]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.024550283327698708, 0.0023912531323730946, -0.01854298636317253, 0.021948760375380516, -0.012030083686113358]\n",
      "Last 5 elements: [1.7941092252731323, -0.09178633987903595, -0.1468723714351654, -0.19371607899665833, 0.053541362285614014]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.09805362671613693, -0.21048705279827118, -0.0457368865609169, -0.08549397438764572, 0.10984773188829422]\n",
      "Last 5 elements: [1.51040518283844, 0.5183773636817932, -1.1477338075637817, -0.2145809531211853, -0.06406287848949432]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.030680887401103973, 0.012098707258701324, 0.06028183922171593, -0.022494863718748093, 0.032745398581027985]\n",
      "Last 5 elements: [1.51040518283844, 0.5183773636817932, -1.1477338075637817, -0.2145809531211853, -0.06406287848949432]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.030680887401103973, 0.012098707258701324, 0.06028183922171593, -0.022494863718748093, 0.032745398581027985]\n",
      "Last 5 elements: [0.8812673091888428, 0.19351176917552948, -0.48214179277420044, -0.08309353142976761, -0.24950338900089264]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.08256196975708008, 0.06670187413692474, -0.15033294260501862, -0.021130278706550598, -0.17256595194339752]\n",
      "Last 5 elements: [0.07182880491018295, -0.021360531449317932, -0.22108101844787598, 0.2266456037759781, 0.09305155277252197]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7943756580352783, -0.2512609660625458, -1.7585691213607788, -2.184143543243408, 0.6704146862030029]\n",
      "Last 5 elements: [-0.08318459987640381, -0.13615456223487854, -1.1012192964553833, -0.20283332467079163, 0.09920530021190643]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.024151410907506943, -0.007639089599251747, -0.053465794771909714, -0.06640453636646271, 0.020382624119520187]\n",
      "Last 5 elements: [-0.08566822856664658, -0.14021970331668854, -1.1340981721878052, -0.20888927578926086, 0.10216725617647171]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024151410907506943, -0.007639089599251747, -0.053465794771909714, -0.06640453636646271, 0.020382624119520187]\n",
      "Last 5 elements: [-0.08566822856664658, -0.14021970331668854, -1.1340981721878052, -0.20888927578926086, 0.10216725617647171]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.35648995637893677, -0.405029296875, -1.0386320352554321, -0.6256522536277771, -1.130230188369751]\n",
      "Last 5 elements: [-2.691934108734131, -0.23089277744293213, -1.4197933673858643, -0.5460337996482849, -2.1936028003692627]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.35648995637893677, -0.405029296875, -1.0386320352554321, -0.6256522536277771, -1.130230188369751]\n",
      "Last 5 elements: [-2.691934108734131, -0.23089277744293213, -1.4197933673858643, -0.5460337996482849, -2.1936028003692627]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.14680595695972443, -0.16205407679080963, -0.2715129852294922, -0.218037948012352, -0.27591022849082947]\n",
      "Last 5 elements: [-0.17080587148666382, -0.10217741876840591, -0.27642521262168884, -0.20027704536914825, -0.22007635235786438]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024151410907506943, -0.007639089599251747, -0.053465794771909714, -0.06640453636646271, 0.020382624119520187]\n",
      "Last 5 elements: [-0.08566822856664658, -0.14021970331668854, -1.1340981721878052, -0.20888927578926086, 0.10216725617647171]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.2553384602069855, -0.052080411463975906, -0.21961137652397156, -0.15496569871902466, 0.38343337178230286]\n",
      "Last 5 elements: [-0.08928975462913513, 2.147120475769043, -0.18420308828353882, 0.7143322229385376, 1.1650947332382202]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.03748520836234093, 0.008439842611551285, 0.059627339243888855, 0.03378840163350105, -0.10579318553209305]\n",
      "Last 5 elements: [0.015251214616000652, -0.2193872332572937, 0.05091837793588638, -0.14306434988975525, -0.25640979409217834]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.4478575885295868, 0.6081739068031311, 0.42987772822380066, -0.23999711871147156, -0.0293007493019104]\n",
      "Last 5 elements: [0.9427470564842224, -1.0637686252593994, -0.48098647594451904, -0.9084025621414185, -1.6609575748443604]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024151410907506943, -0.007639089599251747, -0.053465794771909714, -0.06640453636646271, 0.020382624119520187]\n",
      "Last 5 elements: [-0.08566822856664658, -0.14021970331668854, -1.1340981721878052, -0.20888927578926086, 0.10216725617647171]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.4478575885295868, 0.6081739068031311, 0.42987772822380066, -0.23999711871147156, -0.0293007493019104]\n",
      "Last 5 elements: [0.9427470564842224, -1.0637686252593994, -0.48098647594451904, -0.9084025621414185, -1.6609575748443604]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.7944, -0.2513, -1.7586,  ...,  0.1101, -1.1366, -1.1864],\n",
      "         [ 0.8015,  0.6694,  1.2054,  ..., -1.0677,  0.3701,  0.2216],\n",
      "         [ 1.0943,  0.4228, -0.7782,  ...,  0.3705,  0.0141,  0.2356],\n",
      "         [ 0.9840,  1.2548,  0.1600,  ...,  0.2318,  0.9199,  0.7696],\n",
      "         [ 0.5243,  1.1227,  0.0717,  ...,  0.2527,  0.3593, -0.2604],\n",
      "         [ 1.2454,  0.4019,  0.9162,  ..., -1.1012, -0.2028,  0.0992]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7796961069107056, -0.26312056183815, -1.731839895248413, -2.180386543273926, 0.7010969519615173]\n",
      "Last 5 elements: [-0.09595577418804169, -0.132356658577919, -1.0619111061096191, -0.24313095211982727, 0.0826607197523117]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7147464752197266, -0.14312753081321716, -1.6821367740631104, -2.2268149852752686, 0.6652050018310547]\n",
      "Last 5 elements: [0.08443599939346313, -0.32529282569885254, -1.1867387294769287, -0.3643474578857422, -0.1961132436990738]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7147464752197266, -0.14312753081321716, -1.6821367740631104, -2.2268149852752686, 0.6652050018310547]\n",
      "Last 5 elements: [0.08443599939346313, -0.32529282569885254, -1.1867387294769287, -0.3643474578857422, -0.1961132436990738]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.02170337177813053, -0.004346086177974939, -0.05107830464839935, -0.06761752814054489, 0.020199038088321686]\n",
      "Last 5 elements: [0.0805712565779686, -0.3104037642478943, -1.1324201822280884, -0.3476708233356476, -0.18713690340518951]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02170337177813053, -0.004346086177974939, -0.05107830464839935, -0.06761752814054489, 0.020199038088321686]\n",
      "Last 5 elements: [0.0805712565779686, -0.3104037642478943, -1.1324201822280884, -0.3476708233356476, -0.18713690340518951]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.386288583278656, -2.4747326374053955, -3.7668325901031494, 0.268818736076355, -0.4249664843082428]\n",
      "Last 5 elements: [-0.019684314727783203, -0.3276863694190979, 0.1211242750287056, 0.28837689757347107, 0.38545143604278564]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.386288583278656, -2.4747326374053955, -3.7668325901031494, 0.268818736076355, -0.4249664843082428]\n",
      "Last 5 elements: [-0.019684314727783203, -0.3276863694190979, 0.1211242750287056, 0.28837689757347107, 0.38545143604278564]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.29359951615333557, -1.8809261322021484, -2.862989664077759, 0.20431628823280334, -0.32299673557281494]\n",
      "Last 5 elements: [-0.01821019873023033, -0.303146630525589, 0.1120535358786583, 0.2667809724807739, 0.3565858006477356]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.29359951615333557, -1.8809261322021484, -2.862989664077759, 0.20431628823280334, -0.32299673557281494]\n",
      "Last 5 elements: [-0.01821019873023033, -0.303146630525589, 0.1120535358786583, 0.2667809724807739, 0.3565858006477356]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.3630261719226837, -0.5835386514663696, -0.9836300611495972, -0.6241635084152222, 0.3406957983970642]\n",
      "Last 5 elements: [4.737093448638916, -2.0974717140197754, 4.467917442321777, -6.526447296142578, -0.19206561148166656]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02170337177813053, -0.004346086177974939, -0.05107830464839935, -0.06761752814054489, 0.020199038088321686]\n",
      "Last 5 elements: [0.0805712565779686, -0.3104037642478943, -1.1324201822280884, -0.3476708233356476, -0.18713690340518951]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.0682833194732666, -0.1861197054386139, -0.3097594380378723, 0.31202515959739685, -0.08789315074682236]\n",
      "Last 5 elements: [0.9112758636474609, -1.6477818489074707, 5.14430046081543, 2.6361231803894043, -0.22784468531608582]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.0682833194732666, -0.1861197054386139, -0.3097594380378723, 0.31202515959739685, -0.08789315074682236]\n",
      "Last 5 elements: [-0.28420761227607727, -1.418470025062561, -1.1467061042785645, 1.5220694541931152, 0.35064932703971863]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.010183464735746384, -0.027757050469517708, -0.046196117997169495, 0.04653402045369148, -0.013107986189424992]\n",
      "Last 5 elements: [-0.2999962270259857, -1.4972703456878662, -1.210409164428711, 1.6066250801086426, 0.3701289892196655]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.010183464735746384, -0.027757050469517708, -0.046196117997169495, 0.04653402045369148, -0.013107986189424992]\n",
      "Last 5 elements: [-0.2999962270259857, -1.4972703456878662, -1.210409164428711, 1.6066250801086426, 0.3701289892196655]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.13158920407295227, 0.17232728004455566, 0.06545016169548035, -0.13499507308006287, -0.04041316732764244]\n",
      "Last 5 elements: [-0.9859583377838135, -0.1973699927330017, 0.44476592540740967, -0.5856403112411499, 0.5369861721992493]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.007221776992082596, -0.06049422547221184, 0.17755118012428284, 0.07522305846214294, 0.19984377920627594]\n",
      "Last 5 elements: [-0.9859583377838135, -0.1973699927330017, 0.44476592540740967, -0.5856403112411499, 0.5369861721992493]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.007221776992082596, -0.06049422547221184, 0.17755118012428284, 0.07522305846214294, 0.19984377920627594]\n",
      "Last 5 elements: [-0.8868467211723328, -0.15156380832195282, 0.3592974543571472, -0.4584125876426697, 0.5474496483802795]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.1886187493801117, -0.02380700409412384, 0.20260736346244812, -0.1357657015323639, -0.1897461861371994]\n",
      "Last 5 elements: [-0.29750001430511475, -0.016561437398195267, 0.1824161410331726, -0.34434598684310913, 0.08608192205429077]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6812100410461426, -0.1473604142665863, -1.6461131572723389, -2.2509541511535645, 0.6314681172370911]\n",
      "Last 5 elements: [0.03154044225811958, -0.3282374441623688, -1.154305100440979, -0.4255722463130951, -0.18080785870552063]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.02068505436182022, -0.004474623128771782, -0.04998449608683586, -0.06835059076547623, 0.01917463168501854]\n",
      "Last 5 elements: [0.030388547107577324, -0.316249817609787, -1.1121485233306885, -0.4100298285484314, -0.17420454323291779]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02068505436182022, -0.004474623128771782, -0.04998449608683586, -0.06835059076547623, 0.01917463168501854]\n",
      "Last 5 elements: [0.030388547107577324, -0.316249817609787, -1.1121485233306885, -0.4100298285484314, -0.17420454323291779]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.9886593818664551, 0.011667750775814056, 0.004598658531904221, -1.541900634765625, 0.35909128189086914]\n",
      "Last 5 elements: [0.06722135096788406, -0.9956900477409363, -2.235684633255005, 0.6547580361366272, 0.01852262020111084]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.9886593818664551, 0.011667750775814056, 0.004598658531904221, -1.541900634765625, 0.35909128189086914]\n",
      "Last 5 elements: [0.06722135096788406, -0.9956900477409363, -2.235684633255005, 0.6547580361366272, 0.01852262020111084]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.26810163259506226, 0.005867909174412489, 0.0023046161513775587, -0.2717740833759308, 0.2114402800798416]\n",
      "Last 5 elements: [0.03473992645740509, -0.268626868724823, -0.21594803035259247, 0.43088439106941223, 0.009347079321742058]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02068505436182022, -0.004474623128771782, -0.04998449608683586, -0.06835059076547623, 0.01917463168501854]\n",
      "Last 5 elements: [0.030388547107577324, -0.316249817609787, -1.1121485233306885, -0.4100298285484314, -0.17420454323291779]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [1.5891540050506592, 0.1237478032708168, -0.28501033782958984, 1.3375917673110962, -0.6616535186767578]\n",
      "Last 5 elements: [-0.27437618374824524, 0.11109021306037903, -0.2746674418449402, 0.12241476774215698, -0.5822657942771912]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.42605477571487427, 0.0007261408609338105, -0.0006568394019268453, -0.3635227680206299, -0.13990020751953125]\n",
      "Last 5 elements: [-0.009531808085739613, -0.029841816052794456, 0.05931389331817627, 0.05274661257863045, -0.005442484747618437]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.21963146328926086, 0.733402669429779, 0.4262186884880066, -0.1329222321510315, -0.4170183539390564]\n",
      "Last 5 elements: [0.6606104373931885, 0.39024704694747925, 0.7808382511138916, -0.7859846353530884, 0.8286519050598145]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02068505436182022, -0.004474623128771782, -0.04998449608683586, -0.06835059076547623, 0.01917463168501854]\n",
      "Last 5 elements: [0.030388547107577324, -0.316249817609787, -1.1121485233306885, -0.4100298285484314, -0.17420454323291779]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.21963146328926086, 0.733402669429779, 0.4262186884880066, -0.1329222321510315, -0.4170183539390564]\n",
      "Last 5 elements: [0.6606104373931885, 0.39024704694747925, 0.7808382511138916, -0.7859846353530884, 0.8286519050598145]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6812, -0.1474, -1.6461,  ...,  0.0516, -1.2100, -1.1157],\n",
      "         [ 0.7266,  0.3775,  1.2156,  ..., -1.2663,  0.0980,  0.1549],\n",
      "         [ 0.9602, -0.0825, -1.0168,  ...,  0.4453, -0.0106,  0.1186],\n",
      "         [ 0.9982,  1.3205,  0.2106,  ...,  0.1535,  0.9614,  0.6316],\n",
      "         [ 0.5288,  0.8523,  0.2945,  ...,  0.2317,  0.2933, -0.1789],\n",
      "         [ 1.1881,  0.3487,  1.0130,  ..., -1.1543, -0.4256, -0.1808]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7147464752197266, -0.14312753081321716, -1.6821367740631104, -2.2268149852752686, 0.6652050018310547]\n",
      "Last 5 elements: [0.08443599939346313, -0.32529282569885254, -1.1867387294769287, -0.3643474578857422, -0.1961132436990738]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7202605605125427, -0.016961291432380676, -1.570331335067749, -2.274587631225586, 0.5573222041130066]\n",
      "Last 5 elements: [0.14899709820747375, -0.25885143876075745, -1.0154719352722168, -0.5653204917907715, -0.03347340226173401]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7202605605125427, -0.016961291432380676, -1.570331335067749, -2.274587631225586, 0.5573222041130066]\n",
      "Last 5 elements: [0.14899709820747375, -0.25885143876075745, -1.0154719352722168, -0.5653204917907715, -0.03347340226173401]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.021876713261008263, -0.0005151709774509072, -0.04769619554281235, -0.06908680498600006, 0.016927732154726982]\n",
      "Last 5 elements: [0.13984157145023346, -0.2429456114768982, -0.9530735611915588, -0.530582845211029, -0.03141653910279274]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021876713261008263, -0.0005151709774509072, -0.04769619554281235, -0.06908680498600006, 0.016927732154726982]\n",
      "Last 5 elements: [0.13984157145023346, -0.2429456114768982, -0.9530735611915588, -0.530582845211029, -0.03141653910279274]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.07315821200609207, 0.058546699583530426, 1.2003424167633057, -0.1590791642665863, -1.0940512418746948]\n",
      "Last 5 elements: [-1.0623763799667358, 0.1669684648513794, -1.4573886394500732, 0.7004458904266357, -2.5759506225585938]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.07315821200609207, 0.058546699583530426, 1.2003424167633057, -0.1590791642665863, -1.0940512418746948]\n",
      "Last 5 elements: [-1.0623763799667358, 0.1669684648513794, -1.4573886394500732, 0.7004458904266357, -2.5759506225585938]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.05245446786284447, 0.041978009045124054, 0.8606460094451904, -0.11405982822179794, -0.7844352126121521]\n",
      "Last 5 elements: [-0.9250764846801758, 0.14538970589637756, -1.2690379619598389, 0.6099213361740112, -2.2430386543273926]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.05245446786284447, 0.041978009045124054, 0.8606460094451904, -0.11405982822179794, -0.7844352126121521]\n",
      "Last 5 elements: [-0.9250764846801758, 0.14538970589637756, -1.2690379619598389, 0.6099213361740112, -2.2430386543273926]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.4692622423171997, -0.856462836265564, 0.07710839807987213, -0.7441743612289429, -0.1515817940235138]\n",
      "Last 5 elements: [2.329756736755371, 0.6992779970169067, 6.714110851287842, 2.066394329071045, -0.8695164918899536]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021876713261008263, -0.0005151709774509072, -0.04769619554281235, -0.06908680498600006, 0.016927732154726982]\n",
      "Last 5 elements: [0.13984157145023346, -0.2429456114768982, -0.9530735611915588, -0.530582845211029, -0.03141653910279274]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.06360214948654175, -0.10323570668697357, -0.2907946705818176, 0.09482333809137344, 0.014822673052549362]\n",
      "Last 5 elements: [-2.237412929534912, -0.09098166227340698, -2.0305066108703613, 2.2111165523529053, -1.8863842487335205]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.06360214948654175, -0.10323570668697357, -0.2907946705818176, 0.09482333809137344, 0.014822673052549362]\n",
      "Last 5 elements: [0.14600875973701477, -1.435911774635315, 0.7137100696563721, 1.726540207862854, -0.2805602252483368]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.010512039996683598, -0.01706259697675705, -0.048061978071928024, 0.015672218054533005, 0.0024498626589775085]\n",
      "Last 5 elements: [0.10182590782642365, -1.0013989210128784, 0.49773845076560974, 1.2040820121765137, -0.1956615447998047]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.010512039996683598, -0.01706259697675705, -0.048061978071928024, 0.015672218054533005, 0.0024498626589775085]\n",
      "Last 5 elements: [0.10182590782642365, -1.0013989210128784, 0.49773845076560974, 1.2040820121765137, -0.1956615447998047]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.09500178694725037, -0.06287094205617905, -0.061040595173835754, -0.2660720944404602, 0.06693961471319199]\n",
      "Last 5 elements: [-1.2239861488342285, 0.37618160247802734, 0.7085191011428833, -0.8505613803863525, 1.3044521808624268]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.04568949714303017, -0.004637513309717178, -0.018370337784290314, -0.02340279147028923, -0.009718922898173332]\n",
      "Last 5 elements: [-1.2239861488342285, 0.37618160247802734, 0.7085191011428833, -0.8505613803863525, 1.3044521808624268]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.04568949714303017, -0.004637513309717178, -0.018370337784290314, -0.02340279147028923, -0.009718922898173332]\n",
      "Last 5 elements: [-0.6060243248939514, 0.2508271038532257, 0.2842295169830322, -0.463690847158432, 0.585027277469635]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.1397867202758789, -0.24492737650871277, 0.05870118737220764, -0.0013114996254444122, -0.13865062594413757]\n",
      "Last 5 elements: [-0.3619154989719391, 0.269928514957428, -0.18969662487506866, 0.3751775622367859, -0.2616192400455475]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7451146841049194, -0.060509420931339264, -1.5598942041397095, -2.2748208045959473, 0.5326700806617737]\n",
      "Last 5 elements: [0.08464846014976501, -0.21085810661315918, -1.0492000579833984, -0.4986138641834259, -0.07998935133218765]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.02263111062347889, -0.0018378316890448332, -0.04737812653183937, -0.06909234076738358, 0.01617860421538353]\n",
      "Last 5 elements: [0.08072257041931152, -0.20107875764369965, -1.0005394220352173, -0.4754887521266937, -0.07627954334020615]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02263111062347889, -0.0018378316890448332, -0.04737812653183937, -0.06909234076738358, 0.01617860421538353]\n",
      "Last 5 elements: [0.08072257041931152, -0.20107875764369965, -1.0005394220352173, -0.4754887521266937, -0.07627954334020615]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.3660786151885986, -0.564566433429718, -1.5383415222167969, -1.607104778289795, -0.99886155128479]\n",
      "Last 5 elements: [0.9204543828964233, -1.5888563394546509, -1.0541075468063354, -1.0004690885543823, -2.786202907562256]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.3660786151885986, -0.564566433429718, -1.5383415222167969, -1.607104778289795, -0.99886155128479]\n",
      "Last 5 elements: [0.9204543828964233, -1.5888563394546509, -1.0541075468063354, -1.0004690885543823, -2.786202907562256]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.27766114473342896, -0.20465055108070374, -0.2719426453113556, -0.26837196946144104, -0.2688588798046112]\n",
      "Last 5 elements: [0.6582488417625427, -0.26938244700431824, -0.2724205255508423, -0.26897531747817993, -0.16180682182312012]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02263111062347889, -0.0018378316890448332, -0.04737812653183937, -0.06909234076738358, 0.01617860421538353]\n",
      "Last 5 elements: [0.08072257041931152, -0.20107875764369965, -1.0005394220352173, -0.4754887521266937, -0.07627954334020615]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.9962061643600464, 1.0036659240722656, 0.5226323008537292, -0.5580835342407227, 0.09868845343589783]\n",
      "Last 5 elements: [-0.6510545015335083, 0.40618371963500977, 1.8433799743652344, 0.4539375901222229, 1.0945935249328613]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.2766077518463135, -0.20540077984333038, -0.14212600886821747, 0.149773970246315, -0.02653326652944088]\n",
      "Last 5 elements: [-0.4285558760166168, -0.10941876471042633, -0.5021745562553406, -0.12209800630807877, -0.17711269855499268]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.016787581145763397, 0.2970338761806488, 0.14897282421588898, 0.20429837703704834, -0.1356143057346344]\n",
      "Last 5 elements: [1.7813924551010132, -0.5827912092208862, -0.04992753267288208, 1.6024117469787598, 0.38310766220092773]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02263111062347889, -0.0018378316890448332, -0.04737812653183937, -0.06909234076738358, 0.01617860421538353]\n",
      "Last 5 elements: [0.08072257041931152, -0.20107875764369965, -1.0005394220352173, -0.4754887521266937, -0.07627954334020615]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.016787581145763397, 0.2970338761806488, 0.14897282421588898, 0.20429837703704834, -0.1356143057346344]\n",
      "Last 5 elements: [1.7813924551010132, -0.5827912092208862, -0.04992753267288208, 1.6024117469787598, 0.38310766220092773]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.7451, -0.0605, -1.5599,  ..., -0.1846, -1.1831, -1.1874],\n",
      "         [ 0.2918,  0.4064,  1.1364,  ..., -1.4045, -0.0408,  0.0852],\n",
      "         [ 1.1026, -0.0245, -0.8618,  ...,  0.3474, -0.3252,  0.1972],\n",
      "         [ 0.8828,  1.2916,  0.2492,  ...,  0.0697,  0.8082,  0.6503],\n",
      "         [ 0.4733,  0.8314,  0.1714,  ...,  0.2544, -0.0081, -0.0276],\n",
      "         [ 0.7935, -0.0357,  1.0266,  ..., -1.0492, -0.4986, -0.0800]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7202605605125427, -0.016961291432380676, -1.570331335067749, -2.274587631225586, 0.5573222041130066]\n",
      "Last 5 elements: [0.14899709820747375, -0.25885143876075745, -1.0154719352722168, -0.5653204917907715, -0.03347340226173401]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7421298623085022, -0.007696744054555893, -1.5334068536758423, -2.2384965419769287, 0.5085578560829163]\n",
      "Last 5 elements: [0.40138036012649536, -0.31447848677635193, -1.0580772161483765, -0.21370476484298706, -0.011872738599777222]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7421298623085022, -0.007696744054555893, -1.5334068536758423, -2.2384965419769287, 0.5085578560829163]\n",
      "Last 5 elements: [0.40138036012649536, -0.31447848677635193, -1.0580772161483765, -0.21370476484298706, -0.011872738599777222]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.022541889920830727, -0.00023378543846774846, -0.0465766005218029, -0.0679934099316597, 0.01544723566621542]\n",
      "Last 5 elements: [0.36184313893318176, -0.28350138664245605, -0.9538533091545105, -0.19265417754650116, -0.010703236795961857]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.022541889920830727, -0.00023378543846774846, -0.0465766005218029, -0.0679934099316597, 0.01544723566621542]\n",
      "Last 5 elements: [0.36184313893318176, -0.28350138664245605, -0.9538533091545105, -0.19265417754650116, -0.010703236795961857]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.03429923206567764, 0.7153343558311462, 0.04648736119270325, 2.0975587368011475, 2.2792036533355713]\n",
      "Last 5 elements: [-0.33203721046447754, 1.0331170558929443, -1.9992594718933105, -1.057077169418335, -0.995871365070343]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.03429923206567764, 0.7153343558311462, 0.04648736119270325, 2.0975587368011475, 2.2792036533355713]\n",
      "Last 5 elements: [-0.33203721046447754, 1.0331170558929443, -1.9992594718933105, -1.057077169418335, -0.995871365070343]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.031623631715774536, 0.6595328450202942, 0.04286099597811699, 1.9339332580566406, 2.1014084815979004]\n",
      "Last 5 elements: [-0.2899799644947052, 0.902258038520813, -1.74602472782135, -0.923183262348175, -0.8697300553321838]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.031623631715774536, 0.6595328450202942, 0.04286099597811699, 1.9339332580566406, 2.1014084815979004]\n",
      "Last 5 elements: [-0.2899799644947052, 0.902258038520813, -1.74602472782135, -0.923183262348175, -0.8697300553321838]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.6180221438407898, -1.1847805976867676, -0.16122916340827942, -0.7010841369628906, 0.6700181365013123]\n",
      "Last 5 elements: [1.8208301067352295, -2.6439547538757324, 5.20775842666626, -0.5241125822067261, 2.900665760040283]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.022541889920830727, -0.00023378543846774846, -0.0465766005218029, -0.0679934099316597, 0.01544723566621542]\n",
      "Last 5 elements: [0.36184313893318176, -0.28350138664245605, -0.9538533091545105, -0.19265417754650116, -0.010703236795961857]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.1951696127653122, 0.01071120798587799, 0.12507101893424988, 0.041021592915058136, 0.21526286005973816]\n",
      "Last 5 elements: [0.9126437902450562, -3.09936785697937, -1.6629664897918701, -0.6467562913894653, 0.18920254707336426]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.1951696127653122, 0.01071120798587799, 0.12507101893424988, 0.041021592915058136, 0.21526286005973816]\n",
      "Last 5 elements: [-0.35427799820899963, 0.423042356967926, -0.5746850967407227, -2.5277318954467773, -1.4974077939987183]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.03636771813035011, 0.0019959162455052137, 0.023305613547563553, 0.007643924094736576, 0.04011187329888344]\n",
      "Last 5 elements: [-0.26237979531288147, 0.3133069574832916, -0.42561420798301697, -1.8720488548278809, -1.108986496925354]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.03636771813035011, 0.0019959162455052137, 0.023305613547563553, 0.007643924094736576, 0.04011187329888344]\n",
      "Last 5 elements: [-0.26237979531288147, 0.3133069574832916, -0.42561420798301697, -1.8720488548278809, -1.108986496925354]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.11726295202970505, 0.22720614075660706, 0.09085296094417572, -0.20200571417808533, -1.8130288124084473]\n",
      "Last 5 elements: [-0.5234836935997009, -0.7918999195098877, 1.0990042686462402, 0.7876915335655212, 1.746498942375183]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.029683712869882584, 0.00406525656580925, 0.03867235779762268, -0.009479365311563015, 0.0015478944405913353]\n",
      "Last 5 elements: [-0.5234836935997009, -0.7918999195098877, 1.0990042686462402, 0.7876915335655212, 1.746498942375183]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.029683712869882584, 0.00406525656580925, 0.03867235779762268, -0.009479365311563015, 0.0015478944405913353]\n",
      "Last 5 elements: [-0.042425401508808136, -0.17329105734825134, 0.11588945984840393, 0.10104099661111832, 0.23033928871154785]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.2303295135498047, -0.19038601219654083, -0.2314273566007614, -0.06477732211351395, -0.5175899267196655]\n",
      "Last 5 elements: [0.15161025524139404, -0.09375472366809845, -0.6776378750801086, -0.8979591131210327, -0.20259444415569305]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7011772394180298, -0.04154741019010544, -1.574554681777954, -2.250014066696167, 0.4165302813053131]\n",
      "Last 5 elements: [0.4283366799354553, -0.33114808797836304, -1.1785613298416138, -0.37336206436157227, -0.04789406806230545]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.02129770629107952, -0.0012619697954505682, -0.04782585799694061, -0.06834240257740021, 0.012651778757572174]\n",
      "Last 5 elements: [0.3950902223587036, -0.3054451644420624, -1.0870842933654785, -0.3443826138973236, -0.04417664557695389]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02129770629107952, -0.0012619697954505682, -0.04782585799694061, -0.06834240257740021, 0.012651778757572174]\n",
      "Last 5 elements: [0.3950902223587036, -0.3054451644420624, -1.0870842933654785, -0.3443826138973236, -0.04417664557695389]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.8656371235847473, -0.28955644369125366, -2.6579506397247314, -1.9104379415512085, 0.4778979420661926]\n",
      "Last 5 elements: [-1.0725033283233643, -0.7236773371696472, 3.1108672618865967, 0.011804252862930298, -1.2445037364959717]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.8656371235847473, -0.28955644369125366, -2.6579506397247314, -1.9104379415512085, 0.4778979420661926]\n",
      "Last 5 elements: [-1.0725033283233643, -0.7236773371696472, 3.1108672618865967, 0.011804252862930298, -1.2445037364959717]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2563696503639221, -0.12396271526813507, -0.17409752309322357, -0.24631594121456146, 0.2949831783771515]\n",
      "Last 5 elements: [-0.2734103798866272, -0.23634123802185059, 2.978153705596924, 0.005936961155384779, -0.2783370316028595]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02129770629107952, -0.0012619697954505682, -0.04782585799694061, -0.06834240257740021, 0.012651778757572174]\n",
      "Last 5 elements: [0.3950902223587036, -0.3054451644420624, -1.0870842933654785, -0.3443826138973236, -0.04417664557695389]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.8868082165718079, 1.3603240251541138, 0.11263172328472137, -1.2820327281951904, -0.39027732610702515]\n",
      "Last 5 elements: [0.7835792899131775, 1.740211009979248, -0.7857526540756226, 0.35507723689079285, 0.3717709183692932]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.22735071182250977, -0.168629452586174, -0.01960890367627144, 0.31578510999679565, -0.11512524634599686]\n",
      "Last 5 elements: [-0.2142387181520462, -0.41128361225128174, -2.340092182159424, 0.0021080798469483852, -0.1034776121377945]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.2025473713874817, -0.15569652616977692, -0.1084369421005249, -0.10075843334197998, 0.07395492494106293]\n",
      "Last 5 elements: [-0.18756672739982605, 0.022784650325775146, -0.013288110494613647, -0.9486550688743591, -0.34341371059417725]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02129770629107952, -0.0012619697954505682, -0.04782585799694061, -0.06834240257740021, 0.012651778757572174]\n",
      "Last 5 elements: [0.3950902223587036, -0.3054451644420624, -1.0870842933654785, -0.3443826138973236, -0.04417664557695389]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.2025473713874817, -0.15569652616977692, -0.1084369421005249, -0.10075843334197998, 0.07395492494106293]\n",
      "Last 5 elements: [-0.18756672739982605, 0.022784650325775146, -0.013288110494613647, -0.9486550688743591, -0.34341371059417725]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.7012, -0.0415, -1.5746,  ..., -0.4462, -1.2885, -1.1841],\n",
      "         [ 0.3441,  0.4073,  1.0169,  ..., -1.2470,  0.1672,  0.1435],\n",
      "         [ 1.0124, -0.2047, -0.9987,  ...,  0.8080, -0.3184,  0.2715],\n",
      "         [ 1.0252,  1.1001,  0.3324,  ..., -0.0428,  0.7597,  0.4842],\n",
      "         [ 0.3382,  0.6447,  0.0119,  ...,  0.3461,  0.0306,  0.0395],\n",
      "         [ 0.5651, -0.3160,  0.9163,  ..., -1.1786, -0.3734, -0.0479]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7421298623085022, -0.007696744054555893, -1.5334068536758423, -2.2384965419769287, 0.5085578560829163]\n",
      "Last 5 elements: [0.40138036012649536, -0.31447848677635193, -1.0580772161483765, -0.21370476484298706, -0.011872738599777222]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6651642918586731, -0.06923028081655502, -1.5938347578048706, -2.2679288387298584, 0.4296794831752777]\n",
      "Last 5 elements: [0.3949872851371765, -0.32709696888923645, -1.1809239387512207, -0.5420330762863159, -0.1089530885219574]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6651642918586731, -0.06923028081655502, -1.5938347578048706, -2.2679288387298584, 0.4296794831752777]\n",
      "Last 5 elements: [0.3949872851371765, -0.32709696888923645, -1.1809239387512207, -0.5420330762863159, -0.1089530885219574]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0202019065618515, -0.002102613914757967, -0.04840683937072754, -0.06887995451688766, 0.013049925677478313]\n",
      "Last 5 elements: [0.34393632411956787, -0.28482064604759216, -1.0282930135726929, -0.4719768762588501, -0.09487122297286987]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0202019065618515, -0.002102613914757967, -0.04840683937072754, -0.06887995451688766, 0.013049925677478313]\n",
      "Last 5 elements: [0.34393632411956787, -0.28482064604759216, -1.0282930135726929, -0.4719768762588501, -0.09487122297286987]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.29974713921546936, -0.07977227121591568, -0.007101193070411682, -1.4035048484802246, -1.6382601261138916]\n",
      "Last 5 elements: [-0.47516217827796936, -0.5564954280853271, 1.9518918991088867, -0.1969541311264038, -1.7889846563339233]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.29974713921546936, -0.07977227121591568, -0.007101193070411682, -1.4035048484802246, -1.6382601261138916]\n",
      "Last 5 elements: [-0.47516217827796936, -0.5564954280853271, 1.9518918991088867, -0.1969541311264038, -1.7889846563339233]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.1887051910161972, -0.05022047087550163, -0.00447054160758853, -0.883573591709137, -1.0313633680343628]\n",
      "Last 5 elements: [-0.42551735043525696, -0.49835294485092163, 1.747958779335022, -0.17637641727924347, -1.60207200050354]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.1887051910161972, -0.05022047087550163, -0.00447054160758853, -0.883573591709137, -1.0313633680343628]\n",
      "Last 5 elements: [-0.42551735043525696, -0.49835294485092163, 1.747958779335022, -0.17637641727924347, -1.60207200050354]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.5700670480728149, 0.46849286556243896, -0.3592931628227234, -0.038113273680210114, 0.6636655330657959]\n",
      "Last 5 elements: [1.4021285772323608, 0.6700499057769775, 2.0339322090148926, 2.5376644134521484, 0.0155581533908844]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0202019065618515, -0.002102613914757967, -0.04840683937072754, -0.06887995451688766, 0.013049925677478313]\n",
      "Last 5 elements: [0.34393632411956787, -0.28482064604759216, -1.0282930135726929, -0.4719768762588501, -0.09487122297286987]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.008567284792661667, 0.9573881030082703, 0.15840879082679749, 0.09851518273353577, 0.38800424337387085]\n",
      "Last 5 elements: [0.6021026372909546, 1.4262828826904297, -11.565333366394043, 1.251979112625122, 1.5692102909088135]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.008567284792661667, 0.9573881030082703, 0.15840879082679749, 0.09851518273353577, 0.38800424337387085]\n",
      "Last 5 elements: [2.066608428955078, -0.8066922426223755, 0.2162444293498993, -0.0007675886154174805, 3.349078893661499]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.0016160750528797507, 0.1805952489376068, 0.029881170019507408, 0.01858324185013771, 0.07319051027297974]\n",
      "Last 5 elements: [1.7837859392166138, -0.6962935924530029, 0.18665063381195068, -0.0006625414825975895, 2.8907458782196045]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.0016160750528797507, 0.1805952489376068, 0.029881170019507408, 0.01858324185013771, 0.07319051027297974]\n",
      "Last 5 elements: [1.7837859392166138, -0.6962935924530029, 0.18665063381195068, -0.0006625414825975895, 2.8907458782196045]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.06720142066478729, -0.907483696937561, -0.07371649146080017, -0.138586163520813, -0.1853591650724411]\n",
      "Last 5 elements: [0.17721495032310486, 0.6058131456375122, 0.02932608127593994, 0.261482298374176, -0.47491490840911865]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.07425557076931, 0.008688084781169891, -0.023806137964129448, -0.039824701845645905, -0.014193398877978325]\n",
      "Last 5 elements: [0.17721495032310486, 0.6058131456375122, 0.02932608127593994, 0.261482298374176, -0.47491490840911865]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.07425557076931, 0.008688084781169891, -0.023806137964129448, -0.039824701845645905, -0.014193398877978325]\n",
      "Last 5 elements: [0.13186119496822357, 0.48743805289268494, -0.21907967329025269, 0.2959967851638794, 0.41258135437965393]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.018082454800605774, -0.33366426825523376, 0.18606436252593994, 0.0722905695438385, 0.12171735614538193]\n",
      "Last 5 elements: [-0.24864600598812103, 0.3156026303768158, -0.3829868733882904, -0.463778018951416, -0.02088344097137451]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6619492173194885, -0.12855584919452667, -1.560752511024475, -2.255075454711914, 0.4513208568096161]\n",
      "Last 5 elements: [0.3507779836654663, -0.2709827721118927, -1.2490190267562866, -0.624492883682251, -0.11266616731882095]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.020102787762880325, -0.0039041226264089346, -0.04739861562848091, -0.06848456710577011, 0.013706198893487453]\n",
      "Last 5 elements: [0.3072633743286133, -0.23736688494682312, -1.0940760374069214, -0.5470234751701355, -0.0986897349357605]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020102787762880325, -0.0039041226264089346, -0.04739861562848091, -0.06848456710577011, 0.013706198893487453]\n",
      "Last 5 elements: [0.3072633743286133, -0.23736688494682312, -1.0940760374069214, -0.5470234751701355, -0.0986897349357605]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.205306887626648, -0.41880542039871216, -2.19529128074646, -0.36319005489349365, -1.1482551097869873]\n",
      "Last 5 elements: [-1.2126197814941406, -2.5106987953186035, -1.2994121313095093, -1.9668078422546387, -0.826973557472229]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.205306887626648, -0.41880542039871216, -2.19529128074646, -0.36319005489349365, -1.1482551097869873]\n",
      "Last 5 elements: [-1.2126197814941406, -2.5106987953186035, -1.2994121313095093, -1.9668078422546387, -0.826973557472229]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.27786239981651306, -0.16618309915065765, -0.2199113965034485, -0.14897604286670685, -0.2765089273452759]\n",
      "Last 5 elements: [-0.2779783308506012, -0.18858247995376587, -0.2784172296524048, -0.24139058589935303, -0.25163596868515015]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020102787762880325, -0.0039041226264089346, -0.04739861562848091, -0.06848456710577011, 0.013706198893487453]\n",
      "Last 5 elements: [0.3072633743286133, -0.23736688494682312, -1.0940760374069214, -0.5470234751701355, -0.0986897349357605]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.4852084517478943, -0.42124536633491516, -0.5166100263595581, 0.07807444036006927, 0.11950713396072388]\n",
      "Last 5 elements: [0.31388354301452637, 0.951352596282959, -0.9384586811065674, -0.14246565103530884, -2.0364041328430176]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.13482119143009186, 0.07000385969877243, 0.11360843479633331, -0.011631221510469913, -0.03304478898644447]\n",
      "Last 5 elements: [-0.08725282549858093, -0.17940843105316162, 0.2612830698490143, 0.03438986837863922, 0.5124325156211853]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.0626404881477356, 0.2286517173051834, -0.05404248833656311, -0.15308132767677307, -1.6356680393218994]\n",
      "Last 5 elements: [1.168647289276123, 2.383164882659912, -0.8367944955825806, -0.8401191234588623, 1.9365296363830566]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020102787762880325, -0.0039041226264089346, -0.04739861562848091, -0.06848456710577011, 0.013706198893487453]\n",
      "Last 5 elements: [0.3072633743286133, -0.23736688494682312, -1.0940760374069214, -0.5470234751701355, -0.0986897349357605]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.0626404881477356, 0.2286517173051834, -0.05404248833656311, -0.15308132767677307, -1.6356680393218994]\n",
      "Last 5 elements: [1.168647289276123, 2.383164882659912, -0.8367944955825806, -0.8401191234588623, 1.9365296363830566]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6619, -0.1286, -1.5608,  ..., -0.4907, -1.3384, -1.2981],\n",
      "         [ 0.2023,  0.3176,  0.9757,  ..., -1.0948,  0.2247,  0.1410],\n",
      "         [ 1.2957, -0.4521, -0.7640,  ...,  0.9655, -0.3165, -0.0089],\n",
      "         [ 0.9984,  0.8690,  0.4456,  ...,  0.0864,  0.7241,  0.4020],\n",
      "         [ 0.4258,  0.5922,  0.3537,  ...,  0.5455, -0.2863, -0.1572],\n",
      "         [ 0.6677, -0.2520,  1.2418,  ..., -1.2490, -0.6245, -0.1127]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6651642918586731, -0.06923028081655502, -1.5938347578048706, -2.2679288387298584, 0.4296794831752777]\n",
      "Last 5 elements: [0.3949872851371765, -0.32709696888923645, -1.1809239387512207, -0.5420330762863159, -0.1089530885219574]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6508117318153381, -0.0879015326499939, -1.5703612565994263, -2.2822933197021484, 0.16049879789352417]\n",
      "Last 5 elements: [0.5585637092590332, 0.1527443826198578, -1.3978012800216675, -0.7738661766052246, 0.23164916038513184]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6508117318153381, -0.0879015326499939, -1.5703612565994263, -2.2822933197021484, 0.16049879789352417]\n",
      "Last 5 elements: [0.5585637092590332, 0.1527443826198578, -1.3978012800216675, -0.7738661766052246, 0.23164916038513184]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.019768789410591125, -0.002670060843229294, -0.04770064726471901, -0.0693260058760643, 0.004875245504081249]\n",
      "Last 5 elements: [0.4683701694011688, 0.12808012962341309, -1.1720926761627197, -0.6489068865776062, 0.19424383342266083]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019768789410591125, -0.002670060843229294, -0.04770064726471901, -0.0693260058760643, 0.004875245504081249]\n",
      "Last 5 elements: [0.4683701694011688, 0.12808012962341309, -1.1720926761627197, -0.6489068865776062, 0.19424383342266083]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.4382023811340332, -0.11536486446857452, 0.4543682336807251, -4.414298057556152, -1.8243824243545532]\n",
      "Last 5 elements: [0.748813271522522, -0.20959541201591492, -0.8475114107131958, -0.40585535764694214, 0.35976091027259827]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.4382023811340332, -0.11536486446857452, 0.4543682336807251, -4.414298057556152, -1.8243824243545532]\n",
      "Last 5 elements: [0.748813271522522, -0.20959541201591492, -0.8475114107131958, -0.40585535764694214, 0.35976091027259827]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.8322237730026245, -0.06675651669502258, 0.2629227042198181, -2.5543580055236816, -1.0556889772415161]\n",
      "Last 5 elements: [0.6875532865524292, -0.19244852662086487, -0.7781769633293152, -0.3726525604724884, 0.3303290605545044]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.8322237730026245, -0.06675651669502258, 0.2629227042198181, -2.5543580055236816, -1.0556889772415161]\n",
      "Last 5 elements: [0.6875532865524292, -0.19244852662086487, -0.7781769633293152, -0.3726525604724884, 0.3303290605545044]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.983199954032898, -0.40304452180862427, -0.583095908164978, 0.2975013256072998, -0.25977927446365356]\n",
      "Last 5 elements: [1.4698718786239624, -0.044529616832733154, -9.585882186889648, -0.6105754971504211, 0.3726228177547455]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019768789410591125, -0.002670060843229294, -0.04770064726471901, -0.0693260058760643, 0.004875245504081249]\n",
      "Last 5 elements: [0.4683701694011688, 0.12808012962341309, -1.1720926761627197, -0.6489068865776062, 0.19424383342266083]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.1098170056939125, 0.31976860761642456, 0.171074777841568, -0.22507110238075256, 0.11029937863349915]\n",
      "Last 5 elements: [1.616166114807129, 0.7795578837394714, 1.788786768913269, -1.835374116897583, -3.0905330181121826]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.1098170056939125, 0.31976860761642456, 0.171074777841568, -0.22507110238075256, 0.11029937863349915]\n",
      "Last 5 elements: [-1.364333987236023, 0.0638960599899292, 0.09622201323509216, -1.1981627941131592, 1.1201432943344116]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.024055618792772293, 0.07004590332508087, 0.03747424855828285, -0.04930224269628525, 0.024161282926797867]\n",
      "Last 5 elements: [-1.0833884477615356, 0.05073849484324455, 0.07640784233808517, -0.9514354467391968, 0.889481782913208]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.024055618792772293, 0.07004590332508087, 0.03747424855828285, -0.04930224269628525, 0.024161282926797867]\n",
      "Last 5 elements: [-1.0833884477615356, 0.05073849484324455, 0.07640784233808517, -0.9514354467391968, 0.889481782913208]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.15361525118350983, 0.10521908849477768, 1.1694988012313843, -0.08313263952732086, 0.1492973417043686]\n",
      "Last 5 elements: [-0.6160757541656494, 0.6444957852363586, -0.5145636796951294, -0.08285430073738098, -0.21927523612976074]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.13981573283672333, -0.2457658350467682, -0.35490095615386963, -0.397279292345047, 0.22128689289093018]\n",
      "Last 5 elements: [-0.6160757541656494, 0.6444957852363586, -0.5145636796951294, -0.08285430073738098, -0.21927523612976074]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.13981573283672333, -0.2457658350467682, -0.35490095615386963, -0.397279292345047, 0.22128689289093018]\n",
      "Last 5 elements: [-0.4243948459625244, 0.3702298402786255, -0.4780644476413727, -0.11691762506961823, -0.0650673434138298]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.10984224081039429, 0.28573986887931824, 0.1540772020816803, 0.1432633101940155, 0.11710116267204285]\n",
      "Last 5 elements: [0.4096307158470154, 0.0743151605129242, -0.12312150001525879, -0.3878573179244995, -0.49386146664619446]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6703417301177979, -0.03709693253040314, -1.5429662466049194, -2.2568211555480957, 0.18131940066814423]\n",
      "Last 5 elements: [0.6313961148262024, 0.16595762968063354, -1.4196922779083252, -0.8428272604942322, 0.1438405066728592]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.020361362025141716, -0.0011268045054748654, -0.04686698317527771, -0.06855003535747528, 0.005507504101842642]\n",
      "Last 5 elements: [0.532818078994751, 0.14004714787006378, -1.1980398893356323, -0.7112390995025635, 0.12138310819864273]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020361362025141716, -0.0011268045054748654, -0.04686698317527771, -0.06855003535747528, 0.005507504101842642]\n",
      "Last 5 elements: [0.532818078994751, 0.14004714787006378, -1.1980398893356323, -0.7112390995025635, 0.12138310819864273]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.1411690711975098, -0.9155665040016174, -0.41672682762145996, -1.1826359033584595, -0.694216251373291]\n",
      "Last 5 elements: [-1.8585944175720215, 0.5576308965682983, -1.6020653247833252, -0.6949461102485657, -2.510713577270508]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.1411690711975098, -0.9155665040016174, -0.41672682762145996, -1.1826359033584595, -0.694216251373291]\n",
      "Last 5 elements: [-1.8585944175720215, 0.5576308965682983, -1.6020653247833252, -0.6949461102485657, -2.510713577270508]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.22516389191150665, -0.2617257535457611, -0.16556566953659058, -0.2774210572242737, -0.23124051094055176]\n",
      "Last 5 elements: [-0.25066301226615906, 0.35459983348846436, -0.268655389547348, -0.2313709706068039, -0.18858101963996887]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020361362025141716, -0.0011268045054748654, -0.04686698317527771, -0.06855003535747528, 0.005507504101842642]\n",
      "Last 5 elements: [0.532818078994751, 0.14004714787006378, -1.1980398893356323, -0.7112390995025635, 0.12138310819864273]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.727758526802063, -0.16435232758522034, -0.3748286962509155, 0.8451507091522217, 0.07205048948526382]\n",
      "Last 5 elements: [-0.8160141110420227, -0.24390125274658203, -0.9995666146278381, 1.6136422157287598, 1.2074735164642334]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.16386494040489197, 0.043015237897634506, 0.062058765441179276, -0.23446260392665863, -0.016660992056131363]\n",
      "Last 5 elements: [0.2045445591211319, -0.08648734539747238, 0.2685389518737793, -0.37334996461868286, -0.22770658135414124]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.037558600306510925, -0.4261744022369385, 0.8960834741592407, -0.4129168689250946, -2.0785679817199707]\n",
      "Last 5 elements: [1.3167526721954346, -0.3567507266998291, 0.3834410011768341, 1.4966486692428589, 0.0820554792881012]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020361362025141716, -0.0011268045054748654, -0.04686698317527771, -0.06855003535747528, 0.005507504101842642]\n",
      "Last 5 elements: [0.532818078994751, 0.14004714787006378, -1.1980398893356323, -0.7112390995025635, 0.12138310819864273]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.037558600306510925, -0.4261744022369385, 0.8960834741592407, -0.4129168689250946, -2.0785679817199707]\n",
      "Last 5 elements: [1.3167526721954346, -0.3567507266998291, 0.3834410011768341, 1.4966486692428589, 0.0820554792881012]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6703, -0.0371, -1.5430,  ..., -0.6038, -1.3615, -1.1925],\n",
      "         [ 0.1228,  0.1399,  0.8412,  ..., -1.0273,  0.3743,  0.1555],\n",
      "         [ 1.4611, -0.4216, -0.9835,  ...,  0.7626, -0.3975,  0.1480],\n",
      "         [ 0.8827,  0.9336,  0.3994,  ...,  0.1046,  0.5545,  0.4317],\n",
      "         [ 0.3554,  0.4960,  0.3215,  ...,  0.4502, -0.4319, -0.2867],\n",
      "         [ 0.7950, -0.4278,  0.8758,  ..., -1.4197, -0.8428,  0.1438]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6508117318153381, -0.0879015326499939, -1.5703612565994263, -2.2822933197021484, 0.16049879789352417]\n",
      "Last 5 elements: [0.5585637092590332, 0.1527443826198578, -1.3978012800216675, -0.7738661766052246, 0.23164916038513184]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6770196557044983, -0.11287081986665726, -1.3836424350738525, -2.330237865447998, -0.1882503479719162]\n",
      "Last 5 elements: [0.8655149936676025, 0.10252728313207626, -1.3515163660049438, -0.5767228603363037, 0.15842998027801514]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6770196557044983, -0.11287081986665726, -1.3836424350738525, -2.330237865447998, -0.1882503479719162]\n",
      "Last 5 elements: [0.8655149936676025, 0.10252728313207626, -1.3515163660049438, -0.5767228603363037, 0.15842998027801514]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.020566191524267197, -0.0034287376329302788, -0.042031653225421906, -0.07078689336776733, -0.005718582309782505]\n",
      "Last 5 elements: [0.7403565049171448, 0.0877012386918068, -1.1560792922973633, -0.4933253824710846, 0.1355200856924057]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020566191524267197, -0.0034287376329302788, -0.042031653225421906, -0.07078689336776733, -0.005718582309782505]\n",
      "Last 5 elements: [0.7403565049171448, 0.0877012386918068, -1.1560792922973633, -0.4933253824710846, 0.1355200856924057]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-3.314941167831421, 1.0605841875076294, -0.5548549890518188, 0.3089483976364136, -0.011947058141231537]\n",
      "Last 5 elements: [0.12893232703208923, -0.7183737754821777, -0.28102174401283264, 0.5520513653755188, 0.3203745484352112]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-3.314941167831421, 1.0605841875076294, -0.5548549890518188, 0.3089483976364136, -0.011947058141231537]\n",
      "Last 5 elements: [0.12893232703208923, -0.7183737754821777, -0.28102174401283264, 0.5520513653755188, 0.3203745484352112]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-2.4000067710876465, 0.7678595185279846, -0.40171322226524353, 0.2236776351928711, -0.008649631403386593]\n",
      "Last 5 elements: [0.12762092053890228, -0.7110670208930969, -0.2781634032726288, 0.5464363098144531, 0.3171159327030182]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-2.4000067710876465, 0.7678595185279846, -0.40171322226524353, 0.2236776351928711, -0.008649631403386593]\n",
      "Last 5 elements: [0.12762092053890228, -0.7110670208930969, -0.2781634032726288, 0.5464363098144531, 0.3171159327030182]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.7355020046234131, 0.13199591636657715, 0.008202433586120605, 0.12263154983520508, -1.1511554718017578]\n",
      "Last 5 elements: [2.0893492698669434, -0.5455566644668579, -0.22516879439353943, 3.712961196899414, -0.37799006700515747]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020566191524267197, -0.0034287376329302788, -0.042031653225421906, -0.07078689336776733, -0.005718582309782505]\n",
      "Last 5 elements: [0.7403565049171448, 0.0877012386918068, -1.1560792922973633, -0.4933253824710846, 0.1355200856924057]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.07941717654466629, -0.040196843445301056, -0.22329485416412354, 0.031707294285297394, -0.09262721240520477]\n",
      "Last 5 elements: [-0.18400490283966064, 1.6783292293548584, 1.3177237510681152, -7.946148872375488, 0.09661301970481873]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.07941717654466629, -0.040196843445301056, -0.22329485416412354, 0.031707294285297394, -0.09262721240520477]\n",
      "Last 5 elements: [0.012952804565429688, -1.041066288948059, 0.536117672920227, 1.642478108406067, 0.9196437001228333]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.013514217920601368, -0.00684019410982728, -0.03799751400947571, 0.005395549349486828, -0.01576213538646698]\n",
      "Last 5 elements: [0.012919554486870766, -1.0383938550949097, 0.5347414612770081, 1.6382619142532349, 0.9172829985618591]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.013514217920601368, -0.00684019410982728, -0.03799751400947571, 0.005395549349486828, -0.01576213538646698]\n",
      "Last 5 elements: [0.012919554486870766, -1.0383938550949097, 0.5347414612770081, 1.6382619142532349, 0.9172829985618591]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.05792614072561264, -0.17044676840305328, 0.13238844275474548, -0.10288463532924652, 0.020800556987524033]\n",
      "Last 5 elements: [-0.42229163646698, -0.3755407929420471, -0.38688555359840393, 0.218997061252594, -0.9899948835372925]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.06379826366901398, 0.009130388498306274, 0.0016824975609779358, -0.06373769044876099, 0.012619012966752052]\n",
      "Last 5 elements: [-0.42229163646698, -0.3755407929420471, -0.38688555359840393, 0.218997061252594, -0.9899948835372925]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.06379826366901398, 0.009130388498306274, 0.0016824975609779358, -0.06373769044876099, 0.012619012966752052]\n",
      "Last 5 elements: [-0.08409099280834198, 0.06245418265461922, 0.06299497187137604, -0.08292779326438904, 0.07505674660205841]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.08544518798589706, -0.12620976567268372, 0.009206481277942657, 0.015102870762348175, -0.2441243976354599]\n",
      "Last 5 elements: [0.049293383955955505, 0.1812804788351059, 0.042823877185583115, 0.16397742927074432, 0.27580615878105164]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6618275046348572, -0.13531093299388885, -1.3820055723190308, -2.327552556991577, -0.23165571689605713]\n",
      "Last 5 elements: [0.8742793798446655, 0.13475897908210754, -1.3439022302627563, -0.5475676655769348, 0.20746836066246033]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.02010466903448105, -0.0041104089468717575, -0.041981883347034454, -0.07070524245500565, -0.007037123199552298]\n",
      "Last 5 elements: [0.7572512030601501, 0.11672058701515198, -1.164011836051941, -0.4742720425128937, 0.17969733476638794]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02010466903448105, -0.0041104089468717575, -0.041981883347034454, -0.07070524245500565, -0.007037123199552298]\n",
      "Last 5 elements: [0.7572512030601501, 0.11672058701515198, -1.164011836051941, -0.4742720425128937, 0.17969733476638794]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.020215801894664764, -0.6170955300331116, -1.8019964694976807, -0.698621928691864, -2.1007118225097656]\n",
      "Last 5 elements: [-1.5683082342147827, -1.2719590663909912, -0.21236294507980347, -2.008200168609619, -0.6335282921791077]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.020215801894664764, -0.6170955300331116, -1.8019964694976807, -0.698621928691864, -2.1007118225097656]\n",
      "Last 5 elements: [-1.5683082342147827, -1.2719590663909912, -0.21236294507980347, -2.008200168609619, -0.6335282921791077]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.010005734860897064, -0.21625639498233795, -0.25517749786376953, -0.23202480375766754, -0.22903569042682648]\n",
      "Last 5 elements: [-0.2704668343067169, -0.27845990657806396, -0.0949491485953331, -0.23765972256660461, -0.21965119242668152]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02010466903448105, -0.0041104089468717575, -0.041981883347034454, -0.07070524245500565, -0.007037123199552298]\n",
      "Last 5 elements: [0.7572512030601501, 0.11672058701515198, -1.164011836051941, -0.4742720425128937, 0.17969733476638794]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.4574454426765442, -0.6842987537384033, 0.16910316050052643, 0.6016937494277954, -0.2726390063762665]\n",
      "Last 5 elements: [-2.165982484817505, 1.168618083000183, 0.01648944616317749, -0.6698418855667114, 0.8864743113517761]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.004577077925205231, 0.14798398315906525, -0.04315132275223732, -0.13960787653923035, 0.062444064766168594]\n",
      "Last 5 elements: [0.5858263969421387, -0.3254132866859436, -0.0015656588366255164, 0.1591944396495819, -0.19471514225006104]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.3911218047142029, -0.04091918468475342, -0.16896018385887146, -0.18785926699638367, 0.3006994426250458]\n",
      "Last 5 elements: [-0.3400818109512329, -0.06331300735473633, 1.5784810781478882, -0.2463826835155487, -0.35106128454208374]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02010466903448105, -0.0041104089468717575, -0.041981883347034454, -0.07070524245500565, -0.007037123199552298]\n",
      "Last 5 elements: [0.7572512030601501, 0.11672058701515198, -1.164011836051941, -0.4742720425128937, 0.17969733476638794]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.3911218047142029, -0.04091918468475342, -0.16896018385887146, -0.18785926699638367, 0.3006994426250458]\n",
      "Last 5 elements: [-0.3400818109512329, -0.06331300735473633, 1.5784810781478882, -0.2463826835155487, -0.35106128454208374]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6618, -0.1353, -1.3820,  ..., -0.7822, -1.5408, -1.1595],\n",
      "         [ 0.2525,  0.2856,  0.6856,  ..., -0.9390,  0.4373,  0.2524],\n",
      "         [ 1.3714, -0.5350, -1.0371,  ...,  0.6490, -0.4500,  0.2408],\n",
      "         [ 0.9046,  0.9423,  0.4392,  ...,  0.2854,  0.5196,  0.4200],\n",
      "         [ 0.3033,  0.6095,  0.3190,  ...,  0.2930, -0.5016, -0.3219],\n",
      "         [ 0.6825, -0.1125,  0.7387,  ..., -1.3439, -0.5476,  0.2075]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6770196557044983, -0.11287081986665726, -1.3836424350738525, -2.330237865447998, -0.1882503479719162]\n",
      "Last 5 elements: [0.8655149936676025, 0.10252728313207626, -1.3515163660049438, -0.5767228603363037, 0.15842998027801514]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5922859907150269, -0.1425863653421402, -1.4120466709136963, -2.3609540462493896, -0.17819130420684814]\n",
      "Last 5 elements: [0.813812792301178, 0.12350191175937653, -1.0632480382919312, -0.5913745760917664, 0.14504960179328918]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5922859907150269, -0.1425863653421402, -1.4120466709136963, -2.3609540462493896, -0.17819130420684814]\n",
      "Last 5 elements: [0.813812792301178, 0.12350191175937653, -1.0632480382919312, -0.5913745760917664, 0.14504960179328918]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.01798948459327221, -0.004330771509557962, -0.04288805276155472, -0.07170918583869934, -0.005412199068814516]\n",
      "Last 5 elements: [0.6920240521430969, 0.10501960664987564, -0.9041308164596558, -0.5028741955757141, 0.12334264069795609]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01798948459327221, -0.004330771509557962, -0.04288805276155472, -0.07170918583869934, -0.005412199068814516]\n",
      "Last 5 elements: [0.6920240521430969, 0.10501960664987564, -0.9041308164596558, -0.5028741955757141, 0.12334264069795609]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.2807809114456177, 0.598461389541626, -2.7562263011932373, 2.2066168785095215, 1.1953026056289673]\n",
      "Last 5 elements: [0.9970334768295288, 0.647358775138855, 1.1554880142211914, 0.7862006425857544, -1.0452203750610352]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.2807809114456177, 0.598461389541626, -2.7562263011932373, 2.2066168785095215, 1.1953026056289673]\n",
      "Last 5 elements: [0.9970334768295288, 0.647358775138855, 1.1554880142211914, 0.7862006425857544, -1.0452203750610352]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.018673062324524, 0.47598809003829956, -2.1921730041503906, 1.7550394535064697, 0.9506875872612]\n",
      "Last 5 elements: [0.9249914884567261, 0.600583016872406, 1.0719966888427734, 0.7293926477432251, -0.969696581363678]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.018673062324524, 0.47598809003829956, -2.1921730041503906, 1.7550394535064697, 0.9506875872612]\n",
      "Last 5 elements: [0.9249914884567261, 0.600583016872406, 1.0719966888427734, 0.7293926477432251, -0.969696581363678]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.25627464056015015, 0.0319482684135437, 0.4046754539012909, -0.32550108432769775, 1.07581627368927]\n",
      "Last 5 elements: [-1.5001063346862793, -1.9693535566329956, -0.8763624429702759, 1.9487136602401733, 4.3746538162231445]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01798948459327221, -0.004330771509557962, -0.04288805276155472, -0.07170918583869934, -0.005412199068814516]\n",
      "Last 5 elements: [0.6920240521430969, 0.10501960664987564, -0.9041308164596558, -0.5028741955757141, 0.12334264069795609]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.03486613184213638, -0.004152454435825348, -0.0921449288725853, 0.1197628527879715, 0.42701858282089233]\n",
      "Last 5 elements: [-0.9254662394523621, -2.6535518169403076, 12.132797241210938, 3.8001768589019775, -2.1366565227508545]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.03486613184213638, -0.004152454435825348, -0.0921449288725853, 0.1197628527879715, 0.42701858282089233]\n",
      "Last 5 elements: [-0.4856516122817993, -0.8320353031158447, 0.2759789824485779, 0.2720528542995453, 0.2783662676811218]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.005964807700365782, -0.0007103911484591663, -0.015763916075229645, 0.020488718524575233, 0.07305323332548141]\n",
      "Last 5 elements: [-0.46255576610565186, -0.7924667000770569, 0.2628544270992279, 0.2591150104999542, 0.26512816548347473]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.005964807700365782, -0.0007103911484591663, -0.015763916075229645, 0.020488718524575233, 0.07305323332548141]\n",
      "Last 5 elements: [-0.46255576610565186, -0.7924667000770569, 0.2628544270992279, 0.2591150104999542, 0.26512816548347473]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.3897855281829834, -0.11448357999324799, 0.005626946687698364, -0.008550358936190605, -0.01042332872748375]\n",
      "Last 5 elements: [0.20203427970409393, -0.34237098693847656, -0.3876715302467346, 0.4077969193458557, 0.2470291554927826]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.06266836076974869, -0.05859832093119621, -0.037130869925022125, 0.09258668124675751, 0.0034660659730434418]\n",
      "Last 5 elements: [0.20203427970409393, -0.34237098693847656, -0.3876715302467346, 0.4077969193458557, 0.2470291554927826]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.06266836076974869, -0.05859832093119621, -0.037130869925022125, 0.09258668124675751, 0.0034660659730434418]\n",
      "Last 5 elements: [0.0011615146650001407, -0.05052288994193077, 0.08761491626501083, 0.09063351154327393, 0.04309699311852455]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.1152944564819336, 0.1628308743238449, 0.3502875864505768, 0.01748836413025856, -0.2282734215259552]\n",
      "Last 5 elements: [-0.3856486678123474, -0.05319395288825035, 0.10956569015979767, -0.3374101221561432, 0.15759235620498657]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6127853393554688, -0.11363500356674194, -1.349765419960022, -2.357844591140747, -0.2187783569097519]\n",
      "Last 5 elements: [0.7452443838119507, 0.11404401808977127, -1.0437672138214111, -0.6513661742210388, 0.1730695515871048]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0186116062104702, -0.003451338969171047, -0.0409952737390995, -0.07161279767751694, -0.006644768174737692]\n",
      "Last 5 elements: [0.6447051763534546, 0.09865859895944595, -0.9029549360275269, -0.5634918212890625, 0.14972113072872162]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0186116062104702, -0.003451338969171047, -0.0409952737390995, -0.07161279767751694, -0.006644768174737692]\n",
      "Last 5 elements: [0.6447051763534546, 0.09865859895944595, -0.9029549360275269, -0.5634918212890625, 0.14972113072872162]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.63779616355896, -0.5007339119911194, -0.061885371804237366, -1.8546878099441528, -1.1234904527664185]\n",
      "Last 5 elements: [-0.3698265552520752, -2.986377000808716, -0.8191844820976257, -1.174718976020813, -1.0132337808609009]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.63779616355896, -0.5007339119911194, -0.061885371804237366, -1.8546878099441528, -1.1234904527664185]\n",
      "Last 5 elements: [-0.3698265552520752, -2.986377000808716, -0.8191844820976257, -1.174718976020813, -1.0132337808609009]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2665761709213257, -0.18896105885505676, -0.029985541477799416, -0.25098273158073425, -0.2756645679473877]\n",
      "Last 5 elements: [-0.15110482275485992, -0.14348085224628448, -0.25061869621276855, -0.27723726630210876, -0.26987224817276]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0186116062104702, -0.003451338969171047, -0.0409952737390995, -0.07161279767751694, -0.006644768174737692]\n",
      "Last 5 elements: [0.6447051763534546, 0.09865859895944595, -0.9029549360275269, -0.5634918212890625, 0.14972113072872162]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.3672800660133362, 0.5788074731826782, 0.15803241729736328, 0.28645676374435425, -0.3989410698413849]\n",
      "Last 5 elements: [1.3738133907318115, 0.07439997792243958, -0.08457870781421661, -1.500440001487732, -1.355069875717163]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.09790811687707901, -0.10937207192182541, -0.004738687537610531, -0.07189570367336273, 0.10997391492128372]\n",
      "Last 5 elements: [-0.20758983492851257, -0.010674972087144852, 0.021197006106376648, 0.4159778952598572, 0.3656957447528839]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.06855371594429016, -1.288701057434082, -1.1184161901474, -0.6009588837623596, -0.10882942378520966]\n",
      "Last 5 elements: [-0.9326716661453247, -0.6579468846321106, -0.37860167026519775, 0.9840909242630005, 0.2091505527496338]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0186116062104702, -0.003451338969171047, -0.0409952737390995, -0.07161279767751694, -0.006644768174737692]\n",
      "Last 5 elements: [0.6447051763534546, 0.09865859895944595, -0.9029549360275269, -0.5634918212890625, 0.14972113072872162]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.06855371594429016, -1.288701057434082, -1.1184161901474, -0.6009588837623596, -0.10882942378520966]\n",
      "Last 5 elements: [-0.9326716661453247, -0.6579468846321106, -0.37860167026519775, 0.9840909242630005, 0.2091505527496338]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6128, -0.1136, -1.3498,  ..., -0.7074, -1.5979, -1.1424],\n",
      "         [ 0.2450,  0.3870,  0.4546,  ..., -1.0134,  0.2722,  0.1770],\n",
      "         [ 1.4307, -0.5652, -0.9523,  ...,  0.5959, -0.3334, -0.1082],\n",
      "         [ 1.0572,  0.9726,  0.4791,  ...,  0.2630,  0.4582,  0.3629],\n",
      "         [ 0.3508,  0.5413,  0.2843,  ...,  0.0379, -0.4032, -0.2368],\n",
      "         [ 0.6581, -0.0372,  0.6442,  ..., -1.0438, -0.6514,  0.1731]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5922859907150269, -0.1425863653421402, -1.4120466709136963, -2.3609540462493896, -0.17819130420684814]\n",
      "Last 5 elements: [0.813812792301178, 0.12350191175937653, -1.0632480382919312, -0.5913745760917664, 0.14504960179328918]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6249741911888123, -0.34276628494262695, -1.5486199855804443, -2.4646952152252197, -0.23812824487686157]\n",
      "Last 5 elements: [0.5794152021408081, -0.0029390528798103333, -1.111082673072815, -0.4763946533203125, 0.21025656163692474]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6249741911888123, -0.34276628494262695, -1.5486199855804443, -2.4646952152252197, -0.23812824487686157]\n",
      "Last 5 elements: [0.5794152021408081, -0.0029390528798103333, -1.111082673072815, -0.4763946533203125, 0.21025656163692474]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.018986251205205917, -0.010412984527647495, -0.04704592376947403, -0.074875608086586, -0.007234158925712109]\n",
      "Last 5 elements: [0.48679056763648987, -0.0024692192673683167, -0.9334663152694702, -0.4002387523651123, 0.1766451895236969]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018986251205205917, -0.010412984527647495, -0.04704592376947403, -0.074875608086586, -0.007234158925712109]\n",
      "Last 5 elements: [0.48679056763648987, -0.0024692192673683167, -0.9334663152694702, -0.4002387523651123, 0.1766451895236969]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.222033739089966, -0.8208608031272888, -0.14208607375621796, -1.642714023590088, 0.16388124227523804]\n",
      "Last 5 elements: [0.015546083450317383, 0.11894214898347855, 0.7999253273010254, 1.0272245407104492, 0.27757906913757324]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.222033739089966, -0.8208608031272888, -0.14208607375621796, -1.642714023590088, 0.16388124227523804]\n",
      "Last 5 elements: [0.015546083450317383, 0.11894214898347855, 0.7999253273010254, 1.0272245407104492, 0.27757906913757324]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.895961880683899, -0.7004037499427795, -0.1212356835603714, -1.4016542434692383, 0.1398325264453888]\n",
      "Last 5 elements: [0.014976898208260536, 0.11458735167980194, 0.7706378698348999, 0.9896150231361389, 0.2674161493778229]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.895961880683899, -0.7004037499427795, -0.1212356835603714, -1.4016542434692383, 0.1398325264453888]\n",
      "Last 5 elements: [0.014976898208260536, 0.11458735167980194, 0.7706378698348999, 0.9896150231361389, 0.2674161493778229]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.375331997871399, -2.1015310287475586, -0.09403115510940552, 1.7947986125946045, 0.11197972297668457]\n",
      "Last 5 elements: [-1.8015270233154297, -0.039149463176727295, -3.650491237640381, -2.612565040588379, 1.802175760269165]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018986251205205917, -0.010412984527647495, -0.04704592376947403, -0.074875608086586, -0.007234158925712109]\n",
      "Last 5 elements: [0.48679056763648987, -0.0024692192673683167, -0.9334663152694702, -0.4002387523651123, 0.1766451895236969]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.028469249606132507, -0.07227447628974915, -0.3206374943256378, -0.014850802719593048, 0.312471479177475]\n",
      "Last 5 elements: [-1.476496934890747, 1.052929401397705, -5.819464683532715, 0.015463829040527344, -1.1707525253295898]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.028469249606132507, -0.07227447628974915, -0.3206374943256378, -0.014850802719593048, 0.312471479177475]\n",
      "Last 5 elements: [1.750685214996338, -0.25832802057266235, 1.0780514478683472, 0.7009373903274536, -3.8672807216644287]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.005336999427527189, -0.013548963703215122, -0.06010843440890312, -0.0027840116526931524, 0.05857758969068527]\n",
      "Last 5 elements: [1.501185417175293, -0.22151227295398712, 0.9244124293327332, 0.6010429859161377, -3.3161332607269287]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.005336999427527189, -0.013548963703215122, -0.06010843440890312, -0.0027840116526931524, 0.05857758969068527]\n",
      "Last 5 elements: [1.501185417175293, -0.22151227295398712, 0.9244124293327332, 0.6010429859161377, -3.3161332607269287]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.08719257265329361, -0.1492370367050171, 0.0343521423637867, -0.016951313242316246, 0.16970442235469818]\n",
      "Last 5 elements: [0.5869718194007874, 0.26534226536750793, 0.22219577431678772, -0.21682927012443542, -0.03693285211920738]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.003473689779639244, -0.008254097774624825, 0.09706859290599823, 0.013141227886080742, 0.01486731693148613]\n",
      "Last 5 elements: [0.5869718194007874, 0.26534226536750793, 0.22219577431678772, -0.21682927012443542, -0.03693285211920738]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.003473689779639244, -0.008254097774624825, 0.09706859290599823, 0.013141227886080742, 0.01486731693148613]\n",
      "Last 5 elements: [-0.010593618266284466, -0.044383034110069275, 0.005937580484896898, 0.2116154283285141, -0.045998118817806244]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.4057178795337677, 0.0252796933054924, 0.17609098553657532, 0.04669980704784393, -0.08215858787298203]\n",
      "Last 5 elements: [0.20463815331459045, 0.006451781839132309, 0.15675285458564758, 0.018256589770317078, 0.1425623893737793]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5528374910354614, -0.3382715582847595, -1.5173109769821167, -2.4563920497894287, -0.25273606181144714]\n",
      "Last 5 elements: [0.6157999038696289, -0.001791924936696887, -1.0832120180130005, -0.4731486141681671, 0.2356041818857193]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.01679394207894802, -0.010275918059051037, -0.0460924431681633, -0.0746195837855339, -0.007677544839680195]\n",
      "Last 5 elements: [0.5249866247177124, -0.0015276659978553653, -0.9234684705734253, -0.4033724069595337, 0.20085914433002472]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01679394207894802, -0.010275918059051037, -0.0460924431681633, -0.0746195837855339, -0.007677544839680195]\n",
      "Last 5 elements: [0.5249866247177124, -0.0015276659978553653, -0.9234684705734253, -0.4033724069595337, 0.20085914433002472]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.082882881164551, -0.8499065041542053, -1.0873457193374634, 0.532322108745575, -2.47564697265625]\n",
      "Last 5 elements: [0.12474402785301208, -2.4909074306488037, -1.7905282974243164, -1.050883173942566, -0.3634634017944336]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.082882881164551, -0.8499065041542053, -1.0873457193374634, 0.532322108745575, -2.47564697265625]\n",
      "Last 5 elements: [0.12474402785301208, -2.4909074306488037, -1.7905282974243164, -1.050883173942566, -0.3634634017944336]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.23072442412376404, -0.25450658798217773, -0.2741398811340332, 0.33537599444389343, -0.19206848740577698]\n",
      "Last 5 elements: [0.06625724583864212, -0.19054961204528809, -0.25605979561805725, -0.2722371220588684, -0.14906412363052368]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01679394207894802, -0.010275918059051037, -0.0460924431681633, -0.0746195837855339, -0.007677544839680195]\n",
      "Last 5 elements: [0.5249866247177124, -0.0015276659978553653, -0.9234684705734253, -0.4033724069595337, 0.20085914433002472]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.244187116622925, 0.5544300675392151, 1.1147174835205078, 0.6206477880477905, 0.4566660225391388]\n",
      "Last 5 elements: [1.7044148445129395, -0.3413081169128418, 0.7754291892051697, 0.8575063347816467, 0.5212347507476807]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.5177887678146362, -0.14110609889030457, -0.3055885136127472, 0.20815037190914154, -0.0877111554145813]\n",
      "Last 5 elements: [0.11292983591556549, 0.06503613293170929, -0.19855624437332153, -0.23344506323337555, -0.07769740372896194]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.04909071326255798, -0.9035643339157104, -0.019721031188964844, -0.13352277874946594, 0.3364155888557434]\n",
      "Last 5 elements: [0.451161652803421, 0.6498753428459167, -0.7534371018409729, 2.63958740234375, 0.29496973752975464]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01679394207894802, -0.010275918059051037, -0.0460924431681633, -0.0746195837855339, -0.007677544839680195]\n",
      "Last 5 elements: [0.5249866247177124, -0.0015276659978553653, -0.9234684705734253, -0.4033724069595337, 0.20085914433002472]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.04909071326255798, -0.9035643339157104, -0.019721031188964844, -0.13352277874946594, 0.3364155888557434]\n",
      "Last 5 elements: [0.451161652803421, 0.6498753428459167, -0.7534371018409729, 2.63958740234375, 0.29496973752975464]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.5528, -0.3383, -1.5173,  ..., -0.8239, -1.6915, -1.1949],\n",
      "         [ 0.4768,  0.5797,  0.6545,  ..., -0.7762,  0.4915,  0.2771],\n",
      "         [ 1.1528, -0.3658, -0.7867,  ...,  0.8724, -0.2057,  0.0904],\n",
      "         [ 1.0720,  1.0279,  0.5400,  ...,  0.2941,  0.4081,  0.2933],\n",
      "         [ 0.4873,  0.5658,  0.4819,  ...,  0.2102, -0.2077, -0.0040],\n",
      "         [ 0.9096,  0.1371,  0.7648,  ..., -1.0832, -0.4731,  0.2356]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6249741911888123, -0.34276628494262695, -1.5486199855804443, -2.4646952152252197, -0.23812824487686157]\n",
      "Last 5 elements: [0.5794152021408081, -0.0029390528798103333, -1.111082673072815, -0.4763946533203125, 0.21025656163692474]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5441091656684875, -0.49892544746398926, -1.5208173990249634, -2.4801323413848877, -0.19292131066322327]\n",
      "Last 5 elements: [0.6960165500640869, 0.11375603079795837, -1.2171732187271118, -0.0038295090198516846, 0.2880498468875885]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5441091656684875, -0.49892544746398926, -1.5208173990249634, -2.4801323413848877, -0.19292131066322327]\n",
      "Last 5 elements: [0.6960165500640869, 0.11375603079795837, -1.2171732187271118, -0.0038295090198516846, 0.2880498468875885]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0165276899933815, -0.015155203640460968, -0.046195872128009796, -0.07533572614192963, -0.0058601172640919685]\n",
      "Last 5 elements: [0.5703651905059814, 0.09321973472833633, -0.9974377751350403, -0.0031381703447550535, 0.23604841530323029]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0165276899933815, -0.015155203640460968, -0.046195872128009796, -0.07533572614192963, -0.0058601172640919685]\n",
      "Last 5 elements: [0.5703651905059814, 0.09321973472833633, -0.9974377751350403, -0.0031381703447550535, 0.23604841530323029]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.42913591861724854, -1.8963619470596313, -0.6487236022949219, -0.8201645016670227, -0.2424463927745819]\n",
      "Last 5 elements: [-1.0796678066253662, 0.4342900514602661, -0.03272634744644165, 0.6597399711608887, -1.0164470672607422]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.42913591861724854, -1.8963619470596313, -0.6487236022949219, -0.8201645016670227, -0.2424463927745819]\n",
      "Last 5 elements: [-1.0796678066253662, 0.4342900514602661, -0.03272634744644165, 0.6597399711608887, -1.0164470672607422]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.39943385124206543, -1.7651078701019287, -0.6038230657577515, -0.7633979320526123, -0.22566579282283783]\n",
      "Last 5 elements: [-1.073638916015625, 0.43186497688293457, -0.0325436033308506, 0.6560559868812561, -1.0107712745666504]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.39943385124206543, -1.7651078701019287, -0.6038230657577515, -0.7633979320526123, -0.22566579282283783]\n",
      "Last 5 elements: [-1.073638916015625, 0.43186497688293457, -0.0325436033308506, 0.6560559868812561, -1.0107712745666504]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.44652754068374634, -0.4577323794364929, -0.8017982840538025, -1.3032104969024658, 0.14223623275756836]\n",
      "Last 5 elements: [-0.9934506416320801, 2.683143138885498, 1.0010802745819092, -3.310121536254883, 5.187849044799805]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0165276899933815, -0.015155203640460968, -0.046195872128009796, -0.07533572614192963, -0.0058601172640919685]\n",
      "Last 5 elements: [0.5703651905059814, 0.09321973472833633, -0.9974377751350403, -0.0031381703447550535, 0.23604841530323029]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.11233940720558167, 0.15327508747577667, 0.1367434710264206, -0.024353330954909325, -0.08203255385160446]\n",
      "Last 5 elements: [-1.2176716327667236, 2.6965696811676025, -10.883040428161621, -3.201197385787964, 1.1253572702407837]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.11233940720558167, 0.15327508747577667, 0.1367434710264206, -0.024353330954909325, -0.08203255385160446]\n",
      "Last 5 elements: [-0.1090962365269661, -1.1277966499328613, 1.234391450881958, 0.06939166784286499, 1.016798734664917]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.02571018971502781, 0.03507880121469498, 0.03129534423351288, -0.0055735451169312, -0.018774110823869705]\n",
      "Last 5 elements: [-0.09697487950325012, -1.002490520477295, 1.0972418785095215, 0.06168176978826523, 0.9038252830505371]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.02571018971502781, 0.03507880121469498, 0.03129534423351288, -0.0055735451169312, -0.018774110823869705]\n",
      "Last 5 elements: [-0.09697487950325012, -1.002490520477295, 1.0972418785095215, 0.06168176978826523, 0.9038252830505371]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.27863946557044983, 0.2210865318775177, -0.23714393377304077, -0.3068118095397949, -0.25234633684158325]\n",
      "Last 5 elements: [-0.5923591256141663, -0.39639517664909363, -0.043428897857666016, 0.4610726237297058, 0.39917200803756714]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.11676819622516632, 0.016747403889894485, -0.053947385400533676, -0.06267369538545609, 0.03097192570567131]\n",
      "Last 5 elements: [-0.5923591256141663, -0.39639517664909363, -0.043428897857666016, 0.4610726237297058, 0.39917200803756714]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.11676819622516632, 0.016747403889894485, -0.053947385400533676, -0.06267369538545609, 0.03097192570567131]\n",
      "Last 5 elements: [-0.364509254693985, -0.1304132342338562, -0.16518659889698029, 0.18545326590538025, 0.08763951063156128]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.3382650911808014, -0.27566802501678467, -0.6389412879943848, 0.017088957130908966, -0.151874840259552]\n",
      "Last 5 elements: [0.2920846939086914, -0.028084754943847656, 0.19184431433677673, -0.7117674350738525, 0.3245636224746704]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.48396557569503784, -0.5479393005371094, -1.6344212293624878, -2.4770939350128174, -0.2199246883392334]\n",
      "Last 5 elements: [0.7479492425918579, 0.10876255482435226, -1.183063268661499, -0.13038188219070435, 0.34575730562210083]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.014700406230986118, -0.016643602401018143, -0.04964538291096687, -0.07524148374795914, -0.006680190563201904]\n",
      "Last 5 elements: [0.6221560835838318, 0.09047042578458786, -0.9840908646583557, -0.10845372080802917, 0.287606418132782]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.014700406230986118, -0.016643602401018143, -0.04964538291096687, -0.07524148374795914, -0.006680190563201904]\n",
      "Last 5 elements: [0.6221560835838318, 0.09047042578458786, -0.9840908646583557, -0.10845372080802917, 0.287606418132782]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.4469118118286133, -1.8813501596450806, 0.06231256574392319, -0.1003083661198616, -0.9591668844223022]\n",
      "Last 5 elements: [0.014290675520896912, -2.226799249649048, 0.1689324676990509, -0.4319320321083069, -0.11807185411453247]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.4469118118286133, -1.8813501596450806, 0.06231256574392319, -0.1003083661198616, -0.9591668844223022]\n",
      "Last 5 elements: [0.014290675520896912, -2.226799249649048, 0.1689324676990509, -0.4319320321083069, -0.11807185411453247]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.19493244588375092, -0.24877822399139404, 0.03212668374180794, -0.0476408489048481, -0.26573243737220764]\n",
      "Last 5 elements: [0.007196392398327589, -0.2168225198984146, 0.09158386290073395, -0.17003656923770905, -0.05555472895503044]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.014700406230986118, -0.016643602401018143, -0.04964538291096687, -0.07524148374795914, -0.006680190563201904]\n",
      "Last 5 elements: [0.6221560835838318, 0.09047042578458786, -0.9840908646583557, -0.10845372080802917, 0.287606418132782]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [1.5439019203186035, -0.538844883441925, 0.01748707890510559, 0.09477453678846359, -0.16389644145965576]\n",
      "Last 5 elements: [-1.173762559890747, -2.007124900817871, 1.2940219640731812, 0.3154923915863037, 2.1953353881835938]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.3009565770626068, 0.13405287265777588, 0.0005618018331006169, -0.004515139386057854, 0.04355259984731674]\n",
      "Last 5 elements: [-0.008446856401860714, 0.4351898729801178, 0.11851152777671814, -0.05364524573087692, -0.12196126580238342]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.9233905673027039, -0.3838493227958679, -0.12224315851926804, -0.1913956105709076, -0.11244374513626099]\n",
      "Last 5 elements: [-0.5937975645065308, 1.1060562133789062, 0.7048017978668213, 0.9300100207328796, -0.7583264112472534]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.014700406230986118, -0.016643602401018143, -0.04964538291096687, -0.07524148374795914, -0.006680190563201904]\n",
      "Last 5 elements: [0.6221560835838318, 0.09047042578458786, -0.9840908646583557, -0.10845372080802917, 0.287606418132782]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.9233905673027039, -0.3838493227958679, -0.12224315851926804, -0.1913956105709076, -0.11244374513626099]\n",
      "Last 5 elements: [-0.5937975645065308, 1.1060562133789062, 0.7048017978668213, 0.9300100207328796, -0.7583264112472534]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.4840, -0.5479, -1.6344,  ..., -0.8067, -1.9833, -1.3040],\n",
      "         [ 0.3574,  0.4352,  0.6227,  ..., -0.7448,  0.0503,  0.4315],\n",
      "         [ 0.9913, -0.5309, -0.5338,  ...,  0.9490, -0.3204,  0.1420],\n",
      "         [ 0.9503,  1.0290,  0.6278,  ...,  0.2089,  0.4118,  0.1804],\n",
      "         [ 0.3154,  0.4128,  0.2587,  ..., -0.1621, -0.1574,  0.0887],\n",
      "         [ 1.0359,  0.0544,  0.5600,  ..., -1.1831, -0.1304,  0.3458]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5441091656684875, -0.49892544746398926, -1.5208173990249634, -2.4801323413848877, -0.19292131066322327]\n",
      "Last 5 elements: [0.6960165500640869, 0.11375603079795837, -1.2171732187271118, -0.0038295090198516846, 0.2880498468875885]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.31978654861450195, -0.6161878108978271, -1.656156063079834, -2.5111241340637207, -0.23991720378398895]\n",
      "Last 5 elements: [0.6423719525337219, 0.30541953444480896, -1.0577493906021118, 0.03497406840324402, 0.21092674136161804]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.31978654861450195, -0.6161878108978271, -1.656156063079834, -2.5111241340637207, -0.23991720378398895]\n",
      "Last 5 elements: [0.6423719525337219, 0.30541953444480896, -1.0577493906021118, 0.03497406840324402, 0.21092674136161804]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009714207611978054, -0.018718037754297256, -0.05030932277441025, -0.07628082484006882, -0.00728800380602479]\n",
      "Last 5 elements: [0.5278612375259399, 0.25097471475601196, -0.8691924810409546, 0.028739508241415024, 0.17332644760608673]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009714207611978054, -0.018718037754297256, -0.05030932277441025, -0.07628082484006882, -0.00728800380602479]\n",
      "Last 5 elements: [0.5278612375259399, 0.25097471475601196, -0.8691924810409546, 0.028739508241415024, 0.17332644760608673]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.2634847164154053, 1.236218810081482, 1.0114316940307617, -0.21885204315185547, -1.6167858839035034]\n",
      "Last 5 elements: [1.0022321939468384, 1.08479905128479, -0.006430245935916901, 1.0180234909057617, 1.043898344039917]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.2634847164154053, 1.236218810081482, 1.0114316940307617, -0.21885204315185547, -1.6167858839035034]\n",
      "Last 5 elements: [1.0022321939468384, 1.08479905128479, -0.006430245935916901, 1.0180234909057617, 1.043898344039917]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.18075750768184662, 0.8480789065361023, 0.6938689351081848, -0.15013830363750458, -1.1091580390930176]\n",
      "Last 5 elements: [1.0778988599777222, 1.1666992902755737, -0.006915717385709286, 1.0948823690414429, 1.1227107048034668]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.18075750768184662, 0.8480789065361023, 0.6938689351081848, -0.15013830363750458, -1.1091580390930176]\n",
      "Last 5 elements: [1.0778988599777222, 1.1666992902755737, -0.006915717385709286, 1.0948823690414429, 1.1227107048034668]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.330324411392212, 1.360204815864563, -0.855940580368042, 2.6539011001586914, -0.494802325963974]\n",
      "Last 5 elements: [2.303536891937256, -0.9887250065803528, 8.019309997558594, -1.2920422554016113, 2.087010622024536]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009714207611978054, -0.018718037754297256, -0.05030932277441025, -0.07628082484006882, -0.00728800380602479]\n",
      "Last 5 elements: [0.5278612375259399, 0.25097471475601196, -0.8691924810409546, 0.028739508241415024, 0.17332644760608673]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.08265183866024017, 0.2892226278781891, -0.3772735297679901, -0.12751509249210358, 0.16400542855262756]\n",
      "Last 5 elements: [-0.36616766452789307, 0.4233776330947876, -1.8951823711395264, 3.3394501209259033, 0.3970997929573059]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.08265183866024017, 0.2892226278781891, -0.3772735297679901, -0.12751509249210358, 0.16400542855262756]\n",
      "Last 5 elements: [-0.226700097322464, -0.7763708829879761, -1.7003488540649414, -1.1256091594696045, -0.32231438159942627]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.01674831658601761, 0.05860718712210655, -0.07644955813884735, -0.025839269161224365, 0.033233556896448135]\n",
      "Last 5 elements: [-0.2495325803756714, -0.8545644283294678, -1.8716024160385132, -1.2389768362045288, -0.3547768294811249]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.01674831658601761, 0.05860718712210655, -0.07644955813884735, -0.025839269161224365, 0.033233556896448135]\n",
      "Last 5 elements: [-0.2495325803756714, -0.8545644283294678, -1.8716024160385132, -1.2389768362045288, -0.3547768294811249]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.16411535441875458, 0.0014555130619555712, -0.041713107377290726, 0.04473232477903366, -0.13124576210975647]\n",
      "Last 5 elements: [0.4175298511981964, -0.06417295336723328, -0.5457490086555481, -0.21680352091789246, 0.5999590754508972]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.03221516311168671, -0.004541801288723946, -0.0420340821146965, -0.024405527859926224, 0.00792747363448143]\n",
      "Last 5 elements: [0.4175298511981964, -0.06417295336723328, -0.5457490086555481, -0.21680352091789246, 0.5999590754508972]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.03221516311168671, -0.004541801288723946, -0.0420340821146965, -0.024405527859926224, 0.00792747363448143]\n",
      "Last 5 elements: [0.12355745583772659, -0.08936294913291931, -0.005342571064829826, 0.04838591441512108, 0.0472794808447361]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.03544118255376816, 0.02334502339363098, -0.5553414225578308, 0.20078495144844055, -0.03115241974592209]\n",
      "Last 5 elements: [-0.25741007924079895, 0.16188877820968628, 0.14009341597557068, 0.07909584045410156, 0.04110074043273926]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.326088011264801, -0.6120370626449585, -1.7548959255218506, -2.4754245281219482, -0.24545611441135406]\n",
      "Last 5 elements: [0.5966044068336487, 0.3342033922672272, -1.0328407287597656, 0.04903732240200043, 0.21823446452617645]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009904121980071068, -0.018589120358228683, -0.0533006489276886, -0.07518493384122849, -0.007455125916749239]\n",
      "Last 5 elements: [0.495844304561615, 0.27776002883911133, -0.8584049940109253, 0.04075544327497482, 0.18137700855731964]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009904121980071068, -0.018589120358228683, -0.0533006489276886, -0.07518493384122849, -0.007455125916749239]\n",
      "Last 5 elements: [0.495844304561615, 0.27776002883911133, -0.8584049940109253, 0.04075544327497482, 0.18137700855731964]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.1716451197862625, -0.7081472873687744, -0.49228203296661377, 0.11549447476863861, 0.0352327898144722]\n",
      "Last 5 elements: [-1.0592355728149414, -0.5196332931518555, -0.6714736223220825, -1.0697075128555298, -0.844764232635498]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.1716451197862625, -0.7081472873687744, -0.49228203296661377, 0.11549447476863861, 0.0352327898144722]\n",
      "Last 5 elements: [-1.0592355728149414, -0.5196332931518555, -0.6714736223220825, -1.0697075128555298, -0.844764232635498]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.09317003935575485, -0.23369452357292175, -0.18675020337104797, 0.0610782764852047, 0.01792670041322708]\n",
      "Last 5 elements: [-0.2727060914039612, -0.193791002035141, -0.2270701825618744, -0.27326610684394836, -0.25387895107269287]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009904121980071068, -0.018589120358228683, -0.0533006489276886, -0.07518493384122849, -0.007455125916749239]\n",
      "Last 5 elements: [0.495844304561615, 0.27776002883911133, -0.8584049940109253, 0.04075544327497482, 0.18137700855731964]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [2.6584105491638184, 0.09253567457199097, 0.10593043267726898, -0.40590527653694153, 0.30206507444381714]\n",
      "Last 5 elements: [1.355637550354004, 0.6001538634300232, -2.1006994247436523, 0.180336594581604, 0.7984670400619507]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.24768421053886414, -0.021625081077218056, -0.019782530143857002, -0.02479199506342411, 0.005415030289441347]\n",
      "Last 5 elements: [-0.3696906268596649, -0.1163044199347496, 0.477006196975708, -0.04927987977862358, -0.2027139812707901]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.913393497467041, 0.2665252089500427, 0.6211791038513184, -0.44435200095176697, -0.14468760788440704]\n",
      "Last 5 elements: [-0.2608838677406311, -0.7900047302246094, 0.8808338642120361, -0.35722804069519043, 0.6844786405563354]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009904121980071068, -0.018589120358228683, -0.0533006489276886, -0.07518493384122849, -0.007455125916749239]\n",
      "Last 5 elements: [0.495844304561615, 0.27776002883911133, -0.8584049940109253, 0.04075544327497482, 0.18137700855731964]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.913393497467041, 0.2665252089500427, 0.6211791038513184, -0.44435200095176697, -0.14468760788440704]\n",
      "Last 5 elements: [-0.2608838677406311, -0.7900047302246094, 0.8808338642120361, -0.35722804069519043, 0.6844786405563354]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3261, -0.6120, -1.7549,  ..., -0.9278, -1.9677, -1.2261],\n",
      "         [ 0.2148,  0.4785,  0.4579,  ..., -0.7020,  0.0796,  0.4345],\n",
      "         [ 1.1242, -0.6610, -0.7933,  ...,  0.9993, -0.4658,  0.2166],\n",
      "         [ 0.9866,  0.9295,  0.5257,  ...,  0.0522,  0.4743,  0.2558],\n",
      "         [ 0.4946,  0.2899,  0.3203,  ...,  0.1536, -0.0859,  0.2253],\n",
      "         [ 0.8821,  0.0837,  0.5479,  ..., -1.0328,  0.0490,  0.2182]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.31978654861450195, -0.6161878108978271, -1.656156063079834, -2.5111241340637207, -0.23991720378398895]\n",
      "Last 5 elements: [0.6423719525337219, 0.30541953444480896, -1.0577493906021118, 0.03497406840324402, 0.21092674136161804]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.16368648409843445, -0.5646488070487976, -1.6444501876831055, -2.5544304847717285, -0.271181583404541]\n",
      "Last 5 elements: [0.5502191781997681, 0.19374041259288788, -0.8762283325195312, -0.014477886259555817, 0.3399348855018616]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.16368648409843445, -0.5646488070487976, -1.6444501876831055, -2.5544304847717285, -0.271181583404541]\n",
      "Last 5 elements: [0.5502191781997681, 0.19374041259288788, -0.8762283325195312, -0.014477886259555817, 0.3399348855018616]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.004969852976500988, -0.01714388094842434, -0.04992883279919624, -0.07755767554044724, -0.008233621716499329]\n",
      "Last 5 elements: [0.4528646767139435, 0.1594604253768921, -0.7211905121803284, -0.011916202493011951, 0.2797876000404358]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.004969852976500988, -0.01714388094842434, -0.04992883279919624, -0.07755767554044724, -0.008233621716499329]\n",
      "Last 5 elements: [0.4528646767139435, 0.1594604253768921, -0.7211905121803284, -0.011916202493011951, 0.2797876000404358]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.38070258498191833, -0.3822566568851471, 0.19659800827503204, 1.3969923257827759, -1.5693771839141846]\n",
      "Last 5 elements: [-0.7830625176429749, 0.4644719064235687, 1.0396802425384521, -1.092933177947998, 0.20121383666992188]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.38070258498191833, -0.3822566568851471, 0.19659800827503204, 1.3969923257827759, -1.5693771839141846]\n",
      "Last 5 elements: [-0.7830625176429749, 0.4644719064235687, 1.0396802425384521, -1.092933177947998, 0.20121383666992188]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.314973920583725, -0.3162596821784973, 0.16265517473220825, 1.1558003425598145, -1.2984226942062378]\n",
      "Last 5 elements: [-0.8447213172912598, 0.5010446906089783, 1.1215453147888184, -1.178991436958313, 0.21705754101276398]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.314973920583725, -0.3162596821784973, 0.16265517473220825, 1.1558003425598145, -1.2984226942062378]\n",
      "Last 5 elements: [-0.8447213172912598, 0.5010446906089783, 1.1215453147888184, -1.178991436958313, 0.21705754101276398]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.08199089765548706, -0.8960180878639221, 1.9498865604400635, 0.11688899993896484, -0.9755977392196655]\n",
      "Last 5 elements: [-1.2605050802230835, -2.869635581970215, -1.121193766593933, 0.5977328419685364, 2.958160400390625]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.004969852976500988, -0.01714388094842434, -0.04992883279919624, -0.07755767554044724, -0.008233621716499329]\n",
      "Last 5 elements: [0.4528646767139435, 0.1594604253768921, -0.7211905121803284, -0.011916202493011951, 0.2797876000404358]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.008051887154579163, -0.1536608636379242, 0.03288152813911438, -0.04834289476275444, -0.157111257314682]\n",
      "Last 5 elements: [0.6399383544921875, -1.670933485031128, -2.1741981506347656, -1.8382649421691895, -6.47728967666626]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.008051887154579163, -0.1536608636379242, 0.03288152813911438, -0.04834289476275444, -0.157111257314682]\n",
      "Last 5 elements: [-0.09676100313663483, -0.8932960033416748, 0.20120197534561157, -0.13209104537963867, -1.0134278535842896]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.0011773081496357918, -0.02246755175292492, 0.004807778634130955, -0.00706846546381712, -0.022972051054239273]\n",
      "Last 5 elements: [-0.1154276579618454, -1.0656262636184692, 0.2400168776512146, -0.157573401927948, -1.2089333534240723]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.0011773081496357918, -0.02246755175292492, 0.004807778634130955, -0.00706846546381712, -0.022972051054239273]\n",
      "Last 5 elements: [-0.1154276579618454, -1.0656262636184692, 0.2400168776512146, -0.157573401927948, -1.2089333534240723]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.15149886906147003, -0.12627989053726196, -0.05651482194662094, 0.012302090413868427, -0.056281041353940964]\n",
      "Last 5 elements: [-0.4071342945098877, -0.15777891874313354, -0.17747762799263, 0.6123287081718445, -0.8563809394836426]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.015557421371340752, -0.006503735668957233, -0.027166733518242836, -0.011861270293593407, 0.00350779015570879]\n",
      "Last 5 elements: [-0.4071342945098877, -0.15777891874313354, -0.17747762799263, 0.6123287081718445, -0.8563809394836426]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.015557421371340752, -0.006503735668957233, -0.027166733518242836, -0.011861270293593407, 0.00350779015570879]\n",
      "Last 5 elements: [-0.11513689905405045, 0.34343162178993225, 0.039612025022506714, 0.009203006513416767, -0.07725254446268082]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.1821233332157135, -0.37643852829933167, -0.09232629835605621, 0.041133344173431396, -0.20862141251564026]\n",
      "Last 5 elements: [0.15459975600242615, -0.15900102257728577, -0.1724674552679062, -0.15869660675525665, 0.35763779282569885]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.13130491971969604, -0.6315796375274658, -1.6608657836914062, -2.547116994857788, -0.308274507522583]\n",
      "Last 5 elements: [0.577707052230835, 0.16547000408172607, -0.9068930745124817, -0.042694173753261566, 0.40352293848991394]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0039864531718194485, -0.019174931570887566, -0.05042434111237526, -0.07733117043972015, -0.009359298273921013]\n",
      "Last 5 elements: [0.4819914996623993, 0.13805462419986725, -0.7566373348236084, -0.03562052547931671, 0.3366665244102478]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0039864531718194485, -0.019174931570887566, -0.05042434111237526, -0.07733117043972015, -0.009359298273921013]\n",
      "Last 5 elements: [0.4819914996623993, 0.13805462419986725, -0.7566373348236084, -0.03562052547931671, 0.3366665244102478]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.028670161962509155, -0.5606930255889893, 0.6833571791648865, -0.4685322940349579, -2.0326404571533203]\n",
      "Last 5 elements: [-0.5606518387794495, -2.8459837436676025, 0.22140732407569885, -1.0674092769622803, 0.35670870542526245]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.028670161962509155, -0.5606930255889893, 0.6833571791648865, -0.4685322940349579, -2.0326404571533203]\n",
      "Last 5 elements: [-0.5606518387794495, -2.8459837436676025, 0.22140732407569885, -1.0674092769622803, 0.35670870542526245]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.01412960048764944, -0.20374862849712372, 0.45408234000205994, -0.18036791682243347, -0.23541684448719025]\n",
      "Last 5 elements: [-0.2037390172481537, -0.15621404349803925, 0.12290914356708527, -0.273145854473114, 0.20983155071735382]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0039864531718194485, -0.019174931570887566, -0.05042434111237526, -0.07733117043972015, -0.009359298273921013]\n",
      "Last 5 elements: [0.4819914996623993, 0.13805462419986725, -0.7566373348236084, -0.03562052547931671, 0.3366665244102478]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.7054630517959595, -2.483919858932495, 0.2398439347743988, -0.9589035511016846, 0.27828577160835266]\n",
      "Last 5 elements: [0.2794088125228882, 0.8490634560585022, -1.8658199310302734, -0.519013524055481, -0.3619667589664459]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.009967911057174206, 0.506095290184021, 0.10890889167785645, 0.1729554384946823, -0.06551315635442734]\n",
      "Last 5 elements: [-0.05692647770047188, -0.13263563811779022, -0.22932632267475128, 0.14176639914512634, -0.07595204561948776]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.9839872121810913, 0.2864207625389099, 0.098173126578331, -0.4876764416694641, 0.15867048501968384]\n",
      "Last 5 elements: [0.46941643953323364, 0.503868579864502, -0.8025554418563843, 0.354785680770874, -0.7106590270996094]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0039864531718194485, -0.019174931570887566, -0.05042434111237526, -0.07733117043972015, -0.009359298273921013]\n",
      "Last 5 elements: [0.4819914996623993, 0.13805462419986725, -0.7566373348236084, -0.03562052547931671, 0.3366665244102478]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.9839872121810913, 0.2864207625389099, 0.098173126578331, -0.4876764416694641, 0.15867048501968384]\n",
      "Last 5 elements: [0.46941643953323364, 0.503868579864502, -0.8025554418563843, 0.354785680770874, -0.7106590270996094]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1313, -0.6316, -1.6609,  ..., -1.0159, -2.1862, -1.0481],\n",
      "         [ 0.0269,  1.2046,  0.3697,  ..., -0.4081,  0.0916,  0.5205],\n",
      "         [ 0.9748, -0.2685, -0.6090,  ...,  0.5281, -0.7830,  0.3291],\n",
      "         [ 1.2059,  0.8110,  0.3613,  ...,  0.0180,  0.4180,  0.3328],\n",
      "         [ 0.3794,  0.4916,  0.4764,  ...,  0.0328, -0.4737,  0.2099],\n",
      "         [ 0.6533, -0.0051,  0.4789,  ..., -0.9069, -0.0427,  0.4035]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.16368648409843445, -0.5646488070487976, -1.6444501876831055, -2.5544304847717285, -0.271181583404541]\n",
      "Last 5 elements: [0.5502191781997681, 0.19374041259288788, -0.8762283325195312, -0.014477886259555817, 0.3399348855018616]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.30625802278518677, -0.580653965473175, -1.643410563468933, -2.6338260173797607, -0.28006285429000854]\n",
      "Last 5 elements: [0.6611694097518921, 0.2550579309463501, -1.049587607383728, 0.02038678526878357, 0.2771676182746887]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.30625802278518677, -0.580653965473175, -1.643410563468933, -2.6338260173797607, -0.28006285429000854]\n",
      "Last 5 elements: [0.6611694097518921, 0.2550579309463501, -1.049587607383728, 0.02038678526878357, 0.2771676182746887]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009297565557062626, -0.017627842724323273, -0.049891646951436996, -0.07995927333831787, -0.008502316661179066]\n",
      "Last 5 elements: [0.5429582595825195, 0.20945587754249573, -0.861930787563324, 0.016741812229156494, 0.22761254012584686]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009297565557062626, -0.017627842724323273, -0.049891646951436996, -0.07995927333831787, -0.008502316661179066]\n",
      "Last 5 elements: [0.5429582595825195, 0.20945587754249573, -0.861930787563324, 0.016741812229156494, 0.22761254012584686]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.918132483959198, 0.6501984000205994, -0.5912182927131653, -0.02186417579650879, -2.417084217071533]\n",
      "Last 5 elements: [-0.4279349744319916, -0.21222347021102905, 0.05785746872425079, 1.4923286437988281, -0.7453484535217285]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.918132483959198, 0.6501984000205994, -0.5912182927131653, -0.02186417579650879, -2.417084217071533]\n",
      "Last 5 elements: [-0.4279349744319916, -0.21222347021102905, 0.05785746872425079, 1.4923286437988281, -0.7453484535217285]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.8057138323783875, 0.5705863237380981, -0.5188279151916504, -0.019187066704034805, -2.1211297512054443]\n",
      "Last 5 elements: [-0.48317810893058777, -0.2396198958158493, 0.06532642245292664, 1.6849768161773682, -0.8415672183036804]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.8057138323783875, 0.5705863237380981, -0.5188279151916504, -0.019187066704034805, -2.1211297512054443]\n",
      "Last 5 elements: [-0.48317810893058777, -0.2396198958158493, 0.06532642245292664, 1.6849768161773682, -0.8415672183036804]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.7061166763305664, -0.5116989612579346, -0.3709607720375061, -0.13538837432861328, 3.1162800788879395]\n",
      "Last 5 elements: [1.3348883390426636, -0.88364177942276, 5.395784378051758, -2.576960563659668, 1.3189228773117065]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009297565557062626, -0.017627842724323273, -0.049891646951436996, -0.07995927333831787, -0.008502316661179066]\n",
      "Last 5 elements: [0.5429582595825195, 0.20945587754249573, -0.861930787563324, 0.016741812229156494, 0.22761254012584686]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.06282991170883179, 0.14076915383338928, 0.25037238001823425, 0.07345133274793625, -0.045222457498311996]\n",
      "Last 5 elements: [-0.4608224630355835, 0.28625714778900146, -1.8271262645721436, -2.174643039703369, -2.195094347000122]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.06282991170883179, 0.14076915383338928, 0.25037238001823425, 0.07345133274793625, -0.045222457498311996]\n",
      "Last 5 elements: [-0.5201885104179382, -0.047618478536605835, 1.063162088394165, 0.37090492248535156, -0.29015064239501953]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.013309300877153873, 0.029819220304489136, 0.05303654447197914, 0.0155592430382967, -0.009579502046108246]\n",
      "Last 5 elements: [-0.6724851131439209, -0.06155983358621597, 1.3744261264801025, 0.47949546575546265, -0.3750986158847809]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.013309300877153873, 0.029819220304489136, 0.05303654447197914, 0.0155592430382967, -0.009579502046108246]\n",
      "Last 5 elements: [-0.6724851131439209, -0.06155983358621597, 1.3744261264801025, 0.47949546575546265, -0.3750986158847809]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.030815593898296356, 0.10183046758174896, -0.26169830560684204, -0.0732022374868393, 0.26699376106262207]\n",
      "Last 5 elements: [0.5128716826438904, 0.3930421769618988, -0.7714877128601074, -0.5364702939987183, 0.9705467224121094]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.03742576763033867, -0.06778696924448013, -0.11167024075984955, 0.011803478002548218, -0.04451385885477066]\n",
      "Last 5 elements: [0.5128716826438904, 0.3930421769618988, -0.7714877128601074, -0.5364702939987183, 0.9705467224121094]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.03742576763033867, -0.06778696924448013, -0.11167024075984955, 0.011803478002548218, -0.04451385885477066]\n",
      "Last 5 elements: [0.17017480731010437, -0.08372677862644196, -0.07181606441736221, -0.5569482445716858, 0.4373525083065033]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.025962933897972107, -0.14896303415298462, -0.4699987769126892, 0.08505120873451233, -0.1326746940612793]\n",
      "Last 5 elements: [0.1315108686685562, -0.33596277236938477, 0.0007587596774101257, 0.09264282882213593, 0.13661599159240723]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3016418218612671, -0.6071396470069885, -1.7269763946533203, -2.618703842163086, -0.30365243554115295]\n",
      "Last 5 elements: [0.6845520734786987, 0.19532369077205658, -1.0494526624679565, 0.0368586964905262, 0.3014579713344574]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009157340042293072, -0.01843174174427986, -0.05242810770869255, -0.07949946075677872, -0.00921837892383337]\n",
      "Last 5 elements: [0.569158673286438, 0.16239842772483826, -0.8725488185882568, 0.03064551018178463, 0.2506418824195862]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009157340042293072, -0.01843174174427986, -0.05242810770869255, -0.07949946075677872, -0.00921837892383337]\n",
      "Last 5 elements: [0.569158673286438, 0.16239842772483826, -0.8725488185882568, 0.03064551018178463, 0.2506418824195862]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.9101808071136475, -0.985980212688446, 0.2212962508201599, 0.2860766351222992, -2.183957099914551]\n",
      "Last 5 elements: [-1.5514938831329346, -1.1470303535461426, 0.5490717887878418, -0.6865060925483704, -0.13311317563056946]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.9101808071136475, -0.985980212688446, 0.2212962508201599, 0.2860766351222992, -2.183957099914551]\n",
      "Last 5 elements: [-1.5514938831329346, -1.1470303535461426, 0.5490717887878418, -0.6865060925483704, -0.13311317563056946]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.15031833946704865, -0.26789751648902893, 0.12284141033887863, 0.1633598804473877, -0.22101739048957825]\n",
      "Last 5 elements: [-0.2713106870651245, -0.27647092938423157, 0.3480677008628845, -0.22984962165355682, -0.062133338302373886]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009157340042293072, -0.01843174174427986, -0.05242810770869255, -0.07949946075677872, -0.00921837892383337]\n",
      "Last 5 elements: [0.569158673286438, 0.16239842772483826, -0.8725488185882568, 0.03064551018178463, 0.2506418824195862]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.5711755752563477, 1.7016816139221191, -0.45069175958633423, -0.06941329687833786, -0.30663183331489563]\n",
      "Last 5 elements: [0.7978861331939697, -0.9553791284561157, -0.8032016754150391, -0.0596131905913353, -0.08465009927749634]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.08585816621780396, -0.45587629079818726, -0.05536361038684845, -0.011339347809553146, 0.06777096539735794]\n",
      "Last 5 elements: [-0.21647503972053528, 0.26413455605506897, -0.27956855297088623, 0.013702069409191608, 0.005259593483060598]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.2046954184770584, 0.09641021490097046, 1.4025684595108032, -0.013267181813716888, -0.6250587701797485]\n",
      "Last 5 elements: [-0.6994712948799133, 0.5010126233100891, 0.8312430381774902, 0.4488523602485657, -1.9870778322219849]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009157340042293072, -0.01843174174427986, -0.05242810770869255, -0.07949946075677872, -0.00921837892383337]\n",
      "Last 5 elements: [0.569158673286438, 0.16239842772483826, -0.8725488185882568, 0.03064551018178463, 0.2506418824195862]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.2046954184770584, 0.09641021490097046, 1.4025684595108032, -0.013267181813716888, -0.6250587701797485]\n",
      "Last 5 elements: [-0.6994712948799133, 0.5010126233100891, 0.8312430381774902, 0.4488523602485657, -1.9870778322219849]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3016, -0.6071, -1.7270,  ..., -0.9358, -2.2612, -1.0419],\n",
      "         [ 0.1925,  1.3115,  0.1608,  ..., -0.3507,  0.0367,  0.4519],\n",
      "         [ 1.0393,  0.0497, -1.0265,  ...,  0.6374, -0.7356,  0.1156],\n",
      "         [ 1.2053,  0.7941,  0.3188,  ..., -0.0729,  0.5594,  0.2458],\n",
      "         [ 0.1075,  0.7111,  0.1688,  ..., -0.0061, -0.5083,  0.0094],\n",
      "         [ 0.7543,  0.0324,  0.2261,  ..., -1.0495,  0.0369,  0.3015]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.30625802278518677, -0.580653965473175, -1.643410563468933, -2.6338260173797607, -0.28006285429000854]\n",
      "Last 5 elements: [0.6611694097518921, 0.2550579309463501, -1.049587607383728, 0.02038678526878357, 0.2771676182746887]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2652469277381897, -0.5899978876113892, -1.4775995016098022, -2.621062755584717, -0.41478800773620605]\n",
      "Last 5 elements: [0.560185968875885, 0.28440383076667786, -0.9016575217247009, 0.11666472256183624, -0.05184483528137207]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2652469277381897, -0.5899978876113892, -1.4775995016098022, -2.621062755584717, -0.41478800773620605]\n",
      "Last 5 elements: [0.560185968875885, 0.28440383076667786, -0.9016575217247009, 0.11666472256183624, -0.05184483528137207]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.008048334158957005, -0.017902188003063202, -0.04483450576663017, -0.07953038066625595, -0.012585829012095928]\n",
      "Last 5 elements: [0.4597592055797577, 0.23341763019561768, -0.7400137782096863, 0.09574977308511734, -0.042550407350063324]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008048334158957005, -0.017902188003063202, -0.04483450576663017, -0.07953038066625595, -0.012585829012095928]\n",
      "Last 5 elements: [0.4597592055797577, 0.23341763019561768, -0.7400137782096863, 0.09574977308511734, -0.042550407350063324]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.2463858425617218, 0.8191800117492676, 3.5180952548980713, -0.7893646955490112, -2.615424156188965]\n",
      "Last 5 elements: [-0.04981227219104767, -0.0169411301612854, 0.2529451549053192, -0.024535655975341797, -1.592054843902588]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.2463858425617218, 0.8191800117492676, 3.5180952548980713, -0.7893646955490112, -2.615424156188965]\n",
      "Last 5 elements: [-0.04981227219104767, -0.0169411301612854, 0.2529451549053192, -0.024535655975341797, -1.592054843902588]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.16204078495502472, 0.5387508273124695, 2.313748598098755, -0.5191421508789062, -1.720088243484497]\n",
      "Last 5 elements: [-0.05516503006219864, -0.01876159943640232, 0.28012627363204956, -0.02717222273349762, -1.7631348371505737]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.16204078495502472, 0.5387508273124695, 2.313748598098755, -0.5191421508789062, -1.720088243484497]\n",
      "Last 5 elements: [-0.05516503006219864, -0.01876159943640232, 0.28012627363204956, -0.02717222273349762, -1.7631348371505737]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.729140043258667, -0.966758131980896, 1.5571203231811523, 1.219529628753662, 1.5314526557922363]\n",
      "Last 5 elements: [-2.135255813598633, -0.38979458808898926, -8.165956497192383, 1.5688109397888184, -1.77774977684021]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008048334158957005, -0.017902188003063202, -0.04483450576663017, -0.07953038066625595, -0.012585829012095928]\n",
      "Last 5 elements: [0.4597592055797577, 0.23341763019561768, -0.7400137782096863, 0.09574977308511734, -0.042550407350063324]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.08169957995414734, 0.04809766635298729, 0.0674450695514679, -0.09850963950157166, -1.0027016401290894]\n",
      "Last 5 elements: [1.6643917560577393, 0.06734591722488403, 2.035536289215088, 3.510425090789795, -2.8280928134918213]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.08169957995414734, 0.04809766635298729, 0.0674450695514679, -0.09850963950157166, -1.0027016401290894]\n",
      "Last 5 elements: [-0.3185533285140991, 0.8150498867034912, -0.5494840145111084, -0.33604902029037476, -1.4953620433807373]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.012940758839249611, 0.007618403062224388, 0.010682923719286919, -0.015603379346430302, -0.15882237255573273]\n",
      "Last 5 elements: [-0.3755386769771576, 0.9608525037765503, -0.6477801203727722, -0.3961641490459442, -1.762864351272583]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.012940758839249611, 0.007618403062224388, 0.010682923719286919, -0.015603379346430302, -0.15882237255573273]\n",
      "Last 5 elements: [-0.3755386769771576, 0.9608525037765503, -0.6477801203727722, -0.3961641490459442, -1.762864351272583]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.11557748913764954, 0.04073966294527054, -0.09574517607688904, 0.1746198534965515, -0.08980870991945267]\n",
      "Last 5 elements: [0.17050129175186157, 0.28400495648384094, -0.7990143895149231, 0.016287267208099365, -1.376511812210083]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.027495399117469788, 0.0007357560098171234, 0.04870368540287018, -0.05998668819665909, -0.06690587848424911]\n",
      "Last 5 elements: [0.17050129175186157, 0.28400495648384094, -0.7990143895149231, 0.016287267208099365, -1.376511812210083]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.027495399117469788, 0.0007357560098171234, 0.04870368540287018, -0.05998668819665909, -0.06690587848424911]\n",
      "Last 5 elements: [-0.0022909962572157383, 0.18567173182964325, -0.15405245125293732, 0.22842636704444885, -0.2384781390428543]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.22638551890850067, -0.24511252343654633, -0.20320677757263184, 0.14977480471134186, -0.13174723088741302]\n",
      "Last 5 elements: [-0.5374016761779785, 0.9555071592330933, -0.4945874810218811, 0.30661436915397644, 0.3468645513057709]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.30549830198287964, -0.6335789561271667, -1.5137296915054321, -2.594432830810547, -0.43821269273757935]\n",
      "Last 5 elements: [0.46463584899902344, 0.4542931914329529, -0.9895952939987183, 0.1711808145046234, 0.009827744215726852]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009269358590245247, -0.019223904237151146, -0.045929234474897385, -0.07871967554092407, -0.013296146877110004]\n",
      "Last 5 elements: [0.38328292965888977, 0.37475115060806274, -0.8163273930549622, 0.14120882749557495, 0.00810700748115778]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009269358590245247, -0.019223904237151146, -0.045929234474897385, -0.07871967554092407, -0.013296146877110004]\n",
      "Last 5 elements: [0.38328292965888977, 0.37475115060806274, -0.8163273930549622, 0.14120882749557495, 0.00810700748115778]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.8973021507263184, -2.624721050262451, -2.2328739166259766, -0.25743889808654785, -1.323122501373291]\n",
      "Last 5 elements: [1.305657148361206, -0.5414577722549438, -0.9560813903808594, -1.3801095485687256, -0.9519340991973877]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.8973021507263184, -2.624721050262451, -2.2328739166259766, -0.25743889808654785, -1.323122501373291]\n",
      "Last 5 elements: [1.305657148361206, -0.5414577722549438, -0.9560813903808594, -1.3801095485687256, -0.9519340991973877]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.25986337661743164, -0.17733734846115112, -0.216224804520607, -0.11224166303873062, -0.27825167775154114]\n",
      "Last 5 elements: [1.02727210521698, -0.1991744488477707, -0.2654688358306885, -0.27739015221595764, -0.2651098668575287]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009269358590245247, -0.019223904237151146, -0.045929234474897385, -0.07871967554092407, -0.013296146877110004]\n",
      "Last 5 elements: [0.38328292965888977, 0.37475115060806274, -0.8163273930549622, 0.14120882749557495, 0.00810700748115778]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.1124402284622192, 0.20261499285697937, -0.41960692405700684, -0.8894152641296387, -0.3871917128562927]\n",
      "Last 5 elements: [-0.12316262722015381, -0.54252028465271, -1.5738725662231445, -0.10373890399932861, -1.288739800453186]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.28908246755599976, -0.03593120723962784, 0.09072942286729813, 0.09982945024967194, 0.1077367439866066]\n",
      "Last 5 elements: [-0.1265215277671814, 0.10805618017911911, 0.41781410574913025, 0.028776150196790695, 0.3416576385498047]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.40800052881240845, -0.19699318706989288, 0.14153745770454407, -0.2896243929862976, -0.18034207820892334]\n",
      "Last 5 elements: [1.1735875606536865, 0.4788171947002411, 0.9552297592163086, -0.8947029113769531, -0.0169869065284729]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009269358590245247, -0.019223904237151146, -0.045929234474897385, -0.07871967554092407, -0.013296146877110004]\n",
      "Last 5 elements: [0.38328292965888977, 0.37475115060806274, -0.8163273930549622, 0.14120882749557495, 0.00810700748115778]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.40800052881240845, -0.19699318706989288, 0.14153745770454407, -0.2896243929862976, -0.18034207820892334]\n",
      "Last 5 elements: [1.1735875606536865, 0.4788171947002411, 0.9552297592163086, -0.8947029113769531, -0.0169869065284729]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3055, -0.6336, -1.5137,  ..., -1.0267, -2.3651, -1.0387],\n",
      "         [ 0.2166,  1.4387,  0.3375,  ..., -0.3725,  0.0728,  0.2910],\n",
      "         [ 0.8496,  0.2964, -0.8883,  ...,  0.7028, -0.7391, -0.1159],\n",
      "         [ 1.0865,  0.3973, -0.3321,  ..., -0.4011,  0.2381, -0.0743],\n",
      "         [ 0.1562,  0.6874,  0.2955,  ...,  0.0759, -0.3384, -0.1983],\n",
      "         [ 1.3410,  0.0813,  0.1651,  ..., -0.9896,  0.1712,  0.0098]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2652469277381897, -0.5899978876113892, -1.4775995016098022, -2.621062755584717, -0.41478800773620605]\n",
      "Last 5 elements: [0.560185968875885, 0.28440383076667786, -0.9016575217247009, 0.11666472256183624, -0.05184483528137207]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3780408799648285, -0.6686043739318848, -1.4885642528533936, -2.645928144454956, -0.4702775478363037]\n",
      "Last 5 elements: [0.6732999086380005, 0.5394269824028015, -0.8197552561759949, 0.012102469801902771, 0.006807469297200441]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3780408799648285, -0.6686043739318848, -1.4885642528533936, -2.645928144454956, -0.4702775478363037]\n",
      "Last 5 elements: [0.6732999086380005, 0.5394269824028015, -0.8197552561759949, 0.012102469801902771, 0.006807469297200441]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.011464754119515419, -0.02027660235762596, -0.04514332860708237, -0.08024241775274277, -0.014261993579566479]\n",
      "Last 5 elements: [0.5497693419456482, 0.44045814871788025, -0.6693544983863831, 0.009882026351988316, 0.005558500997722149]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.011464754119515419, -0.02027660235762596, -0.04514332860708237, -0.08024241775274277, -0.014261993579566479]\n",
      "Last 5 elements: [0.5497693419456482, 0.44045814871788025, -0.6693544983863831, 0.009882026351988316, 0.005558500997722149]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.516819953918457, -0.5982603430747986, -0.7509780526161194, 1.8043354749679565, 0.4057520031929016]\n",
      "Last 5 elements: [0.19194471836090088, -0.3422114849090576, 1.07794189453125, -0.22985774278640747, -1.0320982933044434]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.516819953918457, -0.5982603430747986, -0.7509780526161194, 1.8043354749679565, 0.4057520031929016]\n",
      "Last 5 elements: [0.19194471836090088, -0.3422114849090576, 1.07794189453125, -0.22985774278640747, -1.0320982933044434]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.3439617156982422, -0.319466233253479, -0.4010162651538849, 0.9635006785392761, 0.21666832268238068]\n",
      "Last 5 elements: [0.18999284505844116, -0.3387315571308136, 1.0669803619384766, -0.22752033174037933, -1.0216028690338135]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.3439617156982422, -0.319466233253479, -0.4010162651538849, 0.9635006785392761, 0.21666832268238068]\n",
      "Last 5 elements: [0.18999284505844116, -0.3387315571308136, 1.0669803619384766, -0.22752033174037933, -1.0216028690338135]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.2114295959472656, 1.2715246677398682, 0.680553674697876, -0.16145968437194824, -0.5917742848396301]\n",
      "Last 5 elements: [-0.5806276202201843, -0.13881899416446686, 1.750550389289856, 3.6990442276000977, 0.6631760001182556]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.011464754119515419, -0.02027660235762596, -0.04514332860708237, -0.08024241775274277, -0.014261993579566479]\n",
      "Last 5 elements: [0.5497693419456482, 0.44045814871788025, -0.6693544983863831, 0.009882026351988316, 0.005558500997722149]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.008966602385044098, -0.2694072723388672, 0.03345958888530731, 0.06533829867839813, -0.2108757197856903]\n",
      "Last 5 elements: [-0.5658062100410461, -4.522402286529541, 0.9451471567153931, -1.7051420211791992, -0.5050899982452393]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.008966602385044098, -0.2694072723388672, 0.03345958888530731, 0.06533829867839813, -0.2108757197856903]\n",
      "Last 5 elements: [1.4460493326187134, 1.1360247135162354, -2.24995756149292, -0.08231386542320251, -0.7170734405517578]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.001576809911057353, -0.04737625643610954, 0.005883991718292236, 0.011489979922771454, -0.03708326816558838]\n",
      "Last 5 elements: [1.4150547981262207, 1.1116752624511719, -2.2017321586608887, -0.08054955303668976, -0.7017037272453308]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.001576809911057353, -0.04737625643610954, 0.005883991718292236, 0.011489979922771454, -0.03708326816558838]\n",
      "Last 5 elements: [1.4150547981262207, 1.1116752624511719, -2.2017321586608887, -0.08054955303668976, -0.7017037272453308]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.036380231380462646, 0.020997537299990654, -0.045666784048080444, 0.06500641256570816, 0.07086421549320221]\n",
      "Last 5 elements: [0.43493330478668213, 0.1529550850391388, -0.12164241075515747, 0.4672381281852722, -0.13978660106658936]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.017323732376098633, 0.014165624976158142, -0.2088024914264679, -0.2205238789319992, -0.18437673151493073]\n",
      "Last 5 elements: [0.43493330478668213, 0.1529550850391388, -0.12164241075515747, 0.4672381281852722, -0.13978660106658936]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.017323732376098633, 0.014165624976158142, -0.2088024914264679, -0.2205238789319992, -0.18437673151493073]\n",
      "Last 5 elements: [-0.11584483087062836, 0.14188586175441742, 0.0970357209444046, -0.1956625133752823, 0.14527811110019684]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.11391673982143402, -0.31674811244010925, 0.13519912958145142, -0.00968247652053833, -0.07952462136745453]\n",
      "Last 5 elements: [0.251175194978714, 0.3743734657764435, -1.4101014137268066, 0.5040174126625061, 0.29573380947113037]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3982952833175659, -0.724922239780426, -1.464525818824768, -2.6476497650146484, -0.48441705107688904]\n",
      "Last 5 elements: [0.717958927154541, 0.6059906482696533, -1.0704715251922607, 0.10171685367822647, 0.05938899144530296]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.012077365070581436, -0.021981557831168175, -0.04440829157829285, -0.08028373122215271, -0.014688804745674133]\n",
      "Last 5 elements: [0.5951799154281616, 0.5023594498634338, -0.8874089121818542, 0.08432213217020035, 0.049232807010412216]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012077365070581436, -0.021981557831168175, -0.04440829157829285, -0.08028373122215271, -0.014688804745674133]\n",
      "Last 5 elements: [0.5951799154281616, 0.5023594498634338, -0.8874089121818542, 0.08432213217020035, 0.049232807010412216]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.16741511225700378, -2.3880841732025146, -0.19862762093544006, -0.17258977890014648, -3.0774407386779785]\n",
      "Last 5 elements: [0.6840194463729858, -1.1881859302520752, -0.47732067108154297, 0.9332640171051025, -1.5939264297485352]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.16741511225700378, -2.3880841732025146, -0.19862762093544006, -0.17258977890014648, -3.0774407386779785]\n",
      "Last 5 elements: [0.6840194463729858, -1.1881859302520752, -0.47732067108154297, 0.9332640171051025, -1.5939264297485352]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.09069819003343582, -0.20080411434173584, -0.089482881128788, -0.07886651158332825, -0.13555343449115753]\n",
      "Last 5 elements: [0.45462340116500854, -0.2775406837463379, -0.18275894224643707, 0.6698381304740906, -0.26910609006881714]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012077365070581436, -0.021981557831168175, -0.04440829157829285, -0.08028373122215271, -0.014688804745674133]\n",
      "Last 5 elements: [0.5951799154281616, 0.5023594498634338, -0.8874089121818542, 0.08432213217020035, 0.049232807010412216]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.04303997755050659, -0.06290045380592346, 0.7763718366622925, 0.1989523470401764, 0.7789048552513123]\n",
      "Last 5 elements: [1.1390001773834229, -1.7053755521774292, 1.552335262298584, -0.12269455194473267, -0.1113007664680481]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.003903648117557168, 0.012630670331418514, -0.06947198510169983, -0.015690676867961884, -0.10558322817087173]\n",
      "Last 5 elements: [0.5178161263465881, 0.47331109642982483, -0.28370314836502075, -0.08218549191951752, 0.029951713979244232]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.5032587647438049, 0.17732684314250946, -0.47259387373924255, 0.21125631034374237, 0.48367348313331604]\n",
      "Last 5 elements: [1.085575819015503, -2.6665897369384766, 1.8426464796066284, -0.3719381093978882, 0.5131444931030273]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.012077365070581436, -0.021981557831168175, -0.04440829157829285, -0.08028373122215271, -0.014688804745674133]\n",
      "Last 5 elements: [0.5951799154281616, 0.5023594498634338, -0.8874089121818542, 0.08432213217020035, 0.049232807010412216]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.5032587647438049, 0.17732684314250946, -0.47259387373924255, 0.21125631034374237, 0.48367348313331604]\n",
      "Last 5 elements: [1.085575819015503, -2.6665897369384766, 1.8426464796066284, -0.3719381093978882, 0.5131444931030273]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3983, -0.7249, -1.4645,  ..., -0.8450, -2.1731, -1.0040],\n",
      "         [-0.1096,  1.0560,  0.2811,  ..., -0.3454,  0.1069, -0.0810],\n",
      "         [ 0.5408,  0.1972, -0.9319,  ...,  0.6374, -0.2939,  0.2635],\n",
      "         [ 1.0692,  0.3125, -0.4510,  ..., -0.3313,  0.3734, -0.0022],\n",
      "         [ 0.1447,  0.5069,  0.2513,  ...,  0.0156, -0.3902, -0.0120],\n",
      "         [ 1.1609, -0.0495,  0.2207,  ..., -1.0705,  0.1017,  0.0594]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3780408799648285, -0.6686043739318848, -1.4885642528533936, -2.645928144454956, -0.4702775478363037]\n",
      "Last 5 elements: [0.6732999086380005, 0.5394269824028015, -0.8197552561759949, 0.012102469801902771, 0.006807469297200441]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.30881577730178833, -0.6933934688568115, -1.5485531091690063, -2.610088348388672, -0.3984198272228241]\n",
      "Last 5 elements: [0.9109745025634766, 0.13187050819396973, -0.7428486347198486, 0.035586193203926086, 0.15062616765499115]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.30881577730178833, -0.6933934688568115, -1.5485531091690063, -2.610088348388672, -0.3984198272228241]\n",
      "Last 5 elements: [0.9109745025634766, 0.13187050819396973, -0.7428486347198486, 0.035586193203926086, 0.15062616765499115]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009355601854622364, -0.021006418392062187, -0.04691355675458908, -0.07907286286354065, -0.012070165015757084]\n",
      "Last 5 elements: [0.7492775917053223, 0.10846365243196487, -0.6109938621520996, 0.029269685968756676, 0.12389019876718521]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009355601854622364, -0.021006418392062187, -0.04691355675458908, -0.07907286286354065, -0.012070165015757084]\n",
      "Last 5 elements: [0.7492775917053223, 0.10846365243196487, -0.6109938621520996, 0.029269685968756676, 0.12389019876718521]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-2.1144518852233887, 1.4397804737091064, 1.4919837713241577, 1.9776417016983032, -2.115952491760254]\n",
      "Last 5 elements: [1.4338687658309937, -0.8371169567108154, 2.3562748432159424, 0.6999741196632385, 0.7861217260360718]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-2.1144518852233887, 1.4397804737091064, 1.4919837713241577, 1.9776417016983032, -2.115952491760254]\n",
      "Last 5 elements: [1.4338687658309937, -0.8371169567108154, 2.3562748432159424, 0.6999741196632385, 0.7861217260360718]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.3251581192016602, 0.9023315906524658, 0.9350481629371643, 1.2394171953201294, -1.3260985612869263]\n",
      "Last 5 elements: [1.4767745733261108, -0.8621660470962524, 2.4267818927764893, 0.7209194898605347, 0.8096449375152588]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.3251581192016602, 0.9023315906524658, 0.9350481629371643, 1.2394171953201294, -1.3260985612869263]\n",
      "Last 5 elements: [1.4767745733261108, -0.8621660470962524, 2.4267818927764893, 0.7209194898605347, 0.8096449375152588]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.3881598114967346, 2.8953332901000977, -0.5308915972709656, -2.2038981914520264, -0.14945274591445923]\n",
      "Last 5 elements: [-0.3881356120109558, 1.2938647270202637, -5.908073425292969, -2.493542194366455, -0.6730824708938599]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009355601854622364, -0.021006418392062187, -0.04691355675458908, -0.07907286286354065, -0.012070165015757084]\n",
      "Last 5 elements: [0.7492775917053223, 0.10846365243196487, -0.6109938621520996, 0.029269685968756676, 0.12389019876718521]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.03528803586959839, -0.16774362325668335, -4.89354133605957e-05, -0.08480001240968704, -0.03801129758358002]\n",
      "Last 5 elements: [0.5180405378341675, -0.8208420276641846, 0.8662670850753784, -4.675025463104248, -1.4161282777786255]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.03528803586959839, -0.16774362325668335, -4.89354133605957e-05, -0.08480001240968704, -0.03801129758358002]\n",
      "Last 5 elements: [-0.20563900470733643, 0.06847178936004639, 1.469111680984497, 0.2882348299026489, 1.6189029216766357]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.0046478016301989555, -0.022093581035733223, -6.445303370128386e-06, -0.01116904430091381, -0.005006483756005764]\n",
      "Last 5 elements: [-0.2298736721277237, 0.0765412300825119, 1.6422473192214966, 0.32220345735549927, 1.8096915483474731]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.0046478016301989555, -0.022093581035733223, -6.445303370128386e-06, -0.01116904430091381, -0.005006483756005764]\n",
      "Last 5 elements: [-0.2298736721277237, 0.0765412300825119, 1.6422473192214966, 0.32220345735549927, 1.8096915483474731]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.08644367009401321, -0.05858324468135834, -0.04960857704281807, -0.024533173069357872, 0.14919772744178772]\n",
      "Last 5 elements: [0.5723985433578491, -0.9561890363693237, -0.2029496729373932, -0.45809388160705566, 0.48671868443489075]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.14977668225765228, -0.07463754713535309, 0.009608561173081398, -0.22236567735671997, -0.03974473476409912]\n",
      "Last 5 elements: [0.5723985433578491, -0.9561890363693237, -0.2029496729373932, -0.45809388160705566, 0.48671868443489075]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.14977668225765228, -0.07463754713535309, 0.009608561173081398, -0.22236567735671997, -0.03974473476409912]\n",
      "Last 5 elements: [0.29504477977752686, -0.8516731262207031, 0.410591721534729, 0.2220945954322815, 0.24261713027954102]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.007465347647666931, -0.2436523288488388, -0.39285969734191895, 0.28477779030799866, -0.14274150133132935]\n",
      "Last 5 elements: [-0.22370442748069763, 0.14014220237731934, 0.17108112573623657, -0.0722171813249588, 0.16671447455883026]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3101431131362915, -0.7367148995399475, -1.618403673171997, -2.559454917907715, -0.4237992763519287]\n",
      "Last 5 elements: [0.8711998462677002, 0.15678781270980835, -0.7124303579330444, 0.02274596504867077, 0.1802680343389511]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009395796805620193, -0.022318802773952484, -0.04902959614992142, -0.07753877341747284, -0.012839013710618019]\n",
      "Last 5 elements: [0.7280852198600769, 0.1310318112373352, -0.5953972935676575, 0.019009416922926903, 0.1506548523902893]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009395796805620193, -0.022318802773952484, -0.04902959614992142, -0.07753877341747284, -0.012839013710618019]\n",
      "Last 5 elements: [0.7280852198600769, 0.1310318112373352, -0.5953972935676575, 0.019009416922926903, 0.1506548523902893]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.20592795312404633, -0.06206303834915161, 0.19548098742961884, -0.7796846032142639, -4.052201747894287]\n",
      "Last 5 elements: [-1.263670802116394, -2.179405927658081, -0.8063347339630127, 0.4962692856788635, 0.1582479476928711]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.20592795312404633, -0.06206303834915161, 0.19548098742961884, -0.7796846032142639, -4.052201747894287]\n",
      "Last 5 elements: [-1.263670802116394, -2.179405927658081, -0.8063347339630127, 0.4962692856788635, 0.1582479476928711]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.0923997014760971, -0.03006887249648571, 0.10726339370012283, -0.24512338638305664, -0.0692400336265564]\n",
      "Last 5 elements: [-0.27844056487083435, -0.22146067023277283, -0.24889303743839264, 0.3084721565246582, 0.08537153899669647]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009395796805620193, -0.022318802773952484, -0.04902959614992142, -0.07753877341747284, -0.012839013710618019]\n",
      "Last 5 elements: [0.7280852198600769, 0.1310318112373352, -0.5953972935676575, 0.019009416922926903, 0.1506548523902893]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.797150731086731, 0.3448781669139862, 0.5353047847747803, -3.0534188747406006, -0.3001692295074463]\n",
      "Last 5 elements: [0.689435601234436, 0.2822738587856293, -1.20462965965271, 0.16789278388023376, -1.0337852239608765]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.07365649193525314, -0.010370098054409027, 0.05741860717535019, 0.7484643459320068, 0.02078372798860073]\n",
      "Last 5 elements: [-0.19196683168411255, -0.06251256167888641, 0.29982393980026245, 0.05179024860262871, -0.08825583755970001]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.30446377396583557, 0.1297682523727417, 0.3412940502166748, 0.13025258481502533, 1.7782803773880005]\n",
      "Last 5 elements: [0.3446722626686096, -1.2144416570663452, 0.22434133291244507, 0.49822941422462463, 0.24990743398666382]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009395796805620193, -0.022318802773952484, -0.04902959614992142, -0.07753877341747284, -0.012839013710618019]\n",
      "Last 5 elements: [0.7280852198600769, 0.1310318112373352, -0.5953972935676575, 0.019009416922926903, 0.1506548523902893]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.30446377396583557, 0.1297682523727417, 0.3412940502166748, 0.13025258481502533, 1.7782803773880005]\n",
      "Last 5 elements: [0.3446722626686096, -1.2144416570663452, 0.22434133291244507, 0.49822941422462463, 0.24990743398666382]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3101, -0.7367, -1.6184,  ..., -0.7447, -2.1437, -1.1753],\n",
      "         [ 0.0095,  0.8691,  0.3206,  ..., -0.3087,  0.0869, -0.4924],\n",
      "         [ 0.8498,  0.2297, -0.9291,  ...,  0.4302,  0.0405,  0.0690],\n",
      "         [ 0.9563, -0.0059, -0.4953,  ..., -0.1465,  0.4958, -0.2058],\n",
      "         [ 0.2982,  0.4233,  0.4908,  ..., -0.1906, -0.6755,  0.0286],\n",
      "         [ 1.1271, -0.1193,  0.3538,  ..., -0.7124,  0.0227,  0.1803]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.30881577730178833, -0.6933934688568115, -1.5485531091690063, -2.610088348388672, -0.3984198272228241]\n",
      "Last 5 elements: [0.9109745025634766, 0.13187050819396973, -0.7428486347198486, 0.035586193203926086, 0.15062616765499115]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.25600939989089966, -0.7136420607566833, -1.557721495628357, -2.5362958908081055, -0.1076207160949707]\n",
      "Last 5 elements: [0.9324826598167419, -0.05914013087749481, -0.6725424528121948, 0.11133124679327011, 0.22470161318778992]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.25600939989089966, -0.7136420607566833, -1.557721495628357, -2.5362958908081055, -0.1076207160949707]\n",
      "Last 5 elements: [0.9324826598167419, -0.05914013087749481, -0.6725424528121948, 0.11133124679327011, 0.22470161318778992]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.007753551006317139, -0.021613502874970436, -0.04717746004462242, -0.07681475579738617, -0.00325942225754261]\n",
      "Last 5 elements: [0.751021146774292, -0.047631438821554184, -0.5416654348373413, 0.08966614305973053, 0.1809745877981186]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.007753551006317139, -0.021613502874970436, -0.04717746004462242, -0.07681475579738617, -0.00325942225754261]\n",
      "Last 5 elements: [0.751021146774292, -0.047631438821554184, -0.5416654348373413, 0.08966614305973053, 0.1809745877981186]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.881081223487854, -0.3131347596645355, 1.7695744037628174, 0.2556343078613281, -0.14998988807201385]\n",
      "Last 5 elements: [0.2251039743423462, -2.1097910404205322, 0.08524805307388306, -0.7464147806167603, -8.88498306274414]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.881081223487854, -0.3131347596645355, 1.7695744037628174, 0.2556343078613281, -0.14998988807201385]\n",
      "Last 5 elements: [0.2251039743423462, -2.1097910404205322, 0.08524805307388306, -0.7464147806167603, -8.88498306274414]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.6475932002067566, -0.23015351593494415, 1.3006341457366943, 0.18789078295230865, -0.11024230718612671]\n",
      "Last 5 elements: [0.21773864328861237, -2.040759325027466, 0.08245876431465149, -0.7219923138618469, -8.594269752502441]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.6475932002067566, -0.23015351593494415, 1.3006341457366943, 0.18789078295230865, -0.11024230718612671]\n",
      "Last 5 elements: [0.21773864328861237, -2.040759325027466, 0.08245876431465149, -0.7219923138618469, -8.594269752502441]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.6832091808319092, 1.283708095550537, 0.6386550068855286, -0.869827926158905, 0.2870585322380066]\n",
      "Last 5 elements: [-1.9657564163208008, 1.6896003484725952, -0.4755379557609558, 3.319910764694214, -3.467257022857666]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.007753551006317139, -0.021613502874970436, -0.04717746004462242, -0.07681475579738617, -0.00325942225754261]\n",
      "Last 5 elements: [0.751021146774292, -0.047631438821554184, -0.5416654348373413, 0.08966614305973053, 0.1809745877981186]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.13697350025177002, -0.038651689887046814, -0.23401562869548798, -0.06970188021659851, -0.031104136258363724]\n",
      "Last 5 elements: [2.507016897201538, 0.5951778888702393, -11.412158966064453, -2.8054494857788086, -4.770194053649902]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.13697350025177002, -0.038651689887046814, -0.23401562869548798, -0.06970188021659851, -0.031104136258363724]\n",
      "Last 5 elements: [0.36830538511276245, 0.08153152465820312, -1.68947434425354, -0.10355234146118164, -0.5094204545021057]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.021971192210912704, -0.006199912633746862, -0.03753720596432686, -0.011180508881807327, -0.004989249631762505]\n",
      "Last 5 elements: [0.3963867723941803, 0.08774787932634354, -1.8182880878448486, -0.11144766956567764, -0.5482611060142517]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.021971192210912704, -0.006199912633746862, -0.03753720596432686, -0.011180508881807327, -0.004989249631762505]\n",
      "Last 5 elements: [0.3963867723941803, 0.08774787932634354, -1.8182880878448486, -0.11144766956567764, -0.5482611060142517]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.10386323183774948, 0.19003698229789734, 0.08416430652141571, 0.0864269807934761, 0.14894592761993408]\n",
      "Last 5 elements: [-1.6362802982330322, -0.3952457904815674, 0.045869097113609314, 1.159169316291809, 0.6929901838302612]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.28850430250167847, 0.12420420348644257, -0.006409073248505592, 0.028556909412145615, -0.489075243473053]\n",
      "Last 5 elements: [-1.6362802982330322, -0.3952457904815674, 0.045869097113609314, 1.159169316291809, 0.6929901838302612]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.28850430250167847, 0.12420420348644257, -0.006409073248505592, 0.028556909412145615, -0.489075243473053]\n",
      "Last 5 elements: [0.05285681411623955, -0.09524870663881302, -0.009833031333982944, 0.19089624285697937, -0.0028231500182300806]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.48622745275497437, -0.46311742067337036, -0.058737315237522125, -0.0038592591881752014, 0.26224467158317566]\n",
      "Last 5 elements: [0.30838897824287415, 0.42042648792266846, 0.38776904344558716, -0.7490944266319275, -0.14713910222053528]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.1695580780506134, -0.7959843873977661, -1.5681649446487427, -2.5369820594787598, -0.06099356710910797]\n",
      "Last 5 elements: [0.9873142838478088, 0.01561177521944046, -0.6035970449447632, -0.02185788005590439, 0.19854025542736053]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.005134965293109417, -0.024105912074446678, -0.04749093949794769, -0.07683098316192627, -0.0018471537623554468]\n",
      "Last 5 elements: [0.8188422918319702, 0.012947834096848965, -0.5006012916564941, -0.018128124997019768, 0.16466200351715088]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005134965293109417, -0.024105912074446678, -0.04749093949794769, -0.07683098316192627, -0.0018471537623554468]\n",
      "Last 5 elements: [0.8188422918319702, 0.012947834096848965, -0.5006012916564941, -0.018128124997019768, 0.16466200351715088]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.8307422399520874, -0.5669637322425842, -0.5546831488609314, -1.4490301609039307, -1.576466679573059]\n",
      "Last 5 elements: [-2.2938995361328125, 1.523887276649475, 0.12070921063423157, 0.3349131643772125, -0.7768905162811279]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.8307422399520874, -0.5669637322425842, -0.5546831488609314, -1.4490301609039307, -1.576466679573059]\n",
      "Last 5 elements: [-2.2938995361328125, 1.523887276649475, 0.12070921063423157, 0.3349131643772125, -0.7768905162811279]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2521204352378845, -0.20520555973052979, -0.20233651995658875, -0.27553433179855347, -0.27004316449165344]\n",
      "Last 5 elements: [-0.21018877625465393, 1.251279354095459, 0.06399286538362503, 0.1952390819787979, -0.24471308290958405]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005134965293109417, -0.024105912074446678, -0.04749093949794769, -0.07683098316192627, -0.0018471537623554468]\n",
      "Last 5 elements: [0.8188422918319702, 0.012947834096848965, -0.5006012916564941, -0.018128124997019768, 0.16466200351715088]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.1249576285481453, -0.06648458540439606, 0.3252575695514679, 0.0675223246216774, -0.4937227964401245]\n",
      "Last 5 elements: [-0.8477413058280945, -1.314630389213562, 0.39137062430381775, 0.9557777643203735, -1.2089656591415405]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.031504370272159576, 0.013643006794154644, -0.06581148505210876, -0.018604718148708344, 0.1333264708518982]\n",
      "Last 5 elements: [0.17818570137023926, -1.6449698209762573, 0.02504492737352848, 0.18660517036914825, 0.2958497107028961]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.5091139078140259, 0.2994590699672699, 0.04979175329208374, 0.22795066237449646, 0.3348762094974518]\n",
      "Last 5 elements: [2.302558422088623, 1.5247987508773804, 0.36154645681381226, -0.3660898208618164, 0.18643218278884888]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005134965293109417, -0.024105912074446678, -0.04749093949794769, -0.07683098316192627, -0.0018471537623554468]\n",
      "Last 5 elements: [0.8188422918319702, 0.012947834096848965, -0.5006012916564941, -0.018128124997019768, 0.16466200351715088]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.5091139078140259, 0.2994590699672699, 0.04979175329208374, 0.22795066237449646, 0.3348762094974518]\n",
      "Last 5 elements: [2.302558422088623, 1.5247987508773804, 0.36154645681381226, -0.3660898208618164, 0.18643218278884888]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1696, -0.7960, -1.5682,  ..., -0.5625, -2.3309, -1.2168],\n",
      "         [-0.0036,  0.7022,  0.6080,  ..., -0.6647,  0.2117, -0.6295],\n",
      "         [ 0.8880, -0.0830, -1.0251,  ...,  0.4640, -0.0582,  0.1814],\n",
      "         [ 0.9064, -0.3779, -0.3287,  ..., -0.1797,  0.4615, -0.2991],\n",
      "         [ 0.3116,  0.2627,  0.8290,  ..., -0.3551, -0.8921,  0.0663],\n",
      "         [ 1.2379,  0.0591,  0.7081,  ..., -0.6036, -0.0219,  0.1985]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.25600939989089966, -0.7136420607566833, -1.557721495628357, -2.5362958908081055, -0.1076207160949707]\n",
      "Last 5 elements: [0.9324826598167419, -0.05914013087749481, -0.6725424528121948, 0.11133124679327011, 0.22470161318778992]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.07903753221035004, -0.7427405118942261, -1.5593119859695435, -2.4964523315429688, -0.0014525167644023895]\n",
      "Last 5 elements: [1.3967095613479614, 0.28672125935554504, -0.5393140316009521, -0.08694871515035629, 0.23168793320655823]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.07903753221035004, -0.7427405118942261, -1.5593119859695435, -2.4964523315429688, -0.0014525167644023895]\n",
      "Last 5 elements: [1.3967095613479614, 0.28672125935554504, -0.5393140316009521, -0.08694871515035629, 0.23168793320655823]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.002393715549260378, -0.022494496777653694, -0.04722502455115318, -0.07560707628726959, -4.3990647100145e-05]\n",
      "Last 5 elements: [1.1162673234939575, 0.22915112972259521, -0.4310263693332672, -0.0694904774427414, 0.1851678341627121]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002393715549260378, -0.022494496777653694, -0.04722502455115318, -0.07560707628726959, -4.3990647100145e-05]\n",
      "Last 5 elements: [1.1162673234939575, 0.22915112972259521, -0.4310263693332672, -0.0694904774427414, 0.1851678341627121]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.1701139211654663, -0.3402155935764313, 1.3486113548278809, 2.5065059661865234, 0.009318463504314423]\n",
      "Last 5 elements: [-1.6884331703186035, -0.7020784616470337, -0.9993034601211548, -0.23850785195827484, -0.8227614164352417]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.1701139211654663, -0.3402155935764313, 1.3486113548278809, 2.5065059661865234, 0.009318463504314423]\n",
      "Last 5 elements: [-1.6884331703186035, -0.7020784616470337, -0.9993034601211548, -0.23850785195827484, -0.8227614164352417]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.6344208717346191, -0.1844605654478073, 0.7311999201774597, 1.3589956760406494, 0.005052352324128151]\n",
      "Last 5 elements: [-1.6094930171966553, -0.6692538261413574, -0.9525824785232544, -0.22735676169395447, -0.7842944264411926]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.6344208717346191, -0.1844605654478073, 0.7311999201774597, 1.3589956760406494, 0.005052352324128151]\n",
      "Last 5 elements: [-1.6094930171966553, -0.6692538261413574, -0.9525824785232544, -0.22735676169395447, -0.7842944264411926]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.46880000829696655, 1.339951992034912, 0.877090573310852, 0.8685234189033508, 1.9215970039367676]\n",
      "Last 5 elements: [-2.501824378967285, 2.025681495666504, 2.559441089630127, 1.5431358814239502, 0.9538863301277161]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002393715549260378, -0.022494496777653694, -0.04722502455115318, -0.07560707628726959, -4.3990647100145e-05]\n",
      "Last 5 elements: [1.1162673234939575, 0.22915112972259521, -0.4310263693332672, -0.0694904774427414, 0.1851678341627121]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.28955134749412537, 0.20577837526798248, -0.1292303204536438, -0.023760812357068062, 0.12501651048660278]\n",
      "Last 5 elements: [-0.8309918642044067, 3.6196155548095703, -12.00092887878418, 0.27483871579170227, 6.160787105560303]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.28955134749412537, 0.20577837526798248, -0.1292303204536438, -0.023760812357068062, 0.12501651048660278]\n",
      "Last 5 elements: [-0.5735660791397095, 0.4739382863044739, 0.20220626890659332, 2.2062270641326904, 0.7615739107131958]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.04189615324139595, 0.029774760827422142, -0.018698766827583313, -0.0034380313009023666, 0.018089057877659798]\n",
      "Last 5 elements: [-0.5847576856613159, 0.48318591713905334, 0.2061517834663391, 2.2492756843566895, 0.7764339447021484]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.04189615324139595, 0.029774760827422142, -0.018698766827583313, -0.0034380313009023666, 0.018089057877659798]\n",
      "Last 5 elements: [-0.5847576856613159, 0.48318591713905334, 0.2061517834663391, 2.2492756843566895, 0.7764339447021484]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.06810575723648071, -0.010403018444776535, 0.027482200413942337, -0.03658604621887207, -0.36584755778312683]\n",
      "Last 5 elements: [0.03356194496154785, -1.3154072761535645, -1.663014531135559, 0.5276036262512207, -0.45283764600753784]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.03774971514940262, -0.007942147552967072, 0.047375068068504333, -0.047914933413267136, 0.033756792545318604]\n",
      "Last 5 elements: [0.03356194496154785, -1.3154072761535645, -1.663014531135559, 0.5276036262512207, -0.45283764600753784]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.03774971514940262, -0.007942147552967072, 0.047375068068504333, -0.047914933413267136, 0.033756792545318604]\n",
      "Last 5 elements: [0.027973344549536705, -1.2795805931091309, -1.6228071451187134, 0.5144168138504028, -0.4449368119239807]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.02916352078318596, -0.06811384856700897, 0.08418190479278564, 0.13684916496276855, -0.09643146395683289]\n",
      "Last 5 elements: [-0.6604213118553162, 0.3409135937690735, -0.5082658529281616, -0.6262490749359131, 0.19793720543384552]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.08422280848026276, -0.7548511624336243, -1.544344425201416, -2.472120523452759, -0.018598048016428947]\n",
      "Last 5 elements: [1.279286503791809, 0.3473357558250427, -0.629683792591095, -0.19829592108726501, 0.26688119769096375]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.002550190780311823, -0.0228562131524086, -0.04676136001944542, -0.07485358417034149, -0.0005631321691907942]\n",
      "Last 5 elements: [1.0279113054275513, 0.27908551692962646, -0.5059531927108765, -0.15933148562908173, 0.2144400030374527]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002550190780311823, -0.0228562131524086, -0.04676136001944542, -0.07485358417034149, -0.0005631321691907942]\n",
      "Last 5 elements: [1.0279113054275513, 0.27908551692962646, -0.5059531927108765, -0.15933148562908173, 0.2144400030374527]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.6482672691345215, -1.6598542928695679, -3.219501256942749, -2.7324843406677246, 0.6590099930763245]\n",
      "Last 5 elements: [0.07123681902885437, -0.8372663259506226, -1.5703113079071045, -1.6361198425292969, -1.625854730606079]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.6482672691345215, -1.6598542928695679, -3.219501256942749, -2.7324843406677246, 0.6590099930763245]\n",
      "Last 5 elements: [0.07123681902885437, -0.8372663259506226, -1.5703113079071045, -1.6361198425292969, -1.625854730606079]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.26593682169914246, -0.26521411538124084, -0.12375252693891525, -0.16690976917743683, 0.4343125820159912]\n",
      "Last 5 elements: [0.0368865467607975, -0.25294724106788635, -0.2703636884689331, -0.26667729020118713, -0.2672888934612274]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002550190780311823, -0.0228562131524086, -0.04676136001944542, -0.07485358417034149, -0.0005631321691907942]\n",
      "Last 5 elements: [1.0279113054275513, 0.27908551692962646, -0.5059531927108765, -0.15933148562908173, 0.2144400030374527]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.3952551484107971, 1.4776792526245117, 6.094419479370117, 0.1617826521396637, -0.06990952789783478]\n",
      "Last 5 elements: [0.963079571723938, -0.08956004679203033, 1.0200167894363403, -1.931380271911621, -1.9310264587402344]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.10511289536952972, -0.3919014036655426, -0.7541998028755188, -0.027003105729818344, -0.030362587422132492]\n",
      "Last 5 elements: [0.03552468121051788, 0.022653967142105103, -0.2757754921913147, 0.515055239200592, 0.516141951084137]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.6795989871025085, -0.9457632899284363, 1.3383259773254395, 0.263821005821228, -1.2746193408966064]\n",
      "Last 5 elements: [-0.8437203168869019, -1.257503867149353, -0.8997290134429932, -1.5317738056182861, 0.17144644260406494]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.002550190780311823, -0.0228562131524086, -0.04676136001944542, -0.07485358417034149, -0.0005631321691907942]\n",
      "Last 5 elements: [1.0279113054275513, 0.27908551692962646, -0.5059531927108765, -0.15933148562908173, 0.2144400030374527]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.6795989871025085, -0.9457632899284363, 1.3383259773254395, 0.263821005821228, -1.2746193408966064]\n",
      "Last 5 elements: [-0.8437203168869019, -1.257503867149353, -0.8997290134429932, -1.5317738056182861, 0.17144644260406494]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-8.4223e-02, -7.5485e-01, -1.5443e+00,  ..., -5.1668e-01,\n",
      "          -2.5074e+00, -1.2711e+00],\n",
      "         [-1.8132e-01,  9.6000e-01,  6.0436e-01,  ..., -5.7819e-01,\n",
      "           2.9739e-02, -6.6980e-01],\n",
      "         [ 1.5280e+00, -4.4012e-01, -1.1129e+00,  ...,  9.1142e-02,\n",
      "           2.7077e-01,  2.5021e-01],\n",
      "         [ 1.4342e+00, -3.1427e-01, -6.6806e-01,  ..., -4.2861e-01,\n",
      "           3.7953e-01, -2.6012e-01],\n",
      "         [ 4.4514e-01, -1.3674e-01,  9.1642e-01,  ..., -1.0045e-01,\n",
      "          -8.7562e-01,  1.0088e-01],\n",
      "         [ 1.3563e+00,  2.9434e-04,  2.4904e-01,  ..., -6.2968e-01,\n",
      "          -1.9830e-01,  2.6688e-01]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.07903753221035004, -0.7427405118942261, -1.5593119859695435, -2.4964523315429688, -0.0014525167644023895]\n",
      "Last 5 elements: [1.3967095613479614, 0.28672125935554504, -0.5393140316009521, -0.08694871515035629, 0.23168793320655823]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2050556242465973, -0.9230080246925354, -1.3063898086547852, -2.425213098526001, -0.24522559344768524]\n",
      "Last 5 elements: [1.1292729377746582, 0.12375134229660034, -0.7896558046340942, -0.47064557671546936, 0.29736441373825073]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2050556242465973, -0.9230080246925354, -1.3063898086547852, -2.425213098526001, -0.24522559344768524]\n",
      "Last 5 elements: [1.1292729377746582, 0.12375134229660034, -0.7896558046340942, -0.47064557671546936, 0.29736441373825073]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.006207953207194805, -0.02794359251856804, -0.03955027833580971, -0.07342207431793213, -0.007424078416079283]\n",
      "Last 5 elements: [0.8592095971107483, 0.09415645897388458, -0.600811243057251, -0.35809165239334106, 0.2262503206729889]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.006207953207194805, -0.02794359251856804, -0.03955027833580971, -0.07342207431793213, -0.007424078416079283]\n",
      "Last 5 elements: [0.8592095971107483, 0.09415645897388458, -0.600811243057251, -0.35809165239334106, 0.2262503206729889]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.015092268586158752, -0.3713187873363495, 1.2355960607528687, -0.7333298325538635, -1.4294376373291016]\n",
      "Last 5 elements: [-1.316161870956421, 0.6712348461151123, 1.3351027965545654, 0.9905209541320801, 1.1922451257705688]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.015092268586158752, -0.3713187873363495, 1.2355960607528687, -0.7333298325538635, -1.4294376373291016]\n",
      "Last 5 elements: [-1.316161870956421, 0.6712348461151123, 1.3351027965545654, 0.9905209541320801, 1.1922451257705688]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.009551730938255787, -0.23500359058380127, 0.7819951772689819, -0.4641163945198059, -0.9046754240989685]\n",
      "Last 5 elements: [-1.250036597251892, 0.6375113129615784, 1.2680258750915527, 0.9407562017440796, 1.1323455572128296]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.009551730938255787, -0.23500359058380127, 0.7819951772689819, -0.4641163945198059, -0.9046754240989685]\n",
      "Last 5 elements: [-1.250036597251892, 0.6375113129615784, 1.2680258750915527, 0.9407562017440796, 1.1323455572128296]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-2.255312442779541, -0.0005421638488769531, -0.7027416229248047, -1.1738675832748413, 1.968052864074707]\n",
      "Last 5 elements: [-2.4009883403778076, 1.899172306060791, -0.8049906492233276, -1.3323215246200562, 1.17207932472229]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.006207953207194805, -0.02794359251856804, -0.03955027833580971, -0.07342207431793213, -0.007424078416079283]\n",
      "Last 5 elements: [0.8592095971107483, 0.09415645897388458, -0.600811243057251, -0.35809165239334106, 0.2262503206729889]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.05067390948534012, -0.09272318333387375, -0.009868897497653961, 0.14333288371562958, -0.1825283318758011]\n",
      "Last 5 elements: [1.7002763748168945, 0.7407324314117432, -0.18169641494750977, -4.996658802032471, 1.0371248722076416]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.05067390948534012, -0.09272318333387375, -0.009868897497653961, 0.14333288371562958, -0.1825283318758011]\n",
      "Last 5 elements: [-1.3673392534255981, 0.1403234302997589, 1.985495924949646, 0.030284017324447632, -1.0574523210525513]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.007539569400250912, -0.013795914128422737, -0.0014683540211990476, 0.02132592909038067, -0.02715766429901123]\n",
      "Last 5 elements: [-1.344726324081421, 0.13800276815891266, 1.9526599645614624, 0.029783183708786964, -1.0399643182754517]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.007539569400250912, -0.013795914128422737, -0.0014683540211990476, 0.02132592909038067, -0.02715766429901123]\n",
      "Last 5 elements: [-1.344726324081421, 0.13800276815891266, 1.9526599645614624, 0.029783183708786964, -1.0399643182754517]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.7142956256866455, -0.11565648019313812, 0.4408089518547058, 0.21255682408809662, 0.11200781166553497]\n",
      "Last 5 elements: [-0.7770734429359436, 0.4332909882068634, 2.029209613800049, -0.8411394357681274, 0.16472691297531128]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.029812686145305634, 0.008439237251877785, -0.007707469630986452, -0.23375046253204346, -0.021136481314897537]\n",
      "Last 5 elements: [-0.7770734429359436, 0.4332909882068634, 2.029209613800049, -0.8411394357681274, 0.16472691297531128]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.029812686145305634, 0.008439237251877785, -0.007707469630986452, -0.23375046253204346, -0.021136481314897537]\n",
      "Last 5 elements: [0.036989036947488785, -0.047481585294008255, 0.060168616473674774, 0.018419302999973297, 0.023612603545188904]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.2312437891960144, -0.113421730697155, 0.06034413352608681, -0.0825309008359909, -0.44330140948295593]\n",
      "Last 5 elements: [0.07576005160808563, -0.160094752907753, -0.15470656752586365, 0.03537791594862938, 0.09843942523002625]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.1639404296875, -0.943174421787262, -1.2956606149673462, -2.439887046813965, -0.3240446448326111]\n",
      "Last 5 elements: [1.1427431106567383, 0.09528646618127823, -0.8171626329421997, -0.46435537934303284, 0.31486696004867554]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.004962975159287453, -0.02855275757610798, -0.03922358527779579, -0.07386279851198196, -0.009809817187488079]\n",
      "Last 5 elements: [0.8790923953056335, 0.07330221682786942, -0.6286289691925049, -0.35722050070762634, 0.2422216683626175]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.004962975159287453, -0.02855275757610798, -0.03922358527779579, -0.07386279851198196, -0.009809817187488079]\n",
      "Last 5 elements: [0.8790923953056335, 0.07330221682786942, -0.6286289691925049, -0.35722050070762634, 0.2422216683626175]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.3829216957092285, -0.7687852382659912, -2.931950330734253, -0.4684477150440216, -1.2068572044372559]\n",
      "Last 5 elements: [-0.4617963135242462, -0.5225921869277954, -2.052244186401367, -2.284268379211426, 0.9000585079193115]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.3829216957092285, -0.7687852382659912, -2.931950330734253, -0.4684477150440216, -1.2068572044372559]\n",
      "Last 5 elements: [-0.4617963135242462, -0.5225921869277954, -2.052244186401367, -2.284268379211426, 0.9000585079193115]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2773313522338867, -0.243506520986557, -0.14834658801555634, -0.18034474551677704, -0.27788805961608887]\n",
      "Last 5 elements: [-0.1785118728876114, -0.19453300535678864, -0.23359838128089905, -0.21114464104175568, 0.6399069428443909]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.004962975159287453, -0.02855275757610798, -0.03922358527779579, -0.07386279851198196, -0.009809817187488079]\n",
      "Last 5 elements: [0.8790923953056335, 0.07330221682786942, -0.6286289691925049, -0.35722050070762634, 0.2422216683626175]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.3636827766895294, -0.41095322370529175, -1.5982003211975098, 0.5094180107116699, -0.9644052982330322]\n",
      "Last 5 elements: [0.23964369297027588, 0.7313922643661499, 0.12994995713233948, 2.12154221534729, 0.19803708791732788]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.10086063295602798, 0.1000697910785675, 0.23708756268024445, -0.09187085926532745, 0.26799672842025757]\n",
      "Last 5 elements: [-0.04277924448251724, -0.14227993786334991, -0.03035609982907772, -0.4479522705078125, 0.12672530114650726]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.18968437612056732, -0.00924837589263916, -0.22794750332832336, -1.361747145652771, 0.21876734495162964]\n",
      "Last 5 elements: [1.1051301956176758, -0.9103802442550659, -1.398908257484436, 0.48160892724990845, 0.19343344867229462]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.004962975159287453, -0.02855275757610798, -0.03922358527779579, -0.07386279851198196, -0.009809817187488079]\n",
      "Last 5 elements: [0.8790923953056335, 0.07330221682786942, -0.6286289691925049, -0.35722050070762634, 0.2422216683626175]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.18968437612056732, -0.00924837589263916, -0.22794750332832336, -1.361747145652771, 0.21876734495162964]\n",
      "Last 5 elements: [1.1051301956176758, -0.9103802442550659, -1.398908257484436, 0.48160892724990845, 0.19343344867229462]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1639, -0.9432, -1.2957,  ..., -0.7044, -2.4152, -1.2040],\n",
      "         [-1.1951,  1.8717,  0.5606,  ..., -0.6701, -0.2044, -0.5342],\n",
      "         [ 1.7968, -0.9259, -1.0124,  ...,  0.1542,  0.2523,  0.2800],\n",
      "         [ 1.1811, -0.4847, -0.3871,  ..., -0.4680,  0.1899, -0.1551],\n",
      "         [ 0.5285, -0.0448,  1.0669,  ..., -0.2059, -1.0045,  0.3133],\n",
      "         [ 1.3418,  0.6265,  0.4761,  ..., -0.8172, -0.4644,  0.3149]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2050556242465973, -0.9230080246925354, -1.3063898086547852, -2.425213098526001, -0.24522559344768524]\n",
      "Last 5 elements: [1.1292729377746582, 0.12375134229660034, -0.7896558046340942, -0.47064557671546936, 0.29736441373825073]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.13021451234817505, -0.9448187947273254, -1.3361897468566895, -2.6820058822631836, -0.2851477861404419]\n",
      "Last 5 elements: [1.3392354249954224, -0.06657930463552475, -1.06588876247406, -0.37872523069381714, 0.34925946593284607]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.13021451234817505, -0.9448187947273254, -1.3361897468566895, -2.6820058822631836, -0.2851477861404419]\n",
      "Last 5 elements: [1.3392354249954224, -0.06657930463552475, -1.06588876247406, -0.37872523069381714, 0.34925946593284607]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.003943547606468201, -0.028613844886422157, -0.040466517210006714, -0.08122456818819046, -0.008635703474283218]\n",
      "Last 5 elements: [0.956669807434082, -0.047560278326272964, -0.7614072561264038, -0.27053868770599365, 0.24949009716510773]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.003943547606468201, -0.028613844886422157, -0.040466517210006714, -0.08122456818819046, -0.008635703474283218]\n",
      "Last 5 elements: [0.956669807434082, -0.047560278326272964, -0.7614072561264038, -0.27053868770599365, 0.24949009716510773]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.08716681599617004, -0.8757323026657104, -0.7934292554855347, 0.8247106671333313, 1.0269625186920166]\n",
      "Last 5 elements: [0.14439384639263153, 0.2544856071472168, -0.7576413154602051, -0.17188489437103271, 0.03896743059158325]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.08716681599617004, -0.8757323026657104, -0.7934292554855347, 0.8247106671333313, 1.0269625186920166]\n",
      "Last 5 elements: [0.14439384639263153, 0.2544856071472168, -0.7576413154602051, -0.17188489437103271, 0.03896743059158325]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.062083300203084946, -0.6237276196479797, -0.5651084780693054, 0.5873882174491882, 0.7314391732215881]\n",
      "Last 5 elements: [0.13005220890045166, 0.2292093187570572, -0.6823900938034058, -0.1548127681016922, 0.035097066313028336]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.062083300203084946, -0.6237276196479797, -0.5651084780693054, 0.5873882174491882, 0.7314391732215881]\n",
      "Last 5 elements: [0.13005220890045166, 0.2292093187570572, -0.6823900938034058, -0.1548127681016922, 0.035097066313028336]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.08490291237831116, -0.9559479355812073, 0.4750555157661438, 0.6197658777236938, 0.11663311719894409]\n",
      "Last 5 elements: [0.05028426647186279, 0.27102649211883545, 2.154702663421631, 2.142212152481079, -2.200432300567627]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.003943547606468201, -0.028613844886422157, -0.040466517210006714, -0.08122456818819046, -0.008635703474283218]\n",
      "Last 5 elements: [0.956669807434082, -0.047560278326272964, -0.7614072561264038, -0.27053868770599365, 0.24949009716510773]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.13847412168979645, 0.08345024287700653, -0.08281517773866653, -0.04366251826286316, -0.057388462126255035]\n",
      "Last 5 elements: [0.7157037258148193, 2.9791512489318848, -9.805023193359375, 4.753047943115234, 1.433638334274292]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.13847412168979645, 0.08345024287700653, -0.08281517773866653, -0.04366251826286316, -0.057388462126255035]\n",
      "Last 5 elements: [0.9328831434249878, -1.8672633171081543, -0.06617707014083862, 0.6679649949073792, 2.204681873321533]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.01877863146364689, 0.011316781863570213, -0.011230659671127796, -0.0059211235493421555, -0.0077825142070651054]\n",
      "Last 5 elements: [0.7815905213356018, -1.564435362815857, -0.05544464290142059, 0.559636116027832, 1.8471322059631348]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.01877863146364689, 0.011316781863570213, -0.011230659671127796, -0.0059211235493421555, -0.0077825142070651054]\n",
      "Last 5 elements: [0.7815905213356018, -1.564435362815857, -0.05544464290142059, 0.559636116027832, 1.8471322059631348]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.03536112979054451, -0.2942265570163727, -0.13291209936141968, 0.010332999750971794, 0.020576922222971916]\n",
      "Last 5 elements: [-0.4766504466533661, -1.4666483402252197, -2.1861767768859863, 1.019545555114746, -0.9100304841995239]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.03188659995794296, -0.07694617658853531, -0.054026100784540176, 0.0011640177108347416, 0.05324957147240639]\n",
      "Last 5 elements: [-0.4766504466533661, -1.4666483402252197, -2.1861767768859863, 1.019545555114746, -0.9100304841995239]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.03188659995794296, -0.07694617658853531, -0.054026100784540176, 0.0011640177108347416, 0.05324957147240639]\n",
      "Last 5 elements: [0.11226862668991089, 0.0372626893222332, 0.0009751361212693155, 0.15073642134666443, -0.0005386124248616397]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.24463406205177307, 0.35105985403060913, -0.04484019801020622, -0.4431550204753876, -0.2121705561876297]\n",
      "Last 5 elements: [0.26260775327682495, 0.3275253176689148, -0.17261099815368652, -0.4376794397830963, -0.011221498250961304]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.17371049523353577, -0.8824002742767334, -1.3441623449325562, -2.760798931121826, -0.32287174463272095]\n",
      "Last 5 elements: [1.3859270811080933, -0.008345246315002441, -1.0965790748596191, -0.4565446972846985, 0.34726428985595703]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.005260725971311331, -0.026723001152276993, -0.04070720821619034, -0.08360926061868668, -0.009777991101145744]\n",
      "Last 5 elements: [0.9916975498199463, -0.005971425678580999, -0.7846551537513733, -0.32667970657348633, 0.24848432838916779]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005260725971311331, -0.026723001152276993, -0.04070720821619034, -0.08360926061868668, -0.009777991101145744]\n",
      "Last 5 elements: [0.9916975498199463, -0.005971425678580999, -0.7846551537513733, -0.32667970657348633, 0.24848432838916779]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.1768696308135986, -2.3116981983184814, -0.5508043766021729, -0.2709733247756958, -1.8218690156936646]\n",
      "Last 5 elements: [-1.5045228004455566, -1.951570987701416, -0.2140800952911377, -1.616572380065918, -0.9080026149749756]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.1768696308135986, -2.3116981983184814, -0.5508043766021729, -0.2709733247756958, -1.8218690156936646]\n",
      "Last 5 elements: [-1.5045228004455566, -1.951570987701416, -0.2140800952911377, -1.616572380065918, -0.9080026149749756]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.22170747816562653, -0.2084198147058487, -0.20141693949699402, -0.1172415241599083, -0.2536219358444214]\n",
      "Last 5 elements: [-0.27344992756843567, -0.24274063110351562, -0.09562603384256363, -0.26783066987991333, -0.260967880487442]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005260725971311331, -0.026723001152276993, -0.04070720821619034, -0.08360926061868668, -0.009777991101145744]\n",
      "Last 5 elements: [0.9916975498199463, -0.005971425678580999, -0.7846551537513733, -0.32667970657348633, 0.24848432838916779]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.5431294441223145, -0.5385066270828247, 0.29324668645858765, -0.16251513361930847, -0.32028985023498535]\n",
      "Last 5 elements: [-1.5204830169677734, -0.614250123500824, -0.642597496509552, 1.3367589712142944, -0.7400953769683838]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.3421233296394348, 0.11223544925451279, -0.059064850211143494, 0.019053522497415543, 0.08123253285884857]\n",
      "Last 5 elements: [0.41577598452568054, 0.14910346269607544, 0.06144905090332031, -0.35802504420280457, 0.1931411176919937]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.687551736831665, 0.7001318335533142, -0.12645401060581207, 0.39375025033950806, 0.3669132590293884]\n",
      "Last 5 elements: [-0.8128710985183716, -0.9271659255027771, -2.314978837966919, -0.27565211057662964, -0.5026983618736267]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005260725971311331, -0.026723001152276993, -0.04070720821619034, -0.08360926061868668, -0.009777991101145744]\n",
      "Last 5 elements: [0.9916975498199463, -0.005971425678580999, -0.7846551537513733, -0.32667970657348633, 0.24848432838916779]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.687551736831665, 0.7001318335533142, -0.12645401060581207, 0.39375025033950806, 0.3669132590293884]\n",
      "Last 5 elements: [-0.8128710985183716, -0.9271659255027771, -2.314978837966919, -0.27565211057662964, -0.5026983618736267]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1737, -0.8824, -1.3442,  ..., -0.7987, -2.4656, -1.3472],\n",
      "         [-1.3995,  1.1223,  0.7505,  ..., -0.3782, -0.4975, -0.7764],\n",
      "         [ 1.3697, -0.9842, -0.7480,  ...,  0.1819,  0.4019,  0.6767],\n",
      "         [ 0.9983, -0.4235, -0.6470,  ..., -0.7026,  0.1740, -0.0585],\n",
      "         [ 0.6000,  0.0546,  1.2059,  ..., -0.3249, -1.1216,  0.1434],\n",
      "         [ 1.0821,  0.8493,  0.8738,  ..., -1.0966, -0.4565,  0.3473]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.13021451234817505, -0.9448187947273254, -1.3361897468566895, -2.6820058822631836, -0.2851477861404419]\n",
      "Last 5 elements: [1.3392354249954224, -0.06657930463552475, -1.06588876247406, -0.37872523069381714, 0.34925946593284607]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.051463671028614044, -0.7579166889190674, -1.3666459321975708, -2.6907901763916016, -0.2576344907283783]\n",
      "Last 5 elements: [1.2413984537124634, -0.1731955111026764, -1.5081827640533447, -0.5055556893348694, 0.2578844428062439]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.051463671028614044, -0.7579166889190674, -1.3666459321975708, -2.6907901763916016, -0.2576344907283783]\n",
      "Last 5 elements: [1.2413984537124634, -0.1731955111026764, -1.5081827640533447, -0.5055556893348694, 0.2578844428062439]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0015594960423186421, -0.022967036813497543, -0.04141326993703842, -0.0815386176109314, -0.007807060144841671]\n",
      "Last 5 elements: [0.844664990901947, -0.11784466356039047, -1.0261887311935425, -0.34398719668388367, 0.17546820640563965]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0015594960423186421, -0.022967036813497543, -0.04141326993703842, -0.0815386176109314, -0.007807060144841671]\n",
      "Last 5 elements: [0.844664990901947, -0.11784466356039047, -1.0261887311935425, -0.34398719668388367, 0.17546820640563965]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.5160627365112305, 1.4908345937728882, -0.5702787637710571, -1.8169277906417847, 0.8964041471481323]\n",
      "Last 5 elements: [0.21312135457992554, 0.3958277106285095, 0.8653804063796997, 0.5760723352432251, -2.6069552898406982]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.5160627365112305, 1.4908345937728882, -0.5702787637710571, -1.8169277906417847, 0.8964041471481323]\n",
      "Last 5 elements: [0.21312135457992554, 0.3958277106285095, 0.8653804063796997, 0.5760723352432251, -2.6069552898406982]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.6506421566009521, 0.9780496954917908, -0.374126672744751, -1.1919804811477661, 0.5880785584449768]\n",
      "Last 5 elements: [0.21443401277065277, 0.39826568961143494, 0.8707104325294495, 0.5796204805374146, -2.623012065887451]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.6506421566009521, 0.9780496954917908, -0.374126672744751, -1.1919804811477661, 0.5880785584449768]\n",
      "Last 5 elements: [0.21443401277065277, 0.39826568961143494, 0.8707104325294495, 0.5796204805374146, -2.623012065887451]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.7792452573776245, -0.20743539929389954, -0.19805088639259338, 0.8398041725158691, -0.4532487690448761]\n",
      "Last 5 elements: [0.261544406414032, 1.2593040466308594, -1.284539818763733, 1.4630303382873535, -0.8489516973495483]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0015594960423186421, -0.022967036813497543, -0.04141326993703842, -0.0815386176109314, -0.007807060144841671]\n",
      "Last 5 elements: [0.844664990901947, -0.11784466356039047, -1.0261887311935425, -0.34398719668388367, 0.17546820640563965]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.10057850182056427, -0.5300852656364441, -0.35285890102386475, 0.18414872884750366, -0.6884594559669495]\n",
      "Last 5 elements: [-0.8544169664382935, 2.356257915496826, 10.63542366027832, 4.17066764831543, 0.44185879826545715]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.10057850182056427, -0.5300852656364441, -0.35285890102386475, 0.18414872884750366, -0.6884594559669495]\n",
      "Last 5 elements: [1.2671865224838257, 0.5803077220916748, -1.3789594173431396, -0.5050575137138367, -1.643858790397644]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.016611391678452492, -0.08754806965589523, -0.05827763304114342, 0.03041372075676918, -0.11370490491390228]\n",
      "Last 5 elements: [1.3341974020004272, 0.6109952926635742, -1.4518810510635376, -0.5317657589912415, -1.7307887077331543]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.016611391678452492, -0.08754806965589523, -0.05827763304114342, 0.03041372075676918, -0.11370490491390228]\n",
      "Last 5 elements: [1.3341974020004272, 0.6109952926635742, -1.4518810510635376, -0.5317657589912415, -1.7307887077331543]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.07105690985918045, 0.0242653526365757, 0.4080406725406647, -0.09550441801548004, -0.04041322320699692]\n",
      "Last 5 elements: [-0.20116674900054932, -0.5328099727630615, 0.4508764147758484, 1.4336309432983398, -0.6978627443313599]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.024626929312944412, -0.014634900726377964, -0.039916619658470154, -0.022778134793043137, 0.010482333600521088]\n",
      "Last 5 elements: [-0.20116674900054932, -0.5328099727630615, 0.4508764147758484, 1.4336309432983398, -0.6978627443313599]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024626929312944412, -0.014634900726377964, -0.039916619658470154, -0.022778134793043137, 0.010482333600521088]\n",
      "Last 5 elements: [0.15983061492443085, 0.09408484399318695, 0.015405859798192978, 0.0399477444589138, -0.08776058256626129]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.32103070616722107, 0.32374709844589233, 0.098518505692482, 0.04644814133644104, -0.17280760407447815]\n",
      "Last 5 elements: [0.2553272843360901, 0.6996227502822876, 0.33909139037132263, 0.34603554010391235, 0.0038820691406726837]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.10854298621416092, -0.7003543972969055, -1.349129319190979, -2.6825315952301025, -0.28835970163345337]\n",
      "Last 5 elements: [1.286795735359192, -0.0488024577498436, -1.4478923082351685, -0.4440305233001709, 0.2585746645927429]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.003288508392870426, -0.021218517795205116, -0.04087434336543083, -0.08127220720052719, -0.0087363850325346]\n",
      "Last 5 elements: [0.8890868425369263, -0.03371912240982056, -1.0003935098648071, -0.3067943751811981, 0.17865720391273499]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.003288508392870426, -0.021218517795205116, -0.04087434336543083, -0.08127220720052719, -0.0087363850325346]\n",
      "Last 5 elements: [0.8890868425369263, -0.03371912240982056, -1.0003935098648071, -0.3067943751811981, 0.17865720391273499]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.3043169379234314, -2.2919821739196777, -1.702704668045044, -1.038050889968872, -1.1038705110549927]\n",
      "Last 5 elements: [-0.2436443567276001, -0.3391471207141876, -0.14165157079696655, -1.0703399181365967, 0.2154873013496399]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.3043169379234314, -2.2919821739196777, -1.702704668045044, -1.038050889968872, -1.1038705110549927]\n",
      "Last 5 elements: [-0.2436443567276001, -0.3391471207141876, -0.14165157079696655, -1.0703399181365967, 0.2154873013496399]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.1751336306333542, -0.21037913858890533, -0.2624078392982483, -0.2714775502681732, -0.2748807370662689]\n",
      "Last 5 elements: [-0.10705452412366867, -0.14109085500240326, -0.06581786274909973, -0.2732989192008972, 0.11930762976408005]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.003288508392870426, -0.021218517795205116, -0.04087434336543083, -0.08127220720052719, -0.0087363850325346]\n",
      "Last 5 elements: [0.8890868425369263, -0.03371912240982056, -1.0003935098648071, -0.3067943751811981, 0.17865720391273499]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.14736276865005493, 2.0152249336242676, 0.01653607189655304, -0.8498438596725464, -1.0384771823883057]\n",
      "Last 5 elements: [-1.1832976341247559, -0.25754648447036743, -0.01981338858604431, 1.1236523389816284, -0.9089576005935669]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.025808176025748253, -0.4239612817764282, -0.004339194856584072, 0.23071353137493134, 0.2854573726654053]\n",
      "Last 5 elements: [0.12667736411094666, 0.03633745387196541, 0.001304074889048934, -0.30709296464920044, -0.10844557732343674]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.20015744864940643, 0.7513332962989807, -0.28760138154029846, -0.22366440296173096, 0.035910964012145996]\n",
      "Last 5 elements: [1.764190912246704, 2.209484338760376, 0.3533482551574707, -1.5929234027862549, 0.2665446996688843]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.003288508392870426, -0.021218517795205116, -0.04087434336543083, -0.08127220720052719, -0.0087363850325346]\n",
      "Last 5 elements: [0.8890868425369263, -0.03371912240982056, -1.0003935098648071, -0.3067943751811981, 0.17865720391273499]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.20015744864940643, 0.7513332962989807, -0.28760138154029846, -0.22366440296173096, 0.035910964012145996]\n",
      "Last 5 elements: [1.764190912246704, 2.209484338760376, 0.3533482551574707, -1.5929234027862549, 0.2665446996688843]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1085, -0.7004, -1.3491,  ..., -0.6138, -2.6945, -1.4417],\n",
      "         [-1.8298,  1.1637,  1.2219,  ..., -0.5030, -0.6175, -0.9745],\n",
      "         [ 1.5939, -1.2326, -0.3790,  ...,  0.1967,  0.1280,  0.8231],\n",
      "         [ 1.1571, -0.6381, -0.4475,  ..., -0.2043,  0.2149,  0.0199],\n",
      "         [ 1.0349, -0.2877,  1.5233,  ..., -0.4632, -1.0127,  0.4637],\n",
      "         [ 1.3957,  0.5223,  0.8362,  ..., -1.4479, -0.4440,  0.2586]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.051463671028614044, -0.7579166889190674, -1.3666459321975708, -2.6907901763916016, -0.2576344907283783]\n",
      "Last 5 elements: [1.2413984537124634, -0.1731955111026764, -1.5081827640533447, -0.5055556893348694, 0.2578844428062439]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.14413101971149445, -0.5667672157287598, -1.400264859199524, -2.722299098968506, -0.281974732875824]\n",
      "Last 5 elements: [1.6004692316055298, 0.3440442383289337, -1.3850669860839844, -0.7272526025772095, 0.3059663474559784]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.14413101971149445, -0.5667672157287598, -1.400264859199524, -2.722299098968506, -0.281974732875824]\n",
      "Last 5 elements: [1.6004692316055298, 0.3440442383289337, -1.3850669860839844, -0.7272526025772095, 0.3059663474559784]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.004370114766061306, -0.017184626311063766, -0.04245663434267044, -0.08254128694534302, -0.008549596183001995]\n",
      "Last 5 elements: [1.043886423110962, 0.2243986278772354, -0.9033929109573364, -0.47434157133102417, 0.19956278800964355]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.004370114766061306, -0.017184626311063766, -0.04245663434267044, -0.08254128694534302, -0.008549596183001995]\n",
      "Last 5 elements: [1.043886423110962, 0.2243986278772354, -0.9033929109573364, -0.47434157133102417, 0.19956278800964355]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.9788445234298706, -1.9414976835250854, -0.3464556634426117, -0.180419459939003, -1.2702792882919312]\n",
      "Last 5 elements: [-1.0540590286254883, -0.9008188247680664, 0.2810094952583313, 0.3063141703605652, -0.2564922273159027]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.9788445234298706, -1.9414976835250854, -0.3464556634426117, -0.180419459939003, -1.2702792882919312]\n",
      "Last 5 elements: [-1.0540590286254883, -0.9008188247680664, 0.2810094952583313, 0.3063141703605652, -0.2564922273159027]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.3229382038116455, -1.2979704141616821, -0.231619730591774, -0.12061776220798492, -0.8492335081100464]\n",
      "Last 5 elements: [-1.0657280683517456, -0.9107914566993713, 0.28412044048309326, 0.3097052574157715, -0.25933176279067993]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.3229382038116455, -1.2979704141616821, -0.231619730591774, -0.12061776220798492, -0.8492335081100464]\n",
      "Last 5 elements: [-1.0657280683517456, -0.9107914566993713, 0.28412044048309326, 0.3097052574157715, -0.25933176279067993]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [2.2161879539489746, 0.9400973320007324, 0.5111291408538818, -1.114174485206604, -1.4691855907440186]\n",
      "Last 5 elements: [0.8502262830734253, -1.858627438545227, -0.8164641857147217, 0.09126490354537964, 1.0892277956008911]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.004370114766061306, -0.017184626311063766, -0.04245663434267044, -0.08254128694534302, -0.008549596183001995]\n",
      "Last 5 elements: [1.043886423110962, 0.2243986278772354, -0.9033929109573364, -0.47434157133102417, 0.19956278800964355]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.04658113420009613, -0.03006824664771557, -0.11800949275493622, -0.003031272441148758, 0.3928687274456024]\n",
      "Last 5 elements: [-1.3441746234893799, -5.455925941467285, 0.9426994323730469, 3.8686578273773193, 1.7402160167694092]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.04658113420009613, -0.03006824664771557, -0.11800949275493622, -0.003031272441148758, 0.3928687274456024]\n",
      "Last 5 elements: [0.04089711606502533, -0.1299464851617813, -0.16298682987689972, 1.0595262050628662, -0.5370873212814331]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.006205074489116669, -0.0040053920820355415, -0.015720048919320107, -0.00040379591519013047, 0.05233405530452728]\n",
      "Last 5 elements: [0.04058697447180748, -0.12896104156970978, -0.16175082325935364, 1.0514912605285645, -0.5330142974853516]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.006205074489116669, -0.0040053920820355415, -0.015720048919320107, -0.00040379591519013047, 0.05233405530452728]\n",
      "Last 5 elements: [0.04058697447180748, -0.12896104156970978, -0.16175082325935364, 1.0514912605285645, -0.5330142974853516]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.15539774298667908, -0.010473981499671936, -0.03012486733496189, -0.18446703255176544, 0.6507730484008789]\n",
      "Last 5 elements: [-0.6898725032806396, 1.4707013368606567, 1.2743672132492065, 0.006945878267288208, 0.24770723283290863]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.028532564640045166, 0.022835956886410713, 0.023003555834293365, -0.058478109538555145, 0.03288143500685692]\n",
      "Last 5 elements: [-0.6898725032806396, 1.4707013368606567, 1.2743672132492065, 0.006945878267288208, 0.24770723283290863]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.028532564640045166, 0.022835956886410713, 0.023003555834293365, -0.058478109538555145, 0.03288143500685692]\n",
      "Last 5 elements: [-0.01054721511900425, 0.052494391798973083, -0.0347401387989521, -0.038722261786460876, 0.020699355751276016]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.1271052360534668, 0.024662895128130913, -0.03232141211628914, -0.07025827467441559, 0.037044450640678406]\n",
      "Last 5 elements: [-0.06407248228788376, 0.029893293976783752, -0.16217048466205597, 0.12257980555295944, -0.1249045804142952]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.1667303591966629, -0.562382161617279, -1.4060115814208984, -2.7347910404205322, -0.2753882110118866]\n",
      "Last 5 elements: [1.589077115058899, 0.34935927391052246, -1.4139009714126587, -0.705457866191864, 0.283758282661438]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.005054925102740526, -0.017050283029675484, -0.04262740910053253, -0.08291329443454742, -0.008349210023880005]\n",
      "Last 5 elements: [1.0432751178741455, 0.22936448454856873, -0.9282669425010681, -0.46315351128578186, 0.1862955242395401]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005054925102740526, -0.017050283029675484, -0.04262740910053253, -0.08291329443454742, -0.008349210023880005]\n",
      "Last 5 elements: [1.0432751178741455, 0.22936448454856873, -0.9282669425010681, -0.46315351128578186, 0.1862955242395401]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.8383328914642334, -3.0181093215942383, -3.0465571880340576, -0.12905186414718628, -1.3233684301376343]\n",
      "Last 5 elements: [0.48146548867225647, -1.7943010330200195, -0.03331068158149719, -0.7149640321731567, -2.3926913738250732]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.8383328914642334, -3.0181093215942383, -3.0465571880340576, -0.12905186414718628, -1.3233684301376343]\n",
      "Last 5 elements: [0.48146548867225647, -1.7943010330200195, -0.03331068158149719, -0.7149640321731567, -2.3926913738250732]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.25308096408843994, -0.14068743586540222, -0.13821114599704742, -0.06036810204386711, -0.2782493531703949]\n",
      "Last 5 elements: [0.29759085178375244, -0.25577080249786377, -0.016377966850996017, -0.23486775159835815, -0.20034416019916534]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005054925102740526, -0.017050283029675484, -0.04262740910053253, -0.08291329443454742, -0.008349210023880005]\n",
      "Last 5 elements: [1.0432751178741455, 0.22936448454856873, -0.9282669425010681, -0.46315351128578186, 0.1862955242395401]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.8547016382217407, -1.4926934242248535, -0.8899407386779785, 0.5922413468360901, -1.007822871208191]\n",
      "Last 5 elements: [0.24605149030685425, -0.36842837929725647, -0.7242880463600159, -1.4098241329193115, -0.2939611077308655]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.21630871295928955, 0.21000321209430695, 0.12299972772598267, -0.03575248643755913, 0.2804260551929474]\n",
      "Last 5 elements: [0.07322267442941666, 0.09423322230577469, 0.011862365528941154, 0.3311222195625305, 0.058893389999866486]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.007803589105606079, 0.014096975326538086, -1.1989595890045166, -0.8463226556777954, -0.2836622893810272]\n",
      "Last 5 elements: [0.25193852186203003, 0.1358899474143982, -1.7770843505859375, -1.1434192657470703, -0.11063849925994873]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005054925102740526, -0.017050283029675484, -0.04262740910053253, -0.08291329443454742, -0.008349210023880005]\n",
      "Last 5 elements: [1.0432751178741455, 0.22936448454856873, -0.9282669425010681, -0.46315351128578186, 0.1862955242395401]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.007803589105606079, 0.014096975326538086, -1.1989595890045166, -0.8463226556777954, -0.2836622893810272]\n",
      "Last 5 elements: [0.25193852186203003, 0.1358899474143982, -1.7770843505859375, -1.1434192657470703, -0.11063849925994873]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1667, -0.5624, -1.4060,  ..., -0.5253, -2.7137, -1.3922],\n",
      "         [-1.9798,  1.1947,  1.2681,  ..., -0.3003, -0.3532, -1.2081],\n",
      "         [ 1.3826, -0.9893, -0.3107,  ...,  0.6714, -0.1589,  1.2273],\n",
      "         [ 1.1827, -0.8771, -0.4270,  ..., -0.2003,  0.0135, -0.0590],\n",
      "         [ 0.5872, -0.0747,  1.6355,  ..., -0.2286, -1.4017,  0.8816],\n",
      "         [ 1.2986,  0.4851,  0.6599,  ..., -1.4139, -0.7055,  0.2838]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.14413101971149445, -0.5667672157287598, -1.400264859199524, -2.722299098968506, -0.281974732875824]\n",
      "Last 5 elements: [1.6004692316055298, 0.3440442383289337, -1.3850669860839844, -0.7272526025772095, 0.3059663474559784]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.16811783611774445, -0.5598757266998291, -1.6191867589950562, -2.8852672576904297, -0.32582342624664307]\n",
      "Last 5 elements: [1.6338717937469482, 0.37352052330970764, -1.729866862297058, -0.9087580442428589, 0.2640867233276367]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.16811783611774445, -0.5598757266998291, -1.6191867589950562, -2.8852672576904297, -0.32582342624664307]\n",
      "Last 5 elements: [1.6338717937469482, 0.37352052330970764, -1.729866862297058, -0.9087580442428589, 0.2640867233276367]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.0051004099659621716, -0.016985680907964706, -0.049123380333185196, -0.0875341147184372, -0.009884930215775967]\n",
      "Last 5 elements: [0.9983176589012146, 0.22822606563568115, -1.0569719076156616, -0.5552634000778198, 0.16136054694652557]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0051004099659621716, -0.016985680907964706, -0.049123380333185196, -0.0875341147184372, -0.009884930215775967]\n",
      "Last 5 elements: [0.9983176589012146, 0.22822606563568115, -1.0569719076156616, -0.5552634000778198, 0.16136054694652557]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.0320308208465576, 0.8734411001205444, -0.271180123090744, -1.309625267982483, 0.19040420651435852]\n",
      "Last 5 elements: [0.017420418560504913, 0.36414557695388794, 0.9184346795082092, -0.4085365831851959, 2.0288543701171875]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.0320308208465576, 0.8734411001205444, -0.271180123090744, -1.309625267982483, 0.19040420651435852]\n",
      "Last 5 elements: [0.017420418560504913, 0.36414557695388794, 0.9184346795082092, -0.4085365831851959, 2.0288543701171875]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.385454535484314, 0.595518946647644, -0.18489272892475128, -0.892912745475769, 0.1298190802335739]\n",
      "Last 5 elements: [0.017758948728442192, 0.37122198939323425, 0.9362825155258179, -0.4164756238460541, 2.0682809352874756]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.385454535484314, 0.595518946647644, -0.18489272892475128, -0.892912745475769, 0.1298190802335739]\n",
      "Last 5 elements: [0.017758948728442192, 0.37122198939323425, 0.9362825155258179, -0.4164756238460541, 2.0682809352874756]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.5401846766471863, 0.9286022782325745, -0.32444247603416443, 0.12566617131233215, 0.15084907412528992]\n",
      "Last 5 elements: [0.5684503316879272, 0.26306426525115967, -0.9986559152603149, 2.2750422954559326, -1.3955758810043335]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.0051004099659621716, -0.016985680907964706, -0.049123380333185196, -0.0875341147184372, -0.009884930215775967]\n",
      "Last 5 elements: [0.9983176589012146, 0.22822606563568115, -1.0569719076156616, -0.5552634000778198, 0.16136054694652557]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.009247317910194397, -0.06266237795352936, 0.12895026803016663, -0.01164756715297699, 0.05147125571966171]\n",
      "Last 5 elements: [-3.75630521774292, -0.6513410210609436, -1.9298816919326782, -10.673378944396973, -4.790755271911621]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.009247317910194397, -0.06266237795352936, 0.12895026803016663, -0.01164756715297699, 0.05147125571966171]\n",
      "Last 5 elements: [-0.1655513346195221, -0.3896898031234741, 0.0673610270023346, 0.5216937065124512, -0.08249762654304504]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.0010187290608882904, -0.006903189234435558, 0.014205782674252987, -0.0012831520289182663, 0.005670321173965931]\n",
      "Last 5 elements: [-0.16199494898319244, -0.38131844997406006, 0.06591396778821945, 0.5104866027832031, -0.08072540163993835]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.0010187290608882904, -0.006903189234435558, 0.014205782674252987, -0.0012831520289182663, 0.005670321173965931]\n",
      "Last 5 elements: [-0.16199494898319244, -0.38131844997406006, 0.06591396778821945, 0.5104866027832031, -0.08072540163993835]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.19830463826656342, -0.057300616055727005, -0.030383531004190445, -0.11509226262569427, -0.03033187799155712]\n",
      "Last 5 elements: [-0.508385419845581, -0.7928222417831421, -1.1527290344238281, -0.9110039472579956, 1.1490675210952759]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.03755727410316467, 0.009072124026715755, 0.019132470712065697, -0.06651603430509567, 0.016721423715353012]\n",
      "Last 5 elements: [-0.508385419845581, -0.7928222417831421, -1.1527290344238281, -0.9110039472579956, 1.1490675210952759]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.03755727410316467, 0.009072124026715755, 0.019132470712065697, -0.06651603430509567, 0.016721423715353012]\n",
      "Last 5 elements: [0.0023552204947918653, 0.0076003726571798325, -0.0010522365337237716, 0.016782814636826515, 0.00018787737644743174]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.05290822312235832, 0.05499853938817978, 0.05137921869754791, -0.1302553117275238, -0.027745384722948074]\n",
      "Last 5 elements: [-0.021827764809131622, -0.07647249102592468, 0.0402970090508461, -0.031440310180187225, -0.030860308557748795]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.17752492427825928, -0.5500969886779785, -1.6100515127182007, -2.9084267616271973, -0.3307565748691559]\n",
      "Last 5 elements: [1.629990816116333, 0.35992369055747986, -1.7227020263671875, -0.9143481254577637, 0.25859975814819336]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.005385476630181074, -0.016687992960214615, -0.048843253403902054, -0.08823135495185852, -0.010033981874585152]\n",
      "Last 5 elements: [1.0066641569137573, 0.22228486835956573, -1.063921570777893, -0.5646912455558777, 0.15970833599567413]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005385476630181074, -0.016687992960214615, -0.048843253403902054, -0.08823135495185852, -0.010033981874585152]\n",
      "Last 5 elements: [1.0066641569137573, 0.22228486835956573, -1.063921570777893, -0.5646912455558777, 0.15970833599567413]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.9479002952575684, 0.12958993017673492, -1.8182929754257202, -0.16450056433677673, -2.207003593444824]\n",
      "Last 5 elements: [-2.626988649368286, -2.754727363586426, -0.09110742807388306, -0.7570698261260986, -1.0607494115829468]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.9479002952575684, 0.12958993017673492, -1.8182929754257202, -0.16450056433677673, -2.207003593444824]\n",
      "Last 5 elements: [-2.626988649368286, -2.754727363586426, -0.09110742807388306, -0.7570698261260986, -1.0607494115829468]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.14691108465194702, 0.06898748129606247, -0.2539042830467224, -0.07550038397312164, -0.21876554191112518]\n",
      "Last 5 elements: [-0.17711563408374786, -0.1647884100675583, -0.04348001256585121, -0.24171936511993408, -0.272788941860199]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005385476630181074, -0.016687992960214615, -0.048843253403902054, -0.08823135495185852, -0.010033981874585152]\n",
      "Last 5 elements: [1.0066641569137573, 0.22228486835956573, -1.063921570777893, -0.5646912455558777, 0.15970833599567413]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.566760778427124, -0.08697423338890076, -0.42575448751449585, 1.4160362482070923, -0.7390013933181763]\n",
      "Last 5 elements: [0.9846190214157104, 1.434988021850586, 0.6740304827690125, 1.3186793327331543, -0.9738578796386719]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.08326344192028046, -0.006000133231282234, 0.10810089111328125, -0.10691127926111221, 0.16166804730892181]\n",
      "Last 5 elements: [-0.17439141869544983, -0.23646938800811768, -0.02930685319006443, -0.3187503218650818, 0.2656576633453369]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.5825357437133789, -0.5229496955871582, 0.1437108814716339, -0.6416916251182556, -0.990423858165741]\n",
      "Last 5 elements: [-1.8333009481430054, -0.11309915781021118, 0.4568932056427002, 0.8147108554840088, -1.0984187126159668]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.005385476630181074, -0.016687992960214615, -0.048843253403902054, -0.08823135495185852, -0.010033981874585152]\n",
      "Last 5 elements: [1.0066641569137573, 0.22228486835956573, -1.063921570777893, -0.5646912455558777, 0.15970833599567413]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.5825357437133789, -0.5229496955871582, 0.1437108814716339, -0.6416916251182556, -0.990423858165741]\n",
      "Last 5 elements: [-1.8333009481430054, -0.11309915781021118, 0.4568932056427002, 0.8147108554840088, -1.0984187126159668]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.1775, -0.5501, -1.6101,  ..., -0.6212, -2.6545, -1.5923],\n",
      "         [-2.4053,  1.3025,  1.6325,  ..., -0.4371, -0.7489, -1.9228],\n",
      "         [ 1.0558, -1.1860, -0.3378,  ...,  0.4639,  0.2322,  0.9540],\n",
      "         [ 1.4235, -0.4350, -0.7789,  ..., -0.5403,  0.1800, -0.0962],\n",
      "         [ 0.5825, -0.2064,  1.4579,  ..., -0.1947, -1.1861,  0.9501],\n",
      "         [ 1.3439,  0.4894,  0.7069,  ..., -1.7227, -0.9143,  0.2586]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.16811783611774445, -0.5598757266998291, -1.6191867589950562, -2.8852672576904297, -0.32582342624664307]\n",
      "Last 5 elements: [1.6338717937469482, 0.37352052330970764, -1.729866862297058, -0.9087580442428589, 0.2640867233276367]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2810998857021332, -0.643077552318573, -1.584499716758728, -3.022519588470459, -0.5068541169166565]\n",
      "Last 5 elements: [1.3040295839309692, 0.3398146331310272, -1.6414663791656494, -0.7694923877716064, 0.0633007138967514]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2810998857021332, -0.643077552318573, -1.584499716758728, -3.022519588470459, -0.5068541169166565]\n",
      "Last 5 elements: [1.3040295839309692, 0.3398146331310272, -1.6414663791656494, -0.7694923877716064, 0.0633007138967514]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.00853449385613203, -0.019524523988366127, -0.04810710996389389, -0.09176693856716156, -0.015388634987175465]\n",
      "Last 5 elements: [0.7792215943336487, 0.20305590331554413, -0.9808566570281982, -0.45980942249298096, 0.03782527893781662]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00853449385613203, -0.019524523988366127, -0.04810710996389389, -0.09176693856716156, -0.015388634987175465]\n",
      "Last 5 elements: [0.7792215943336487, 0.20305590331554413, -0.9808566570281982, -0.45980942249298096, 0.03782527893781662]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.0733387470245361, 0.9087350368499756, -0.34391939640045166, -0.23022937774658203, 0.1589128077030182]\n",
      "Last 5 elements: [0.7701175808906555, -4.175437927246094, -0.8275125026702881, -0.06817616522312164, 1.0576145648956299]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.0733387470245361, 0.9087350368499756, -0.34391939640045166, -0.23022937774658203, 0.1589128077030182]\n",
      "Last 5 elements: [0.7701175808906555, -4.175437927246094, -0.8275125026702881, -0.06817616522312164, 1.0576145648956299]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.7180966734886169, 0.607971727848053, -0.23009265959262848, -0.15403054654598236, 0.10631755739450455]\n",
      "Last 5 elements: [0.6795013546943665, -3.684133291244507, -0.7301428914070129, -0.06015418842434883, 0.9331699013710022]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.7180966734886169, 0.607971727848053, -0.23009265959262848, -0.15403054654598236, 0.10631755739450455]\n",
      "Last 5 elements: [0.6795013546943665, -3.684133291244507, -0.7301428914070129, -0.06015418842434883, 0.9331699013710022]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.3076183795928955, -0.2386259138584137, 1.5284532308578491, 0.522430956363678, -0.17492049932479858]\n",
      "Last 5 elements: [1.1993308067321777, 0.8224393129348755, 9.314376831054688, -0.344146192073822, 1.58362877368927]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00853449385613203, -0.019524523988366127, -0.04810710996389389, -0.09176693856716156, -0.015388634987175465]\n",
      "Last 5 elements: [0.7792215943336487, 0.20305590331554413, -0.9808566570281982, -0.45980942249298096, 0.03782527893781662]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.04985721409320831, 0.07569581270217896, 0.08253207802772522, 0.038218799978494644, -0.042539697140455246]\n",
      "Last 5 elements: [0.07048898935317993, 0.7551912069320679, -2.11187744140625, -0.8375993967056274, 2.823416233062744]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.04985721409320831, 0.07569581270217896, 0.08253207802772522, 0.038218799978494644, -0.042539697140455246]\n",
      "Last 5 elements: [0.13005609810352325, -1.3981996774673462, 0.5822280645370483, 1.5914684534072876, 1.2099031209945679]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.007190099451690912, 0.010916383005678654, 0.01190226711332798, 0.005511679220944643, -0.006134812254458666]\n",
      "Last 5 elements: [0.10774999856948853, -1.1583925485610962, 0.4823693335056305, 1.3185135126113892, 1.00239098072052]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.007190099451690912, 0.010916383005678654, 0.01190226711332798, 0.005511679220944643, -0.006134812254458666]\n",
      "Last 5 elements: [0.10774999856948853, -1.1583925485610962, 0.4823693335056305, 1.3185135126113892, 1.00239098072052]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.016016876325011253, -0.10629727691411972, -0.014423930086195469, 0.11927176266908646, 0.003634020686149597]\n",
      "Last 5 elements: [0.15570637583732605, -0.35498642921447754, -1.0073457956314087, -0.16286447644233704, 0.8856140971183777]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.008381699211895466, 0.018772337585687637, 0.0028233546763658524, 0.03132299333810806, -0.017198482528328896]\n",
      "Last 5 elements: [0.15570637583732605, -0.35498642921447754, -1.0073457956314087, -0.16286447644233704, 0.8856140971183777]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.008381699211895466, 0.018772337585687637, 0.0028233546763658524, 0.03132299333810806, -0.017198482528328896]\n",
      "Last 5 elements: [0.060635972768068314, -0.13846652209758759, -0.7518398761749268, 0.08472834527492523, 0.6669734120368958]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.16505196690559387, -0.0631498396396637, 0.16796240210533142, 0.09159016609191895, 0.023919465020298958]\n",
      "Last 5 elements: [-0.3635373115539551, -0.6770009994506836, 0.8165813088417053, 0.5370598435401917, -0.483519971370697]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3104461431503296, -0.6543055772781372, -1.554636001586914, -3.006234884262085, -0.5026012063026428]\n",
      "Last 5 elements: [1.239392638206482, 0.21944373846054077, -1.4962780475616455, -0.6740030646324158, -0.022669225931167603]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009425128810107708, -0.019864683970808983, -0.047198668122291565, -0.09126913547515869, -0.01525894645601511]\n",
      "Last 5 elements: [0.7453780174255371, 0.13197475671768188, -0.8998703956604004, -0.40534940361976624, -0.013633404858410358]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009425128810107708, -0.019864683970808983, -0.047198668122291565, -0.09126913547515869, -0.01525894645601511]\n",
      "Last 5 elements: [0.7453780174255371, 0.13197475671768188, -0.8998703956604004, -0.40534940361976624, -0.013633404858410358]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.7778910398483276, -2.1032001972198486, -2.9797403812408447, -2.1484978199005127, -2.087383985519409]\n",
      "Last 5 elements: [-1.1441981792449951, 0.42197927832603455, -0.5392239093780518, -0.44750821590423584, 1.260294795036316]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.7778910398483276, -2.1032001972198486, -2.9797403812408447, -2.1484978199005127, -2.087383985519409]\n",
      "Last 5 elements: [-1.1441981792449951, 0.42197927832603455, -0.5392239093780518, -0.44750821590423584, 1.260294795036316]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2570185959339142, -0.22879910469055176, -0.14406916499137878, -0.22445717453956604, -0.2302991896867752]\n",
      "Last 5 elements: [-0.27638155221939087, 0.25485724210739136, -0.19863291084766388, -0.17450733482837677, 0.9818664789199829]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009425128810107708, -0.019864683970808983, -0.047198668122291565, -0.09126913547515869, -0.01525894645601511]\n",
      "Last 5 elements: [0.7453780174255371, 0.13197475671768188, -0.8998703956604004, -0.40534940361976624, -0.013633404858410358]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.3663254976272583, -0.3524181842803955, -0.13326947391033173, -0.9144487380981445, 0.7285263538360596]\n",
      "Last 5 elements: [-0.6204463243484497, 0.2410072684288025, -0.4204556941986084, 0.02841430902481079, 0.13695231080055237]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.09415246546268463, 0.08063296228647232, 0.019200021401047707, 0.20525458455085754, -0.16777902841567993]\n",
      "Last 5 elements: [0.17147992551326752, 0.061422448605298996, 0.08351633697748184, -0.004958505276590586, 0.13446888327598572]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.11030672490596771, 0.39539217948913574, 0.33085405826568604, -0.3482738137245178, -0.59248948097229]\n",
      "Last 5 elements: [1.3521208763122559, 0.052603721618652344, -1.4927458763122559, -1.0629863739013672, -0.5702747106552124]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009425128810107708, -0.019864683970808983, -0.047198668122291565, -0.09126913547515869, -0.01525894645601511]\n",
      "Last 5 elements: [0.7453780174255371, 0.13197475671768188, -0.8998703956604004, -0.40534940361976624, -0.013633404858410358]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.11030672490596771, 0.39539217948913574, 0.33085405826568604, -0.3482738137245178, -0.59248948097229]\n",
      "Last 5 elements: [1.3521208763122559, 0.052603721618652344, -1.4927458763122559, -1.0629863739013672, -0.5702747106552124]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3104, -0.6543, -1.5546,  ..., -0.4306, -2.8590, -1.7891],\n",
      "         [-2.2754,  1.1025,  1.8420,  ..., -0.2707, -0.6301, -1.9568],\n",
      "         [ 1.1160, -1.4971, -0.2037,  ...,  0.8319,  0.6078,  0.8615],\n",
      "         [ 1.6053, -0.8829, -0.9556,  ..., -0.6588,  0.6563,  0.0132],\n",
      "         [ 0.8292, -0.4736,  1.8385,  ..., -0.0837, -0.9828,  0.6986],\n",
      "         [ 1.6546,  0.3858,  0.6596,  ..., -1.4963, -0.6740, -0.0227]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2810998857021332, -0.643077552318573, -1.584499716758728, -3.022519588470459, -0.5068541169166565]\n",
      "Last 5 elements: [1.3040295839309692, 0.3398146331310272, -1.6414663791656494, -0.7694923877716064, 0.0633007138967514]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.29083359241485596, -0.5840047597885132, -1.4958100318908691, -3.0681581497192383, -0.6079459190368652]\n",
      "Last 5 elements: [1.4797999858856201, 0.22879669070243835, -1.761688470840454, -0.8630022406578064, -0.12406416982412338]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.29083359241485596, -0.5840047597885132, -1.4958100318908691, -3.0681581497192383, -0.6079459190368652]\n",
      "Last 5 elements: [1.4797999858856201, 0.22879669070243835, -1.761688470840454, -0.8630022406578064, -0.12406416982412338]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.008837093599140644, -0.017745215445756912, -0.04545077681541443, -0.09322719275951385, -0.01847267523407936]\n",
      "Last 5 elements: [0.877190887928009, 0.13562533259391785, -1.0442878007888794, -0.5115675926208496, -0.07354234158992767]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008837093599140644, -0.017745215445756912, -0.04545077681541443, -0.09322719275951385, -0.01847267523407936]\n",
      "Last 5 elements: [0.877190887928009, 0.13562533259391785, -1.0442878007888794, -0.5115675926208496, -0.07354234158992767]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.3623982071876526, 1.0810266733169556, 1.0695637464523315, 0.5316314697265625, 1.2453668117523193]\n",
      "Last 5 elements: [-0.6039506793022156, -0.06542268395423889, -0.6326080560684204, 0.6611875295639038, -2.9777092933654785]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.3623982071876526, 1.0810266733169556, 1.0695637464523315, 0.5316314697265625, 1.2453668117523193]\n",
      "Last 5 elements: [-0.6039506793022156, -0.06542268395423889, -0.6326080560684204, 0.6611875295639038, -2.9777092933654785]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.25102698802948, 0.7488085031509399, 0.740868330001831, 0.3682519495487213, 0.8626440763473511]\n",
      "Last 5 elements: [-0.5770543217658997, -0.06250914931297302, -0.6044354438781738, 0.6317421793937683, -2.845099925994873]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.25102698802948, 0.7488085031509399, 0.740868330001831, 0.3682519495487213, 0.8626440763473511]\n",
      "Last 5 elements: [-0.5770543217658997, -0.06250914931297302, -0.6044354438781738, 0.6317421793937683, -2.845099925994873]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.2798706293106079, 0.22722631692886353, -0.8148912191390991, 1.1308393478393555, 0.028294682502746582]\n",
      "Last 5 elements: [-1.3691370487213135, 0.12093174457550049, -6.4568986892700195, -1.448512077331543, -2.953296184539795]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.008837093599140644, -0.017745215445756912, -0.04545077681541443, -0.09322719275951385, -0.01847267523407936]\n",
      "Last 5 elements: [0.877190887928009, 0.13562533259391785, -1.0442878007888794, -0.5115675926208496, -0.07354234158992767]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.05333279073238373, 0.09594063460826874, -0.24708902835845947, -0.09953892230987549, -0.0685521811246872]\n",
      "Last 5 elements: [2.346113443374634, 1.2642784118652344, 0.5915371775627136, -1.65384840965271, 2.5702896118164062]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.05333279073238373, 0.09594063460826874, -0.24708902835845947, -0.09953892230987549, -0.0685521811246872]\n",
      "Last 5 elements: [-0.4942178726196289, -0.0676504373550415, 1.5324294567108154, -0.556317150592804, 0.5419596433639526]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.00928329024463892, 0.016699759289622307, -0.04300916939973831, -0.01732608862221241, -0.011932429857552052]\n",
      "Last 5 elements: [-0.2902336120605469, -0.03972829133272171, 0.8999321460723877, -0.32670193910598755, 0.31827038526535034]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.00928329024463892, 0.016699759289622307, -0.04300916939973831, -0.01732608862221241, -0.011932429857552052]\n",
      "Last 5 elements: [-0.2902336120605469, -0.03972829133272171, 0.8999321460723877, -0.32670193910598755, 0.31827038526535034]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.03241464123129845, 0.11019928008317947, -0.012035389430820942, -0.2914312183856964, 0.06509379297494888]\n",
      "Last 5 elements: [-0.16493424773216248, -0.11840511113405228, 0.053942691534757614, 1.064570426940918, 0.23463982343673706]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.014009001664817333, -0.16823002696037292, -0.09734849631786346, -0.03316483646631241, 0.10647448897361755]\n",
      "Last 5 elements: [-0.16493424773216248, -0.11840511113405228, 0.053942691534757614, 1.064570426940918, 0.23463982343673706]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.014009001664817333, -0.16823002696037292, -0.09734849631786346, -0.03316483646631241, 0.10647448897361755]\n",
      "Last 5 elements: [-0.005515499971807003, -0.06866662204265594, -0.011369808577001095, -0.03302963823080063, 0.0416322685778141]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.056304141879081726, 0.020906934514641762, 0.028042353689670563, -0.061583198606967926, -0.07855221629142761]\n",
      "Last 5 elements: [-0.2950234115123749, 0.2693004012107849, -0.021493859589099884, -0.010852761566638947, -0.24239695072174072]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3008444905281067, -0.580287516117096, -1.4908241033554077, -3.0791077613830566, -0.6219125390052795]\n",
      "Last 5 elements: [1.427344799041748, 0.2766783535480499, -1.765510082244873, -0.8649318814277649, -0.16716238856315613]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.00914022047072649, -0.01763022504746914, -0.04529403895139694, -0.09354908019304276, -0.018894871696829796]\n",
      "Last 5 elements: [0.8561202883720398, 0.1659514605998993, -1.0589516162872314, -0.5187854766845703, -0.10026387125253677]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00914022047072649, -0.01763022504746914, -0.04529403895139694, -0.09354908019304276, -0.018894871696829796]\n",
      "Last 5 elements: [0.8561202883720398, 0.1659514605998993, -1.0589516162872314, -0.5187854766845703, -0.10026387125253677]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.3374807834625244, -1.825348138809204, -3.0900821685791016, -1.5692516565322876, -2.2347967624664307]\n",
      "Last 5 elements: [-1.3121310472488403, -1.4356971979141235, -1.129923939704895, -2.632718086242676, 0.24272355437278748]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.3374807834625244, -1.825348138809204, -3.0900821685791016, -1.5692516565322876, -2.2347967624664307]\n",
      "Last 5 elements: [-1.3121310472488403, -1.4356971979141235, -1.129923939704895, -2.632718086242676, 0.24272355437278748]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.27809521555900574, -0.2533462345600128, -0.13447485864162445, -0.27041831612586975, -0.21603547036647797]\n",
      "Last 5 elements: [-0.27834299206733704, -0.2759590148925781, -0.27589935064315796, -0.1765558421611786, 0.1360185742378235]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00914022047072649, -0.01763022504746914, -0.04529403895139694, -0.09354908019304276, -0.018894871696829796]\n",
      "Last 5 elements: [0.8561202883720398, 0.1659514605998993, -1.0589516162872314, -0.5187854766845703, -0.10026387125253677]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.37001529335975647, -1.0650932788848877, -1.024789571762085, 0.8395094871520996, -0.1402401477098465]\n",
      "Last 5 elements: [-0.9142066240310669, 0.024304866790771484, -0.7920832633972168, -1.007448434829712, -0.09535446763038635]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.10289948433637619, 0.2698373794555664, 0.1378084272146225, -0.22701874375343323, 0.030296845361590385]\n",
      "Last 5 elements: [0.2544630169868469, -0.006707147229462862, 0.21853525936603546, 0.17787089943885803, -0.012969979085028172]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.17381900548934937, -0.04846006631851196, -0.43610167503356934, -0.5028424263000488, 0.35659441351890564]\n",
      "Last 5 elements: [0.7172704935073853, -1.0084342956542969, 0.011089444160461426, 0.07836811244487762, -1.2730588912963867]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.00914022047072649, -0.01763022504746914, -0.04529403895139694, -0.09354908019304276, -0.018894871696829796]\n",
      "Last 5 elements: [0.8561202883720398, 0.1659514605998993, -1.0589516162872314, -0.5187854766845703, -0.10026387125253677]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.17381900548934937, -0.04846006631851196, -0.43610167503356934, -0.5028424263000488, 0.35659441351890564]\n",
      "Last 5 elements: [0.7172704935073853, -1.0084342956542969, 0.011089444160461426, 0.07836811244487762, -1.2730588912963867]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3008, -0.5803, -1.4908,  ..., -0.4454, -2.7610, -1.5927],\n",
      "         [-1.5575,  0.8758,  2.1081,  ..., -0.3746, -0.1832, -0.9727],\n",
      "         [ 0.9157, -1.4234, -0.3968,  ...,  0.8550,  0.8897,  1.0719],\n",
      "         [ 1.7144, -0.3886, -1.0279,  ..., -0.5998,  0.6715,  0.2947],\n",
      "         [ 0.7693, -0.5672,  1.6124,  ..., -0.1846, -1.0980,  0.4280],\n",
      "         [ 1.5917,  0.2279,  0.6206,  ..., -1.7655, -0.8649, -0.1672]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.29083359241485596, -0.5840047597885132, -1.4958100318908691, -3.0681581497192383, -0.6079459190368652]\n",
      "Last 5 elements: [1.4797999858856201, 0.22879669070243835, -1.761688470840454, -0.8630022406578064, -0.12406416982412338]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3317495286464691, -0.5889037251472473, -1.568363070487976, -3.168513298034668, -0.5585100054740906]\n",
      "Last 5 elements: [1.5548756122589111, 0.09737855195999146, -1.7635383605957031, -0.850998044013977, -0.393512487411499]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3317495286464691, -0.5889037251472473, -1.568363070487976, -3.168513298034668, -0.5585100054740906]\n",
      "Last 5 elements: [1.5548756122589111, 0.09737855195999146, -1.7635383605957031, -0.850998044013977, -0.393512487411499]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.01008655410259962, -0.01790510304272175, -0.04768470674753189, -0.09633587300777435, -0.016981007531285286]\n",
      "Last 5 elements: [0.9098564982414246, 0.0569823794066906, -1.0319583415985107, -0.4979730248451233, -0.2302691638469696]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01008655410259962, -0.01790510304272175, -0.04768470674753189, -0.09633587300777435, -0.016981007531285286]\n",
      "Last 5 elements: [0.9098564982414246, 0.0569823794066906, -1.0319583415985107, -0.4979730248451233, -0.2302691638469696]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.3537142872810364, -1.959423303604126, -1.3561046123504639, -0.5418744683265686, 0.5606761574745178]\n",
      "Last 5 elements: [0.24249467253684998, -0.0011453032493591309, -0.5431144833564758, -0.044623732566833496, 0.18890774250030518]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.3537142872810364, -1.959423303604126, -1.3561046123504639, -0.5418744683265686, 0.5606761574745178]\n",
      "Last 5 elements: [0.24249467253684998, -0.0011453032493591309, -0.5431144833564758, -0.044623732566833496, 0.18890774250030518]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.2239522933959961, -1.2405983209609985, -0.8586103320121765, -0.3430849015712738, 0.35498908162117004]\n",
      "Last 5 elements: [0.19518591463565826, -0.0009218637715093791, -0.43715721368789673, -0.03591800108551979, 0.1520533561706543]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.2239522933959961, -1.2405983209609985, -0.8586103320121765, -0.3430849015712738, 0.35498908162117004]\n",
      "Last 5 elements: [0.19518591463565826, -0.0009218637715093791, -0.43715721368789673, -0.03591800108551979, 0.1520533561706543]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.5790348052978516, -0.9866859912872314, -0.5524576902389526, 3.170267343521118, -0.5749962329864502]\n",
      "Last 5 elements: [-0.21270330250263214, -0.9465425610542297, -0.335568904876709, -3.0346791744232178, 5.175703048706055]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01008655410259962, -0.01790510304272175, -0.04768470674753189, -0.09633587300777435, -0.016981007531285286]\n",
      "Last 5 elements: [0.9098564982414246, 0.0569823794066906, -1.0319583415985107, -0.4979730248451233, -0.2302691638469696]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.08487757295370102, -0.14736926555633545, -0.03131029009819031, -0.052430517971515656, -0.026522191241383553]\n",
      "Last 5 elements: [1.9353207349777222, -2.3538060188293457, 10.11735725402832, 2.1993584632873535, -2.548827886581421]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.08487757295370102, -0.14736926555633545, -0.03131029009819031, -0.052430517971515656, -0.026522191241383553]\n",
      "Last 5 elements: [-0.7934738397598267, 0.6909911632537842, -0.9801802635192871, 0.24634242057800293, 1.5510538816452026]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.012041009031236172, -0.02090628445148468, -0.00444177957251668, -0.007437963970005512, -0.0037625243421643972]\n",
      "Last 5 elements: [-0.5921348929405212, 0.5156565308570862, -0.731465756893158, 0.18383459746837616, 1.1574838161468506]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.012041009031236172, -0.02090628445148468, -0.00444177957251668, -0.007437963970005512, -0.0037625243421643972]\n",
      "Last 5 elements: [-0.5921348929405212, 0.5156565308570862, -0.731465756893158, 0.18383459746837616, 1.1574838161468506]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.03654755651950836, 0.052577629685401917, -0.04479888454079628, -0.15376214683055878, 0.024101760238409042]\n",
      "Last 5 elements: [-2.4493887424468994, -0.05547881871461868, -0.1203162670135498, -1.3863354921340942, -0.056184858083724976]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.024343211203813553, 0.00035500293597579, -0.0052615003660321236, -0.042711082845926285, -0.05045132339000702]\n",
      "Last 5 elements: [-2.4493887424468994, -0.05547881871461868, -0.1203162670135498, -1.3863354921340942, -0.056184858083724976]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024343211203813553, 0.00035500293597579, -0.0052615003660321236, -0.042711082845926285, -0.05045132339000702]\n",
      "Last 5 elements: [0.027271538972854614, -0.06312591582536697, 0.016330113634467125, -0.01423327811062336, -0.05374710634350777]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.05447874963283539, -0.20303195714950562, 0.13077980279922485, 0.33180391788482666, -0.2689133882522583]\n",
      "Last 5 elements: [-0.36684250831604004, 0.07953861355781555, 0.7013240456581116, -0.2014818787574768, 0.32659900188446045]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3220632076263428, -0.6250028610229492, -1.5451103448867798, -3.109518527984619, -0.6063228845596313]\n",
      "Last 5 elements: [1.4896509647369385, 0.11152052879333496, -1.6388428211212158, -0.8868215680122375, -0.3354431390762329]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.009791085496544838, -0.019000794738531113, -0.046973101794719696, -0.09453287720680237, -0.018432902172207832]\n",
      "Last 5 elements: [0.8704387545585632, 0.06516411155462265, -0.957615077495575, -0.5181910991668701, -0.19600746035575867]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009791085496544838, -0.019000794738531113, -0.046973101794719696, -0.09453287720680237, -0.018432902172207832]\n",
      "Last 5 elements: [0.8704387545585632, 0.06516411155462265, -0.957615077495575, -0.5181910991668701, -0.19600746035575867]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.2681021690368652, 0.5990307927131653, -2.379967212677002, -4.190887928009033, -2.0587034225463867]\n",
      "Last 5 elements: [-2.2110543251037598, -0.958760142326355, -0.08210322260856628, -0.4747629463672638, -0.30094820261001587]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.2681021690368652, 0.5990307927131653, -2.379967212677002, -4.190887928009033, -2.0587034225463867]\n",
      "Last 5 elements: [-2.2110543251037598, -0.958760142326355, -0.08210322260856628, -0.4747629463672638, -0.30094820261001587]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.21274664998054504, 0.3866351544857025, -0.20161442458629608, -0.06247462332248688, -0.23299559950828552]\n",
      "Last 5 elements: [-0.21836857497692108, -0.2656978368759155, -0.039367321878671646, -0.18206661939620972, -0.12800100445747375]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009791085496544838, -0.019000794738531113, -0.046973101794719696, -0.09453287720680237, -0.018432902172207832]\n",
      "Last 5 elements: [0.8704387545585632, 0.06516411155462265, -0.957615077495575, -0.5181910991668701, -0.19600746035575867]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.6107036471366882, -0.4933357834815979, 0.5499919056892395, 2.426814079284668, -0.08849798142910004]\n",
      "Last 5 elements: [-1.2231266498565674, 0.6973698735237122, -0.3822312355041504, -0.2900196611881256, 1.6045291423797607]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.12992516160011292, -0.19074095785617828, -0.11088629812002182, -0.15161429345607758, 0.02061964012682438]\n",
      "Last 5 elements: [0.26709243655204773, -0.185289666056633, 0.01504741981625557, 0.05280289798974991, -0.2053813487291336]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.9684914946556091, 0.7066521644592285, -0.5182638764381409, 0.21569907665252686, 0.4993939995765686]\n",
      "Last 5 elements: [-0.59537273645401, -0.23869776725769043, 0.7104010581970215, -0.5105164051055908, 1.337915062904358]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009791085496544838, -0.019000794738531113, -0.046973101794719696, -0.09453287720680237, -0.018432902172207832]\n",
      "Last 5 elements: [0.8704387545585632, 0.06516411155462265, -0.957615077495575, -0.5181910991668701, -0.19600746035575867]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.9684914946556091, 0.7066521644592285, -0.5182638764381409, 0.21569907665252686, 0.4993939995765686]\n",
      "Last 5 elements: [-0.59537273645401, -0.23869776725769043, 0.7104010581970215, -0.5105164051055908, 1.337915062904358]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.3221, -0.6250, -1.5451,  ..., -0.4663, -2.9318, -1.6169],\n",
      "         [-2.3927,  0.6364,  2.1262,  ...,  0.0368, -0.1195, -0.6268],\n",
      "         [ 1.0505, -1.9966, -0.3374,  ...,  0.2497,  0.6495,  1.2112],\n",
      "         [ 1.6245, -0.6678, -1.1379,  ..., -0.9376,  0.5342,  0.1423],\n",
      "         [ 0.5235, -0.5841,  2.0651,  ..., -0.3211, -0.8825,  0.5421],\n",
      "         [ 1.2581,  0.4554,  0.8369,  ..., -1.6388, -0.8868, -0.3354]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.3317495286464691, -0.5889037251472473, -1.568363070487976, -3.168513298034668, -0.5585100054740906]\n",
      "Last 5 elements: [1.5548756122589111, 0.09737855195999146, -1.7635383605957031, -0.850998044013977, -0.393512487411499]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4942611753940582, -0.49935996532440186, -1.6372578144073486, -3.071167230606079, -0.5175305604934692]\n",
      "Last 5 elements: [1.383793592453003, 0.06908002495765686, -1.51253342628479, -0.9775914549827576, -0.09756159782409668]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4942611753940582, -0.49935996532440186, -1.6372578144073486, -3.071167230606079, -0.5175305604934692]\n",
      "Last 5 elements: [1.383793592453003, 0.06908002495765686, -1.51253342628479, -0.9775914549827576, -0.09756159782409668]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.015037055127322674, -0.015192177146673203, -0.049810782074928284, -0.09343503415584564, -0.01574498601257801]\n",
      "Last 5 elements: [0.7862465381622314, 0.039250023663043976, -0.8593941926956177, -0.5554497838020325, -0.05543273687362671]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.015037055127322674, -0.015192177146673203, -0.049810782074928284, -0.09343503415584564, -0.01574498601257801]\n",
      "Last 5 elements: [0.7862465381622314, 0.039250023663043976, -0.8593941926956177, -0.5554497838020325, -0.05543273687362671]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.2691076397895813, 0.8134991526603699, 1.8094853162765503, 0.4203929305076599, -0.874973475933075]\n",
      "Last 5 elements: [1.3758022785186768, -0.8506466150283813, 0.14257299900054932, -0.0674668699502945, 1.102684497833252]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.2691076397895813, 0.8134991526603699, 1.8094853162765503, 0.4203929305076599, -0.874973475933075]\n",
      "Last 5 elements: [1.3758022785186768, -0.8506466150283813, 0.14257299900054932, -0.0674668699502945, 1.102684497833252]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.19734060764312744, 0.5965509414672852, 1.3269222974777222, 0.308280348777771, -0.6416309475898743]\n",
      "Last 5 elements: [1.2986866235733032, -0.8029667139053345, 0.1345815807580948, -0.06368526071310043, 1.0408774614334106]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.19734060764312744, 0.5965509414672852, 1.3269222974777222, 0.308280348777771, -0.6416309475898743]\n",
      "Last 5 elements: [1.2986866235733032, -0.8029667139053345, 0.1345815807580948, -0.06368526071310043, 1.0408774614334106]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.3000688552856445, 0.20141488313674927, -1.4501953125, -1.1618657112121582, -2.3948161602020264]\n",
      "Last 5 elements: [1.8506824970245361, 0.7673893570899963, -0.19500459730625153, -2.007888078689575, -1.0723822116851807]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.015037055127322674, -0.015192177146673203, -0.049810782074928284, -0.09343503415584564, -0.01574498601257801]\n",
      "Last 5 elements: [0.7862465381622314, 0.039250023663043976, -0.8593941926956177, -0.5554497838020325, -0.05543273687362671]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.13931985199451447, 0.02420450747013092, -0.10267825424671173, -0.03181316703557968, -0.07457632571458817]\n",
      "Last 5 elements: [-2.568221092224121, -0.22474342584609985, 12.783740043640137, 0.67024827003479, -2.6250970363616943]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.13931985199451447, 0.02420450747013092, -0.10267825424671173, -0.03181316703557968, -0.07457632571458817]\n",
      "Last 5 elements: [0.816411018371582, -0.6570086479187012, 0.3953971862792969, -0.49085718393325806, 0.5636653900146484]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.019594786688685417, 0.003404268529266119, -0.01444129180163145, -0.004474396351724863, -0.01048886589705944]\n",
      "Last 5 elements: [1.032178521156311, -0.8306480646133423, 0.499895840883255, -0.6205847859382629, 0.7126352787017822]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.019594786688685417, 0.003404268529266119, -0.01444129180163145, -0.004474396351724863, -0.01048886589705944]\n",
      "Last 5 elements: [1.032178521156311, -0.8306480646133423, 0.499895840883255, -0.6205847859382629, 0.7126352787017822]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.07060705125331879, 0.12751512229442596, -0.12666715681552887, 0.09939412772655487, -0.17493222653865814]\n",
      "Last 5 elements: [-0.5041096210479736, -0.29792773723602295, -0.17780834436416626, 0.4676888585090637, -0.15942007303237915]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.05914568156003952, -0.006391304079443216, -0.028120629489421844, 0.002071295864880085, 0.008890785276889801]\n",
      "Last 5 elements: [-0.5041096210479736, -0.29792773723602295, -0.17780834436416626, 0.4676888585090637, -0.15942007303237915]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.05914568156003952, -0.006391304079443216, -0.028120629489421844, 0.002071295864880085, 0.008890785276889801]\n",
      "Last 5 elements: [-0.10677056014537811, -0.020539110526442528, -0.010631040669977665, -0.07354786992073059, -0.09207361191511154]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.04270245507359505, -0.05480824038386345, 0.19212979078292847, 0.05725317820906639, 0.14036309719085693]\n",
      "Last 5 elements: [0.24142765998840332, -0.19311124086380005, -0.5265786647796631, -0.3305882215499878, 0.4348111152648926]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5018537044525146, -0.5091049075126648, -1.6030970811843872, -3.060987710952759, -0.49257397651672363]\n",
      "Last 5 elements: [1.4267194271087646, 0.034744810312986374, -1.6061592102050781, -1.036370038986206, -0.020252101123332977]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.015267942100763321, -0.015488546341657639, -0.048771172761917114, -0.09312471747398376, -0.014985623769462109]\n",
      "Last 5 elements: [0.8141036033630371, 0.01982581429183483, -0.9164941310882568, -0.5913654565811157, -0.01155609730631113]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.015267942100763321, -0.015488546341657639, -0.048771172761917114, -0.09312471747398376, -0.014985623769462109]\n",
      "Last 5 elements: [0.8141036033630371, 0.01982581429183483, -0.9164941310882568, -0.5913654565811157, -0.01155609730631113]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.7013843059539795, -1.8187220096588135, -3.1423213481903076, -1.9318281412124634, -0.7898634672164917]\n",
      "Last 5 elements: [-0.26949143409729004, -1.5002975463867188, -0.17380103468894958, 0.14645490050315857, -1.2063894271850586]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.7013843059539795, -1.8187220096588135, -3.1423213481903076, -1.9318281412124634, -0.7898634672164917]\n",
      "Last 5 elements: [-0.26949143409729004, -1.5002975463867188, -0.17380103468894958, 0.14645490050315857, -1.2063894271850586]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2325126826763153, -0.25387048721313477, -0.1300760954618454, -0.24446970224380493, -0.24659377336502075]\n",
      "Last 5 elements: [-0.11669839918613434, -0.2736259996891022, -0.07936776429414749, 0.07858014106750488, -0.27788040041923523]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.015267942100763321, -0.015488546341657639, -0.048771172761917114, -0.09312471747398376, -0.014985623769462109]\n",
      "Last 5 elements: [0.8141036033630371, 0.01982581429183483, -0.9164941310882568, -0.5913654565811157, -0.01155609730631113]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [1.053511619567871, -2.720899820327759, 2.3203108310699463, -0.157831072807312, 0.7633402943611145]\n",
      "Last 5 elements: [-1.8722723722457886, 0.39787471294403076, -0.3322649300098419, -0.124350905418396, -1.6566575765609741]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.24495480954647064, 0.6907561421394348, -0.3018169701099396, 0.038584914058446884, -0.18823496997356415]\n",
      "Last 5 elements: [0.21849118173122406, -0.10886886715888977, 0.026371125131845474, -0.009771511889994144, 0.46035265922546387]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.1497587263584137, 0.6745383739471436, 0.24688713252544403, -0.7211344242095947, -0.4580209255218506]\n",
      "Last 5 elements: [-0.6741094589233398, 1.6014457941055298, 0.4678236246109009, -0.297484815120697, -0.14359688758850098]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.015267942100763321, -0.015488546341657639, -0.048771172761917114, -0.09312471747398376, -0.014985623769462109]\n",
      "Last 5 elements: [0.8141036033630371, 0.01982581429183483, -0.9164941310882568, -0.5913654565811157, -0.01155609730631113]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.1497587263584137, 0.6745383739471436, 0.24688713252544403, -0.7211344242095947, -0.4580209255218506]\n",
      "Last 5 elements: [-0.6741094589233398, 1.6014457941055298, 0.4678236246109009, -0.297484815120697, -0.14359688758850098]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.5019, -0.5091, -1.6031,  ..., -0.6137, -2.7815, -1.7277],\n",
      "         [-2.2343,  1.0983,  1.4519,  ...,  0.4089, -0.6117, -0.3370],\n",
      "         [ 1.9546, -1.7702, -0.4337,  ...,  0.4707,  0.7745,  1.2066],\n",
      "         [ 1.3349, -0.8358, -0.8971,  ..., -1.1688,  0.7321,  0.4514],\n",
      "         [ 0.5616, -0.7023,  1.9303,  ..., -0.7402, -1.0084,  0.3686],\n",
      "         [ 1.3339,  0.0559,  0.7963,  ..., -1.6062, -1.0364, -0.0203]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.4942611753940582, -0.49935996532440186, -1.6372578144073486, -3.071167230606079, -0.5175305604934692]\n",
      "Last 5 elements: [1.383793592453003, 0.06908002495765686, -1.51253342628479, -0.9775914549827576, -0.09756159782409668]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5284808278083801, -0.38917186856269836, -1.5592005252838135, -3.1892056465148926, -0.5740101933479309]\n",
      "Last 5 elements: [1.3068625926971436, 0.31948214769363403, -1.5229800939559937, -1.089262843132019, -0.04578365385532379]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5284808278083801, -0.38917186856269836, -1.5592005252838135, -3.1892056465148926, -0.5740101933479309]\n",
      "Last 5 elements: [1.3068625926971436, 0.31948214769363403, -1.5229800939559937, -1.089262843132019, -0.04578365385532379]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.016089972108602524, -0.011848612688481808, -0.04747096449136734, -0.09709762036800385, -0.017476147040724754]\n",
      "Last 5 elements: [0.7301267981529236, 0.17849043011665344, -0.8508687615394592, -0.6085566878318787, -0.02557872049510479]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.016089972108602524, -0.011848612688481808, -0.04747096449136734, -0.09709762036800385, -0.017476147040724754]\n",
      "Last 5 elements: [0.7301267981529236, 0.17849043011665344, -0.8508687615394592, -0.6085566878318787, -0.02557872049510479]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.8686572909355164, 1.8320761919021606, 1.0460336208343506, -1.771369457244873, -1.0356229543685913]\n",
      "Last 5 elements: [0.6621795296669006, 0.6800265312194824, 0.9750339984893799, 0.5523437261581421, 0.3427756726741791]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.8686572909355164, 1.8320761919021606, 1.0460336208343506, -1.771369457244873, -1.0356229543685913]\n",
      "Last 5 elements: [0.6621795296669006, 0.6800265312194824, 0.9750339984893799, 0.5523437261581421, 0.3427756726741791]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.6377981901168823, 1.3451735973358154, 0.7680339813232422, -1.3006006479263306, -0.7603901028633118]\n",
      "Last 5 elements: [0.6082773208618164, 0.6246715188026428, 0.8956650495529175, 0.5073822736740112, 0.3148733079433441]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.6377981901168823, 1.3451735973358154, 0.7680339813232422, -1.3006006479263306, -0.7603901028633118]\n",
      "Last 5 elements: [0.6082773208618164, 0.6246715188026428, 0.8956650495529175, 0.5073822736740112, 0.3148733079433441]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [2.919069290161133, -2.8467211723327637, 1.7455663681030273, -0.860630989074707, -0.7669019103050232]\n",
      "Last 5 elements: [0.5699594020843506, 2.4573066234588623, -0.06053286790847778, 1.454756736755371, 0.9777577519416809]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.016089972108602524, -0.011848612688481808, -0.04747096449136734, -0.09709762036800385, -0.017476147040724754]\n",
      "Last 5 elements: [0.7301267981529236, 0.17849043011665344, -0.8508687615394592, -0.6085566878318787, -0.02557872049510479]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.0437619611620903, 0.11674486100673676, -0.03357546776533127, -4.132299423217773, -0.1375683844089508]\n",
      "Last 5 elements: [0.8768794536590576, 5.08772087097168, -0.7805881500244141, -8.017132759094238, 2.7759547233581543]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.0437619611620903, 0.11674486100673676, -0.03357546776533127, -4.132299423217773, -0.1375683844089508]\n",
      "Last 5 elements: [1.311611533164978, -0.9552258849143982, 0.30618640780448914, 0.666554868221283, 0.3507559299468994]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.006406087428331375, 0.01708967797458172, -0.0049149394035339355, -0.6049059629440308, -0.020137924700975418]\n",
      "Last 5 elements: [1.2903735637664795, -0.9397585988044739, 0.3012285530567169, 0.6557618379592896, 0.34507641196250916]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.006406087428331375, 0.01708967797458172, -0.0049149394035339355, -0.6049059629440308, -0.020137924700975418]\n",
      "Last 5 elements: [1.2903735637664795, -0.9397585988044739, 0.3012285530567169, 0.6557618379592896, 0.34507641196250916]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.01478002592921257, 0.4477904140949249, -0.09115883708000183, 0.027828047052025795, -0.08937114477157593]\n",
      "Last 5 elements: [-1.2073789834976196, -0.01265573501586914, -1.1091299057006836, -0.9828618168830872, -0.19600525498390198]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.0013325698673725128, 0.020662818104028702, 0.039745453745126724, -0.02103228121995926, 0.00707155279815197]\n",
      "Last 5 elements: [-1.2073789834976196, -0.01265573501586914, -1.1091299057006836, -0.9828618168830872, -0.19600525498390198]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.0013325698673725128, 0.020662818104028702, 0.039745453745126724, -0.02103228121995926, 0.00707155279815197]\n",
      "Last 5 elements: [-0.008096265606582165, -0.04813003912568092, 0.03518611937761307, 0.00438160914927721, 0.049788154661655426]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.36342376470565796, -0.021342914551496506, 0.1189718022942543, 0.0782158225774765, -0.08041557669639587]\n",
      "Last 5 elements: [-0.8995099067687988, -0.3766344487667084, -0.3806764483451843, 0.7419924736022949, -0.09563302993774414]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5930976271629333, -0.392966628074646, -1.5380473136901855, -3.1752989292144775, -0.5883080959320068]\n",
      "Last 5 elements: [1.1469296216964722, 0.2525164783000946, -1.5906643867492676, -0.95733642578125, -0.06278721988201141]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.018055610358715057, -0.011963042430579662, -0.04682261496782303, -0.09666530042886734, -0.017909802496433258]\n",
      "Last 5 elements: [0.6437147855758667, 0.14172498881816864, -0.8927611112594604, -0.537305474281311, -0.03523935377597809]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018055610358715057, -0.011963042430579662, -0.04682261496782303, -0.09666530042886734, -0.017909802496433258]\n",
      "Last 5 elements: [0.6437147855758667, 0.14172498881816864, -0.8927611112594604, -0.537305474281311, -0.03523935377597809]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.15106913447380066, -3.5132384300231934, -0.9021124243736267, -1.1232106685638428, -0.16253456473350525]\n",
      "Last 5 elements: [-2.0295326709747314, -0.46508947014808655, 0.17054510116577148, -0.23206722736358643, -1.0555675029754639]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.15106913447380066, -3.5132384300231934, -0.9021124243736267, -1.1232106685638428, -0.16253456473350525]\n",
      "Last 5 elements: [-2.0295326709747314, -0.46508947014808655, 0.17054510116577148, -0.23206722736358643, -1.0555675029754639]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.06983991712331772, -0.10166572779417038, -0.2603645920753479, -0.2756541073322296, -0.07467741519212723]\n",
      "Last 5 elements: [-0.23570360243320465, -0.1794218271970749, 0.0925263836979866, -0.10262991487979889, -0.2725025713443756]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018055610358715057, -0.011963042430579662, -0.04682261496782303, -0.09666530042886734, -0.017909802496433258]\n",
      "Last 5 elements: [0.6437147855758667, 0.14172498881816864, -0.8927611112594604, -0.537305474281311, -0.03523935377597809]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.0007144510746002197, -0.7516586184501648, 0.23727038502693176, 2.036797285079956, 0.9869711399078369]\n",
      "Last 5 elements: [-0.6288943886756897, 0.08680753409862518, 1.6736576557159424, 0.08359360694885254, 0.028136953711509705]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [4.9897204007720575e-05, 0.07641792297363281, -0.06177680566906929, -0.5614515542984009, -0.07370445132255554]\n",
      "Last 5 elements: [0.14823266863822937, -0.015575166791677475, 0.15485748648643494, -0.00857920479029417, -0.007667392026633024]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.017235517501831055, 0.4123237729072571, -1.2186362743377686, -0.6592092514038086, -0.8599534630775452]\n",
      "Last 5 elements: [1.496079444885254, 0.6119228601455688, 0.05847656726837158, 0.5323142409324646, 1.3251187801361084]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018055610358715057, -0.011963042430579662, -0.04682261496782303, -0.09666530042886734, -0.017909802496433258]\n",
      "Last 5 elements: [0.6437147855758667, 0.14172498881816864, -0.8927611112594604, -0.537305474281311, -0.03523935377597809]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.017235517501831055, 0.4123237729072571, -1.2186362743377686, -0.6592092514038086, -0.8599534630775452]\n",
      "Last 5 elements: [1.496079444885254, 0.6119228601455688, 0.05847656726837158, 0.5323142409324646, 1.3251187801361084]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.5931, -0.3930, -1.5380,  ..., -0.6054, -2.8690, -1.6494],\n",
      "         [-2.7733,  1.1861,  2.4983,  ...,  0.8786, -1.2476,  0.3860],\n",
      "         [ 1.3878, -2.1974, -0.2411,  ...,  0.6038,  0.8297,  1.1973],\n",
      "         [ 1.4854, -0.5970, -0.8759,  ..., -1.3750,  0.8233,  0.4723],\n",
      "         [ 0.1297, -0.3052,  1.9872,  ..., -0.5771, -1.0298,  0.0351],\n",
      "         [ 1.0231,  0.4338,  0.7126,  ..., -1.5907, -0.9573, -0.0628]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5284808278083801, -0.38917186856269836, -1.5592005252838135, -3.1892056465148926, -0.5740101933479309]\n",
      "Last 5 elements: [1.3068625926971436, 0.31948214769363403, -1.5229800939559937, -1.089262843132019, -0.04578365385532379]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5900331735610962, -0.3196553885936737, -1.7547210454940796, -3.292506456375122, -0.7412079572677612]\n",
      "Last 5 elements: [1.4129328727722168, 0.3613164722919464, -1.5802671909332275, -0.8626908659934998, 0.1728191375732422]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5900331735610962, -0.3196553885936737, -1.7547210454940796, -3.292506456375122, -0.7412079572677612]\n",
      "Last 5 elements: [1.4129328727722168, 0.3613164722919464, -1.5802671909332275, -0.8626908659934998, 0.1728191375732422]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.017977576702833176, -0.009739501401782036, -0.05346416309475899, -0.10031857341527939, -0.02258368395268917]\n",
      "Last 5 elements: [0.7784762382507324, 0.19907264411449432, -0.8706715703010559, -0.4753122627735138, 0.0952172577381134]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.017977576702833176, -0.009739501401782036, -0.05346416309475899, -0.10031857341527939, -0.02258368395268917]\n",
      "Last 5 elements: [0.7784762382507324, 0.19907264411449432, -0.8706715703010559, -0.4753122627735138, 0.0952172577381134]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.0037060976028442, 2.1318888664245605, -0.42329344153404236, 1.5706454515457153, 1.3683793544769287]\n",
      "Last 5 elements: [0.8609994053840637, -0.5180554389953613, -0.7621545791625977, 0.05143427848815918, 0.35598617792129517]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.0037060976028442, 2.1318888664245605, -0.42329344153404236, 1.5706454515457153, 1.3683793544769287]\n",
      "Last 5 elements: [0.8609994053840637, -0.5180554389953613, -0.7621545791625977, 0.05143427848815918, 0.35598617792129517]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.5078398585319519, 1.078660488128662, -0.21417154371738434, 0.7946911454200745, 0.6923516392707825]\n",
      "Last 5 elements: [0.7408520579338074, -0.44576388597488403, -0.6558004021644592, 0.04425692930817604, 0.30631041526794434]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.5078398585319519, 1.078660488128662, -0.21417154371738434, 0.7946911454200745, 0.6923516392707825]\n",
      "Last 5 elements: [0.7408520579338074, -0.44576388597488403, -0.6558004021644592, 0.04425692930817604, 0.30631041526794434]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-1.2220802307128906, -0.792064368724823, -1.0360488891601562, 1.137643575668335, 1.0946452617645264]\n",
      "Last 5 elements: [-1.5371475219726562, 2.0439400672912598, 1.8034626245498657, -0.5659687519073486, -2.1272335052490234]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.017977576702833176, -0.009739501401782036, -0.05346416309475899, -0.10031857341527939, -0.02258368395268917]\n",
      "Last 5 elements: [0.7784762382507324, 0.19907264411449432, -0.8706715703010559, -0.4753122627735138, 0.0952172577381134]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.009940646588802338, 0.2097284495830536, 0.09103401005268097, -0.004980325698852539, -0.12158802896738052]\n",
      "Last 5 elements: [-0.7017402052879333, 1.212660551071167, -17.003860473632812, -1.6558597087860107, 1.0946255922317505]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.009940646588802338, 0.2097284495830536, 0.09103401005268097, -0.004980325698852539, -0.12158802896738052]\n",
      "Last 5 elements: [-0.04322183132171631, -0.8104972243309021, -1.0390338897705078, 0.9657636880874634, 0.1845937967300415]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.0017594785895198584, 0.03712160140275955, 0.016112875193357468, -0.0008815097389742732, -0.021520886570215225]\n",
      "Last 5 elements: [-0.03570577874779701, -0.6695559620857239, -0.8583512902259827, 0.7978223562240601, 0.1524938941001892]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.0017594785895198584, 0.03712160140275955, 0.016112875193357468, -0.0008815097389742732, -0.021520886570215225]\n",
      "Last 5 elements: [-0.03570577874779701, -0.6695559620857239, -0.8583512902259827, 0.7978223562240601, 0.1524938941001892]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.07732667028903961, 0.11706854403018951, 0.040180571377277374, -0.03457430750131607, -0.0291687473654747]\n",
      "Last 5 elements: [-0.418143093585968, 1.4315170049667358, 1.1115422248840332, -0.4215124845504761, 0.15265673398971558]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-0.009430035948753357, -0.0951615497469902, -0.03431590646505356, 0.07423698902130127, -0.08351043611764908]\n",
      "Last 5 elements: [-0.418143093585968, 1.4315170049667358, 1.1115422248840332, -0.4215124845504761, 0.15265673398971558]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.009430035948753357, -0.0951615497469902, -0.03431590646505356, 0.07423698902130127, -0.08351043611764908]\n",
      "Last 5 elements: [-0.15486781299114227, 0.7702687978744507, 0.6449909210205078, -0.21909099817276, 0.030797597020864487]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.3715001940727234, 0.14400413632392883, -0.08281943202018738, 0.28459596633911133, -0.006423383951187134]\n",
      "Last 5 elements: [1.1100939512252808, -0.5521782040596008, 1.1728581190109253, 0.5308467149734497, -0.4596252143383026]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6560859680175781, -0.2940514385700226, -1.7694463729858398, -3.2419052124023438, -0.7423500418663025]\n",
      "Last 5 elements: [1.6103078126907349, 0.26313909888267517, -1.3717328310012817, -0.7683062553405762, 0.09109769016504288]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.019986821338534355, -0.00895790196955204, -0.05390392616391182, -0.09876050055027008, -0.022614747285842896]\n",
      "Last 5 elements: [0.8915672898292542, 0.14569029211997986, -0.7594772577285767, -0.42538249492645264, 0.05043739080429077]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019986821338534355, -0.00895790196955204, -0.05390392616391182, -0.09876050055027008, -0.022614747285842896]\n",
      "Last 5 elements: [0.8915672898292542, 0.14569029211997986, -0.7594772577285767, -0.42538249492645264, 0.05043739080429077]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-2.4840235710144043, -1.2771273851394653, -1.4163068532943726, -2.4945199489593506, -0.7912862300872803]\n",
      "Last 5 elements: [0.7748899459838867, -0.9518771171569824, -2.0966243743896484, -1.347419261932373, 2.3174586296081543]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-2.4840235710144043, -1.2771273851394653, -1.4163068532943726, -2.4945199489593506, -0.7912862300872803]\n",
      "Last 5 elements: [0.7748899459838867, -0.9518771171569824, -2.0966243743896484, -1.347419261932373, 2.3174586296081543]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.1912345588207245, -0.27846434712409973, -0.2765214741230011, -0.19019030034542084, -0.24679628014564514]\n",
      "Last 5 elements: [0.5304723978042603, -0.26510488986968994, -0.22942383587360382, -0.2779626250267029, 2.109611988067627]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019986821338534355, -0.00895790196955204, -0.05390392616391182, -0.09876050055027008, -0.022614747285842896]\n",
      "Last 5 elements: [0.8915672898292542, 0.14569029211997986, -0.7594772577285767, -0.42538249492645264, 0.05043739080429077]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.19962190091609955, -0.24216249585151672, -0.5928277373313904, -0.41896694898605347, -1.5414981842041016]\n",
      "Last 5 elements: [-1.037427544593811, -0.0394798219203949, -1.0041563510894775, 1.1536930799484253, -0.6543428301811218]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.03817460685968399, 0.06743361800909042, 0.16392959654331207, 0.07968345284461975, 0.3804360032081604]\n",
      "Last 5 elements: [-0.5503267049789429, 0.010466293431818485, 0.2303774058818817, -0.3206835687160492, -1.3804094791412354]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.25167524814605713, 0.2637574374675751, -0.3103371262550354, -1.1519380807876587, 0.45418503880500793]\n",
      "Last 5 elements: [-0.6243504285812378, -0.6002892851829529, 1.767957091331482, -0.08777356147766113, -0.5277683138847351]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.019986821338534355, -0.00895790196955204, -0.05390392616391182, -0.09876050055027008, -0.022614747285842896]\n",
      "Last 5 elements: [0.8915672898292542, 0.14569029211997986, -0.7594772577285767, -0.42538249492645264, 0.05043739080429077]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.25167524814605713, 0.2637574374675751, -0.3103371262550354, -1.1519380807876587, 0.45418503880500793]\n",
      "Last 5 elements: [-0.6243504285812378, -0.6002892851829529, 1.767957091331482, -0.08777356147766113, -0.5277683138847351]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6561, -0.2941, -1.7694,  ..., -0.6825, -2.7666, -1.7214],\n",
      "         [-2.8948,  1.2528,  2.1977,  ...,  0.9825, -2.4242,  0.1810],\n",
      "         [ 1.9840, -2.1546,  0.1138,  ...,  0.7330,  0.4866,  1.5403],\n",
      "         [ 1.9281, -1.2225, -1.0223,  ..., -1.7539,  1.2402,  0.2757],\n",
      "         [ 0.0847, -0.4393,  1.8035,  ..., -0.8266, -0.8332,  0.1471],\n",
      "         [ 1.1290,  0.3192,  0.7310,  ..., -1.3717, -0.7683,  0.0911]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5900331735610962, -0.3196553885936737, -1.7547210454940796, -3.292506456375122, -0.7412079572677612]\n",
      "Last 5 elements: [1.4129328727722168, 0.3613164722919464, -1.5802671909332275, -0.8626908659934998, 0.1728191375732422]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7008338570594788, -0.2471553236246109, -1.8246244192123413, -3.4467201232910156, -0.66159588098526]\n",
      "Last 5 elements: [1.4992982149124146, 0.15640756487846375, -1.057389736175537, -0.7839124202728271, -0.0027396082878112793]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7008338570594788, -0.2471553236246109, -1.8246244192123413, -3.4467201232910156, -0.66159588098526]\n",
      "Last 5 elements: [1.4992982149124146, 0.15640756487846375, -1.057389736175537, -0.7839124202728271, -0.0027396082878112793]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.021368181332945824, -0.0075356801971793175, -0.05563216656446457, -0.10508929938077927, -0.02017182856798172]\n",
      "Last 5 elements: [0.8198398947715759, 0.08552612364292145, -0.5781973600387573, -0.4286556541919708, -0.0014980609994381666]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021368181332945824, -0.0075356801971793175, -0.05563216656446457, -0.10508929938077927, -0.02017182856798172]\n",
      "Last 5 elements: [0.8198398947715759, 0.08552612364292145, -0.5781973600387573, -0.4286556541919708, -0.0014980609994381666]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.227196216583252, 5.644714832305908, -0.582525372505188, 0.7320221066474915, 3.648128032684326]\n",
      "Last 5 elements: [0.7763107419013977, 0.3173690438270569, -1.3206346035003662, 0.10063636302947998, -3.9866549968719482]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.227196216583252, 5.644714832305908, -0.582525372505188, 0.7320221066474915, 3.648128032684326]\n",
      "Last 5 elements: [0.7763107419013977, 0.3173690438270569, -1.3206346035003662, 0.10063636302947998, -3.9866549968719482]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [1.0648490190505981, 2.698805332183838, -0.27851229906082153, 0.3499884605407715, 1.744213342666626]\n",
      "Last 5 elements: [0.682880699634552, 0.27917325496673584, -1.1616945266723633, 0.08852464705705643, -3.5068557262420654]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [1.0648490190505981, 2.698805332183838, -0.27851229906082153, 0.3499884605407715, 1.744213342666626]\n",
      "Last 5 elements: [0.682880699634552, 0.27917325496673584, -1.1616945266723633, 0.08852464705705643, -3.5068557262420654]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.9041408896446228, -1.066943883895874, -0.784127950668335, -0.48407334089279175, -0.24798071384429932]\n",
      "Last 5 elements: [1.9695756435394287, 1.6596070528030396, -1.1715319156646729, 1.2278614044189453, -0.23605769872665405]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021368181332945824, -0.0075356801971793175, -0.05563216656446457, -0.10508929938077927, -0.02017182856798172]\n",
      "Last 5 elements: [0.8198398947715759, 0.08552612364292145, -0.5781973600387573, -0.4286556541919708, -0.0014980609994381666]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.03249986469745636, 0.1703166961669922, 0.0437326654791832, -0.0444951057434082, -0.04441650211811066]\n",
      "Last 5 elements: [0.18234780430793762, 1.5384411811828613, 15.392983436584473, 1.0363553762435913, -3.722074031829834]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.03249986469745636, 0.1703166961669922, 0.0437326654791832, -0.0444951057434082, -0.04441650211811066]\n",
      "Last 5 elements: [-2.4966702461242676, -0.9859601855278015, -0.24392038583755493, 0.017275124788284302, -0.444035142660141]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.005706301890313625, 0.02990407682955265, 0.00767854880541563, -0.007812417112290859, -0.00779861630871892]\n",
      "Last 5 elements: [-2.3362135887145996, -0.9225942492485046, -0.22824405133724213, 0.016164883971214294, -0.4154977798461914]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.005706301890313625, 0.02990407682955265, 0.00767854880541563, -0.007812417112290859, -0.00779861630871892]\n",
      "Last 5 elements: [-2.3362135887145996, -0.9225942492485046, -0.22824405133724213, 0.016164883971214294, -0.4154977798461914]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.05446738377213478, -0.02177620679140091, 0.2965069115161896, 6.356183439493179e-05, 0.028114624321460724]\n",
      "Last 5 elements: [-1.1541012525558472, 0.6761100888252258, -0.764739990234375, 0.18292585015296936, 0.9706792831420898]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.15397416055202484, -0.023295754566788673, 0.048180047422647476, -0.08082122355699539, -0.13478225469589233]\n",
      "Last 5 elements: [-1.1541012525558472, 0.6761100888252258, -0.764739990234375, 0.18292585015296936, 0.9706792831420898]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.15397416055202484, -0.023295754566788673, 0.048180047422647476, -0.08082122355699539, -0.13478225469589233]\n",
      "Last 5 elements: [-0.7040709853172302, 0.2353086620569229, -0.502818763256073, 0.1624235063791275, 0.5048492550849915]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.22886772453784943, 0.5824337005615234, 0.26481008529663086, 0.15815448760986328, -0.3633773922920227]\n",
      "Last 5 elements: [0.6015607714653015, 0.9582605957984924, 1.0610408782958984, -0.2856045067310333, 0.2353062927722931]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7415266036987305, -0.1435984969139099, -1.777541160583496, -3.41860032081604, -0.7262044548988342]\n",
      "Last 5 elements: [1.6062557697296143, 0.32678645849227905, -0.8687365055084229, -0.8346929550170898, 0.03909789398312569]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.02260507084429264, -0.00437752902507782, -0.054187461733818054, -0.10421434044837952, -0.02213798277080059]\n",
      "Last 5 elements: [0.8632713556289673, 0.17562918365001678, -0.46689659357070923, -0.4486001133918762, 0.02101290039718151]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02260507084429264, -0.00437752902507782, -0.054187461733818054, -0.10421434044837952, -0.02213798277080059]\n",
      "Last 5 elements: [0.8632713556289673, 0.17562918365001678, -0.46689659357070923, -0.4486001133918762, 0.02101290039718151]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.5518381595611572, -3.821559190750122, -1.598250389099121, -3.0138988494873047, -1.5877350568771362]\n",
      "Last 5 elements: [-1.8738137483596802, -1.0039191246032715, -1.1616780757904053, -0.2712094187736511, -0.26277753710746765]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.5518381595611572, -3.821559190750122, -1.598250389099121, -3.0138988494873047, -1.5877350568771362]\n",
      "Last 5 elements: [-1.8738137483596802, -1.0039191246032715, -1.1616780757904053, -0.2712094187736511, -0.26277753710746765]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2712938189506531, -0.0818752869963646, -0.26886773109436035, -0.14105620980262756, -0.2694430649280548]\n",
      "Last 5 elements: [-0.2494065910577774, -0.26922258734703064, -0.2769005000591278, -0.1173279657959938, -0.11422441899776459]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02260507084429264, -0.00437752902507782, -0.054187461733818054, -0.10421434044837952, -0.02213798277080059]\n",
      "Last 5 elements: [0.8632713556289673, 0.17562918365001678, -0.46689659357070923, -0.4486001133918762, 0.02101290039718151]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.755272388458252, -0.6387640833854675, 1.1247836351394653, -0.5215247869491577, -0.8252192139625549]\n",
      "Last 5 elements: [0.8115533590316772, 1.3979160785675049, -0.1153649091720581, -0.10196810960769653, -0.34942227602005005]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.20490072667598724, 0.05229899287223816, -0.3024180233478546, 0.073564313352108, 0.2223495990037918]\n",
      "Last 5 elements: [-0.20240676403045654, -0.3763505816459656, 0.031944602727890015, 0.011963711120188236, 0.03991255536675453]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.30179563164711, 0.443550169467926, -0.07450658082962036, -0.21182110905647278, -0.6066898107528687]\n",
      "Last 5 elements: [2.0508203506469727, 1.7198737859725952, 0.0927424430847168, -2.4969654083251953, -0.5030933618545532]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.02260507084429264, -0.00437752902507782, -0.054187461733818054, -0.10421434044837952, -0.02213798277080059]\n",
      "Last 5 elements: [0.8632713556289673, 0.17562918365001678, -0.46689659357070923, -0.4486001133918762, 0.02101290039718151]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.30179563164711, 0.443550169467926, -0.07450658082962036, -0.21182110905647278, -0.6066898107528687]\n",
      "Last 5 elements: [2.0508203506469727, 1.7198737859725952, 0.0927424430847168, -2.4969654083251953, -0.5030933618545532]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.7415, -0.1436, -1.7775,  ..., -0.6030, -2.6893, -1.6721],\n",
      "         [-3.3588,  1.4525,  1.0769,  ...,  0.6469, -3.6414, -0.0340],\n",
      "         [ 2.2253, -2.0260,  0.2761,  ...,  0.6045,  0.0433,  1.4272],\n",
      "         [ 2.1366, -0.9634, -0.5966,  ..., -1.7342,  1.5234,  0.3516],\n",
      "         [ 0.0091,  0.0490,  2.1970,  ..., -0.6682, -0.9716, -0.0187],\n",
      "         [ 1.0420, -0.0228,  0.5955,  ..., -0.8687, -0.8347,  0.0391]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7008338570594788, -0.2471553236246109, -1.8246244192123413, -3.4467201232910156, -0.66159588098526]\n",
      "Last 5 elements: [1.4992982149124146, 0.15640756487846375, -1.057389736175537, -0.7839124202728271, -0.0027396082878112793]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.795185923576355, -0.06473519653081894, -1.7907884120941162, -3.4562621116638184, -0.8340740203857422]\n",
      "Last 5 elements: [1.9708919525146484, 0.6325802803039551, -0.852246880531311, -1.278653860092163, -0.050352197140455246]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.795185923576355, -0.06473519653081894, -1.7907884120941162, -3.4562621116638184, -0.8340740203857422]\n",
      "Last 5 elements: [1.9708919525146484, 0.6325802803039551, -0.852246880531311, -1.278653860092163, -0.050352197140455246]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.024264799430966377, -0.001975370105355978, -0.05464523658156395, -0.10546653717756271, -0.025451455265283585]\n",
      "Last 5 elements: [1.0250918865203857, 0.32901495695114136, -0.44326701760292053, -0.6650480031967163, -0.026188969612121582]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024264799430966377, -0.001975370105355978, -0.05464523658156395, -0.10546653717756271, -0.025451455265283585]\n",
      "Last 5 elements: [1.0250918865203857, 0.32901495695114136, -0.44326701760292053, -0.6650480031967163, -0.026188969612121582]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.3691351413726807, -1.031744360923767, 2.2356810569763184, 0.3142518699169159, 1.8117386102676392]\n",
      "Last 5 elements: [-0.4666735827922821, 0.1990303099155426, 1.237391710281372, 0.16488859057426453, 1.1230340003967285]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.3691351413726807, -1.031744360923767, 2.2356810569763184, 0.3142518699169159, 1.8117386102676392]\n",
      "Last 5 elements: [-0.4666735827922821, 0.1990303099155426, 1.237391710281372, 0.16488859057426453, 1.1230340003967285]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.8043087720870972, -0.6061059832572937, 1.3133677244186401, 0.18460963666439056, 1.0643194913864136]\n",
      "Last 5 elements: [-0.4138581454753876, 0.1765052080154419, 1.097350835800171, 0.14622744917869568, 0.9959354400634766]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.8043087720870972, -0.6061059832572937, 1.3133677244186401, 0.18460963666439056, 1.0643194913864136]\n",
      "Last 5 elements: [-0.4138581454753876, 0.1765052080154419, 1.097350835800171, 0.14622744917869568, 0.9959354400634766]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.7148561477661133, -0.3886595070362091, -0.31192970275878906, -4.692956924438477, 0.5259522199630737]\n",
      "Last 5 elements: [1.6104350090026855, -2.215435743331909, 6.93994140625, 1.072043776512146, 0.1498727798461914]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024264799430966377, -0.001975370105355978, -0.05464523658156395, -0.10546653717756271, -0.025451455265283585]\n",
      "Last 5 elements: [1.0250918865203857, 0.32901495695114136, -0.44326701760292053, -0.6650480031967163, -0.026188969612121582]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.12280596792697906, -0.05907371640205383, -0.04087430238723755, 0.007245287299156189, -0.1191057562828064]\n",
      "Last 5 elements: [-3.838738441467285, 0.4560672640800476, -0.9360843896865845, 2.5371487140655518, -0.6833420395851135]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.12280596792697906, -0.05907371640205383, -0.04087430238723755, 0.007245287299156189, -0.1191057562828064]\n",
      "Last 5 elements: [1.0819908380508423, -2.1098711490631104, -0.40020331740379333, 0.22773981094360352, 1.230151653289795]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.022771166637539864, -0.010953681543469429, -0.007579074241220951, 0.0013434496941044927, -0.02208505943417549]\n",
      "Last 5 elements: [1.0615544319152832, -2.0700201988220215, -0.39264434576034546, 0.2234383076429367, 1.2069168090820312]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.022771166637539864, -0.010953681543469429, -0.007579074241220951, 0.0013434496941044927, -0.02208505943417549]\n",
      "Last 5 elements: [1.0615544319152832, -2.0700201988220215, -0.39264434576034546, 0.2234383076429367, 1.2069168090820312]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.09575223922729492, 0.4103376567363739, 0.1714601367712021, -0.5715349316596985, -0.15598775446414948]\n",
      "Last 5 elements: [-0.04204612970352173, -0.18999755382537842, 0.23034995794296265, -2.0314667224884033, 1.6401118040084839]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.0025331638753414154, -0.08721683919429779, -0.030348125845193863, -0.0592808872461319, 0.012392573989927769]\n",
      "Last 5 elements: [-0.04204612970352173, -0.18999755382537842, 0.23034995794296265, -2.0314667224884033, 1.6401118040084839]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.0025331638753414154, -0.08721683919429779, -0.030348125845193863, -0.0592808872461319, 0.012392573989927769]\n",
      "Last 5 elements: [-0.03231487795710564, -0.0852816179394722, 0.19443264603614807, -0.10152091085910797, 0.07421114295721054]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.05746445059776306, 0.1529911458492279, 0.05519811064004898, 0.14917519688606262, -0.03769861161708832]\n",
      "Last 5 elements: [-0.3075403571128845, 0.6449480056762695, 0.020228058099746704, -1.0732907056808472, -0.11746060848236084]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.8054031133651733, -0.037533342838287354, -1.7809741497039795, -3.429738759994507, -0.8407768607139587]\n",
      "Last 5 elements: [1.9162112474441528, 0.7472521662712097, -0.848650336265564, -1.4694851636886597, -0.07123671472072601]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.024574263021349907, -0.0011452081380411983, -0.05434064939618111, -0.10464735329151154, -0.025653578341007233]\n",
      "Last 5 elements: [1.0029460191726685, 0.39111217856407166, -0.4441840350627899, -0.7691293358802795, -0.03728533536195755]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024574263021349907, -0.0011452081380411983, -0.05434064939618111, -0.10464735329151154, -0.025653578341007233]\n",
      "Last 5 elements: [1.0029460191726685, 0.39111217856407166, -0.4441840350627899, -0.7691293358802795, -0.03728533536195755]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-3.748570442199707, -2.4734761714935303, -2.2173116207122803, -1.2059500217437744, -0.8782737255096436]\n",
      "Last 5 elements: [-1.0914299488067627, -2.228764533996582, -0.3679535686969757, -1.4664502143859863, 0.06377065181732178]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-3.748570442199707, -2.4734761714935303, -2.2173116207122803, -1.2059500217437744, -0.8782737255096436]\n",
      "Last 5 elements: [-1.0914299488067627, -2.228764533996582, -0.3679535686969757, -1.4664502143859863, 0.06377065181732178]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.08625267446041107, -0.1922846883535385, -0.21775470674037933, -0.27787312865257263, -0.25780463218688965]\n",
      "Last 5 elements: [-0.27432993054389954, -0.21662922203540802, -0.15050610899925232, -0.27493414282798767, 0.03290165588259697]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024574263021349907, -0.0011452081380411983, -0.05434064939618111, -0.10464735329151154, -0.025653578341007233]\n",
      "Last 5 elements: [1.0029460191726685, 0.39111217856407166, -0.4441840350627899, -0.7691293358802795, -0.03728533536195755]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.4484469890594482, 0.2671661674976349, 0.49589964747428894, -1.3507589101791382, 0.9305224418640137]\n",
      "Last 5 elements: [0.0015763044357299805, -0.6325100660324097, -0.48864322900772095, 1.3195457458496094, -0.19750964641571045]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.1249324232339859, -0.05137196183204651, -0.10798448324203491, 0.3753395974636078, -0.23989298939704895]\n",
      "Last 5 elements: [-0.00043242747779004276, 0.13702017068862915, 0.07354379445314407, -0.3627881705760956, -0.006498394533991814]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.7335008382797241, 1.1195755004882812, -0.6603037118911743, -0.7251499891281128, 0.609591007232666]\n",
      "Last 5 elements: [2.793424606323242, -0.8172203898429871, 0.6771978139877319, -1.4114972352981567, 1.0749619007110596]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024574263021349907, -0.0011452081380411983, -0.05434064939618111, -0.10464735329151154, -0.025653578341007233]\n",
      "Last 5 elements: [1.0029460191726685, 0.39111217856407166, -0.4441840350627899, -0.7691293358802795, -0.03728533536195755]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.7335008382797241, 1.1195755004882812, -0.6603037118911743, -0.7251499891281128, 0.609591007232666]\n",
      "Last 5 elements: [2.793424606323242, -0.8172203898429871, 0.6771978139877319, -1.4114972352981567, 1.0749619007110596]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.8054, -0.0375, -1.7810,  ..., -0.5226, -2.6624, -1.7562],\n",
      "         [-3.0157,  1.5637,  1.6477,  ..., -0.1174, -3.8413,  0.3424],\n",
      "         [ 1.1968, -1.9428,  0.2562,  ...,  0.3627, -0.3270,  1.3833],\n",
      "         [ 1.9332, -0.6006, -0.8211,  ..., -1.7735,  1.4422,  0.3098],\n",
      "         [-0.2878, -0.6235,  2.3445,  ..., -1.0032, -1.1579, -0.0362],\n",
      "         [ 1.2538,  0.0272,  0.7022,  ..., -0.8487, -1.4695, -0.0712]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.795185923576355, -0.06473519653081894, -1.7907884120941162, -3.4562621116638184, -0.8340740203857422]\n",
      "Last 5 elements: [1.9708919525146484, 0.6325802803039551, -0.852246880531311, -1.278653860092163, -0.050352197140455246]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6749865412712097, 0.1615273803472519, -1.898376226425171, -3.5586705207824707, -0.7323914766311646]\n",
      "Last 5 elements: [2.4128825664520264, 0.6019502282142639, -0.728244423866272, -1.720449686050415, 0.1198917031288147]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6749865412712097, 0.1615273803472519, -1.898376226425171, -3.5586705207824707, -0.7323914766311646]\n",
      "Last 5 elements: [2.4128825664520264, 0.6019502282142639, -0.728244423866272, -1.720449686050415, 0.1198917031288147]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.020620420575141907, 0.004934560973197222, -0.05799421668052673, -0.10871517658233643, -0.02237410470843315]\n",
      "Last 5 elements: [1.2259224653244019, 0.30583515763282776, -0.3700019121170044, -0.8741154074668884, 0.06091383472084999]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020620420575141907, 0.004934560973197222, -0.05799421668052673, -0.10871517658233643, -0.02237410470843315]\n",
      "Last 5 elements: [1.2259224653244019, 0.30583515763282776, -0.3700019121170044, -0.8741154074668884, 0.06091383472084999]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [2.2484986782073975, -0.2573777735233307, 0.024948865175247192, -3.2394826412200928, -0.04329995810985565]\n",
      "Last 5 elements: [-0.36860907077789307, -0.04206925630569458, -0.17193642258644104, -0.04758723825216293, 1.6528284549713135]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [2.2484986782073975, -0.2573777735233307, 0.024948865175247192, -3.2394826412200928, -0.04329995810985565]\n",
      "Last 5 elements: [-0.36860907077789307, -0.04206925630569458, -0.17193642258644104, -0.04758723825216293, 1.6528284549713135]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.9210892915725708, -0.1054338663816452, 0.010220211930572987, -1.3270422220230103, -0.017737669870257378]\n",
      "Last 5 elements: [-0.31342270970344543, -0.03577084839344025, -0.1461949348449707, -0.04046270623803139, 1.4053748846054077]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.9210892915725708, -0.1054338663816452, 0.010220211930572987, -1.3270422220230103, -0.017737669870257378]\n",
      "Last 5 elements: [-0.31342270970344543, -0.03577084839344025, -0.1461949348449707, -0.04046270623803139, 1.4053748846054077]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.3352498412132263, -0.9633650183677673, -0.6318353414535522, 0.4337596893310547, -1.1795141696929932]\n",
      "Last 5 elements: [-0.03810332715511322, -2.0419347286224365, 1.030095100402832, -0.0042753666639328, 3.7751855850219727]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.020620420575141907, 0.004934560973197222, -0.05799421668052673, -0.10871517658233643, -0.02237410470843315]\n",
      "Last 5 elements: [1.2259224653244019, 0.30583515763282776, -0.3700019121170044, -0.8741154074668884, 0.06091383472084999]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.1512855887413025, -0.037300072610378265, 0.8388415575027466, 0.07555930316448212, -0.08451521396636963]\n",
      "Last 5 elements: [3.123730182647705, -4.128645896911621, -11.240263938903809, 0.1768292784690857, -0.7914317846298218]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.1512855887413025, -0.037300072610378265, 0.8388415575027466, 0.07555930316448212, -0.08451521396636963]\n",
      "Last 5 elements: [1.3969500064849854, -1.0849298238754272, 0.29922327399253845, 1.7689799070358276, -0.21146607398986816]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.032237984240055084, -0.007948405109345913, 0.17875173687934875, 0.016101201996207237, -0.018009647727012634]\n",
      "Last 5 elements: [1.498160719871521, -1.1635342836380005, 0.32090237736701965, 1.8971446752548218, -0.2267870455980301]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.032237984240055084, -0.007948405109345913, 0.17875173687934875, 0.016101201996207237, -0.018009647727012634]\n",
      "Last 5 elements: [1.498160719871521, -1.1635342836380005, 0.32090237736701965, 1.8971446752548218, -0.2267870455980301]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.04512353241443634, -0.3733067512512207, -0.002975206822156906, -0.3313036262989044, 0.8175761103630066]\n",
      "Last 5 elements: [-1.8334100246429443, 0.6696584820747375, -0.528110146522522, 1.20334792137146, -0.37288880348205566]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.082859568297863, 0.03203991800546646, -0.13023729622364044, 0.05386434867978096, -0.03428518772125244]\n",
      "Last 5 elements: [-1.8334100246429443, 0.6696584820747375, -0.528110146522522, 1.20334792137146, -0.37288880348205566]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.082859568297863, 0.03203991800546646, -0.13023729622364044, 0.05386434867978096, -0.03428518772125244]\n",
      "Last 5 elements: [0.07379823178052902, 0.10112237185239792, 0.07454200088977814, 0.10110411047935486, -0.10152972489595413]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.14886276423931122, 0.14869418740272522, 0.25259333848953247, 0.3535533547401428, -0.49984487891197205]\n",
      "Last 5 elements: [-0.4064965844154358, -0.1497785747051239, -0.11051014065742493, -1.4529188871383667, 0.851536214351654]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.7014543414115906, 0.18796522915363312, -1.8534650802612305, -3.4958086013793945, -0.8212639689445496]\n",
      "Last 5 elements: [2.3406074047088623, 0.5753195881843567, -0.7478931546211243, -1.9787789583206177, 0.2712950110435486]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.021419301629066467, 0.0057396236807107925, -0.05659659579396248, -0.10674647241830826, -0.025077754631638527]\n",
      "Last 5 elements: [1.1960322856903076, 0.2939838767051697, -0.38216763734817505, -1.0111408233642578, 0.13862966001033783]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021419301629066467, 0.0057396236807107925, -0.05659659579396248, -0.10674647241830826, -0.025077754631638527]\n",
      "Last 5 elements: [1.1960322856903076, 0.2939838767051697, -0.38216763734817505, -1.0111408233642578, 0.13862966001033783]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.9419265985488892, -4.120973587036133, -1.3415335416793823, -4.118556499481201, -1.83897066116333]\n",
      "Last 5 elements: [-0.9910745620727539, -1.024022102355957, 0.2712724506855011, -0.038432776927948, -0.8667224645614624]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.9419265985488892, -4.120973587036133, -1.3415335416793823, -4.118556499481201, -1.83897066116333]\n",
      "Last 5 elements: [-0.9910745620727539, -1.024022102355957, 0.2712724506855011, -0.038432776927948, -0.8667224645614624]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2435881793498993, -0.06581006199121475, -0.2780435383319855, -0.06592807918787003, -0.25225725769996643]\n",
      "Last 5 elements: [-0.26828375458717346, -0.2705923914909363, 0.15392141044139862, -0.018847165629267693, -0.25649502873420715]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021419301629066467, 0.0057396236807107925, -0.05659659579396248, -0.10674647241830826, -0.025077754631638527]\n",
      "Last 5 elements: [1.1960322856903076, 0.2939838767051697, -0.38216763734817505, -1.0111408233642578, 0.13862966001033783]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.1671130657196045, -0.4394874572753906, 0.5591552257537842, 1.3870066404342651, 0.06101495772600174]\n",
      "Last 5 elements: [0.3850063681602478, 0.39463675022125244, 1.2316975593566895, -0.20359103381633759, -0.7810474634170532]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.04070676863193512, 0.02892269752919674, -0.15546949207782745, -0.09144268184900284, -0.015391466207802296]\n",
      "Last 5 elements: [-0.10329095274209976, -0.10678569972515106, 0.1895846277475357, 0.003837113967165351, 0.20033478736877441]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.7396088242530823, 1.8174337148666382, 0.9035148620605469, -0.16447293758392334, 0.5095938444137573]\n",
      "Last 5 elements: [0.24482464790344238, -3.223541736602783, -0.5861000418663025, 0.32464122772216797, -2.015688896179199]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.021419301629066467, 0.0057396236807107925, -0.05659659579396248, -0.10674647241830826, -0.025077754631638527]\n",
      "Last 5 elements: [1.1960322856903076, 0.2939838767051697, -0.38216763734817505, -1.0111408233642578, 0.13862966001033783]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.7396088242530823, 1.8174337148666382, 0.9035148620605469, -0.16447293758392334, 0.5095938444137573]\n",
      "Last 5 elements: [0.24482464790344238, -3.223541736602783, -0.5861000418663025, 0.32464122772216797, -2.015688896179199]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.7015,  0.1880, -1.8535,  ..., -0.2641, -2.6795, -1.6993],\n",
      "         [-2.5067,  1.4031,  1.7749,  ..., -0.7774, -3.9575,  1.0450],\n",
      "         [ 0.9142, -1.9473, -0.1274,  ..., -0.2601, -0.5605,  1.4648],\n",
      "         [ 1.1391, -0.6055, -1.1263,  ..., -2.2824,  1.5967,  0.7138],\n",
      "         [-0.5678, -0.6738,  2.2231,  ..., -1.4545, -1.7308,  0.1178],\n",
      "         [ 1.0358,  0.1846,  0.3743,  ..., -0.7479, -1.9788,  0.2713]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6749865412712097, 0.1615273803472519, -1.898376226425171, -3.5586705207824707, -0.7323914766311646]\n",
      "Last 5 elements: [2.4128825664520264, 0.6019502282142639, -0.728244423866272, -1.720449686050415, 0.1198917031288147]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5699517726898193, 0.5111052393913269, -1.6928199529647827, -3.5250518321990967, -0.7306581139564514]\n",
      "Last 5 elements: [2.3841371536254883, 0.002173304557800293, -0.8521018624305725, -1.9210577011108398, -0.08709484338760376]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5699517726898193, 0.5111052393913269, -1.6928199529647827, -3.5250518321990967, -0.7306581139564514]\n",
      "Last 5 elements: [2.3841371536254883, 0.002173304557800293, -0.8521018624305725, -1.9210577011108398, -0.08709484338760376]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.01742957904934883, 0.015630004927515984, -0.051767781376838684, -0.10779888927936554, -0.022344106808304787]\n",
      "Last 5 elements: [1.1796051263809204, 0.0010752909583970904, -0.4215964376926422, -0.9504862427711487, -0.04309212043881416]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01742957904934883, 0.015630004927515984, -0.051767781376838684, -0.10779888927936554, -0.022344106808304787]\n",
      "Last 5 elements: [1.1796051263809204, 0.0010752909583970904, -0.4215964376926422, -0.9504862427711487, -0.04309212043881416]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-2.70526385307312, -2.898555040359497, 0.12160886824131012, 1.9487215280532837, 1.0061421394348145]\n",
      "Last 5 elements: [-0.4891592860221863, -0.3223910331726074, 0.42341700196266174, 0.22736170887947083, 0.34209588170051575]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-2.70526385307312, -2.898555040359497, 0.12160886824131012, 1.9487215280532837, 1.0061421394348145]\n",
      "Last 5 elements: [-0.4891592860221863, -0.3223910331726074, 0.42341700196266174, 0.22736170887947083, 0.34209588170051575]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.491841197013855, -1.598433256149292, 0.06706226617097855, 1.0746393203735352, 0.5548458099365234]\n",
      "Last 5 elements: [-0.38793620467185974, -0.2556777596473694, 0.33579814434051514, 0.1803131103515625, 0.27130502462387085]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.491841197013855, -1.598433256149292, 0.06706226617097855, 1.0746393203735352, 0.5548458099365234]\n",
      "Last 5 elements: [-0.38793620467185974, -0.2556777596473694, 0.33579814434051514, 0.1803131103515625, 0.27130502462387085]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [0.5256664156913757, -1.10921049118042, -0.48348039388656616, -1.3362468481063843, -1.0508310794830322]\n",
      "Last 5 elements: [0.5409048795700073, 0.12419819831848145, 0.3623354434967041, 1.4678186178207397, 0.07087671756744385]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.01742957904934883, 0.015630004927515984, -0.051767781376838684, -0.10779888927936554, -0.022344106808304787]\n",
      "Last 5 elements: [1.1796051263809204, 0.0010752909583970904, -0.4215964376926422, -0.9504862427711487, -0.04309212043881416]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.20748712122440338, -0.006383292376995087, -0.0680936798453331, 0.034178346395492554, 0.11471191793680191]\n",
      "Last 5 elements: [0.2195194959640503, -1.6997582912445068, -15.658557891845703, 0.3042418658733368, -2.3608176708221436]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.20748712122440338, -0.006383292376995087, -0.0680936798453331, 0.034178346395492554, 0.11471191793680191]\n",
      "Last 5 elements: [0.8428664207458496, -2.511836528778076, -0.42917314171791077, 0.03820514678955078, -0.5102916955947876]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.030679918825626373, -0.0009438604465685785, -0.010068617761135101, 0.005053753964602947, 0.01696178689599037]\n",
      "Last 5 elements: [0.6319523453712463, -1.883288860321045, -0.3217793107032776, 0.028644908219575882, -0.38259920477867126]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.030679918825626373, -0.0009438604465685785, -0.010068617761135101, 0.005053753964602947, 0.01696178689599037]\n",
      "Last 5 elements: [0.6319523453712463, -1.883288860321045, -0.3217793107032776, 0.028644908219575882, -0.38259920477867126]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.002251258585602045, -0.3130481243133545, 0.2384973019361496, -0.0300897266715765, 0.04790090024471283]\n",
      "Last 5 elements: [0.4112117886543274, -0.8544000387191772, 1.3989418745040894, 0.9624118804931641, 0.533234715461731]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.031848154962062836, 0.001835627481341362, -0.03440073877573013, -0.018889619037508965, 0.030841408297419548]\n",
      "Last 5 elements: [0.4112117886543274, -0.8544000387191772, 1.3989418745040894, 0.9624118804931641, 0.533234715461731]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.031848154962062836, 0.001835627481341362, -0.03440073877573013, -0.018889619037508965, 0.030841408297419548]\n",
      "Last 5 elements: [0.4078173339366913, -0.8619212508201599, 1.387603521347046, 0.9635013341903687, 0.5342985391616821]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.20887288451194763, 0.14556825160980225, 0.152400940656662, 0.10141066461801529, -0.15303948521614075]\n",
      "Last 5 elements: [0.6807543635368347, 0.759688675403595, -1.2195665836334229, -0.7215505242347717, 0.17300182580947876]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.6070894002914429, 0.5369873046875, -1.6657230854034424, -3.507020950317383, -0.7578685879707336]\n",
      "Last 5 elements: [2.5051753520965576, 0.13724608719348907, -1.0689409971237183, -2.049349546432495, -0.05633508786559105]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.018563121557235718, 0.01641959138214588, -0.050933223217725754, -0.10723503679037094, -0.023173533380031586]\n",
      "Last 5 elements: [1.2284902334213257, 0.06730286031961441, -0.5241882801055908, -1.0049618482589722, -0.02762565203011036]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018563121557235718, 0.01641959138214588, -0.050933223217725754, -0.10723503679037094, -0.023173533380031586]\n",
      "Last 5 elements: [1.2284902334213257, 0.06730286031961441, -0.5241882801055908, -1.0049618482589722, -0.02762565203011036]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.251154899597168, -0.007822364568710327, -1.3498890399932861, -1.4518293142318726, -0.6021685004234314]\n",
      "Last 5 elements: [-0.5088817477226257, 0.27891111373901367, -2.221104383468628, 1.8121472597122192, -0.6309696435928345]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.251154899597168, -0.007822364568710327, -1.3498890399932861, -1.4518293142318726, -0.6021685004234314]\n",
      "Last 5 elements: [-0.5088817477226257, 0.27891111373901367, -2.221104383468628, 1.8121472597122192, -0.6309696435928345]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2783823311328888, -0.0038958850782364607, -0.27792665362358093, -0.27544134855270386, -0.21307595074176788]\n",
      "Last 5 elements: [-0.1910625547170639, 0.15877830982208252, -0.2173822820186615, 1.5577601194381714, -0.21912989020347595]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018563121557235718, 0.01641959138214588, -0.050933223217725754, -0.10723503679037094, -0.023173533380031586]\n",
      "Last 5 elements: [1.2284902334213257, 0.06730286031961441, -0.5241882801055908, -1.0049618482589722, -0.02762565203011036]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.316232830286026, -1.0277925729751587, -0.025030270218849182, 0.5811952948570251, -0.24561268091201782]\n",
      "Last 5 elements: [-1.2751028537750244, -2.4578609466552734, 0.6690651774406433, 1.304486632347107, -2.411409854888916]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.08803363144397736, 0.0040041618049144745, 0.00695657916367054, -0.16008521616458893, 0.05233415588736534]\n",
      "Last 5 elements: [0.24362440407276154, -0.39025500416755676, -0.1454429179430008, 2.0320773124694824, 0.5284119844436646]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.1059560775756836, -0.4990229904651642, 1.8389323949813843, 0.7883110046386719, -0.9620295763015747]\n",
      "Last 5 elements: [0.7485175728797913, 1.3804521560668945, -0.2597361207008362, -2.0999484062194824, 0.19360679388046265]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.018563121557235718, 0.01641959138214588, -0.050933223217725754, -0.10723503679037094, -0.023173533380031586]\n",
      "Last 5 elements: [1.2284902334213257, 0.06730286031961441, -0.5241882801055908, -1.0049618482589722, -0.02762565203011036]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-1.1059560775756836, -0.4990229904651642, 1.8389323949813843, 0.7883110046386719, -0.9620295763015747]\n",
      "Last 5 elements: [0.7485175728797913, 1.3804521560668945, -0.2597361207008362, -2.0999484062194824, 0.19360679388046265]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.6071,  0.5370, -1.6657,  ..., -0.2050, -2.7100, -1.7498],\n",
      "         [-1.9641,  1.2451,  2.5051,  ..., -1.3628, -3.7053,  1.1283],\n",
      "         [ 1.1543, -1.9290, -0.2295,  ..., -0.7914, -0.4536,  1.4061],\n",
      "         [ 1.1467, -0.2578, -1.4182,  ..., -2.4811,  1.3148,  0.4590],\n",
      "         [-0.6288, -0.6263,  2.1944,  ..., -1.8642, -1.5028, -0.1784],\n",
      "         [ 0.8874, -0.4180,  0.8054,  ..., -1.0689, -2.0493, -0.0563]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.5699517726898193, 0.5111052393913269, -1.6928199529647827, -3.5250518321990967, -0.7306581139564514]\n",
      "Last 5 elements: [2.3841371536254883, 0.002173304557800293, -0.8521018624305725, -1.9210577011108398, -0.08709484338760376]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.8037285804748535, 0.44826093316078186, -1.3387606143951416, -3.366859197616577, -0.928917646408081]\n",
      "Last 5 elements: [2.6382617950439453, 0.3826907277107239, -1.1151220798492432, -2.4227206707000732, -0.02191176638007164]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.8037285804748535, 0.44826093316078186, -1.3387606143951416, -3.366859197616577, -0.928917646408081]\n",
      "Last 5 elements: [2.6382617950439453, 0.3826907277107239, -1.1151220798492432, -2.4227206707000732, -0.02191176638007164]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.024613618850708008, 0.013727674260735512, -0.04099859669804573, -0.10310768336057663, -0.02844744548201561]\n",
      "Last 5 elements: [1.248323917388916, 0.18107451498508453, -0.5276328325271606, -1.1463381052017212, -0.01036780420690775]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024613618850708008, 0.013727674260735512, -0.04099859669804573, -0.10310768336057663, -0.02844744548201561]\n",
      "Last 5 elements: [1.248323917388916, 0.18107451498508453, -0.5276328325271606, -1.1463381052017212, -0.01036780420690775]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.3746695518493652, -1.456228494644165, -1.8617570400238037, -1.766843318939209, -0.7659544348716736]\n",
      "Last 5 elements: [-0.14086949825286865, 1.513298749923706, 0.13527047634124756, -0.6228759288787842, -0.5959562659263611]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.3746695518493652, -1.456228494644165, -1.8617570400238037, -1.766843318939209, -0.7659544348716736]\n",
      "Last 5 elements: [-0.14086949825286865, 1.513298749923706, 0.13527047634124756, -0.6228759288787842, -0.5959562659263611]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.8659185171127319, -0.9172933101654053, -1.172739863395691, -1.1129528284072876, -0.48248258233070374]\n",
      "Last 5 elements: [-0.12875990569591522, 1.3832106590270996, 0.12364218384027481, -0.5693314671516418, -0.5447259545326233]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.8659185171127319, -0.9172933101654053, -1.172739863395691, -1.1129528284072876, -0.48248258233070374]\n",
      "Last 5 elements: [-0.12875990569591522, 1.3832106590270996, 0.12364218384027481, -0.5693314671516418, -0.5447259545326233]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.12851589918136597, -0.342830091714859, 1.0871834754943848, 0.44162845611572266, -0.6470128297805786]\n",
      "Last 5 elements: [-0.08175498247146606, 2.150362014770508, -0.3268170952796936, -3.017031669616699, -1.2659170627593994]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.024613618850708008, 0.013727674260735512, -0.04099859669804573, -0.10310768336057663, -0.02844744548201561]\n",
      "Last 5 elements: [1.248323917388916, 0.18107451498508453, -0.5276328325271606, -1.1463381052017212, -0.01036780420690775]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.028449445962905884, 0.08462914824485779, 0.11563725769519806, 0.06115814298391342, -0.014035597443580627]\n",
      "Last 5 elements: [-0.4042026996612549, 1.1625406742095947, -7.2177300453186035, 1.1988074779510498, -1.2342188358306885]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.028449445962905884, 0.08462914824485779, 0.11563725769519806, 0.06115814298391342, -0.014035597443580627]\n",
      "Last 5 elements: [-0.2734907269477844, 0.3037128448486328, 0.8022803068161011, 0.22689011693000793, -1.2932171821594238]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.006614363752305508, 0.019675884395837784, 0.026885125786066055, 0.014218984171748161, -0.0032632111106067896]\n",
      "Last 5 elements: [-0.27190735936164856, 0.3019545078277588, 0.7976354956626892, 0.22557653486728668, -1.2857301235198975]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.006614363752305508, 0.019675884395837784, 0.026885125786066055, 0.014218984171748161, -0.0032632111106067896]\n",
      "Last 5 elements: [-0.27190735936164856, 0.3019545078277588, 0.7976354956626892, 0.22557653486728668, -1.2857301235198975]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-0.45715293288230896, 0.3072131276130676, -0.24125640094280243, 0.47616004943847656, 0.3189729154109955]\n",
      "Last 5 elements: [-2.1995742321014404, 0.4946315288543701, 1.2296677827835083, 3.0190269947052, -0.5261043310165405]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.07075236737728119, 0.03420233726501465, 0.016202546656131744, -0.0427250862121582, 0.010883720591664314]\n",
      "Last 5 elements: [-2.1995742321014404, 0.4946315288543701, 1.2296677827835083, 3.0190269947052, -0.5261043310165405]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.07075236737728119, 0.03420233726501465, 0.016202546656131744, -0.0427250862121582, 0.010883720591664314]\n",
      "Last 5 elements: [-0.009067399427294731, 0.009706337936222553, 0.09215705096721649, -0.062456805258989334, 0.020720701664686203]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.4642789959907532, -0.0913715660572052, 0.322500616312027, -0.18332330882549286, -0.24246864020824432]\n",
      "Last 5 elements: [0.248468279838562, 0.21004906296730042, -0.2368798553943634, 0.1983017921447754, -0.23748713731765747]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.886277437210083, 0.432015061378479, -1.2814199924468994, -3.399454116821289, -0.9720286130905151]\n",
      "Last 5 elements: [2.6824395656585693, 0.42003747820854187, -1.157239317893982, -2.387462615966797, -0.06413702666759491]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.027138421311974525, 0.013228596188127995, -0.03923795372247696, -0.10409360378980637, -0.02976417914032936]\n",
      "Last 5 elements: [1.281332015991211, 0.20064105093479156, -0.5527833104133606, -1.140429139137268, -0.03063659928739071]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.027138421311974525, 0.013228596188127995, -0.03923795372247696, -0.10409360378980637, -0.02976417914032936]\n",
      "Last 5 elements: [1.281332015991211, 0.20064105093479156, -0.5527833104133606, -1.140429139137268, -0.03063659928739071]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-1.1177616119384766, -0.47248291969299316, 0.18075208365917206, 0.14911237359046936, -2.0216240882873535]\n",
      "Last 5 elements: [-1.8354430198669434, 1.7764471769332886, -1.786030650138855, -0.08577433228492737, -2.603018045425415]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-1.1177616119384766, -0.47248291969299316, 0.18075208365917206, 0.14911237359046936, -2.0216240882873535]\n",
      "Last 5 elements: [-1.8354430198669434, 1.7764471769332886, -1.786030650138855, -0.08577433228492737, -2.603018045425415]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.2754463255405426, -0.18144702911376953, 0.09852170199155807, 0.0801045298576355, -0.2364313006401062]\n",
      "Last 5 elements: [-0.2525406777858734, 1.519320011138916, -0.2564026713371277, -0.04104898124933243, -0.17946361005306244]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.027138421311974525, 0.013228596188127995, -0.03923795372247696, -0.10409360378980637, -0.02976417914032936]\n",
      "Last 5 elements: [1.281332015991211, 0.20064105093479156, -0.5527833104133606, -1.140429139137268, -0.03063659928739071]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [1.6863844394683838, -1.3910257816314697, 0.6431803703308105, 0.3312128484249115, -1.4896055459976196]\n",
      "Last 5 elements: [-0.41837233304977417, 0.6067673563957214, -1.224859356880188, 1.2937829494476318, 6.159722328186035]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.46450838446617126, 0.2523975074291229, 0.06336722522974014, 0.026531649753451347, 0.3521893620491028]\n",
      "Last 5 elements: [0.10565603524446487, 0.9218738079071045, 0.31405720114707947, -0.053108472377061844, -1.1054459810256958]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.32485783100128174, 2.1353983879089355, 6.626687049865723, -8.282712936401367, 1.14022958278656]\n",
      "Last 5 elements: [0.16162174940109253, 0.2744184732437134, 0.6005915403366089, 0.3591207265853882, 0.09708452224731445]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.027138421311974525, 0.013228596188127995, -0.03923795372247696, -0.10409360378980637, -0.02976417914032936]\n",
      "Last 5 elements: [1.281332015991211, 0.20064105093479156, -0.5527833104133606, -1.140429139137268, -0.03063659928739071]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.32485783100128174, 2.1353983879089355, 6.626687049865723, -8.282712936401367, 1.14022958278656]\n",
      "Last 5 elements: [0.16162174940109253, 0.2744184732437134, 0.6005915403366089, 0.3591207265853882, 0.09708452224731445]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-0.8863,  0.4320, -1.2814,  ..., -0.0439, -2.9751, -1.8366],\n",
      "         [-1.8468,  1.8066,  2.0181,  ..., -1.7311, -3.8651,  0.2077],\n",
      "         [ 0.4744, -2.1645,  0.2226,  ..., -1.1626, -0.8916,  1.2282],\n",
      "         [ 0.7505, -0.5844, -1.6399,  ..., -2.3974,  0.7634,  0.1926],\n",
      "         [-0.5751, -0.8300,  1.7361,  ..., -1.9191, -1.7067, -0.4637],\n",
      "         [ 0.8735, -0.5448,  1.2269,  ..., -1.1572, -2.3875, -0.0641]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.8037285804748535, 0.44826093316078186, -1.3387606143951416, -3.366859197616577, -0.928917646408081]\n",
      "Last 5 elements: [2.6382617950439453, 0.3826907277107239, -1.1151220798492432, -2.4227206707000732, -0.02191176638007164]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.9440371990203857, 0.8116892576217651, -0.10319387912750244, -4.872121810913086, -0.7692955732345581]\n",
      "Last 5 elements: [2.7111759185791016, 0.46882912516593933, -1.050454020500183, -2.323610782623291, -0.04687537997961044]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.9440371990203857, 0.8116892576217651, -0.10319387912750244, -4.872121810913086, -0.7692955732345581]\n",
      "Last 5 elements: [2.7111759185791016, 0.46882912516593933, -1.050454020500183, -2.323610782623291, -0.04687537997961044]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.031079282984137535, 0.026722166687250137, -0.003397315042093396, -0.16039839386940002, -0.025326495990157127]\n",
      "Last 5 elements: [1.2330061197280884, 0.2132171392440796, -0.47773224115371704, -1.0567467212677002, -0.021318288519978523]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.031079282984137535, 0.026722166687250137, -0.003397315042093396, -0.16039839386940002, -0.025326495990157127]\n",
      "Last 5 elements: [1.2330061197280884, 0.2132171392440796, -0.47773224115371704, -1.0567467212677002, -0.021318288519978523]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-1.8060489892959595, 3.08823823928833, -1.1846582889556885, 1.435452938079834, 2.49509334564209]\n",
      "Last 5 elements: [1.935082197189331, -0.5718031525611877, 0.3708445131778717, 0.4864785671234131, 0.3471302390098572]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-1.8060489892959595, 3.08823823928833, -1.1846582889556885, 1.435452938079834, 2.49509334564209]\n",
      "Last 5 elements: [1.935082197189331, -0.5718031525611877, 0.3708445131778717, 0.4864785671234131, 0.3471302390098572]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.9898028373718262, 1.6925050020217896, -0.6492504477500916, 0.7866981625556946, 1.367432713508606]\n",
      "Last 5 elements: [1.4175589084625244, -0.4188786745071411, 0.27166491746902466, 0.35637351870536804, 0.2542928457260132]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.9898028373718262, 1.6925050020217896, -0.6492504477500916, 0.7866981625556946, 1.367432713508606]\n",
      "Last 5 elements: [1.4175589084625244, -0.4188786745071411, 0.27166491746902466, 0.35637351870536804, 0.2542928457260132]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [1.0710690021514893, -1.1918681859970093, -0.7354282140731812, 0.5916151404380798, 5.121194362640381]\n",
      "Last 5 elements: [-0.15766754746437073, -0.8804872035980225, -7.578046798706055, -0.12784966826438904, 0.5144311189651489]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.031079282984137535, 0.026722166687250137, -0.003397315042093396, -0.16039839386940002, -0.025326495990157127]\n",
      "Last 5 elements: [1.2330061197280884, 0.2132171392440796, -0.47773224115371704, -1.0567467212677002, -0.021318288519978523]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.0664384737610817, 0.10822010040283203, 0.3186693489551544, -0.13168120384216309, 0.0619732141494751]\n",
      "Last 5 elements: [-1.0074512958526611, -2.488755702972412, -0.0279691219329834, -0.47143158316612244, 2.3995935916900635]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.0664384737610817, 0.10822010040283203, 0.3186693489551544, -0.13168120384216309, 0.0619732141494751]\n",
      "Last 5 elements: [-0.7004711627960205, 1.1048943996429443, 0.2704343795776367, 0.21569105982780457, 2.34714412689209]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.013421326875686646, 0.021861689165234566, 0.06437482684850693, -0.026601098477840424, 0.01251929346472025]\n",
      "Last 5 elements: [-0.5930717587471008, 0.9354869723320007, 0.22897015511989594, 0.1826203316450119, 1.9872692823410034]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.013421326875686646, 0.021861689165234566, 0.06437482684850693, -0.026601098477840424, 0.01251929346472025]\n",
      "Last 5 elements: [-0.5930717587471008, 0.9354869723320007, 0.22897015511989594, 0.1826203316450119, 1.9872692823410034]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [0.20786498486995697, -0.12533947825431824, -0.26753780245780945, -0.08898790925741196, 1.3499289751052856]\n",
      "Last 5 elements: [-2.1530261039733887, -1.2996262311935425, -0.39376401901245117, 0.8800156116485596, 0.08950205147266388]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.008262146264314651, -0.019526701420545578, -0.047363389283418655, -0.01323976181447506, 0.06947197765111923]\n",
      "Last 5 elements: [-2.1530261039733887, -1.2996262311935425, -0.39376401901245117, 0.8800156116485596, 0.08950205147266388]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.008262146264314651, -0.019526701420545578, -0.047363389283418655, -0.01323976181447506, 0.06947197765111923]\n",
      "Last 5 elements: [-0.3650168478488922, -0.13456052541732788, -0.18628573417663574, 0.2170744687318802, 0.023111136630177498]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.5054996609687805, -0.3761414885520935, 0.16233956813812256, 0.3161599040031433, -0.6924566030502319]\n",
      "Last 5 elements: [-0.028796643018722534, -0.08323126286268234, 0.45222342014312744, 0.1390370875597, 0.034419745206832886]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.0339151620864868, 0.7448112368583679, -0.07432987540960312, -4.815908432006836, -0.8924144506454468]\n",
      "Last 5 elements: [2.7060558795928955, 0.4540306031703949, -0.9700486063957214, -2.2988898754119873, -0.04075554385781288]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.03403526172041893, 0.02451830357313156, -0.002446851460263133, -0.1585339903831482, -0.029377225786447525]\n",
      "Last 5 elements: [1.2346080541610718, 0.20714643597602844, -0.4425739347934723, -1.0488430261611938, -0.01859426498413086]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.03403526172041893, 0.02451830357313156, -0.002446851460263133, -0.1585339903831482, -0.029377225786447525]\n",
      "Last 5 elements: [1.2346080541610718, 0.20714643597602844, -0.4425739347934723, -1.0488430261611938, -0.01859426498413086]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.5029827952384949, -1.0297613143920898, -1.3773614168167114, -3.309135675430298, -2.3936729431152344]\n",
      "Last 5 elements: [-3.791667938232422, -0.733512282371521, -0.3637533187866211, -1.1584317684173584, 0.3090330958366394]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [-0.5029827952384949, -1.0297613143920898, -1.3773614168167114, -3.309135675430298, -2.3936729431152344]\n",
      "Last 5 elements: [-3.791667938232422, -0.733512282371521, -0.3637533187866211, -1.1584317684173584, 0.3090330958366394]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.18954400718212128, -0.2709614932537079, -0.2774462103843689, -0.1166771724820137, -0.2002461552619934]\n",
      "Last 5 elements: [-0.08364537358283997, -0.2379693239927292, -0.14915752410888672, -0.2768099904060364, 0.17820370197296143]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.03403526172041893, 0.02451830357313156, -0.002446851460263133, -0.1585339903831482, -0.029377225786447525]\n",
      "Last 5 elements: [1.2346080541610718, 0.20714643597602844, -0.4425739347934723, -1.0488430261611938, -0.01859426498413086]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [-0.8299707174301147, 0.7030148506164551, -0.4517814517021179, -1.512305498123169, -1.4714140892028809]\n",
      "Last 5 elements: [3.9906091690063477, -0.11782780289649963, -2.412308692932129, -0.04709434509277344, -0.017098069190979004]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.15731596946716309, -0.19048994779586792, 0.12534505128860474, 0.17645153403282166, 0.2946450114250183]\n",
      "Last 5 elements: [-0.3337959945201874, 0.02803940325975418, 0.35981398820877075, 0.013036184944212437, -0.0030469391494989395]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-2.574563980102539, -7.741923809051514, 3.4557600021362305, 11.124720573425293, 7.9004435539245605]\n",
      "Last 5 elements: [-0.8966405391693115, -1.2647085189819336, 3.7394089698791504, -1.5964587926864624, 2.508659601211548]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.03403526172041893, 0.02451830357313156, -0.002446851460263133, -0.1585339903831482, -0.029377225786447525]\n",
      "Last 5 elements: [1.2346080541610718, 0.20714643597602844, -0.4425739347934723, -1.0488430261611938, -0.01859426498413086]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-2.574563980102539, -7.741923809051514, 3.4557600021362305, 11.124720573425293, 7.9004435539245605]\n",
      "Last 5 elements: [-0.8966405391693115, -1.2647085189819336, 3.7394089698791504, -1.5964587926864624, 2.508659601211548]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-1.0339,  0.7448, -0.0743,  ...,  2.2653, -3.0024, -1.1718],\n",
      "         [-0.4583,  2.0750,  1.1012,  ..., -4.0651, -3.2611, -0.0690],\n",
      "         [ 0.1697, -1.6001, -0.1663,  ..., -0.9816, -0.7405,  1.5767],\n",
      "         [ 1.1146, -0.7891, -2.0505,  ..., -2.4742,  0.5455,  0.3739],\n",
      "         [-1.6321, -0.9234,  1.8841,  ..., -1.4602, -1.3715, -0.5102],\n",
      "         [ 0.5473, -0.5297,  1.1968,  ..., -0.9700, -2.2989, -0.0408]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.9440371990203857, 0.8116892576217651, -0.10319387912750244, -4.872121810913086, -0.7692955732345581]\n",
      "Last 5 elements: [2.7111759185791016, 0.46882912516593933, -1.050454020500183, -2.323610782623291, -0.04687537997961044]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.4916731119155884, -0.6317041516304016, 0.540104866027832, -2.8379311561584473, 0.5122858285903931]\n",
      "Last 5 elements: [2.546633005142212, 0.2291651964187622, -0.30518102645874023, -2.582740545272827, 0.405284583568573]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.4916731119155884, -0.6317041516304016, 0.540104866027832, -2.8379311561584473, 0.5122858285903931]\n",
      "Last 5 elements: [2.546633005142212, 0.2291651964187622, -0.30518102645874023, -2.582740545272827, 0.405284583568573]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.11596754193305969, -0.04911074787378311, 0.041989516466856, -0.22063004970550537, 0.03982677683234215]\n",
      "Last 5 elements: [1.1458317041397095, 0.10311055928468704, -0.137313112616539, -1.1620779037475586, 0.1823536902666092]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.11596754193305969, -0.04911074787378311, 0.041989516466856, -0.22063004970550537, 0.03982677683234215]\n",
      "Last 5 elements: [1.1458317041397095, 0.10311055928468704, -0.137313112616539, -1.1620779037475586, 0.1823536902666092]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.7266485095024109, 1.5856378078460693, -1.7615042924880981, -1.6594263315200806, -1.6457421779632568]\n",
      "Last 5 elements: [1.0220990180969238, -1.4856882095336914, -1.5647035837173462, -0.43148598074913025, 1.2525551319122314]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.7266485095024109, 1.5856378078460693, -1.7615042924880981, -1.6594263315200806, -1.6457421779632568]\n",
      "Last 5 elements: [1.0220990180969238, -1.4856882095336914, -1.5647035837173462, -0.43148598074913025, 1.2525551319122314]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [-0.32673633098602295, 0.7129794955253601, -0.7920575737953186, -0.7461583614349365, -0.7400053143501282]\n",
      "Last 5 elements: [0.8151084184646606, -1.1848137378692627, -1.2478272914886475, -0.34410351514816284, 0.998893678188324]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [-0.32673633098602295, 0.7129794955253601, -0.7920575737953186, -0.7461583614349365, -0.7400053143501282]\n",
      "Last 5 elements: [0.8151084184646606, -1.1848137378692627, -1.2478272914886475, -0.34410351514816284, 0.998893678188324]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-2.8983964920043945, 1.7942396402359009, 0.4858945608139038, -1.6369174718856812, 1.1162590980529785]\n",
      "Last 5 elements: [1.9438949823379517, 0.49282538890838623, 0.05010354518890381, 1.7129935026168823, -1.680084466934204]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.11596754193305969, -0.04911074787378311, 0.041989516466856, -0.22063004970550537, 0.03982677683234215]\n",
      "Last 5 elements: [1.1458317041397095, 0.10311055928468704, -0.137313112616539, -1.1620779037475586, 0.1823536902666092]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [0.46738505363464355, 0.15352466702461243, 0.092526376247406, -0.14874139428138733, 0.02459058165550232]\n",
      "Last 5 elements: [2.43359375, 0.3070852756500244, -1.24680757522583, -16.694679260253906, 8.149800300598145]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.46738505363464355, 0.15352466702461243, 0.092526376247406, -0.14874139428138733, 0.02459058165550232]\n",
      "Last 5 elements: [-0.30811023712158203, -0.4470120668411255, -0.73347407579422, 0.46918249130249023, -2.698692560195923]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [0.07163151353597641, 0.023529216647148132, 0.014180608093738556, -0.022796131670475006, 0.003768756752833724]\n",
      "Last 5 elements: [-0.2630324959754944, -0.3816124498844147, -0.626163899898529, 0.40053924918174744, -2.303863286972046]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [0.07163151353597641, 0.023529216647148132, 0.014180608093738556, -0.022796131670475006, 0.003768756752833724]\n",
      "Last 5 elements: [-0.2630324959754944, -0.3816124498844147, -0.626163899898529, 0.40053924918174744, -2.303863286972046]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [-1.2176752090454102, -0.28761351108551025, -0.3253907263278961, 0.6230208873748779, 0.6210647821426392]\n",
      "Last 5 elements: [0.8075343370437622, -1.1867637634277344, -1.2657681703567505, -0.8435245752334595, -0.8287026882171631]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [-4.961222171783447, 0.537653923034668, -1.031206727027893, 1.301225185394287, -0.751135528087616]\n",
      "Last 5 elements: [0.8075343370437622, -1.1867637634277344, -1.2657681703567505, -0.8435245752334595, -0.8287026882171631]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-4.961222171783447, 0.537653923034668, -1.031206727027893, 1.301225185394287, -0.751135528087616]\n",
      "Last 5 elements: [0.5213637351989746, -0.6329801082611084, -0.9233332872390747, -0.45667505264282227, -0.26510000228881836]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-2.9147822856903076, -0.1792205274105072, -0.3300524353981018, 0.24460744857788086, -0.11952930688858032]\n",
      "Last 5 elements: [-0.26813000440597534, 0.7222217321395874, -0.821073055267334, 1.0560972690582275, -1.2941553592681885]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-2.0099220275878906, -0.6635695695877075, 0.48142147064208984, -2.7944397926330566, 0.49103349447250366]\n",
      "Last 5 elements: [2.498959541320801, 0.3575763702392578, -0.4511679410934448, -2.3949663639068604, 0.17518353462219238]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.15806631743907928, -0.05218510702252388, 0.037860434502363205, -0.2197631597518921, 0.038616351783275604]\n",
      "Last 5 elements: [1.0773341655731201, 0.15415585041046143, -0.19450441002845764, -1.0325013399124146, 0.07552391290664673]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.15806631743907928, -0.05218510702252388, 0.037860434502363205, -0.2197631597518921, 0.038616351783275604]\n",
      "Last 5 elements: [1.0773341655731201, 0.15415585041046143, -0.19450441002845764, -1.0325013399124146, 0.07552391290664673]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [2.9526774883270264, -0.263611376285553, 1.23536217212677, 0.06210808455944061, -1.8152968883514404]\n",
      "Last 5 elements: [-0.36856091022491455, -2.640493869781494, -0.14479148387908936, -2.497093677520752, -0.8837320804595947]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [2.9526774883270264, -0.263611376285553, 1.23536217212677, 0.06210808455944061, -1.8152968883514404]\n",
      "Last 5 elements: [-0.36856091022491455, -2.640493869781494, -0.14479148387908936, -2.497093677520752, -0.8837320804595947]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [2.80619478225708, -0.11453285068273544, 0.9571038484573364, 0.032018084079027176, -0.25414004921913147]\n",
      "Last 5 elements: [-0.1507004201412201, -0.17579704523086548, -0.06716373562812805, -0.1899343878030777, -0.25840768218040466]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.15806631743907928, -0.05218510702252388, 0.037860434502363205, -0.2197631597518921, 0.038616351783275604]\n",
      "Last 5 elements: [1.0773341655731201, 0.15415585041046143, -0.19450441002845764, -1.0325013399124146, 0.07552391290664673]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.8208281397819519, 8.754165649414062, 0.7796609401702881, 2.4418768882751465, -0.24563857913017273]\n",
      "Last 5 elements: [1.1994318962097168, -5.5000901222229, -0.18125326931476593, 0.9054430723190308, 0.3138623833656311]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [2.303403615951538, -1.0026395320892334, 0.7462164759635925, 0.07818421721458435, 0.062426600605249405]\n",
      "Last 5 elements: [-0.1807548850774765, 0.966899573802948, 0.012173647060990334, -0.171974778175354, -0.08110444992780685]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-7.599792003631592, -12.416755676269531, -2.36309814453125, 0.8428975939750671, -10.410055160522461]\n",
      "Last 5 elements: [-0.4490092992782593, 1.730233907699585, 2.445190191268921, 4.754446506500244, 3.987105369567871]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.15806631743907928, -0.05218510702252388, 0.037860434502363205, -0.2197631597518921, 0.038616351783275604]\n",
      "Last 5 elements: [1.0773341655731201, 0.15415585041046143, -0.19450441002845764, -1.0325013399124146, 0.07552391290664673]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-7.599792003631592, -12.416755676269531, -2.36309814453125, 0.8428975939750671, -10.410055160522461]\n",
      "Last 5 elements: [-0.4490092992782593, 1.730233907699585, 2.445190191268921, 4.754446506500244, 3.987105369567871]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-2.0099, -0.6636,  0.4814,  ..., -1.7072, -0.5294, -1.4701],\n",
      "         [ 0.3561,  3.1448,  1.3369,  ..., -3.0517, -5.3715,  1.7509],\n",
      "         [ 0.2845, -1.3850, -0.0170,  ..., -0.5046, -0.9964,  0.7877],\n",
      "         [ 1.1735, -0.1367, -2.0621,  ..., -1.8798,  1.0027,  0.2383],\n",
      "         [-1.3399, -1.1490,  1.7378,  ..., -1.1019, -1.4128,  0.0690],\n",
      "         [ 0.8192, -0.5376,  0.8432,  ..., -0.4512, -2.3950,  0.1752]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-1.4916731119155884, -0.6317041516304016, 0.540104866027832, -2.8379311561584473, 0.5122858285903931]\n",
      "Last 5 elements: [2.546633005142212, 0.2291651964187622, -0.30518102645874023, -2.582740545272827, 0.405284583568573]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-3.361166477203369, -2.8712711334228516, 0.06126219034194946, -2.6445724964141846, -1.3598761558532715]\n",
      "Last 5 elements: [2.419125556945801, 0.6652122735977173, -0.016412675380706787, -1.5496249198913574, 0.8840915560722351]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-3.361166477203369, -2.8712711334228516, 0.06126219034194946, -2.6445724964141846, -1.3598761558532715]\n",
      "Last 5 elements: [2.419125556945801, 0.6652122735977173, -0.016412675380706787, -1.5496249198913574, 0.8840915560722351]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.294199138879776, -0.25131914019584656, 0.0053622107952833176, -0.23147645592689514, -0.11902843415737152]\n",
      "Last 5 elements: [0.9262970685958862, 0.25471359491348267, -0.0062845079228281975, -0.5933603048324585, 0.3385237455368042]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.294199138879776, -0.25131914019584656, 0.0053622107952833176, -0.23147645592689514, -0.11902843415737152]\n",
      "Last 5 elements: [0.9262970685958862, 0.25471359491348267, -0.0062845079228281975, -0.5933603048324585, 0.3385237455368042]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.732616126537323, -0.3260105848312378, 1.617396593093872, 2.387237310409546, 0.5876775979995728]\n",
      "Last 5 elements: [-1.3109455108642578, -1.1010479927062988, 1.6719236373901367, -1.7608366012573242, -0.26146209239959717]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.732616126537323, -0.3260105848312378, 1.617396593093872, 2.387237310409546, 0.5876775979995728]\n",
      "Last 5 elements: [-1.3109455108642578, -1.1010479927062988, 1.6719236373901367, -1.7608366012573242, -0.26146209239959717]\n",
      "Input: shape=torch.Size([6, 768])\n",
      "First 5 elements: [0.28891485929489136, -0.1285656988620758, 0.6378373503684998, 0.9414321184158325, 0.23175683617591858]\n",
      "Last 5 elements: [-1.2614387273788452, -1.0594677925109863, 1.608784794807434, -1.6943399906158447, -0.25158819556236267]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 768])\n",
      "First 5 elements: [0.28891485929489136, -0.1285656988620758, 0.6378373503684998, 0.9414321184158325, 0.23175683617591858]\n",
      "Last 5 elements: [-1.2614387273788452, -1.0594677925109863, 1.608784794807434, -1.6943399906158447, -0.25158819556236267]\n",
      "Input: shape=torch.Size([6, 3840])\n",
      "First 5 elements: [-0.2074495255947113, 0.28441980481147766, 0.936236560344696, -0.9439380764961243, 1.0840108394622803]\n",
      "Last 5 elements: [0.09212896227836609, 0.9841794371604919, -1.3623381853103638, -2.2128849029541016, -2.5333995819091797]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.294199138879776, -0.25131914019584656, 0.0053622107952833176, -0.23147645592689514, -0.11902843415737152]\n",
      "Last 5 elements: [0.9262970685958862, 0.25471359491348267, -0.0062845079228281975, -0.5933603048324585, 0.3385237455368042]\n",
      "Input: shape=torch.Size([6, 288])\n",
      "First 5 elements: [-0.1947111338376999, 0.3838973641395569, 0.3485978841781616, -0.15258383750915527, 0.03883293271064758]\n",
      "Last 5 elements: [-0.4356677532196045, 3.181049108505249, -3.789499521255493, 10.80636978149414, -1.4242734909057617]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.1947111338376999, 0.3838973641395569, 0.3485978841781616, -0.15258383750915527, 0.03883293271064758]\n",
      "Last 5 elements: [-0.8408017754554749, -0.5057963132858276, 0.1401572823524475, 1.0132133960723877, 0.2867277264595032]\n",
      "Input: shape=torch.Size([6, 256])\n",
      "First 5 elements: [-0.022405581548810005, 0.0441754087805748, 0.04011346399784088, -0.017557956278324127, 0.004468539729714394]\n",
      "Last 5 elements: [-0.9283337593078613, -0.5584524273872375, 0.15474840998649597, 1.1186943054199219, 0.31657761335372925]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 256])\n",
      "First 5 elements: [-0.022405581548810005, 0.0441754087805748, 0.04011346399784088, -0.017557956278324127, 0.004468539729714394]\n",
      "Last 5 elements: [-0.9283337593078613, -0.5584524273872375, 0.15474840998649597, 1.1186943054199219, 0.31657761335372925]\n",
      "Input: shape=torch.Size([6, 5120])\n",
      "First 5 elements: [1.208732008934021, 0.37505602836608887, -0.6619798541069031, 0.09611889719963074, -0.3255053162574768]\n",
      "Last 5 elements: [0.515390157699585, -1.166919231414795, -1.457319736480713, -0.31086963415145874, -0.997943639755249]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMLongRoPE'>\n",
      "Input: shape=torch.Size([1, 40, 6, 64])\n",
      "First 5 elements: [0.17630045115947723, 0.07737302780151367, -0.13570554554462433, 0.1404799073934555, 0.07313026487827301]\n",
      "Last 5 elements: [0.515390157699585, -1.166919231414795, -1.457319736480713, -0.31086963415145874, -0.997943639755249]\n",
      "Input: shape=torch.Size([6, 32])\n",
      "First 5 elements: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Last 5 elements: [0.9999998211860657, 0.9999999403953552, 1.0, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.17630045115947723, 0.07737302780151367, -0.13570554554462433, 0.1404799073934555, 0.07313026487827301]\n",
      "Last 5 elements: [0.2573765814304352, -0.11237365752458572, 0.00047463056398555636, -0.23407147824764252, 0.022517841309309006]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.027003392577171326, 0.28310903906822205, -0.6428793668746948, -0.27797645330429077, 0.29920151829719543]\n",
      "Last 5 elements: [-0.11405017971992493, 0.8643263578414917, 1.7908339500427246, -2.1283950805664062, 1.3525128364562988]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-3.3659677505493164, -2.820934295654297, -0.05304187536239624, -2.6939966678619385, -1.306678056716919]\n",
      "Last 5 elements: [2.3988473415374756, 0.8188896179199219, 0.30199792981147766, -1.9280539751052856, 1.1245685815811157]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [-0.2950361371040344, -0.24726247787475586, -0.004649262875318527, -0.2361360639333725, -0.11453384906053543]\n",
      "Last 5 elements: [0.908418595790863, 0.31010499596595764, 0.11436347663402557, -0.7301340103149414, 0.4258624315261841]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2950361371040344, -0.24726247787475586, -0.004649262875318527, -0.2361360639333725, -0.11453384906053543]\n",
      "Last 5 elements: [0.908418595790863, 0.31010499596595764, 0.11436347663402557, -0.7301340103149414, 0.4258624315261841]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [1.3218822479248047, -1.4006738662719727, 0.9785912036895752, -1.6046795845031738, 0.4956584870815277]\n",
      "Last 5 elements: [-4.549498558044434, 0.13143283128738403, -2.873718023300171, 1.254797101020813, -2.4746668338775635]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.activation.SiLU'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [1.3218822479248047, -1.4006738662719727, 0.9785912036895752, -1.6046795845031738, 0.4956584870815277]\n",
      "Last 5 elements: [-4.549498558044434, 0.13143283128738403, -2.873718023300171, 1.254797101020813, -2.4746668338775635]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [1.04361891746521, -0.2769261300563812, 0.7112680673599243, -0.26850876212120056, 0.3080212473869324]\n",
      "Last 5 elements: [-0.04759638383984566, 0.07002885639667511, -0.15365245938301086, 0.9763941764831543, -0.19216610491275787]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2950361371040344, -0.24726247787475586, -0.004649262875318527, -0.2361360639333725, -0.11453384906053543]\n",
      "Last 5 elements: [0.908418595790863, 0.31010499596595764, 0.11436347663402557, -0.7301340103149414, 0.4258624315261841]\n",
      "Input: shape=torch.Size([6, 6400])\n",
      "First 5 elements: [0.39380815625190735, 0.6741451621055603, 11.414555549621582, -2.0121190547943115, 2.273162841796875]\n",
      "Last 5 elements: [-0.9128866791725159, -0.22957399487495422, 6.81213903427124, -17.82054901123047, 6.9929609298706055]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 6400])\n",
      "First 5 elements: [0.41098564863204956, -0.1866884082555771, 8.11880874633789, 0.5402715802192688, 0.7001824378967285]\n",
      "Last 5 elements: [0.04345010593533516, -0.01607680507004261, -1.0467019081115723, -17.399879455566406, -1.3438100814819336]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [21.315452575683594, 3.3766462802886963, -22.282426834106445, 25.67865753173828, -12.37171459197998]\n",
      "Last 5 elements: [0.7443790435791016, 0.6592469215393066, 1.185687780380249, -4.7301177978515625, -0.77808678150177]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMMLP'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-0.2950361371040344, -0.24726247787475586, -0.004649262875318527, -0.2361360639333725, -0.11453384906053543]\n",
      "Last 5 elements: [0.908418595790863, 0.31010499596595764, 0.11436347663402557, -0.7301340103149414, 0.4258624315261841]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [21.315452575683594, 3.3766462802886963, -22.282426834106445, 25.67865753173828, -12.37171459197998]\n",
      "Last 5 elements: [0.7443790435791016, 0.6592469215393066, 1.185687780380249, -4.7301177978515625, -0.77808678150177]\n",
      "--------------------------------------------------\n",
      "attn tensor([[[-3.3660, -2.8209, -0.0530,  ..., -0.5226, -0.3401, -3.8622],\n",
      "         [-0.0799,  2.9188, -0.5289,  ..., -2.9683, -6.0982,  2.2087],\n",
      "         [-0.0626, -1.6047, -0.3198,  ...,  0.4525, -0.8043,  1.2983],\n",
      "         [ 0.9720, -0.5201, -2.0698,  ..., -0.9156,  0.3653,  0.4368],\n",
      "         [-1.1102, -0.4856,  2.1881,  ..., -0.0176, -0.8719,  1.2458],\n",
      "         [ 0.9719, -0.3575,  0.7952,  ...,  0.3020, -1.9281,  1.1246]]])\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMDecoderLayer'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [-3.361166477203369, -2.8712711334228516, 0.06126219034194946, -2.6445724964141846, -1.3598761558532715]\n",
      "Last 5 elements: [2.419125556945801, 0.6652122735977173, -0.016412675380706787, -1.5496249198913574, 0.8840915560722351]\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.4239234924316406, -2.2205660343170166, -4.014861106872559, 1.871673345565796, -3.506371021270752]\n",
      "Last 5 elements: [2.531198024749756, 0.9361038208007812, 0.5128134489059448, -2.7690696716308594, 0.9862245917320251]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPMRMSNorm'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.4239234924316406, -2.2205660343170166, -4.014861106872559, 1.871673345565796, -3.506371021270752]\n",
      "Last 5 elements: [2.531198024749756, 0.9361038208007812, 0.5128134489059448, -2.7690696716308594, 0.9862245917320251]\n",
      "Input: shape=torch.Size([6, 2560])\n",
      "First 5 elements: [0.612274706363678, -3.071485757827759, -5.664867401123047, 2.828032970428467, -4.986356735229492]\n",
      "Last 5 elements: [7.569416046142578, 2.8551340103149414, 1.5335417985916138, -8.247767448425293, 2.961003303527832]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPM3Model'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "Layer: <class 'torch.nn.modules.linear.Linear'>\n",
      "Input: shape=torch.Size([1, 6, 2560])\n",
      "First 5 elements: [0.0612274706363678, -0.3071485757827759, -0.5664867162704468, 0.2828032970428467, -0.4986356794834137]\n",
      "Last 5 elements: [0.7569416165351868, 0.28551340103149414, 0.15335418283939362, -0.8247767686843872, 0.29610031843185425]\n",
      "Input: shape=torch.Size([6, 73448])\n",
      "First 5 elements: [-7.202436447143555, -1.7661309242248535, 1.573729395866394, -5.375678062438965, -5.375767707824707]\n",
      "Last 5 elements: [-3.5195670127868652, -3.6190524101257324, -4.52184534072876, -4.521968364715576, -4.521862983703613]\n",
      "--------------------------------------------------\n",
      "Layer: <class 'transformers_modules.cpm.modeling_minicpm.MiniCPM3ForCausalLM'>\n",
      "error\n",
      "error\n",
      "--------------------------------------------------\n",
      "tensor([[    1, 11152,  6138,  1348,  1817, 59342,  1377]])\n",
      "Once upon a time, in\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "def print_tensor_elements(tensor, label=\"Tensor\", num_elements=5):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        elements = tensor.flatten()\n",
    "        print(f\"{label}: shape={tensor.shape}\")\n",
    "        print(\"First 5 elements:\", elements[:num_elements].tolist())\n",
    "        print(\n",
    "            \"Last 5 elements:\",\n",
    "            (\n",
    "                elements[-num_elements:].tolist()\n",
    "                if len(elements) >= num_elements\n",
    "                else elements.tolist()\n",
    "            ),\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{label}: Not a Tensor\")\n",
    "\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Layer: {module.__class__}\")\n",
    "\n",
    "    # 处理输入张量\n",
    "    if input and isinstance(input[0], torch.Tensor):\n",
    "        print_tensor_elements(input[0], label=\"Input\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    # 处理输出张量\n",
    "    if input and isinstance(output[0], torch.Tensor):\n",
    "        print_tensor_elements(output[0], label=\"Input\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# 选择设备\n",
    "device_id = 0  # ← 修改这里选择GPU编号\n",
    "device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 加载预训练模型和分词器\n",
    "model_path = \"/home/ztf/cpm\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "model.eval()\n",
    "# 遍历所有子模块并注册钩子\n",
    "hooks = []\n",
    "for name, module in model.named_modules():\n",
    "    if not isinstance(module, (torch.nn.ModuleList, torch.nn.Sequential)):\n",
    "        hooks.append(module.register_forward_hook(hook_fn))\n",
    "        # if name == 'transformer.ln_f':\n",
    "        #     hooks.append(module.register_forward_hook(hook_fn))\n",
    "\n",
    "# 手动构建张量并进行推理\n",
    "inputs = \"Once upon a time,\"\n",
    "generated_tokens = torch.tensor([[59422]])\n",
    "# 将文本转换为模型输入\n",
    "input_ids = tokenizer(inputs, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# 使用模型进行推理\n",
    "with torch.no_grad():  # 确保推理过程中不计算梯度以节省内存\n",
    "    outputs = model.generate(input_ids , max_length=7, do_sample=True)\n",
    "print(outputs)\n",
    "for i in range(outputs.shape[0]):  # 遍历所有生成的序列\n",
    "    print(tokenizer.decode(outputs[i], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rope_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32768, 16])\n",
      "torch.Size([16])\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.1001e-01,  4.7962e-01,  2.4841e-01,  ...,  3.3592e-05,\n",
      "          1.8739e-05,  1.0497e-05],\n",
      "        [ 9.5000e-01,  8.4171e-01,  4.8124e-01,  ...,  6.7184e-05,\n",
      "          3.7477e-05,  2.0994e-05],\n",
      "        ...,\n",
      "        [-6.4275e-01, -2.5325e-03,  4.6815e-01,  ...,  8.9150e-01,\n",
      "          5.7612e-01,  3.3719e-01],\n",
      "        [-9.9751e-01, -4.8165e-01,  6.7293e-01,  ...,  8.9151e-01,\n",
      "          5.7613e-01,  3.3720e-01],\n",
      "        [-5.2681e-01, -8.4389e-01,  8.3556e-01,  ...,  8.9153e-01,\n",
      "          5.7615e-01,  3.3721e-01]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1051865/2738580333.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ext_factors = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "max_seq_len_cached = 1\n",
    "dim = 32  #  qk_rope_head_dim\n",
    "rope_theta = 10000.0  # rope_theta\n",
    "max_position_embeddings = 32768\n",
    "\n",
    "long_factor = torch.tensor(\n",
    "    [\n",
    "        1.0591234137867171,\n",
    "        1.1241891283591912,\n",
    "        1.2596935748670968,\n",
    "        1.5380380402321725,\n",
    "        2.093982484148734,\n",
    "        3.1446935121267696,\n",
    "        4.937952647693647,\n",
    "        7.524541999994549,\n",
    "        10.475458000005451,\n",
    "        13.062047352306353,\n",
    "        14.85530648787323,\n",
    "        15.906017515851266,\n",
    "        16.461961959767827,\n",
    "        16.740306425132907,\n",
    "        16.87581087164081,\n",
    "        16.940876586213285,\n",
    "    ]\n",
    ")\n",
    "original_max_position_embeddings = 32768\n",
    "short_factor = torch.tensor(\n",
    "    [\n",
    "        1.0591234137867171,\n",
    "        1.1241891283591912,\n",
    "        1.2596935748670968,\n",
    "        1.5380380402321725,\n",
    "        2.093982484148734,\n",
    "        3.1446935121267696,\n",
    "        4.937952647693647,\n",
    "        7.524541999994549,\n",
    "        10.475458000005451,\n",
    "        13.062047352306353,\n",
    "        14.85530648787323,\n",
    "        15.906017515851266,\n",
    "        16.461961959767827,\n",
    "        16.740306425132907,\n",
    "        16.87581087164081,\n",
    "        16.940876586213285,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class MiniCPMRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (\n",
    "            self.base ** (torch.arange(0, self.dim, 2).float().to(device) / self.dim)\n",
    "        )\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        # Build here to make `torch.jit.trace` work.\n",
    "        self._set_cos_sin_cache(\n",
    "            # seq_len=max_position_embeddings, device=self.inv_freq.device, dtype=torch.get_default_dtype()\n",
    "            seq_len=max_position_embeddings,\n",
    "            device=self.inv_freq.device,\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        #   let t=(theta as f32).powf(k as f32 / dh as f32).recip()*factor.recip()*self.val() as f32;\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        t = torch.arange(\n",
    "            self.max_seq_len_cached, device=device, dtype=self.inv_freq.dtype\n",
    "        )\n",
    "        freqs = torch.outer(t, self.inv_freq)\n",
    "        # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos().to(dtype), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin().to(dtype), persistent=False)\n",
    "\n",
    "    def forward(self, x, seq_len=None):\n",
    "        # x: [bs, num_attention_heads, seq_len, head_size]\n",
    "        if seq_len > self.max_seq_len_cached:\n",
    "            self._set_cos_sin_cache(seq_len=seq_len, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        return (\n",
    "            # TODO 一次计算完之后按位置取\n",
    "            self.cos_cached[:seq_len].to(dtype=x.dtype),\n",
    "            self.sin_cached[:seq_len].to(dtype=x.dtype),\n",
    "        )\n",
    "\n",
    "\n",
    "class MiniCPMLongRoPE(MiniCPMRotaryEmbedding):\n",
    "    \"\"\"MiniCPMRotaryEmbedding extended with Dynamic NTK scaling. Credits to the Reddit users /u/bloc97 and /u/emozilla\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        max_position_embeddings=2048,\n",
    "        base=10000,\n",
    "        device=None,\n",
    "        short_factor=None,\n",
    "        long_factor=None,\n",
    "        original_max_position_embeddings=None,\n",
    "    ):\n",
    "        self.short_factor = short_factor\n",
    "        self.long_factor = long_factor\n",
    "        self.original_max_position_embeddings = original_max_position_embeddings\n",
    "        scale = max_position_embeddings / self.original_max_position_embeddings\n",
    "        self.scaling_factor = math.sqrt(\n",
    "            1 + math.log(scale) / math.log(self.original_max_position_embeddings)\n",
    "        )\n",
    "        super().__init__(dim, max_position_embeddings, base, device)\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        t = torch.arange(\n",
    "            self.max_seq_len_cached, device=device, dtype=self.inv_freq.dtype\n",
    "        )\n",
    "        if seq_len > self.original_max_position_embeddings:\n",
    "            ext_factors = torch.tensor(\n",
    "                self.long_factor, dtype=torch.float32, device=device\n",
    "            )\n",
    "        else:\n",
    "            ext_factors = torch.tensor(\n",
    "                self.short_factor, dtype=torch.float32, device=device\n",
    "            )\n",
    "        print(torch.outer(t, 1.0 / ext_factors).to(device=device).shape)\n",
    "        print(self.inv_freq.shape)\n",
    "        freqs = torch.mul(\n",
    "            torch.outer(t, 1.0 / ext_factors).to(device=device),\n",
    "            self.inv_freq.to(device=device).to(dtype),\n",
    "        ) \n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        print(emb.sin().to(dtype) * self.scaling_factor)\n",
    "        self.register_buffer(\n",
    "            \"cos_cached\", emb.cos().to(dtype) * self.scaling_factor, persistent=False\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sin_cached\", emb.sin().to(dtype) * self.scaling_factor, persistent=False\n",
    "        )\n",
    "\n",
    "\n",
    "model=MiniCPMLongRoPE(\n",
    "    dim,\n",
    "    max_position_embeddings=max_position_embeddings,\n",
    "    short_factor=short_factor,\n",
    "    long_factor=long_factor,\n",
    "    base=rope_theta,\n",
    "    original_max_position_embeddings=max_position_embeddings,\n",
    ")\n",
    "model.forward(long_factor,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出模型指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n",
      "<class 'transformers_modules.cpm.modeling_minicpm.MiniCPMSdpaAttention'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "def print_tensor_elements(tensor, label=\"Tensor\", num_elements=5):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        elements = tensor.flatten()\n",
    "        print(f\"{label}: shape={tensor.shape}\")\n",
    "        print(\"First 5 elements:\", elements[:num_elements].tolist())\n",
    "        print(\n",
    "            \"Last 5 elements:\",\n",
    "            (\n",
    "                elements[-num_elements:].tolist()\n",
    "                if len(elements) >= num_elements\n",
    "                else elements.tolist()\n",
    "            ),\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{label}: Not a Tensor\")\n",
    "\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    # 处理输入张量\n",
    "    if input and isinstance(input[0], torch.Tensor):\n",
    "        print_tensor_elements(input[0], label=\"Input\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    # 处理输出张量\n",
    "    if input and isinstance(output[0], torch.Tensor):\n",
    "        print_tensor_elements(output[0], label=\"Input\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# 选择设备\n",
    "device_id = 0  # ← 修改这里选择GPU编号\n",
    "device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 加载预训练模型和分词器\n",
    "model_path = \"/home/ztf/cpm\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "model.eval()\n",
    "# 遍历所有子模块并注册钩子\n",
    "hooks = []\n",
    "for name, module in model.named_modules():\n",
    "    layer_name=module.__class__.__name__\n",
    "    match layer_name:\n",
    "        case \"MiniCPMLongRoPE\":\n",
    "            hooks.append(module.register_forward_hook(hook_fn))\n",
    "        case \"MiniCPMSdpaAttention\":\n",
    "            print(module.__class__)\n",
    "\n",
    "# # 手动构建张量并进行推理\n",
    "# inputs = \"Once upon a time,\"\n",
    "# generated_tokens = torch.tensor([[59422]])\n",
    "# # 将文本转换为模型输入\n",
    "# input_ids = tokenizer(inputs, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# # 使用模型进行推理\n",
    "# with torch.no_grad():  # 确保推理过程中不计算梯度以节省内存\n",
    "#     outputs = model.generate(generated_tokens, max_length=2, do_sample=True)\n",
    "# print(outputs)\n",
    "# for i in range(outputs.shape[0]):  # 遍历所有生成的序列\n",
    "#     print(tokenizer.decode(outputs[i], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
